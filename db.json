{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/livemylife/source/css/archive.styl","path":"css/archive.styl","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/beantech.css","path":"css/beantech.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/beantech.min.css","path":"css/beantech.min.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/bootstrap.css","path":"css/bootstrap.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/catalog.styl","path":"css/catalog.styl","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/hux-blog.min.css","path":"css/hux-blog.min.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/rocket.styl","path":"css/rocket.styl","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/livemylife.css","path":"css/livemylife.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/scroll.css","path":"css/scroll.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/search.css","path":"css/search.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/signature.styl","path":"css/signature.styl","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/themecolor.css","path":"css/themecolor.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/top.css","path":"css/top.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/viewer.min.css","path":"css/viewer.min.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/wave.css","path":"css/wave.css","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/widget.styl","path":"css/widget.styl","modified":0,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":0,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":0,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":0,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":0,"renderable":1},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/bootstrap.js","path":"js/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/hux-blog.js","path":"js/hux-blog.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/catalog.js","path":"js/catalog.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/hux-blog.min.js","path":"js/hux-blog.min.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.js","path":"js/jquery.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.nav.js","path":"js/jquery.nav.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/line.js","path":"js/line.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/mouseclick.js","path":"js/mouseclick.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/ribbonDynamic.js","path":"js/ribbonDynamic.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/scroll.js","path":"js/scroll.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/langselect.js","path":"js/langselect.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/ziploader.js","path":"js/ziploader.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up.png","path":"css/images/beside_up.png","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up2.png","path":"css/images/beside_up2.png","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/comment/gitalk.js","path":"js/comment/gitalk.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up_white.png","path":"css/images/beside_up_white.png","modified":0,"renderable":1},{"_id":"themes/livemylife/source/css/images/beside_up_white2.png","path":"css/images/beside_up_white2.png","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/comment/gitalk_.js","path":"js/comment/gitalk_.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/viewer/pic-viewer.js","path":"js/viewer/pic-viewer.js","modified":0,"renderable":1},{"_id":"themes/livemylife/source/js/viewer/viewer.min.js","path":"js/viewer/viewer.min.js","modified":0,"renderable":1},{"_id":"source/LICENSE","path":"LICENSE","modified":0,"renderable":0},{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/about/vx.jpg","path":"about/vx.jpg","modified":0,"renderable":0},{"_id":"source/img/avatar/Bin.jpg","path":"img/avatar/Bin.jpg","modified":0,"renderable":0},{"_id":"source/img/avatar/fatpeople.jpg","path":"img/avatar/fatpeople.jpg","modified":0,"renderable":0},{"_id":"source/img/avatar/smile.jpg","path":"img/avatar/smile.jpg","modified":0,"renderable":0},{"_id":"source/img/avatar/vx.jpg","path":"img/avatar/vx.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/1.jpg","path":"img/header_img/1.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/2.jpg","path":"img/header_img/2.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/404_bg.jpg","path":"img/header_img/404_bg.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/4.jpg","path":"img/header_img/4.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/3.jpg","path":"img/header_img/3.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/5.jpg","path":"img/header_img/5.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/6.jpg","path":"img/header_img/6.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/8.jpeg","path":"img/header_img/8.jpeg","modified":0,"renderable":0},{"_id":"source/img/header_img/8.jpg","path":"img/header_img/8.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/archive_bg2.jpg","path":"img/header_img/archive_bg2.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/categories_bg.jpg","path":"img/header_img/categories_bg.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/lml_bg.jpg","path":"img/header_img/lml_bg.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/me.jpg","path":"img/header_img/me.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/newhome_bg.jpg","path":"img/header_img/newhome_bg.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/tag_bg.jpg","path":"img/header_img/tag_bg.jpg","modified":0,"renderable":0},{"_id":"source/img/header_img/tiger.png","path":"img/header_img/tiger.png","modified":0,"renderable":0},{"_id":"source/img/header_img/vehicle.jpg","path":"img/header_img/vehicle.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"source/404.md","hash":"ec2d37d705a85fa3eaf6f32af4c8962f5c7ef230","modified":1642064468723},{"_id":"source/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1642064468723},{"_id":"source/CNAME","hash":"8929eb36e7c7960e964c2fea3cd9b4253ed169df","modified":1642064468723},{"_id":"source/_readme.txt","hash":"bddab7042d69720ee508338cfcde9d2b1ae901bf","modified":1642064480840},{"_id":"source/_posts/2020全国大学生数学建模比赛B题.md","hash":"4b1174044c491580d5e871fa7154b91240f23ccb","modified":1642064468743},{"_id":"source/_posts/2020年数学建模美赛A题.md","hash":"fe1ecbdd1db9b98e4cdff012222477499dd11e94","modified":1642064470318},{"_id":"source/_posts/20岁那年的一些故事.md","hash":"5ea559783ee9742a1fef6e1b7ae979c15f0476c0","modified":1642064473267},{"_id":"source/_posts/Hexo-Theme-LiveMyLife.md","hash":"fb8b1d5489fd717201bb8302d8839121982fb8e3","modified":1642064473267},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页.md","hash":"9fe4ff274927e807e64f8be688c2c4dbe51c2d6f","modified":1642064475021},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用.md","hash":"8a61eaccaa3ef51c41876d7859cb1e96340b2646","modified":1642064476414},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台.md","hash":"a32b006b23b220259d6ec1b1d518a3f86b8150f4","modified":1642064477853},{"_id":"source/_posts/子空间学习(1)-PCA.md","hash":"b96a41c9c0c304715991724bcf1e3871ce93be5b","modified":1642078539323},{"_id":"source/_posts/子空间学习(10)-t-SNE.md","hash":"97b607adb2a350c6feda1a9379277c7df1f4552a","modified":1642078597487},{"_id":"source/_posts/子空间学习(2)-LLE.md","hash":"a9bd57e5c9dab07e4465b2a3bd1941b8fbc2c387","modified":1642078545290},{"_id":"source/_posts/子空间学习(3)-LE.md","hash":"0b8e9686774df32ee3c45691fc57ee629bfea44a","modified":1642138164372},{"_id":"source/_posts/子空间学习(4)-LPP&NPE.md","hash":"c82d536a4934408b0d2e9ebf3ef568626599650e","modified":1642137709708},{"_id":"source/_posts/子空间学习(5)-GE.md","hash":"e4490b45382dfd950b3cc151e404c92080ebed6d","modified":1642145390242},{"_id":"source/_posts/子空间学习(6)-LDE.md","hash":"f97e9c38f960d945f7a3f471e22111553e4c3727","modified":1642078567715},{"_id":"source/_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts.md","hash":"a45a76eaebc34411c3068b0fea9547e8fe550470","modified":1642078574381},{"_id":"source/_posts/子空间学习(8)-Sparse Representation.md","hash":"cbf4ea9501efbe5656006cca6e842a0d26b722d9","modified":1642078583363},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior.md","hash":"2f0ef4542a2121720e25514a4f80b693e5ecac97","modified":1642078588949},{"_id":"source/about/index.md","hash":"86c222fb0f4211c5c1ab72b955794c6ae8af3bfd","modified":1642139431842},{"_id":"source/categories/index.md","hash":"16745c5712d3f36e5458cfeda2ba4cdea3d21bce","modified":1642064480850},{"_id":"source/about/vx.jpg","hash":"3e1f96d216c5dec35bfa91e2a16ecf90d3f83cb1","modified":1642064480840},{"_id":"source/archive/index.md","hash":"90f2e7b29b67d2250549ae0739b4fcf64d49862c","modified":1642064480840},{"_id":"source/tags/index.md","hash":"52e3cad1bc1fb97f9429d4b5053ab97dc6cf22e8","modified":1642064483486},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/1.jpg","hash":"1df60f42138fa0184875e47343419aa624607e10","modified":1642064468753},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/1.png","hash":"a303b365db7a5aec712aa159bd2c98383ad9f510","modified":1642064468758},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/4.png","hash":"abe5d587c8c8e6f40a739a451df3f204686b432a","modified":1642064470278},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/6.png","hash":"834efefcea121af28389bcadf1add67da5559f1c","modified":1642064470278},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/7.png","hash":"04b27db6062897544ac5b00e9b8447de74588abc","modified":1642064470278},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/9.png","hash":"f784da1903455e69eb0b952eb49e52955de663ef","modified":1642064470318},{"_id":"source/_posts/2020年数学建模美赛A题/15.png","hash":"13aa5e995cd497edaa5d0f1df2981229d33c0e31","modified":1642064473036},{"_id":"source/_posts/2020年数学建模美赛A题/19.png","hash":"ac15f1ef1a1841d763ab49f4d08ee5c6ee0a65fe","modified":1642064473088},{"_id":"source/_posts/2020年数学建模美赛A题/22.png","hash":"1289c556303f56b9f96b9a03aec6357000d03734","modified":1642064473117},{"_id":"source/_posts/2020年数学建模美赛A题/24.png","hash":"4110ef03c33788dafb75c2d8f117630383da1843","modified":1642064473117},{"_id":"source/_posts/2020年数学建模美赛A题/7.png","hash":"d0a3c7afdfa3ca148270ad3bee7339090b3177a9","modified":1642064473147},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/1.png","hash":"e4adb896b7c939c6a67afdc77d3c18a3fc72e9a3","modified":1642064475021},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/10.png","hash":"dbb8ae699a772d1a90b9d81bb82981837c00cc74","modified":1642064475021},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/13.png","hash":"6ef39e19b1b099a934f1c759fc8041b2741401b6","modified":1642064475021},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/15.png","hash":"32f46dc81f10b5727239e7831a1fc59414718c7b","modified":1642064475743},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/2.png","hash":"57f53aa761ae4407cae512e9fb4e40f19076fc89","modified":1642064475763},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/19.png","hash":"bbea10c68b3f4c2f840439afedfe166d202e69b1","modified":1642064475763},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/20.png","hash":"bbea10c68b3f4c2f840439afedfe166d202e69b1","modified":1642064475763},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/7.png","hash":"66009652905b6fc54d83d0885b4ec4fd69a9fce2","modified":1642064475763},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/8.png","hash":"3cad442d0a9b5dc9c833faed31ab2a6cc2096783","modified":1642064476013},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/9.png","hash":"82381a5765ed6f5425ff34694b8aa4bb0433439d","modified":1642064476414},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/10.png","hash":"c6ca7b608bd2ba96d5a92a5b84600ef8d297d6de","modified":1642064477031},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/5.png","hash":"455b4d5cdd492c799808f6574a281719fc6d82f5","modified":1642064477601},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/51.png","hash":"9f4e0b0e5fcff60fa06619718a58608fb1276b4e","modified":1642064477601},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/6.png","hash":"1e5f78a53fd44d54aed18a6730639f31cd99bade","modified":1642064477601},{"_id":"source/_posts/子空间学习(2)-LLE/k.png","hash":"1d7d618066740ecab8cdc79b49f6f0fbc8b71e81","modified":1634381062000},{"_id":"source/_posts/子空间学习(3)-LE/com.png","hash":"2590c1e9b12dc76802081453eb20aac73333ace1","modified":1641462419680},{"_id":"source/_posts/子空间学习(3)-LE/le_swiss.png","hash":"ca0157234a9400fa1ca2e9765cec85861fbeab15","modified":1641462429134},{"_id":"source/_posts/子空间学习(3)-LE/parameter.png","hash":"2c434fd8b676df4785888820a9c1c125da626ddd","modified":1641462421610},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/acc.png","hash":"db6381a3b737d30314aebb1cab701a62dfc7566c","modified":1641478111350},{"_id":"source/_posts/子空间学习(6)-LDE/com.png","hash":"f4201740d491b08895c8ab852882f82605c0940d","modified":1641890144581},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/Acc.png","hash":"ea98d101403f5bf1f7608c23b99297b0b46d9247","modified":1641990216267},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/L2.png","hash":"2cdf19b100fd41c193ac9e6cb5c475fb3824a3e3","modified":1641990348929},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/equation.png","hash":"1b45b7479a7bb4918ccc3194656133599e7e1542","modified":1641981091164},{"_id":"source/img/avatar/fatpeople.jpg","hash":"04cc046c50473ab78aee784df62f05448be8b884","modified":1642064480850},{"_id":"source/img/avatar/vx.jpg","hash":"3e1f96d216c5dec35bfa91e2a16ecf90d3f83cb1","modified":1642064480950},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/2.png","hash":"ceb1e2a0162e6112ecd2a3272e5f2f2b2f3cc830","modified":1642064470268},{"_id":"source/_posts/2020年数学建模美赛A题/0.png","hash":"1c05785df934a8992c31439c55234950764c0496","modified":1642064470318},{"_id":"source/_posts/2020年数学建模美赛A题/10.png","hash":"1a39a7f2fb16fd7e06538bb9f240ce60c2b9e371","modified":1642064470318},{"_id":"source/_posts/2020年数学建模美赛A题/11.png","hash":"42e62dc00ea972f0384bf7cb737f08bbade01a88","modified":1642064470328},{"_id":"source/_posts/2020年数学建模美赛A题/14.png","hash":"3564af6e994d024bb3aa2d506cd5d874ee7c7be6","modified":1642064473036},{"_id":"source/_posts/2020年数学建模美赛A题/25.png","hash":"2a1dd6442f9dcf5bef05e21af5e36b3ce7fb8d6f","modified":1642064473117},{"_id":"source/_posts/2020年数学建模美赛A题/8.png","hash":"59629ca53f15d21efb05add88985235f2bfced6c","modified":1642064473147},{"_id":"source/_posts/2020年数学建模美赛A题/9.png","hash":"255884029f307486cb0a67ae198553265f26fb21","modified":1642064473257},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/home_posts_tag-true.png","hash":"3c6f335347d04e093fccc77e916c4a9d0c6c4a75","modified":1642064473267},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/12.png","hash":"98f7d0242ebfb0173eb1c7aa5a54fb523f7259e3","modified":1642064475021},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/17.png","hash":"f771ec8e6b83adeba6e7e05b4149fa5dc87aafbb","modified":1642064475753},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/18.png","hash":"ddac2712a771144402f7772d85b35dea65486164","modified":1642064475763},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/4.png","hash":"cd82f569bb6c8e75506a5bd2ac34cc43b1a139c2","modified":1642064475763},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/5.png","hash":"e305604b2f7bfb81a866e675165ec9caa8f12089","modified":1642064475763},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/1.png","hash":"b32ecfaad5a309fd653094cce1c856521d80030c","modified":1642064477021},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/13.png","hash":"84fdedc4f07471650a70f42ac80aabdcc1e42f93","modified":1642064478776},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/6.png","hash":"c1ae9721492e739134df4f4448b3c9edc789c856","modified":1642064480681},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/7.png","hash":"097aa6166f34c163c875c3bd46fb925aee2cc6a3","modified":1642064480681},{"_id":"source/_posts/子空间学习(1)-PCA/test_pca.png","hash":"ddbffb7faedb2f0c6cb13e7e96273a80d490ada3","modified":1632480388000},{"_id":"source/_posts/子空间学习(1)-PCA/train_pca.png","hash":"eb8514266b2e690cd7404e0d10b4aa484aa19c23","modified":1632480388000},{"_id":"source/_posts/子空间学习(10)-t-SNE/MNIST.png","hash":"f168fe1277a958d12d9eb75090856040822f6abc","modified":1641992998054},{"_id":"source/_posts/子空间学习(3)-LE/pca_swiss.png","hash":"b7a9775b9cc41911435e34b9e58a796bb21ea137","modified":1641462436124},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/eig.png","hash":"b1f38c280c82d4bbb9dd6e0d6a1cd869a641bfc7","modified":1641478150969},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/parameter.png","hash":"6e713cff35a4878a6783aef810fbc13dded2955f","modified":1641478114855},{"_id":"source/_posts/子空间学习(5)-GE/com.png","hash":"a9f5597c18e8af3ce000084769e45506c6ed8e02","modified":1641545780576},{"_id":"source/_posts/子空间学习(6)-LDE/parameter.png","hash":"1154289909e3a623334e945b74e2544adcd9d9ae","modified":1641890146413},{"_id":"source/_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts/NC.png","hash":"3e1dcf3f2b1b51169eb93d343d3b7a223575b1e9","modified":1641958589289},{"_id":"source/_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts/algorithm.png","hash":"af6fe77c80c3ca2a75689a45cb7c43e3b049eae5","modified":1641956506621},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/LRR.png","hash":"eb24b0a88479119a0ca2081e0f6d742adba3212d","modified":1641990341940},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/SSC.png","hash":"0ea773f9516f3261c3fa97428102e684263b48d1","modified":1641990345103},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/8.png","hash":"464247afe628c34e89e143b8e957124f341b7ab0","modified":1642064470318},{"_id":"source/_posts/2020年数学建模美赛A题/2.png","hash":"4e29d71b7a1838146d8d33edca4b921f85d5f47d","modified":1642064473088},{"_id":"source/_posts/2020年数学建模美赛A题/20.png","hash":"dafb2412b0c64a0367061d1a2c2fd9f5058e6869","modified":1642064473088},{"_id":"source/_posts/2020年数学建模美赛A题/26.png","hash":"04c26dccb8a01f1b2bb04c1b42ff44efeb3aca6f","modified":1642064473117},{"_id":"source/_posts/2020年数学建模美赛A题/3.png","hash":"6b193416623a9e7e2c3c6b684069bfe581182250","modified":1642064473117},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/11.png","hash":"ba1dcd790ef2826c13a6a3df3b2c2a9536b75de1","modified":1642064475021},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/3.png","hash":"f5829624bbec6690710e99180a00ee27e4e304fa","modified":1642064475763},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/6.png","hash":"7b2a07dce7798cbf191ac23e381b7347c9e8fbf2","modified":1642064475763},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/8.png","hash":"7df5bfbe9d7010dd98194d103c0c334fd64cd01b","modified":1642064480681},{"_id":"source/_posts/子空间学习(3)-LE/isomap_swiss.png","hash":"e1e8b6f4bcdf5d549b8f45e13974ce1ce179f1e1","modified":1641462426201},{"_id":"source/_posts/子空间学习(3)-LE/lle_swiss.png","hash":"bb6c8e9eb7507d6077145381c43069d1654a45fd","modified":1641462431735},{"_id":"source/_posts/子空间学习(3)-LE/mds_swiss.png","hash":"02be24187605fa68b74803b3fbd922bcfe514054","modified":1641462434039},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/face.png","hash":"23d124f204367a1eed0fa7bc3b9e8e884da15333","modified":1641478108950},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/10.png","hash":"19522d37e17f636cbaf20323ea2cc02e4338f8c9","modified":1642064468759},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/3.png","hash":"d1a9613609e4e0da24599127b2b5d8fa719edf35","modified":1642064470278},{"_id":"source/_posts/2020年数学建模美赛A题/23.png","hash":"0fb0c336a54089cc76d96d7a73d12e35928c0e72","modified":1642064473117},{"_id":"source/_posts/2020年数学建模美赛A题/6.png","hash":"2ca0df262e07af7d8f088205b1fd226be1efb473","modified":1642064473147},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/16.png","hash":"3147d8d8f6d66f7afb8b9efef9fb9fac95229768","modified":1642064475753},{"_id":"source/_posts/子空间学习(10)-t-SNE/MNIST2.png","hash":"529aa5a8b1e20a89ab05c0dfacd23d3140a10f0b","modified":1641993030869},{"_id":"source/_posts/子空间学习(3)-LE/swiss.png","hash":"2fb4060eb605de067db0f6ae4e3ab2b809441a66","modified":1641462403627},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/algorithm.png","hash":"c889f543a8878d0b59ad57fdea2cbcf3cc9f8f49","modified":1641981038894},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/5.png","hash":"cab3ebe209d832f922e42e3f0f3766dd469b4097","modified":1642064470278},{"_id":"source/_posts/2020年数学建模美赛A题/1.png","hash":"9b52061b572e5d96b61cf170a0934bb2c225cd10","modified":1642064470318},{"_id":"source/_posts/2020年数学建模美赛A题/12.png","hash":"c85b3ea1df612c9f7df2ad4e6406539f74c97e42","modified":1642064470328},{"_id":"source/_posts/2020年数学建模美赛A题/16.png","hash":"fde1297223dfb8622088d347888d17f4ab04739f","modified":1642064473036},{"_id":"source/_posts/2020年数学建模美赛A题/1617.png","hash":"37cf6f79641d79d3dc64f05eeb0c76cbe188c373","modified":1642064473036},{"_id":"source/_posts/2020年数学建模美赛A题/17.png","hash":"2be8c7f0effea7fde43f4934c0ecbc8f5653d97d","modified":1642064473058},{"_id":"source/_posts/2020年数学建模美赛A题/18.png","hash":"eb6c203dc06e97ef1a8aa06ae01e85904f1e1556","modified":1642064473088},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/3.png","hash":"21a2d1926611933bba1c2140cbe7dab8ff4d593c","modified":1642064477282},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/12.png","hash":"d7dc3c37fe971c08dc2e31df9a70ec45c30250b8","modified":1642064478776},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/2.png","hash":"ee6d362b84c67960617d9cab7626819ce085f4be","modified":1642064479307},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/4.png","hash":"dfe700faa7de7241431f41d9e9262d36ad1cc7cf","modified":1642064480630},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/5.png","hash":"0343e1400c83b5e943491333e438a56009a80585","modified":1642064480681},{"_id":"themes/livemylife/LICENSE","hash":"2b209f06bebeb2a8c2b7e187e436f3e1e1fbc8a7","modified":1634620821000},{"_id":"themes/livemylife/_config.yml","hash":"1b8c3d1138eb20ad2b8b135f69c7866c48cf1bc5","modified":1642160087435},{"_id":"themes/livemylife/languages/cn.yml","hash":"0a629acf131afb24fd571e09b8b79423404ade10","modified":1634620821000},{"_id":"themes/livemylife/languages/default.yml","hash":"736a02687bb045869622e41397acde60dfde0170","modified":1634620821000},{"_id":"themes/livemylife/languages/en.yml","hash":"736a02687bb045869622e41397acde60dfde0170","modified":1634620821000},{"_id":"themes/livemylife/languages/tw.yml","hash":"5461ef5509b9214d8e1128a1fd70c85cb5e2ab27","modified":1634620821000},{"_id":"themes/livemylife/layout/404.ejs","hash":"007f4b206b68a000b891115100a0a2992b0732f4","modified":1634620821000},{"_id":"themes/livemylife/layout/about.ejs","hash":"145d53bf1ed755cdcff669eed2c1a1862eb9fb98","modified":1634620821000},{"_id":"themes/livemylife/layout/archive.ejs","hash":"c09dd7bb49a28ec5ac65ef2b4d9f4e0e2c4e31a4","modified":1634620821000},{"_id":"themes/livemylife/layout/index.ejs","hash":"5a90fc30cf6e2c9f250580c81ff373c3d0b836ed","modified":1634620821000},{"_id":"themes/livemylife/layout/categories.ejs","hash":"3b074215b4880c6c5fcc428f586587f8c92d78a2","modified":1634620821000},{"_id":"themes/livemylife/layout/keynote.ejs","hash":"200bacc9da69024bda94c593b1571adbfc6be28d","modified":1634620821000},{"_id":"themes/livemylife/layout/layout.ejs","hash":"10880698337ee90d600a9d0e586ae15ce7947521","modified":1634620821000},{"_id":"themes/livemylife/layout/page.ejs","hash":"73a76818a48584d3859b97624f1b5cf42c99df61","modified":1634620821000},{"_id":"themes/livemylife/layout/tags.ejs","hash":"90d1e6e2d719f56b12e01331857b0206025008c4","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/anchorjs.ejs","hash":"9a9ff58f3767c7d23c029fcb2030ea353824f79a","modified":1634620821000},{"_id":"themes/livemylife/layout/post.ejs","hash":"67e927aa45b5d4a62f3dd305bcaa0eb2fc0cb6cc","modified":1642160629668},{"_id":"themes/livemylife/layout/_partial/article.ejs","hash":"c8ea8819f1e66e879e7d3f17d991618c6c709c0b","modified":1642141296737},{"_id":"themes/livemylife/layout/_partial/catalog.ejs","hash":"11db668dce21b88b0648478ad82e053f50f06919","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/footer.ejs","hash":"d1dd2d70427c5f7c024422e35d7f6c4be43e9711","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/comment.ejs","hash":"c73c3e5d741688d14750af1897dd2388cbfc5368","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/gitter.ejs","hash":"348193932983df5196a3bc49e8b59276d978b09f","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/head.ejs","hash":"76889b25d50a38617ccd7474b987f5e38218911d","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/langselect.ejs","hash":"6ead51e4f41fd08eb086edcf7964431dcb8ded8e","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/header.ejs","hash":"1f925baa3b78a8d907a327307cf11edebf7709e6","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/nav.ejs","hash":"0f143be3eccfa56ea1a1be1a01cadf92b78d1cc4","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/pagination.ejs","hash":"1c3f390b60dba1da3d57fb7fa95c0dd96efa99b8","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/sidebar.ejs","hash":"693e7199e6cbdd3d1fea8d6726786a43c548bd78","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/search.ejs","hash":"351b0ae458d04a379ac91014d7caa1b9c19ac7f1","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/socialshare.ejs","hash":"1df693cf21a2f4af133fb0da0d2352ee2aa556e0","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/themecolor.ejs","hash":"c0da1e6af0e15dd1eb4a07fa8be93fa637fca8e8","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/tip.ejs","hash":"d535578b4629e830a2518695e9002f4aca115fc3","modified":1634620821000},{"_id":"themes/livemylife/layout/_widget/archive.ejs","hash":"075b78b11c4dc4360bd4651f19128b19bd5e321e","modified":1634620821000},{"_id":"themes/livemylife/layout/_widget/category.ejs","hash":"002621598f14fc57d17bc3516f07981d5719af1c","modified":1634620821000},{"_id":"themes/livemylife/layout/_widget/featured-tags.ejs","hash":"dd023418a4399ddcc4118235585eb15e77f7762f","modified":1634620821000},{"_id":"themes/livemylife/layout/_widget/friends-blog.ejs","hash":"3bda9bab322b28e670a660dc9444ab9985676838","modified":1634620821000},{"_id":"themes/livemylife/layout/_widget/recent-posts.ejs","hash":"ad0f544631bdd168dece8cbbcf19fe42e195e085","modified":1634620821000},{"_id":"themes/livemylife/layout/_widget/short-about.ejs","hash":"b682f5e9e30fd6800c4f6b50b41467d66d134c24","modified":1634620821000},{"_id":"themes/livemylife/layout/_widget/visitor.ejs","hash":"f5a895fe5144588a1f80995d7e0a693aa1ca86ef","modified":1634620821000},{"_id":"themes/livemylife/source/css/archive.styl","hash":"715bcbd085eb95ec26c9805c11c374919cde971c","modified":1634620821000},{"_id":"themes/livemylife/source/css/beantech.css","hash":"c192d3170301f774fa4c2185dc125cb3d6ec4929","modified":1634620821000},{"_id":"themes/livemylife/source/css/beantech.min.css","hash":"52f8485f36e94a35de73b9cf1eb49b6237fbedc5","modified":1634620821000},{"_id":"themes/livemylife/source/css/catalog.styl","hash":"b4b4b71b20d8b6bce185b962c2feb79314b7813c","modified":1634620821000},{"_id":"themes/livemylife/source/css/gitalk.css","hash":"51783fd60dff05e8e339ff83b41504538662f6ca","modified":1634620821000},{"_id":"themes/livemylife/source/css/highlight.styl","hash":"e842080e6d580f0f70a7df71fbde3c4e49463c19","modified":1634620821000},{"_id":"themes/livemylife/source/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1634620821000},{"_id":"themes/livemylife/source/css/rocket.styl","hash":"d81a811f3b7149b519f8cebf9a9b5719dd4870c0","modified":1634620821000},{"_id":"themes/livemylife/source/css/livemylife.css","hash":"07f90cf42f19b7b86361d202b24918ee0c626211","modified":1634620821000},{"_id":"themes/livemylife/source/css/scroll.css","hash":"ba16b97532dd6aaec66a82f3c33cc989d361fa7a","modified":1634620821000},{"_id":"themes/livemylife/source/css/search.css","hash":"c633ff24b9126676013197280b18bb79ea4abb6c","modified":1634620821000},{"_id":"themes/livemylife/source/css/signature.styl","hash":"88159b31c59d59c01a0b534af57242662a2a3969","modified":1634620821000},{"_id":"themes/livemylife/source/css/themecolor.css","hash":"4f64a3b505375296762dd0363284dfcd233ee521","modified":1634620821000},{"_id":"themes/livemylife/source/css/top.css","hash":"0303375fbe2ca942cd3d86f31d12fef9bf5785af","modified":1634620821000},{"_id":"themes/livemylife/source/css/viewer.min.css","hash":"0e045aa3df1be7d138caa701ec3aa623ccc7a52d","modified":1634620821000},{"_id":"themes/livemylife/source/css/wave.css","hash":"041f3b4a78e2840ba17679cea05fb14bb646722f","modified":1634620821000},{"_id":"themes/livemylife/source/css/widget.styl","hash":"7a9f735f5ef323dc2950fbd9d76daa16c9a0f1a9","modified":1634620821000},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1634620821000},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1634620821000},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1634620821000},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1634620821000},{"_id":"themes/livemylife/source/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1634620821000},{"_id":"themes/livemylife/source/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1634620821000},{"_id":"themes/livemylife/source/js/catalog.js","hash":"059f3f31492e5b1a9dddf422a48c32969d247415","modified":1634620821000},{"_id":"themes/livemylife/source/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1634620821000},{"_id":"themes/livemylife/source/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1634620821000},{"_id":"themes/livemylife/source/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1634620821000},{"_id":"themes/livemylife/source/js/line.js","hash":"d69576bfe75048345a137c148ffca1d9985811dc","modified":1634620821000},{"_id":"themes/livemylife/source/js/mouseclick.js","hash":"b27fb5ae779a855a93b85c923f1ac927ba52dc86","modified":1634620821000},{"_id":"themes/livemylife/source/js/ribbonDynamic.js","hash":"576f0ce237c87738277868489af30b6538681201","modified":1634620821000},{"_id":"themes/livemylife/source/js/scroll.js","hash":"265a4c4fc33b5b44b620db64ff31d2bc05d233e9","modified":1634620821000},{"_id":"themes/livemylife/source/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1634620821000},{"_id":"themes/livemylife/source/js/langselect.js","hash":"52ca6e30814272bc329868944f528f89630404e4","modified":1634620821000},{"_id":"themes/livemylife/source/js/ziploader.js","hash":"9c25324caf53b56cb68839dcfb34e61e5a6a63f3","modified":1634620821000},{"_id":"themes/livemylife/layout/_partial/post/gitalk.ejs","hash":"2507fd643fb63501898ee64b42f8b56b047064d2","modified":1642141257379},{"_id":"themes/livemylife/source/css/images/beside_up2.png","hash":"ef066ba2e93a4738df45ae05020726e066c4dd1f","modified":1634620821000},{"_id":"themes/livemylife/source/css/images/beside_up.png","hash":"183d87f1a99e93fc663ec798fa8c94cb87c83bcb","modified":1634620821000},{"_id":"themes/livemylife/source/css/images/beside_up_white.png","hash":"49c5922a8de63dcf9468fbcffc70d2ec36b1b527","modified":1634620821000},{"_id":"themes/livemylife/source/css/images/beside_up_white2.png","hash":"52e9d5715def1d3d09ab076d5eb3d22916d8f7d7","modified":1634620821000},{"_id":"themes/livemylife/source/js/viewer/pic-viewer.js","hash":"9bf7c37cce781628346803ed7ce8f02623c2d013","modified":1634620821000},{"_id":"themes/livemylife/source/js/viewer/viewer.min.js","hash":"ae5380974b6fb8b0e15356c8418186c6c0821222","modified":1634620821000},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/3.png","hash":"e4757ff9d7fe42e2b803c50a90cb546ac2ed2cb4","modified":1642064480630},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/com.png","hash":"901bb744862c75e8df764a8423cd43750b6e8e63","modified":1641478106184},{"_id":"themes/livemylife/source/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1634620821000},{"_id":"themes/livemylife/source/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1634620821000},{"_id":"themes/livemylife/source/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1634620821000},{"_id":"themes/livemylife/source/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1634620821000},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/14.jpeg","hash":"fbcdc3e21ce667275d9e3b6e4f3d158741ef5d37","modified":1642064478776},{"_id":"source/_posts/子空间学习(2)-LLE/LLE-Val.png","hash":"49a4b76ebc489ab3b42a0ae02aebd62d72410f57","modified":1634263800000},{"_id":"themes/livemylife/source/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1634620821000},{"_id":"source/_posts/2020年数学建模美赛A题/1314.png","hash":"b834a06dd9a8ad0ffc90b7986a3b3272f1a19cc5","modified":1642064473036},{"_id":"source/_posts/2020年数学建模美赛A题/4.png","hash":"c7954db6e34d8d8a35739abfd2dd878ff3005e74","modified":1642064473138},{"_id":"source/_posts/2020年数学建模美赛A题/5.png","hash":"5c93f4b4a467ebd8060f8d1cdeedcd81fd9f0924","modified":1642064473138},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/2.png","hash":"9e021642115d7b2d35d098b71c4ffff8b19d0924","modified":1642064477272},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/4.png","hash":"deecfa48b1498e216b867d610dff8bed6c259d4c","modified":1642064477592},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/8.png","hash":"54acafc791478f7bcd2fac79634f66904ed80581","modified":1642064477843},{"_id":"source/_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts/SC.png","hash":"c310010104c722b78017cb13947efc53db291be0","modified":1641958610339},{"_id":"source/_posts/子空间学习(8)-Sparse Representation/inpainting_yiding.png","hash":"3cf76611ff4d39f47645f054c2a143a124e572b2","modified":1641974077190},{"_id":"source/img/avatar/Bin.jpg","hash":"9799f4343389eef20c1e16039c5bde71a995ef1b","modified":1642064480850},{"_id":"themes/livemylife/source/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1634620821000},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/14.png","hash":"942f3b3b5c565f8b7dfe3f0539165d5dd0e16a43","modified":1642064475031},{"_id":"source/img/header_img/8.jpeg","hash":"2b3865efea33e5c711e54de01811e87d5c380ff7","modified":1642064483106},{"_id":"source/_posts/2020年数学建模美赛A题/13.png","hash":"0b54a1edae29f6e90d5a38dcd23b889b2e34b114","modified":1642064470991},{"_id":"source/_posts/2020年数学建模美赛A题/21.png","hash":"00b3cad20acadd14fabafe3a936b1c0a33f9a439","modified":1642064473108},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/dark.png","hash":"0eefd914a47c1958e23f5fd9cb854e785763f03c","modified":1642064473267},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/light.png","hash":"8a03996cff1eb0cbda41655e64d5c8fa5e0e9592","modified":1642064474320},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/wave.png","hash":"c933776e89f9f821ee6dfc1622401ec9ce5c9e35","modified":1642064475021},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/7.png","hash":"883791bbe657c720fab27efd1cf790dd4620c223","modified":1642064477601},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/9.png","hash":"dc815469d630853099ea10aeec891016316d96e2","modified":1642064477853},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/livemylife-desktop.png","hash":"45fc4bfd838997c93db72ab389c1c52b18a2d506","modified":1642064474480},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/11.png","hash":"d5998d6f87430d96f9b44eaadca4c77687475dc6","modified":1642064478766},{"_id":"source/img/avatar/smile.jpg","hash":"6cae0280505eaee6a8da4f4f6e83e0409e43199f","modified":1642064480950},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/top.png","hash":"e60e82f384b4ce8455c04d6cd5979d16672954e8","modified":1642064474490},{"_id":"themes/livemylife/source/js/comment/gitalk_.js","hash":"9256bc4b8f7341f60083da291d5c7c9f0fe5f1bd","modified":1634620821000},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/10.png","hash":"2cf52f4f7e767c712204f678e0bea85e2d3337c2","modified":1642064478756},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/12.png","hash":"da780aa856effab0dec8c66a8447800c3eb883b3","modified":1642064477232},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/26.jpg","hash":"ce119f17c941ac1d965c234fbe730be1424762f2","modified":1642064479648},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/28.jpg","hash":"a63dc10c445a4c3fa0bea1c06de1667af4a81dde","modified":1642064480359},{"_id":"themes/livemylife/source/js/comment/gitalk.js","hash":"e5c1b7f8a2803765cff831793af377a9f81fb385","modified":1634620821000},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/9.png","hash":"401f7f27de5250408f02db9e462f0971bdc5cfa9","modified":1642064480840},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/24.jpg","hash":"3a8c71474e634448247a962f01a99052746e45b0","modified":1642064479397},{"_id":"source/_posts/子空间学习(8)-Sparse Representation/Image_debluring.png","hash":"ea0da9797d35945303c4dc3e01acc12199f3587d","modified":1641974066270},{"_id":"source/img/header_img/1.jpg","hash":"788f01a7d357e3f14e9bd7d0820e3a058ba08e93","modified":1642064481139},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/11.png","hash":"a38237d57eef77fde245842070e2093b7435b7d3","modified":1642064477152},{"_id":"source/img/header_img/6.jpg","hash":"7cf3773e7ef5cb29a9fc2c5b35e2d6c54a017a26","modified":1642064483106},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/25.jpg","hash":"6e43db885a55aee8a14ce65f0c9009787521005b","modified":1642064479557},{"_id":"source/img/header_img/4.jpg","hash":"b4bd9331cd50955b02632b032348b5de37f5e299","modified":1642064483025},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/16.jpg","hash":"c89bb8fdc08db9b9b8742569e12759037bd29dfa","modified":1642064479167},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/21.jpg","hash":"3ea56c9affcdc5b34909f85f7c0709d9c04869bd","modified":1642064479387},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/15.jpg","hash":"a408c7de09fcc76c3000e48c82e82d1774baf9f9","modified":1642064479117},{"_id":"source/img/header_img/5.jpg","hash":"fff32018adc37b2bbe62289b32208d7188986172","modified":1642064483086},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/19.jpg","hash":"179a875cd6bb15daeab5544aaf96ae87ea021a3d","modified":1642064479307},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/20.jpg","hash":"e0c2f2857ba310507bc46dc1f34bff9fdf83b396","modified":1642064479347},{"_id":"source/img/header_img/me.jpg","hash":"561ccafcfd6db165211e10683d71d928c8cc7f84","modified":1642064483296},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/17.jpg","hash":"349c16855c7ac61521527b68abbc2e6c5176ad58","modified":1642064479207},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/18.jpg","hash":"0128ef630566c82d2f25fcd51910a7d23823b82c","modified":1642064479257},{"_id":"source/img/header_img/newhome_bg.jpg","hash":"d770c4659027f3d4fe479afb6909ed6968f56d68","modified":1642064483316},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/1.jpg","hash":"799acc2107267e2f6545b5592bed121f9e1e2ba5","modified":1642064478626},{"_id":"source/img/header_img/2.jpg","hash":"41800ed5f1ee477d631efe6839fdf04583f0cbdd","modified":1642064481579},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/29.jpg","hash":"719cf8285521e90e6e6bcc7db8eba46289f8671f","modified":1642064480620},{"_id":"source/img/header_img/8.jpg","hash":"5a62e5b9a58498312d4dcb7484341dcee9434943","modified":1642064483136},{"_id":"source/img/header_img/3.jpg","hash":"9ebc361943ca015395561ca2057342255ae92bc2","modified":1642064482494},{"_id":"source/img/header_img/tiger.png","hash":"f500b04ade8f15363d6ea3d5b55ba42ecf916c85","modified":1642142289823},{"_id":"source/img/header_img/vehicle.jpg","hash":"ee7302c8ce23867e1dbe3fce20b38776ebad555a","modified":1642064483476},{"_id":"source/img/header_img/categories_bg.jpg","hash":"2acefcb91238d3d17bea6c53881fb8c025ebe370","modified":1642064483216},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/27.jpg","hash":"632296607cc5d89bbf0931967d39f6bf4f790431","modified":1642064479998},{"_id":"source/img/header_img/404_bg.jpg","hash":"9a899c297a352c1664d0b7ec44d5fbc0c8c048fd","modified":1642064483067},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/11.png","hash":"1396bc652948acbc18a40b5b636e59af4532d152","modified":1642064470268},{"_id":"source/img/header_img/lml_bg.jpg","hash":"c572aa5a4ed446f43c898c3864bf8b144844ef35","modified":1642064483276},{"_id":"source/img/header_img/tag_bg.jpg","hash":"0cf9fb6a4fdad42dcc936dc9e90cfd3e5b7b8cef","modified":1642064483366},{"_id":"source/img/header_img/archive_bg2.jpg","hash":"ecc208724bde2e07787a9b83191f6e1c755c1422","modified":1642064483186},{"_id":"public/baidusitemap.xml","hash":"e55d132d63d87443bf5cbeacf81fe889c8a5e988","modified":1642161399331},{"_id":"public/sitemap.xml","hash":"9dcedb6e5eeeb1b26b7a63829121feda5b13044a","modified":1642161399331},{"_id":"public/searchVersion.json","hash":"1ef8f8f493b94bc6810f62dadc7cff099d691f55","modified":1642161399331},{"_id":"public/categories/index.html","hash":"063f1ea34c405011d709820339d31633d539b854","modified":1642161399331},{"_id":"public/404.html","hash":"7ea639fff7821146312ca0a3099eb84d7256419d","modified":1642161399331},{"_id":"public/tags/index.html","hash":"56378a516b070cede92ddbe30f8fce39fbd614c8","modified":1642161399331},{"_id":"public/2022/01/22/子空间学习(10)-t-SNE/index.html","hash":"bc80b43d49a372e2df09ce308c7e725ccc2a3624","modified":1642161399331},{"_id":"public/2022/01/19/子空间学习(9)-On Regularization and the Prior/index.html","hash":"4acebfd80cd2fe3ded2d77966adec6cf49fc2a1a","modified":1642161399331},{"_id":"public/2022/01/18/子空间学习(8)-Sparse Representation/index.html","hash":"00b5756ea8c85e2714192948d685d699b5c331d4","modified":1642161399331},{"_id":"public/2022/01/17/子空间学习(7)-Spectral Clustering and Normalized Cuts/index.html","hash":"755259a3883fe36309ca1307639593820f8e5d06","modified":1642161399331},{"_id":"public/2022/01/16/子空间学习(6)-LDE/index.html","hash":"e6494f7ae4d079ceaa3949fc3f27214b3658643c","modified":1642161399331},{"_id":"public/2022/01/15/子空间学习(5)-GE/index.html","hash":"9eca7bc8b1745f06cce83cb07547274923c6a10d","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/index.html","hash":"6ff49f4f54ce47e503b5885b99a0b964f8403d2f","modified":1642161399331},{"_id":"public/2022/01/14/子空间学习(4)-LPP&NPE/index.html","hash":"8b1a201701d8c7dc8b8cd93b3ab0072f2de54904","modified":1642161399331},{"_id":"public/2022/01/12/子空间学习(2)-LLE/index.html","hash":"d4bae6e9900f14c1488c2fb0104f31674520e865","modified":1642161399331},{"_id":"public/2022/01/11/子空间学习(1)-PCA/index.html","hash":"9cc71c11b1c3a57f9c55cdd9a1a75a90eeeef7e9","modified":1642161399331},{"_id":"public/2021/02/19/20岁那年的一些故事/index.html","hash":"44c78feea49a82a41cc972a4a78d98185b3cb1cd","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/index.html","hash":"713b080c8ee9ea94a8bbead34a99248b734bd1a0","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/index.html","hash":"90e90256415a66b0d2bba94ed48dfcdc3304cf2c","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/index.html","hash":"97e12f7fd797293bd85c1459c0cd42b48dab600a","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/index.html","hash":"239de355f43e72c6bc97a1ff0af28ad649a8dfc9","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/index.html","hash":"9a264e367337352518081cdea57f6f5ac91ea708","modified":1642161399331},{"_id":"public/2020/04/17/Hexo-Theme-LiveMyLife/index.html","hash":"31952bf53c8f7451d37758ace09fe11b326a1c02","modified":1642161399331},{"_id":"public/about/index.html","hash":"f0ea06a706e93dff656b6a6231b340be06debf7b","modified":1642161399331},{"_id":"public/archive/index.html","hash":"f776d33a0ba45febdd42a3a6d3354b143d958d32","modified":1642161399331},{"_id":"public/categories/数学建模/index.html","hash":"57097a0eeed3852035d4c1d0579ad7a445b5cfe5","modified":1642161399331},{"_id":"public/categories/生活日常/index.html","hash":"e96d8600a44c4b6d84f6609193993b9363fc293e","modified":1642161399331},{"_id":"public/categories/Hexo-Theme-LiveMyLife/index.html","hash":"8a5f041ef5e35ddd844404faf098fa6efd1f0a43","modified":1642161399331},{"_id":"public/categories/工程项目/index.html","hash":"3230ebb38bd39ff5e4d942b750c2c7909349b7b2","modified":1642161399331},{"_id":"public/categories/子空间学习/index.html","hash":"94ce94e889e6d1d67fa7baa8bcc492bad7dd7274","modified":1642161399331},{"_id":"public/index.html","hash":"1fd81bba531211ef010385d6365fac3d563d0979","modified":1642161399331},{"_id":"public/categories/算法改进/index.html","hash":"f9f9d929cda4047e54c5b950f822b6275e3d7048","modified":1642161399331},{"_id":"public/archives/2/index.html","hash":"1bdc59b2a304cf20bf27c1fcf6d571f0b339cec7","modified":1642161399331},{"_id":"public/archives/index.html","hash":"e31893a29c5189fa325fd33896159a1d8d4b16c7","modified":1642161399331},{"_id":"public/archives/2020/index.html","hash":"558a9c2aa13f7d2034433671aea0741fde981eab","modified":1642161399331},{"_id":"public/archives/archives/2/index.html","hash":"942d12ac256491e5b5d1b8387d15b752119315ee","modified":1642161399331},{"_id":"public/archives/2020/04/index.html","hash":"7196f7f73805c0765fae923251f7310dbb2edfd9","modified":1642161399331},{"_id":"public/archives/2021/index.html","hash":"1c98140415cd3afcccac8fc630af79f560890c77","modified":1642161399331},{"_id":"public/archives/2021/01/index.html","hash":"feac11041f0a557bf97675c21ec9b1e3c21e9983","modified":1642161399331},{"_id":"public/archives/2021/02/index.html","hash":"7a6d00d0fbe4522c2583fd0bd67eb58f1b1f91e2","modified":1642161399331},{"_id":"public/archives/2022/index.html","hash":"500c86473a810367525e3a92d6ed844c1b385cba","modified":1642161399331},{"_id":"public/archives/2022/01/index.html","hash":"3ca647f327f86457b09487044df9ab9371a2114d","modified":1642161399331},{"_id":"public/tags/C/index.html","hash":"b73f0d81b0a55624891a2c8910fa0edc3d4f12f8","modified":1642161399331},{"_id":"public/tags/Matlab/index.html","hash":"6457dc90e8094aa80a3ec78a3174a3d0c7f09e17","modified":1642161399331},{"_id":"public/tags/Latex/index.html","hash":"a42d07e41b1754b01fbbf9d35c6dd97e917121af","modified":1642161399331},{"_id":"public/tags/Python/index.html","hash":"1d75060e0f7a1c4ca35193d081eeb610a9499839","modified":1642161399331},{"_id":"public/tags/Python/archives/2/index.html","hash":"1b2acf5a42647e58f09847a13bfb80378b7915f0","modified":1642161399331},{"_id":"public/tags/Premiere-Pro-CC/index.html","hash":"0c69d3718b53e28b7e9fbd7bdccdeceec4448fb3","modified":1642161399331},{"_id":"public/tags/Google-earth/index.html","hash":"8b8e7f7fbe156e451a636f4b330244cccf08f385","modified":1642161399331},{"_id":"public/tags/Osmo-Mobile3/index.html","hash":"3afa3d95344e32019000576014e9d6af55916c29","modified":1642161399331},{"_id":"public/tags/Hexo/index.html","hash":"399be9d03572b37c0192db75e0840350b6ad68d3","modified":1642161399331},{"_id":"public/tags/Hexo-Theme-LiveMyLife/index.html","hash":"a07f902bd5384cbf5a22c31c03cb3713c41dc970","modified":1642161399331},{"_id":"public/tags/Javascript/index.html","hash":"875e3df05422a76c5ce0a3afb0aece2bc3fd6105","modified":1642161399331},{"_id":"public/tags/Vercel/index.html","hash":"edc45eef83c7ab3a01bdb9c52891cb8d90549bd2","modified":1642161399331},{"_id":"public/tags/Django/index.html","hash":"47a61e366419b5bbf0162f63611147b23fac97c0","modified":1642161399331},{"_id":"public/tags/Pyqt5/index.html","hash":"cc5f7c4f176b56ec49eb520d2d03970973e3cd94","modified":1642161399331},{"_id":"public/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1642161399331},{"_id":"public/css/images/beside_up.png","hash":"183d87f1a99e93fc663ec798fa8c94cb87c83bcb","modified":1642161399331},{"_id":"public/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1642161399331},{"_id":"public/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1642161399331},{"_id":"public/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1642161399331},{"_id":"public/css/images/beside_up2.png","hash":"ef066ba2e93a4738df45ae05020726e066c4dd1f","modified":1642161399331},{"_id":"public/css/images/beside_up_white.png","hash":"49c5922a8de63dcf9468fbcffc70d2ec36b1b527","modified":1642161399331},{"_id":"public/css/images/beside_up_white2.png","hash":"52e9d5715def1d3d09ab076d5eb3d22916d8f7d7","modified":1642161399331},{"_id":"public/LICENSE","hash":"b314c7ebb7d599944981908b7f3ed33a30e78f3a","modified":1642161399331},{"_id":"public/CNAME","hash":"8929eb36e7c7960e964c2fea3cd9b4253ed169df","modified":1642161399331},{"_id":"public/about/vx.jpg","hash":"3e1f96d216c5dec35bfa91e2a16ecf90d3f83cb1","modified":1642161399331},{"_id":"public/img/avatar/fatpeople.jpg","hash":"04cc046c50473ab78aee784df62f05448be8b884","modified":1642161399331},{"_id":"public/img/avatar/vx.jpg","hash":"3e1f96d216c5dec35bfa91e2a16ecf90d3f83cb1","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/1.jpg","hash":"1df60f42138fa0184875e47343419aa624607e10","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/1.png","hash":"a303b365db7a5aec712aa159bd2c98383ad9f510","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/4.png","hash":"abe5d587c8c8e6f40a739a451df3f204686b432a","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/6.png","hash":"834efefcea121af28389bcadf1add67da5559f1c","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/7.png","hash":"04b27db6062897544ac5b00e9b8447de74588abc","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/9.png","hash":"f784da1903455e69eb0b952eb49e52955de663ef","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/15.png","hash":"13aa5e995cd497edaa5d0f1df2981229d33c0e31","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/19.png","hash":"ac15f1ef1a1841d763ab49f4d08ee5c6ee0a65fe","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/22.png","hash":"1289c556303f56b9f96b9a03aec6357000d03734","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/24.png","hash":"4110ef03c33788dafb75c2d8f117630383da1843","modified":1642161399331},{"_id":"public/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/2.png","hash":"ceb1e2a0162e6112ecd2a3272e5f2f2b2f3cc830","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/0.png","hash":"1c05785df934a8992c31439c55234950764c0496","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/11.png","hash":"42e62dc00ea972f0384bf7cb737f08bbade01a88","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/10.png","hash":"1a39a7f2fb16fd7e06538bb9f240ce60c2b9e371","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/14.png","hash":"3564af6e994d024bb3aa2d506cd5d874ee7c7be6","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/7.png","hash":"d0a3c7afdfa3ca148270ad3bee7339090b3177a9","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/13.png","hash":"6ef39e19b1b099a934f1c759fc8041b2741401b6","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/10.png","hash":"dbb8ae699a772d1a90b9d81bb82981837c00cc74","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/15.png","hash":"32f46dc81f10b5727239e7831a1fc59414718c7b","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/1.png","hash":"e4adb896b7c939c6a67afdc77d3c18a3fc72e9a3","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/19.png","hash":"bbea10c68b3f4c2f840439afedfe166d202e69b1","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/2.png","hash":"57f53aa761ae4407cae512e9fb4e40f19076fc89","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/20.png","hash":"bbea10c68b3f4c2f840439afedfe166d202e69b1","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/7.png","hash":"66009652905b6fc54d83d0885b4ec4fd69a9fce2","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/8.png","hash":"3cad442d0a9b5dc9c833faed31ab2a6cc2096783","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/9.png","hash":"82381a5765ed6f5425ff34694b8aa4bb0433439d","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/10.png","hash":"c6ca7b608bd2ba96d5a92a5b84600ef8d297d6de","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/5.png","hash":"455b4d5cdd492c799808f6574a281719fc6d82f5","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/51.png","hash":"9f4e0b0e5fcff60fa06619718a58608fb1276b4e","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/6.png","hash":"1e5f78a53fd44d54aed18a6730639f31cd99bade","modified":1642161399331},{"_id":"public/2022/01/12/子空间学习(2)-LLE/k.png","hash":"1d7d618066740ecab8cdc79b49f6f0fbc8b71e81","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/com.png","hash":"2590c1e9b12dc76802081453eb20aac73333ace1","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/le_swiss.png","hash":"ca0157234a9400fa1ca2e9765cec85861fbeab15","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/parameter.png","hash":"2c434fd8b676df4785888820a9c1c125da626ddd","modified":1642161399331},{"_id":"public/2022/01/14/子空间学习(4)-LPP&NPE/acc.png","hash":"db6381a3b737d30314aebb1cab701a62dfc7566c","modified":1642161399331},{"_id":"public/2022/01/16/子空间学习(6)-LDE/com.png","hash":"f4201740d491b08895c8ab852882f82605c0940d","modified":1642161399331},{"_id":"public/2022/01/19/子空间学习(9)-On Regularization and the Prior/Acc.png","hash":"ea98d101403f5bf1f7608c23b99297b0b46d9247","modified":1642161399331},{"_id":"public/2022/01/19/子空间学习(9)-On Regularization and the Prior/L2.png","hash":"2cdf19b100fd41c193ac9e6cb5c475fb3824a3e3","modified":1642161399331},{"_id":"public/2022/01/19/子空间学习(9)-On Regularization and the Prior/equation.png","hash":"1b45b7479a7bb4918ccc3194656133599e7e1542","modified":1642161399331},{"_id":"public/css/archive.css","hash":"8db895ebaeff19ac145c961abcfd5d4a8d67a8ea","modified":1642161399331},{"_id":"public/css/catalog.css","hash":"6e63e8902ec9ba5ef6256a0c2ef93934c56d612c","modified":1642161399331},{"_id":"public/css/highlight.css","hash":"03d1f0a648e9bdf7b1f57d217313cbac5d0c7eb1","modified":1642161399331},{"_id":"public/css/rocket.css","hash":"1aa31deaf2c434e883a7b4d096d187244eb964d0","modified":1642161399331},{"_id":"public/css/scroll.css","hash":"ba16b97532dd6aaec66a82f3c33cc989d361fa7a","modified":1642161399331},{"_id":"public/css/livemylife.css","hash":"07f90cf42f19b7b86361d202b24918ee0c626211","modified":1642161399331},{"_id":"public/css/signature.css","hash":"820fa4743cea34a61808cd8f7de528605c32d7e3","modified":1642161399331},{"_id":"public/css/viewer.min.css","hash":"0e045aa3df1be7d138caa701ec3aa623ccc7a52d","modified":1642161399331},{"_id":"public/css/search.css","hash":"c633ff24b9126676013197280b18bb79ea4abb6c","modified":1642161399331},{"_id":"public/css/top.css","hash":"0303375fbe2ca942cd3d86f31d12fef9bf5785af","modified":1642161399331},{"_id":"public/css/wave.css","hash":"041f3b4a78e2840ba17679cea05fb14bb646722f","modified":1642161399331},{"_id":"public/css/widget.css","hash":"da95ad3f1938f24d20f1fa77d7a38f0c392b5ec8","modified":1642161399331},{"_id":"public/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1642161399331},{"_id":"public/js/catalog.js","hash":"059f3f31492e5b1a9dddf422a48c32969d247415","modified":1642161399331},{"_id":"public/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1642161399331},{"_id":"public/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1642161399331},{"_id":"public/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1642161399331},{"_id":"public/js/line.js","hash":"d69576bfe75048345a137c148ffca1d9985811dc","modified":1642161399331},{"_id":"public/js/mouseclick.js","hash":"b27fb5ae779a855a93b85c923f1ac927ba52dc86","modified":1642161399331},{"_id":"public/js/ribbonDynamic.js","hash":"576f0ce237c87738277868489af30b6538681201","modified":1642161399331},{"_id":"public/js/scroll.js","hash":"265a4c4fc33b5b44b620db64ff31d2bc05d233e9","modified":1642161399331},{"_id":"public/js/langselect.js","hash":"52ca6e30814272bc329868944f528f89630404e4","modified":1642161399331},{"_id":"public/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1642161399331},{"_id":"public/js/viewer/pic-viewer.js","hash":"9bf7c37cce781628346803ed7ce8f02623c2d013","modified":1642161399331},{"_id":"public/css/beantech.css","hash":"c192d3170301f774fa4c2185dc125cb3d6ec4929","modified":1642161399331},{"_id":"public/css/beantech.min.css","hash":"52f8485f36e94a35de73b9cf1eb49b6237fbedc5","modified":1642161399331},{"_id":"public/css/gitalk.css","hash":"51783fd60dff05e8e339ff83b41504538662f6ca","modified":1642161399331},{"_id":"public/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1642161399331},{"_id":"public/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1642161399331},{"_id":"public/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1642161399331},{"_id":"public/css/themecolor.css","hash":"4f64a3b505375296762dd0363284dfcd233ee521","modified":1642161399331},{"_id":"public/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1642161399331},{"_id":"public/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1642161399331},{"_id":"public/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1642161399331},{"_id":"public/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1642161399331},{"_id":"public/js/ziploader.js","hash":"9c25324caf53b56cb68839dcfb34e61e5a6a63f3","modified":1642161399331},{"_id":"public/js/viewer/viewer.min.js","hash":"ae5380974b6fb8b0e15356c8418186c6c0821222","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/25.png","hash":"2a1dd6442f9dcf5bef05e21af5e36b3ce7fb8d6f","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/8.png","hash":"464247afe628c34e89e143b8e957124f341b7ab0","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/2.png","hash":"4e29d71b7a1838146d8d33edca4b921f85d5f47d","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/20.png","hash":"dafb2412b0c64a0367061d1a2c2fd9f5058e6869","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/9.png","hash":"255884029f307486cb0a67ae198553265f26fb21","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/8.png","hash":"59629ca53f15d21efb05add88985235f2bfced6c","modified":1642161399331},{"_id":"public/2020/04/17/Hexo-Theme-LiveMyLife/home_posts_tag-true.png","hash":"3c6f335347d04e093fccc77e916c4a9d0c6c4a75","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/12.png","hash":"98f7d0242ebfb0173eb1c7aa5a54fb523f7259e3","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/18.png","hash":"ddac2712a771144402f7772d85b35dea65486164","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/17.png","hash":"f771ec8e6b83adeba6e7e05b4149fa5dc87aafbb","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/4.png","hash":"cd82f569bb6c8e75506a5bd2ac34cc43b1a139c2","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/5.png","hash":"e305604b2f7bfb81a866e675165ec9caa8f12089","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/1.png","hash":"b32ecfaad5a309fd653094cce1c856521d80030c","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/13.png","hash":"84fdedc4f07471650a70f42ac80aabdcc1e42f93","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/6.png","hash":"c1ae9721492e739134df4f4448b3c9edc789c856","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/7.png","hash":"097aa6166f34c163c875c3bd46fb925aee2cc6a3","modified":1642161399331},{"_id":"public/2022/01/11/子空间学习(1)-PCA/train_pca.png","hash":"eb8514266b2e690cd7404e0d10b4aa484aa19c23","modified":1642161399331},{"_id":"public/2022/01/11/子空间学习(1)-PCA/test_pca.png","hash":"ddbffb7faedb2f0c6cb13e7e96273a80d490ada3","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/pca_swiss.png","hash":"b7a9775b9cc41911435e34b9e58a796bb21ea137","modified":1642161399331},{"_id":"public/2022/01/22/子空间学习(10)-t-SNE/MNIST.png","hash":"f168fe1277a958d12d9eb75090856040822f6abc","modified":1642161399331},{"_id":"public/2022/01/14/子空间学习(4)-LPP&NPE/eig.png","hash":"b1f38c280c82d4bbb9dd6e0d6a1cd869a641bfc7","modified":1642161399331},{"_id":"public/2022/01/14/子空间学习(4)-LPP&NPE/parameter.png","hash":"6e713cff35a4878a6783aef810fbc13dded2955f","modified":1642161399331},{"_id":"public/2022/01/15/子空间学习(5)-GE/com.png","hash":"a9f5597c18e8af3ce000084769e45506c6ed8e02","modified":1642161399331},{"_id":"public/2022/01/16/子空间学习(6)-LDE/parameter.png","hash":"1154289909e3a623334e945b74e2544adcd9d9ae","modified":1642161399331},{"_id":"public/2022/01/17/子空间学习(7)-Spectral Clustering and Normalized Cuts/algorithm.png","hash":"af6fe77c80c3ca2a75689a45cb7c43e3b049eae5","modified":1642161399331},{"_id":"public/2022/01/17/子空间学习(7)-Spectral Clustering and Normalized Cuts/NC.png","hash":"3e1dcf3f2b1b51169eb93d343d3b7a223575b1e9","modified":1642161399331},{"_id":"public/2022/01/19/子空间学习(9)-On Regularization and the Prior/LRR.png","hash":"eb24b0a88479119a0ca2081e0f6d742adba3212d","modified":1642161399331},{"_id":"public/2022/01/19/子空间学习(9)-On Regularization and the Prior/SSC.png","hash":"0ea773f9516f3261c3fa97428102e684263b48d1","modified":1642161399331},{"_id":"public/js/comment/gitalk_.js","hash":"9256bc4b8f7341f60083da291d5c7c9f0fe5f1bd","modified":1642161399331},{"_id":"public/js/comment/gitalk.js","hash":"e5c1b7f8a2803765cff831793af377a9f81fb385","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/10.png","hash":"19522d37e17f636cbaf20323ea2cc02e4338f8c9","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/3.png","hash":"d1a9613609e4e0da24599127b2b5d8fa719edf35","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/3.png","hash":"6b193416623a9e7e2c3c6b684069bfe581182250","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/26.png","hash":"04c26dccb8a01f1b2bb04c1b42ff44efeb3aca6f","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/11.png","hash":"ba1dcd790ef2826c13a6a3df3b2c2a9536b75de1","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/6.png","hash":"7b2a07dce7798cbf191ac23e381b7347c9e8fbf2","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/3.png","hash":"f5829624bbec6690710e99180a00ee27e4e304fa","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/8.png","hash":"7df5bfbe9d7010dd98194d103c0c334fd64cd01b","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/isomap_swiss.png","hash":"e1e8b6f4bcdf5d549b8f45e13974ce1ce179f1e1","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/lle_swiss.png","hash":"bb6c8e9eb7507d6077145381c43069d1654a45fd","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/mds_swiss.png","hash":"02be24187605fa68b74803b3fbd922bcfe514054","modified":1642161399331},{"_id":"public/2022/01/14/子空间学习(4)-LPP&NPE/face.png","hash":"23d124f204367a1eed0fa7bc3b9e8e884da15333","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/23.png","hash":"0fb0c336a54089cc76d96d7a73d12e35928c0e72","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/5.png","hash":"cab3ebe209d832f922e42e3f0f3766dd469b4097","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/1.png","hash":"9b52061b572e5d96b61cf170a0934bb2c225cd10","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/12.png","hash":"c85b3ea1df612c9f7df2ad4e6406539f74c97e42","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/16.png","hash":"fde1297223dfb8622088d347888d17f4ab04739f","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/1617.png","hash":"37cf6f79641d79d3dc64f05eeb0c76cbe188c373","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/17.png","hash":"2be8c7f0effea7fde43f4934c0ecbc8f5653d97d","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/18.png","hash":"eb6c203dc06e97ef1a8aa06ae01e85904f1e1556","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/6.png","hash":"2ca0df262e07af7d8f088205b1fd226be1efb473","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/16.png","hash":"3147d8d8f6d66f7afb8b9efef9fb9fac95229768","modified":1642161399331},{"_id":"public/2022/01/13/子空间学习(3)-LE/swiss.png","hash":"2fb4060eb605de067db0f6ae4e3ab2b809441a66","modified":1642161399331},{"_id":"public/2022/01/22/子空间学习(10)-t-SNE/MNIST2.png","hash":"529aa5a8b1e20a89ab05c0dfacd23d3140a10f0b","modified":1642161399331},{"_id":"public/2022/01/19/子空间学习(9)-On Regularization and the Prior/algorithm.png","hash":"c889f543a8878d0b59ad57fdea2cbcf3cc9f8f49","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/3.png","hash":"21a2d1926611933bba1c2140cbe7dab8ff4d593c","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/12.png","hash":"d7dc3c37fe971c08dc2e31df9a70ec45c30250b8","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/2.png","hash":"ee6d362b84c67960617d9cab7626819ce085f4be","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/4.png","hash":"dfe700faa7de7241431f41d9e9262d36ad1cc7cf","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/5.png","hash":"0343e1400c83b5e943491333e438a56009a80585","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/3.png","hash":"e4757ff9d7fe42e2b803c50a90cb546ac2ed2cb4","modified":1642161399331},{"_id":"public/2022/01/14/子空间学习(4)-LPP&NPE/com.png","hash":"901bb744862c75e8df764a8423cd43750b6e8e63","modified":1642161399331},{"_id":"public/img/avatar/Bin.jpg","hash":"9799f4343389eef20c1e16039c5bde71a995ef1b","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/1314.png","hash":"b834a06dd9a8ad0ffc90b7986a3b3272f1a19cc5","modified":1642161399331},{"_id":"public/2022/01/12/子空间学习(2)-LLE/LLE-Val.png","hash":"49a4b76ebc489ab3b42a0ae02aebd62d72410f57","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/14.jpeg","hash":"fbcdc3e21ce667275d9e3b6e4f3d158741ef5d37","modified":1642161399331},{"_id":"public/img/header_img/8.jpeg","hash":"2b3865efea33e5c711e54de01811e87d5c380ff7","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/4.png","hash":"c7954db6e34d8d8a35739abfd2dd878ff3005e74","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/5.png","hash":"5c93f4b4a467ebd8060f8d1cdeedcd81fd9f0924","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/2.png","hash":"9e021642115d7b2d35d098b71c4ffff8b19d0924","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/4.png","hash":"deecfa48b1498e216b867d610dff8bed6c259d4c","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/8.png","hash":"54acafc791478f7bcd2fac79634f66904ed80581","modified":1642161399331},{"_id":"public/2022/01/17/子空间学习(7)-Spectral Clustering and Normalized Cuts/SC.png","hash":"c310010104c722b78017cb13947efc53db291be0","modified":1642161399331},{"_id":"public/2022/01/18/子空间学习(8)-Sparse Representation/inpainting_yiding.png","hash":"3cf76611ff4d39f47645f054c2a143a124e572b2","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/13.png","hash":"0b54a1edae29f6e90d5a38dcd23b889b2e34b114","modified":1642161399331},{"_id":"public/2021/01/26/2020年数学建模美赛A题/21.png","hash":"00b3cad20acadd14fabafe3a936b1c0a33f9a439","modified":1642161399331},{"_id":"public/2021/01/28/关于使用Vercel和hexo搭建个人主页/14.png","hash":"942f3b3b5c565f8b7dfe3f0539165d5dd0e16a43","modified":1642161399331},{"_id":"public/2020/04/17/Hexo-Theme-LiveMyLife/dark.png","hash":"0eefd914a47c1958e23f5fd9cb854e785763f03c","modified":1642161399331},{"_id":"public/2020/04/17/Hexo-Theme-LiveMyLife/light.png","hash":"8a03996cff1eb0cbda41655e64d5c8fa5e0e9592","modified":1642161399331},{"_id":"public/2020/04/17/Hexo-Theme-LiveMyLife/wave.png","hash":"c933776e89f9f821ee6dfc1622401ec9ce5c9e35","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/7.png","hash":"883791bbe657c720fab27efd1cf790dd4620c223","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/9.png","hash":"dc815469d630853099ea10aeec891016316d96e2","modified":1642161399331},{"_id":"public/2020/04/17/Hexo-Theme-LiveMyLife/livemylife-desktop.png","hash":"45fc4bfd838997c93db72ab389c1c52b18a2d506","modified":1642161399331},{"_id":"public/img/avatar/smile.jpg","hash":"6cae0280505eaee6a8da4f4f6e83e0409e43199f","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/11.png","hash":"d5998d6f87430d96f9b44eaadca4c77687475dc6","modified":1642161399331},{"_id":"public/2020/04/17/Hexo-Theme-LiveMyLife/top.png","hash":"e60e82f384b4ce8455c04d6cd5979d16672954e8","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/10.png","hash":"2cf52f4f7e767c712204f678e0bea85e2d3337c2","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/12.png","hash":"da780aa856effab0dec8c66a8447800c3eb883b3","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/26.jpg","hash":"ce119f17c941ac1d965c234fbe730be1424762f2","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/28.jpg","hash":"a63dc10c445a4c3fa0bea1c06de1667af4a81dde","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/9.png","hash":"401f7f27de5250408f02db9e462f0971bdc5cfa9","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/24.jpg","hash":"3a8c71474e634448247a962f01a99052746e45b0","modified":1642161399331},{"_id":"public/img/header_img/1.jpg","hash":"788f01a7d357e3f14e9bd7d0820e3a058ba08e93","modified":1642161399331},{"_id":"public/2022/01/18/子空间学习(8)-Sparse Representation/Image_debluring.png","hash":"ea0da9797d35945303c4dc3e01acc12199f3587d","modified":1642161399331},{"_id":"public/img/header_img/6.jpg","hash":"7cf3773e7ef5cb29a9fc2c5b35e2d6c54a017a26","modified":1642161399331},{"_id":"public/2021/01/27/基于Yolov4和Deepsort的智能交通场景应用/11.png","hash":"a38237d57eef77fde245842070e2093b7435b7d3","modified":1642161399331},{"_id":"public/img/header_img/4.jpg","hash":"b4bd9331cd50955b02632b032348b5de37f5e299","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/25.jpg","hash":"6e43db885a55aee8a14ce65f0c9009787521005b","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/16.jpg","hash":"c89bb8fdc08db9b9b8742569e12759037bd29dfa","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/21.jpg","hash":"3ea56c9affcdc5b34909f85f7c0709d9c04869bd","modified":1642161399331},{"_id":"public/img/header_img/5.jpg","hash":"fff32018adc37b2bbe62289b32208d7188986172","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/15.jpg","hash":"a408c7de09fcc76c3000e48c82e82d1774baf9f9","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/19.jpg","hash":"179a875cd6bb15daeab5544aaf96ae87ea021a3d","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/20.jpg","hash":"e0c2f2857ba310507bc46dc1f34bff9fdf83b396","modified":1642161399331},{"_id":"public/img/header_img/me.jpg","hash":"561ccafcfd6db165211e10683d71d928c8cc7f84","modified":1642161399331},{"_id":"public/img/header_img/newhome_bg.jpg","hash":"d770c4659027f3d4fe479afb6909ed6968f56d68","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/17.jpg","hash":"349c16855c7ac61521527b68abbc2e6c5176ad58","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/18.jpg","hash":"0128ef630566c82d2f25fcd51910a7d23823b82c","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/1.jpg","hash":"799acc2107267e2f6545b5592bed121f9e1e2ba5","modified":1642161399331},{"_id":"public/img/header_img/2.jpg","hash":"41800ed5f1ee477d631efe6839fdf04583f0cbdd","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/29.jpg","hash":"719cf8285521e90e6e6bcc7db8eba46289f8671f","modified":1642161399331},{"_id":"public/img/header_img/8.jpg","hash":"5a62e5b9a58498312d4dcb7484341dcee9434943","modified":1642161399331},{"_id":"public/img/header_img/3.jpg","hash":"9ebc361943ca015395561ca2057342255ae92bc2","modified":1642161399331},{"_id":"public/img/header_img/tiger.png","hash":"f500b04ade8f15363d6ea3d5b55ba42ecf916c85","modified":1642161399331},{"_id":"public/img/header_img/vehicle.jpg","hash":"ee7302c8ce23867e1dbe3fce20b38776ebad555a","modified":1642161399331},{"_id":"public/img/header_img/categories_bg.jpg","hash":"2acefcb91238d3d17bea6c53881fb8c025ebe370","modified":1642161399331},{"_id":"public/img/header_img/404_bg.jpg","hash":"9a899c297a352c1664d0b7ec44d5fbc0c8c048fd","modified":1642161399331},{"_id":"public/2021/01/27/基于改进Mobilenetv2的东北虎识别平台/27.jpg","hash":"632296607cc5d89bbf0931967d39f6bf4f790431","modified":1642161399331},{"_id":"public/2021/01/27/2020全国大学生数学建模比赛B题/11.png","hash":"1396bc652948acbc18a40b5b636e59af4532d152","modified":1642161399331},{"_id":"public/img/header_img/lml_bg.jpg","hash":"c572aa5a4ed446f43c898c3864bf8b144844ef35","modified":1642161399331},{"_id":"public/img/header_img/tag_bg.jpg","hash":"0cf9fb6a4fdad42dcc936dc9e90cfd3e5b7b8cef","modified":1642161399331},{"_id":"public/img/header_img/archive_bg2.jpg","hash":"ecc208724bde2e07787a9b83191f6e1c755c1422","modified":1642161399331}],"Category":[{"name":"数学建模","_id":"ckyechxwp00043ouegyd1br3x"},{"name":"生活日常","_id":"ckyechxwv000c3oue39spbh4i"},{"name":"Hexo-Theme-LiveMyLife","_id":"ckyechxx2000l3oue561qaq9t"},{"name":"工程项目","_id":"ckyechxx4000r3ouedvhi734q"},{"name":"子空间学习","_id":"ckyechxx800143oue0cbybkdc"},{"name":"算法改进","_id":"ckyechxx8001a3ouecwa16mdp"}],"Data":[],"Page":[{"layout":"about","title":"About","date":"2016-04-20T20:48:33.000Z","description":"将近的晚风快吹干整条小巷，燃尽的灯光无法再将我们点亮","header-img":"img/header_img/1.jpg","_content":"\n> 心生向阳\n>\n> 未来可期\n\n第一次接触计算机知识大概是在成年以后，所以我学习cs的经历并不是一个能从小讲起的故事。高考结束之后，我也对自己的专业有过思考。当年的分数足够在母校里选择大多数的专业，而我只想一心搞钱，于是一入cs深如海，选择了这个容易早年秃顶，中年猝死的专业。\n\n所以故事从刚成年的夏天写起...\n\n18级四川大学计算机科学与技术（试验班）的混日子选手，目前在四川大学XLearning实验室下学习，完成一些比较基础的项目，暂时的研究方向为机器学习。\n\n\n\n### 项目&研究经历\n\n* 物体目标识别与跟踪项目(计算机视觉，网络优化，模块融合) :\n\n* 基于PaddlePaddle 的野生东北虎识别平台(计算机视觉，网络优化，参数改进，迁移学习) :\n* Utooth-口腔健康小游戏(微信云数据库，游戏引擎) :\n* 基于生成式对抗网络和端到端匹配网络的异源图像配准项目(计算机视觉，多模态融合) :\n* To be continued...\n\n\n\n### 联系方式\n\n> 请发送邮箱到：:email:bin.cs@foxmail.com\n>\n> 或者添加我的微信：BiningBin\n>","source":"about/index.md","raw":"---\nlayout: \"about\"\ntitle: \"About\"\ndate: 2016-04-21 04:48:33\ndescription: \"将近的晚风快吹干整条小巷，燃尽的灯光无法再将我们点亮\"\nheader-img: img/header_img/1.jpg\n---\n\n> 心生向阳\n>\n> 未来可期\n\n第一次接触计算机知识大概是在成年以后，所以我学习cs的经历并不是一个能从小讲起的故事。高考结束之后，我也对自己的专业有过思考。当年的分数足够在母校里选择大多数的专业，而我只想一心搞钱，于是一入cs深如海，选择了这个容易早年秃顶，中年猝死的专业。\n\n所以故事从刚成年的夏天写起...\n\n18级四川大学计算机科学与技术（试验班）的混日子选手，目前在四川大学XLearning实验室下学习，完成一些比较基础的项目，暂时的研究方向为机器学习。\n\n\n\n### 项目&研究经历\n\n* 物体目标识别与跟踪项目(计算机视觉，网络优化，模块融合) :\n\n* 基于PaddlePaddle 的野生东北虎识别平台(计算机视觉，网络优化，参数改进，迁移学习) :\n* Utooth-口腔健康小游戏(微信云数据库，游戏引擎) :\n* 基于生成式对抗网络和端到端匹配网络的异源图像配准项目(计算机视觉，多模态融合) :\n* To be continued...\n\n\n\n### 联系方式\n\n> 请发送邮箱到：:email:bin.cs@foxmail.com\n>\n> 或者添加我的微信：BiningBin\n>","updated":"2022-01-14T05:50:31.842Z","path":"about/index.html","comments":1,"_id":"ckyechxwh00003oue6xb3bzip","content":"<blockquote>\n<p>心生向阳</p>\n<p>未来可期</p>\n</blockquote>\n<p>第一次接触计算机知识大概是在成年以后，所以我学习cs的经历并不是一个能从小讲起的故事。高考结束之后，我也对自己的专业有过思考。当年的分数足够在母校里选择大多数的专业，而我只想一心搞钱，于是一入cs深如海，选择了这个容易早年秃顶，中年猝死的专业。</p>\n<p>所以故事从刚成年的夏天写起…</p>\n<p>18级四川大学计算机科学与技术（试验班）的混日子选手，目前在四川大学XLearning实验室下学习，完成一些比较基础的项目，暂时的研究方向为机器学习。</p>\n<h3 id=\"项目-amp-研究经历\"><a href=\"#项目-amp-研究经历\" class=\"headerlink\" title=\"项目&amp;研究经历\"></a>项目&amp;研究经历</h3><ul>\n<li><p>物体目标识别与跟踪项目(计算机视觉，网络优化，模块融合) :</p>\n</li>\n<li><p>基于PaddlePaddle 的野生东北虎识别平台(计算机视觉，网络优化，参数改进，迁移学习) :</p>\n</li>\n<li>Utooth-口腔健康小游戏(微信云数据库，游戏引擎) :</li>\n<li>基于生成式对抗网络和端到端匹配网络的异源图像配准项目(计算机视觉，多模态融合) :</li>\n<li>To be continued…</li>\n</ul>\n<h3 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h3><blockquote>\n<p>请发送邮箱到：:email:bin.cs@foxmail.com</p>\n<p>或者添加我的微信：BiningBin</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>心生向阳</p>\n<p>未来可期</p>\n</blockquote>\n<p>第一次接触计算机知识大概是在成年以后，所以我学习cs的经历并不是一个能从小讲起的故事。高考结束之后，我也对自己的专业有过思考。当年的分数足够在母校里选择大多数的专业，而我只想一心搞钱，于是一入cs深如海，选择了这个容易早年秃顶，中年猝死的专业。</p>\n<p>所以故事从刚成年的夏天写起…</p>\n<p>18级四川大学计算机科学与技术（试验班）的混日子选手，目前在四川大学XLearning实验室下学习，完成一些比较基础的项目，暂时的研究方向为机器学习。</p>\n<h3 id=\"项目-amp-研究经历\"><a href=\"#项目-amp-研究经历\" class=\"headerlink\" title=\"项目&amp;研究经历\"></a>项目&amp;研究经历</h3><ul>\n<li><p>物体目标识别与跟踪项目(计算机视觉，网络优化，模块融合) :</p>\n</li>\n<li><p>基于PaddlePaddle 的野生东北虎识别平台(计算机视觉，网络优化，参数改进，迁移学习) :</p>\n</li>\n<li>Utooth-口腔健康小游戏(微信云数据库，游戏引擎) :</li>\n<li>基于生成式对抗网络和端到端匹配网络的异源图像配准项目(计算机视觉，多模态融合) :</li>\n<li>To be continued…</li>\n</ul>\n<h3 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h3><blockquote>\n<p>请发送邮箱到：:email:bin.cs@foxmail.com</p>\n<p>或者添加我的微信：BiningBin</p>\n</blockquote>\n"},{"layout":"categories","title":"Categories","description":"每个时期都会永存，每个瞬间即永恒","header-img":"img/header_img/categories_bg.jpg","_content":"","source":"categories/index.md","raw":"---\nlayout: \"categories\"\ntitle: \"Categories\"\ndescription: \"每个时期都会永存，每个瞬间即永恒\"\nheader-img: \"img/header_img/categories_bg.jpg\"\n---\n","date":"2022-01-13T09:01:20.850Z","updated":"2022-01-13T09:01:20.850Z","path":"categories/index.html","comments":1,"_id":"ckyechxwn00023oue9zun0qma","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"archive","title":"Archives","header-img":"img/header_img/8.jpg","date":"2017-03-20T12:49:56.000Z","description":"故事开始于一个闷热无聊的夏日...","_content":"","source":"archive/index.md","raw":"---\nlayout: \"archive\"\ntitle: \"Archives\"\nheader-img: \"img/header_img/8.jpg\"\ndate: 2017-03-20 20:49:56\ndescription: \"故事开始于一个闷热无聊的夏日...\"\n---\n","updated":"2022-01-13T09:01:20.840Z","path":"archive/index.html","comments":1,"_id":"ckyechxwr00063oue4ptd7mwa","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"tags","title":"Tags","description":"I don’t know where I am going, but I am on my way......","header-img":"img/header_img/tag_bg.jpg","_content":"","source":"tags/index.md","raw":"---\nlayout: \"tags\"\ntitle: \"Tags\"\ndescription: \"I don’t know where I am going, but I am on my way......\"\nheader-img: \"img/header_img/tag_bg.jpg\"\n---\n","date":"2022-01-14T06:26:22.649Z","updated":"2022-01-13T09:01:23.486Z","path":"tags/index.html","comments":1,"_id":"ckyechxwt00083oue0gilcj5q","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"404","description":"I'm sorry there is nothing that you want , but you can enjoy the scenery here ...","header-img":"img/header_img/404_bg.jpg","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"I'm sorry there is nothing that you want , but you can enjoy the scenery here ...\"\nheader-img: \"img/header_img/404_bg.jpg\"\n---\n","date":"2022-01-14T05:51:39.522Z","updated":"2022-01-13T09:01:08.723Z","path":"404.html","title":"","comments":1,"_id":"ckyechxwu000a3oueeazc0p70","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"2020全国大学生数学建模比赛B题","catalog":true,"date":"2021-01-27T03:56:51.000Z","subtitle":"沙漠掘金的利益最大化研究","top":3,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 于2020年的9月份参加了全国大学生数学建模比赛，第二次参加建模比赛，主要负责论文撰写、模型的设计和验证。在团队中担任了一名相对划水的角色，参赛的时间段正值个人心态爆炸的阶段，导致状态不太靠谱，好在队友非常给力。B题是一道ACM中求最短路的题目，第一问是有标答的，估计后来进国赛也是因为第一问的答案正确，最终在及其神奇的一场答辩中获得了国家二等奖，也算是为我的建模生涯画上了一个比较不错的句号(当然也就参加了两场:smiley:)。\n\n\n\n## 题目大意\n\n考虑如下的小游戏：玩家凭借一张地图，利用初始资金购买一定数量的水和食物（包括食品和其他日常用品），从起点出发，在沙漠中行走。途中会遇到不同的天气，也可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。\n游戏的基本规则如下：\n（1）以天为基本时间单位，游戏的开始时间为第0天，玩家位于起点。玩家必须在截止日期或之前到达终点，到达终点后该玩家的游戏结束。\n（2）穿越沙漠需水和食物两种资源，它们的最小计量单位均为箱。每天玩家拥有的水和食物质量之和不能超过负重上限。若未到达终点而水或食物已耗尽，视为游戏失败。\n（3）每天的天气为“晴朗”、“高温”、“沙暴”三种状况之一，沙漠中所有区域的天气相同。\n（4）每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。沙暴日必须在原地停留。\n（5）玩家在原地停留一天消耗的资源数量称为基础消耗量，行走一天消耗的资源数量为基础消耗量的 倍。\n（6）玩家第0天可在起点处用初始资金以基准价格购买水和食物。玩家可在起点停留或回到起点，但不能多次在起点购买资源。玩家到达终点后可退回剩余的水和食物，每箱退回价格为基准价格的一半。\n（7）玩家在矿山停留时，可通过挖矿获得资金，挖矿一天获得的资金量称为基础收益。如果挖矿，消耗的资源数量为基础消耗量的 倍；如果不挖矿，消耗的资源数量为基础消耗量。到达矿山当天不能挖矿。沙暴日也可挖矿。\n（8）玩家经过或在村庄停留时可用剩余的初始资金或挖矿获得的资金随时购买水和食物，每箱价格为基准价格的2倍。\n请根据游戏的不同设定，建立数学模型，解决以下问题。\n\n* 假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入Result.xlsx。\n\n* 假设只有一名玩家，玩家仅知道当天的天气状况，可据此决定当天的行动方案，试给出一般情况下玩家的最佳策略，并对附件中的“第三关”和“第四关”进行具体讨论。\n\n* 现有 名玩家，他们有相同的初始资金，且同时从起点出发。若某天其中的任意 名玩家均从区域A行走到区域B( )，则他们中的任一位消耗的资源数量均为基础消耗量的 倍；若某天其中的任意 名玩家在同一矿山挖矿，则他们中的任一位消耗的资源数量均为基础消耗量的 倍，且每名玩家一天可通过挖矿获得的资金是基础收益的 ；若某天其中的任意 名玩家在同一村庄购买资源，每箱价格均为基准价格的 倍。其他情况下消耗资源数量与资源价格与单人游戏相同。\n  （1）假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案需在第 天确定且此后不能更改。试给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行具体讨论。\n  （2）假设所有玩家仅知道当天的天气状况，从第 天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。\n\n  注1：附件所给地图中，有公共边界的两个区域称为相邻，仅有公共顶点而没有公共边界的两个区域不视作相邻。\n  注2：Result.xlsx中剩余资金数（剩余水量、剩余食物量）指当日所需资源全部消耗完毕后的资金数（水量、食物量）。若当日还有购买行为，则指完成购买后的资金数（水量、食物量）。\n\n## 题目解答\n\n第一二问的核心是建立一个最短路模型，当然在后面和夏大佬的讨论中，我们得知建图的方法不唯一，所谓条条大路通罗马嘛。我甚至怀疑在四川赛区的国赛答辩中，有人是通过非常玄学的方式手算进的答辩，而这只是个人推测嘛，事实如何也并不重要。然后题目的第三问是一道非常扯的题目，很多人都初步了解过博弈这个知识点，但是我们通常了解的都是双人博弈，在过去的ACM训练中，我感觉这是很难弄懂的一个板块，会涉及到一定的数学推导。但事实上第三问并非双人博弈，而是多人博弈模型，所以...\n\n我们在搜集了大量的资料后，对第三问的解法还是一知半解，于是最终采用了相对比较合理的多人博弈模型，但是也仅供大家参考。\n\n### 摘要\n\n考虑如下的小游戏:玩家凭借一张地图，利用初始资金购买一定数量的水和食物 (包括食品和其他日常用品)，从起点出发，在沙漠中行走，途中会遇到不同的天气，也 可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。\n\n本文主要尝试建立一种在算法和逻辑层面都优化的最短路算法(OLBA模型)，在此 基础上进行适当的改进已应对各种不同的参数设定情况，给出了附件excel 表格的解决方案。同时使用了博弈论来求解第三题中的两个问题，根据实际题目的情况，给出了一般情况下玩家应采取的策略。\n\n对问题一，建立了OLBA模型并使用了带队列优化的BellmanFord模型求最短路， 对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，对模型的情况进行了优化。该模型适用于所有可能情况，鲁棒性强，最后用附件中的样例来验证模型是否正确。第1关最优路径结论:在起点购买178 箱水和 333 箱食物，走如图2的路线到终点资金数最大，为10470。第2关最优路径结论:在起点购买130 箱水和405箱食物，走如图2的路线到终点资金数最大，为12730。\n\n对问题二，基于第一问建立的OLBA模型进行改进， 将每个连接分成三种天气进行讨论，对边权进行更新和推导，输出任意区域的任意天数下的最大期望收益，从而给出一般情况下的最优决策，得到最终模型(W-OLBA模型)这是一种合理的一种改进模型，核心是求策略集合中期望收益最大的状态，该状态即为玩家的最佳策略下的选择， 具体情况需要具体分析。\n\n对问题三，针对第一问建立了基于改进的OLBA和混合博弈模型的多玩家同策略集模型(MCSM模型)，使用收益相等法计算纳什均衡，为了避免非最优策略和最优策略 有过多的重复路径，将原始图模型G划分成了n个子图 最终在一般情况下玩家应该选择本文图5所展示的A或者C策略的任意一条。针对第二问建立了多阶段纳什均衡和子博弈完美均衡的博弈模型(MNSE模型)，基于W-OLBA模型在利用逆向归纳法求解子博弈纳什均衡的过程中，从动态博弈的最后一个阶段或最后一个子博弈开始，逐步向前倒推，从而达到求解动态博弈均衡的目的。\n\n### 符号说明\n\n![1](2020全国大学生数学建模比赛B题/1.png)\n\n### 第一题求解\n\n题目要求假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入 Result.xlsx。\n\n由于我们要给出一般情况下玩家的最优策略，所以第一问的思路是先建立数学模型，最后用附件中的样例来验证答案是否正确。我们根据参数设定、天气状况和地图综合考虑到达终点的所有情况，这里便涉及到了非常多的问题，是否去村庄，是否去矿山， 是否停留。当然如果仅仅从第一关和第二关给出的数据去讨论到达终点的情况是非常片面而且麻烦的。所以我们首先想到基于动态规划模型 (DP 模型) 来思考这道题的结题思路，这样我们的目标终点就不仅仅是某个点，而是一般情况的所有点，同时可以根据不同的参数设定、天气状况和地图去改变 DP 的过程，符合题目要求。\n\n我们考虑状态的定义，就是最终 DP 的过程量，我们发现第一问影响到结论的不仅仅是到达终点的位置，同样也有负重上限 (水的限制、食物的限制) 和时间上限，因为在保持到某个点的最大收益的同时也要保证负重上限和时间上限没有被超过。如果将这四个数组都搜索一遍，这道题的时间复杂度将达到 O($TnM_{water}M_{food}log(TnM_{water}M_{food})$)， 我们假设普通计算机一秒运算$10^{8}$左右次，在这个复杂度的限制下，我们所能处理的最大的数据规模将被限制在  $TnM_{water}M_{food}$的乘积在$5\\times10^{5}$个数据以内，仅仅处理这道题的所有问题显然足够，但是并非最优，所有我们考虑优化这个时间复杂度。于是我们对图的数据进行了预处理缩点，将最短路直接连边。\n\n![1](2020全国大学生数学建模比赛B题/2.png)\n\n由于题目中的第四个条件规定了每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。不难看出这是一个建图的过程，我们将位置信息和时间信息作为图的节点加入图 中，然后设动态规划过程量以位置和负重上限作为标记，而这个数组的值，便是在某个负重上限的限制里到某一节点的最大收益，即:\n\nd[i] [j] [k]= 在水和食物的箱数分别至少备 j 箱和 k 箱的情况下，从起点到第 i 个点的最小花销。\n\n有向图模型得出后，转化这道题的题意，将核心从在规定时间内到达终点，并保留尽可能多的资金，转化为在规定时间内到达终点，并尽可能减少花销。这道题将转化为求最短路，我们采用队列优化带限制的 BellmanFord 算法。我们将所有的目标终点的但不同时间的节点都连到一个最终节点，我们求得最短路就是将出发点的第 0 天作为起点，将刚刚提到的最终节点作为终点，求得的一个最短路径，每个边权就是这一天的花销(可能为负)。同时由于在终点卖出食物和水的价格是原价的一半，所以我们优化模型在最后达到终点后的水和食物剩余量为 0。\n\n建图规则：\n\n* 每条边保存三个值，分别为边的权值、消耗的水的箱数、消耗的食物的箱数。\n* 连节点的方法，边的种类有三种，分别为相同区域相邻天数节点之间的连边（原地停留）、相邻区域相邻天数节点的连边、挖矿连边。其中相同区域相邻天数节点的连边的权值为 0，消耗的水和食物的箱数为基础消耗，相邻区域相邻天数节点的连边的权值为 0，消耗的水和食物为基础消耗的 2 倍，挖矿连边的权值为基础工资，消耗的水和食物的箱数为基础消耗的 3 倍，相邻区域由当前节点 (第 i 个位置，第 j 天) 可以到达相邻点节点 (相邻点的位置，第 j+1 天) 或者原地停留到 (第 i 个位置，第 j+1 天)。\n* 初始位置为起点的第 0 天。如果不能走到终点，那么最终节点的最小花销值将是INF(无穷大)，如果能走到终点，终点的每一天与最终节点相连，取$D^{i}_{destination}$  ( $1\\leq i \\leq T$)。\n\nOLBA 模型伪代码如下:\n\n \n\n------\n\n输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：\n\nn， m 区域以及相邻区域关系的数目\n\nK：负重上限\n\nInit S: 初始资金\n\nDDL：截止日期\n\nIncome： 基础收入 \n\nWater：一箱水的重量和价格\n\nFood：一箱食物的重量和价格\n\nConsume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴\n\nWeather[DDL]： 当前天气       \n\nMine[n]：区域的类别，其中 1 代表矿山，2 代表村庄\n\nD[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益\n\n输出：最优路线\n\n------\n\n带限制的 BellmanFord\n\n------\n\n算法：\n\n初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。\n\n------\n\n建图：\n\n------\n\n顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。\n\n边：存储 3 个值，分别为权值 val（权值为从上一个状态到当前状态所需的花费，其中只有挖矿边有权值，其余为 0）、从上一个状态到下一个状态所消耗的水的箱数 W、从上一个状态到下一个状态所消耗的食物的箱数 F。\n\n建边规则：\n\n同一区域相邻天数顶点之间的边：权值为 0，消耗的水和食物箱数为基础消耗。\n\n矿山顶点直接按挖矿事件的边：权值为基础收入，消耗的水和食物箱数为基础消耗的 2\n\n倍。\n\n相邻区域相邻天数顶点（同时天气不为沙暴）之间的边：权值为 0，消耗的水和食物箱数为基础消耗的 3 倍。\n\n* 步骤一：队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。（由于本小题天气情况已知，因此到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解），将状态（T，j，0，0，0）放进队列中，其中 T 为终点区域，j 为日期天数。\n* 步骤二：\n\n1. 从队列中取出顶点 x。\n\n2. 判断该状态是否为属于起点区域中的第一天，如果是，更新答案ans = max(ans， 该状态的 d 值减去水和食物的价格)。\n\n3. 判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：\n\n（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n4. 更新同一区域相邻天数和相邻区域相邻天数的 d 值，如果同一区域相邻天数的 d 值或相邻区域相邻天数的d 值大于在当前状态下d 值加上两者之间边的权值，则更新同一区域相邻天数的d 值或相邻区域相邻天数的d 值，如果该状态不在队列中，则将其加入队列。\n\n* 步骤三：重复步骤二，直至优先队列为空。\n* 步骤四：输出最优路线\n\n------\n\n\n\n我们使用c++ 代码，在使用了队列优化带限制的BellmanFord 算法，后我们得出了每天的一个行动轨迹和最终的金额。第 1 关和第 2 关的路线图如下:\n\n![3](2020全国大学生数学建模比赛B题/3.png)\n\n具体每一步的资金消耗图如下:\n\n![4](2020全国大学生数学建模比赛B题/4.png)\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第一二关的过程图</center>\n\n最终的结论是，如图所示，结合 Result.xls 中表格。\n\n玩家在第一关的最优方案可表述为：\n\n玩家在起点购买 178 箱水和 333 箱食物，从此处出发，第 13 天依次走到区域 25、24、23，第 4 天停留在 23 区域，第 5、6 天依次走到区域 22、9；第 7 天在区域 9 停留后，第 8 天走到区域 15，即村庄，在此购买 163 箱水；第 9、10 天依次走到区域 14、12，然后第 11 天开始在区域 12 挖矿；连续挖矿 9 天后，第 20 天离开矿区进入区域 14，然后走到村庄（区域 15），并购买 36 箱水和 40 箱食物，以满足行程最后三天所需；第 22天从村庄走到区域 9，途径区域 21，在第 24 天抵达终点（即区域 27）。\n\n此时剩余资金数最大，为 10470，没有剩余的水和食物。\n\n第二关的最优方案表示为：\n\n玩家在起点购买 130 箱水和 405 箱食物，依次经过区域 9/10/19/20/28/30，到达村庄1（即区域 39），玩家在此处购买 168 箱水和 54 箱食物，然后途径区域 47 到达矿区 1（区域 55）挖矿；从第 14 天（到达矿区我的第二天）开始，连续挖矿 5 天，然后去村庄2（区域 62）购买 185 箱水和 8 箱食物，然后回到矿区 1（区域 55）挖矿 8 天；在第 29 天的时候，离开矿区 1（区域 55），经区域 56 到达终点（区域 64）。\n\n到达终点时剩余资金数为 12730，无剩余的水和食物。\n\n### 第二题求解\n\nW-OLBA 模型伪代码如下:\n\n------\n\n输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：\n\nn， m 区域以及相邻区域关系的数目\n\nK：负重上限\n\nInit S: 初始资金\n\nDDL：截止日期\n\nIncome：基础收入\n\nWater：一箱水的重量和价格\n\nFood：一箱食物的重量和价格\n\nConsume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴 \n\nMine[n]：区域的类别，其中 1 代表矿山，2 代表村庄\n\nD[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大期望利益\n\nDp[i] [j] [k] [t]：代表该状态 i 下拥有 j 箱水和 k 箱食物在天气 t 下所能取得的最大期望收益\n\n输出：输出任意区域的任意天数下的最大期望收益\n\n------\n\n概率 DP 算法：\n\n------\n\n初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。\n\n------\n\n建图：\n\n------\n\n顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。\n\n边：权值为从上一个状态到当前状态所需的花费。\n\n* 步骤一：\n\n队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。将状态（T，j，w，f）放进优先队列中，其中 T 为终点区域，j 为任意天数，w， f 为任意满足条件的值，同时更新该状态下的 d 值。\n\n* 步骤二：\n\n1. 从队列中取出顶点 x。\n\n2. 判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：\n\n（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n3. 更新同一区域相邻天数和相邻区域相邻天数的 dp 值:\n\n每个连接分成三种天气进行讨论：\n\n在不同天气下，在天气k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f，如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值。\n\n如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值，如果该状态不在队列中，则将其加入队列\n\n* 步骤三：重复步骤二，直至优先队列为空。\n\n* 步骤四：输出任意区域的任意天数下的最大期望收益\n\n------\n\n 状态 [i，j，w，f] 代表区域 i 第 j 天玩家拥有的水的箱数 w 以及食物箱数 f，d 值代表该状态下的最大期望收益。\n\n首先根据算法 2 计算出所有的 d 值，然后进行决策，决策过程如下：\n\n找出该状态下的所有相邻状态集合，然后找出集合中 d 值最大的状态，该状态即为玩家的最佳策略下的选择。\n\n![5](2020全国大学生数学建模比赛B题/5.png)\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第3关动态决策示例</center>\n\n本文在第三关中共取出来 4 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。\n\n1. 状态[1，1，200，200] 在晴朗天气的情况下有相邻状态为[4，2，194，192]，[1，2，197，196]，其d 值分别为 [868.00，574.00]， 因此在该状态下最佳策略的选择为状态 [4，2，194，192]； \n\n2. 状态[3，5，200，200] 在高温天气的情况下有相邻状态为[9，6，182，182]，[4，6，182，182]，[3，6，191，191] 其d 值分别为 [1971.00，860.00，1310.67]， 因此在该状态下最佳策略的选择为状态 [9，6，182，182]；\n\n3. 状态[6，15，200，200] 在高温天气的情况下有相邻状态为[13，16，182，182]，[4，16，182，182]，其d 值分别为[860.00，860.00，569.66]， 因此在该状态下最佳策略的选择为状态[13，16，182，182]或 [4，16，182，182]；\n\n4. 状态[9，20，200，200] 在晴朗天气的情况下有相邻状态为[11，21，194，192]，[3，21，194，192]， [9，21，191，188] 其d 值分别为 [1282.33，1282.33，1948.67]， 因此在该状态下最佳策略的选择为状态 [9，21，191，188]；\n\n本文在第四关中共取出来 5 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。\n\n1. 状态 [1，1，150，200] 在晴朗天气的情况下有相邻状态为 [6，2，144，192]，[1，2，147，196]，其 d 值分别为 [324.67， 193.33]， 因此在该状态下最佳策略的选择为状态 [6，2，144，192]；\n\n2. 状态 [7，5，200，200] 在高温天气的情况下有相邻状态为 [8，6，182，182]，[6，6，182，182]，[7，6，191，191] 其d 值分别为 [362.33，362.33，237.67]， 因此在该状态下最佳策略的选择为状态 [8，6，182，182] 或 [6，6，182，182]；\n\n3. 状态[14，10，200，200] 在沙暴天气的情况下有相邻状态为[19，11，180，180]，[9，11，180，180]，[14，11，190，190] 其d 值分别为 [1298.67， 558.00， 863.00]， 因此在该状态下最佳策略的选择为状态 [19，11，180，180]；\n\n4. 状态[18，15，200，200] 在高温天气的情况下有相邻状态为[19，16，182，182]，[17，16，182，182]， [18，16，173，173] 其 d 值分别为 [1297.67，1297.67，1954.00]， 因此在该状态下最佳策略的选择为状态 [18，16，173，173]；\n\n5. 状态[20，20，200，200] 在晴朗天气的情况下有相邻状态为[25，21，194，192]，[19，21，194，192]，其d 值分别为[515.67，1256.33，811.67]， 因此在该状态下最佳策略的选择为状态[19，21，194，192]；\n\n### 第三题求解\n\n#### 第三题第一问求解\n\n题目给定了新的多人掘金游戏模型，假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案在第 0 天确定且此后不能更改。我们了给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行了具体讨论。\n\n该问基于改进的 OLBA 和混合博弈模型（完全信息的静态博弈），建立了多玩家同策略集模型 (MNSM 模型)。\n\n在这种情况下可以视每位玩家都有心中的一个最优策略，那么当多人参加这个游戏时，就涉及到了相互之间的博弈。参加斗争或竞争的各方各自具有不同的目标和利益。为了达到各自的目标和利益，各方必须考虑对手的各种可能的行动方案，并力图选取对自己最为有利或最为合理的方案。博弈论就是研究对策行为中斗争各方是否存在着最合理的行动方案，以及如何找到这个合理的行动方案的数学理论和方法。同时由于所有信息都给定，这可以看作完全信息博弈。\n\n我们确定了本问中博弈论的三大要素：\n\n(1). 局中人数: 根据题目要求，玩家人数为 n。\n\n(2). 策略集: 本题的策略集采用第一问的 OLBA 模型，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上，将会有次优策略、第三优策略等等，每一个新的最优策略建立在已经加入策略集的策略之上， 我们一步步挑选这些策略加入策略集，直到当一个策略满足: 该策略的收益$E_{cur}$小于等于直接从起点走带限制的最短路径到达终点的收益$E_{direct}$。此时如果再将操作继续下去将没有实际意义，故可以不考虑，对算法进行剪枝。将直接从起点走带限制的最短路径到达终点的策略也加入策略集，当前策略集中便是最终的本问所要使用的策略集S。设策略集的个数为 m，玩家 i 的有限纯策略集合可视作：\n$$\nS_{i}=s_{i 1}, s_{i 2}, \\cdots, s_{i m}\n$$\n为了避免次优策略等非最优策略和最优策略有过多的重复路径，我们需要对原始图模型G 进行划分，即求图G 中顶点集V 的划分 V1， V2， ...， Vn，将 G 分成n 个生成子图G[V1]， G[V2]， ...，G[Vn]， 使得：\n\n![6](2020全国大学生数学建模比赛B题/6.png)\n\n(3). 支付函数: 由于是多人的博弈，求支付函数的过程，也就是求纳什均衡的过程。支付函数由每个玩家的收益期望根据纳什均衡决定，故首先我们需要定义玩家 p 做决策i 的收益 Upi。\n\n该收益 Upi 由两大部分组成：\n\na. 基础收益：在只有一个玩家的情况下，玩家 p 做决策 i 的最后剩余资金量 Bpi\n\nb. 综合损耗：在其他玩家的影响下所减少的资金。该损耗由两大影响因素决定：\n\n* 选择该决策 i 的玩家人数 K（假设选择决策 i 的人数为 Ki）\n* 其他决策 j 对该决策的固有损耗以及选择决策 j 的玩家人数 Kj\n\n对于本问，我们首先需要得出策略集。纯策略纳什均衡是指在一个纯策略组合中， 如果给定其他的策略不变，该节点不会单方面改变自己的策略，否则不会使节点访问代价变小。由于策略集可能会比较大，使用纯策略纳什均衡会难以选出最优策略，这时我们考虑加入混合策略纳什均衡博弈的模型。混合策略纳什均衡是面对其他博弈者选择的不确定性的一个理性对策，其主要特征是作为混合策略一部分的每一个纯策略有相同的期望值，否则，一个博弈者会选择那个期望值最高的策略而排除所有其他策略，这意味着原初的状态不是一个均衡。我们设定游戏中每个人都会选择混合策略来考虑自己一开始的路线。\n\n我们将采用收益相等法，来计算纳什均衡，在得出概率情况之后，由于要给出一般情况下的最优策略，我们需要去具体去衡量每个人选择不同策略的概率，我们通过收益来权衡每个人选择不同策略的概率。将每个人选择不同策略的概率与纳什均衡得出的概率比较，得出一般情况下的最优决策模型。\n\n在上述模型建立的基础上，我们对附件中的“第五关”进行具体求解：\n\n（1） 确定局中人数 n=2。\n\n（2） 根据第一问 OLBA 模型确定策略集。\n\n首先加入的是最优策略，第 5 关最优策略如图:\n\n根据第一问的 OLBA 模型确定最优解为 1->4->6->13，最后收益为 9535。如图所示，按模型中的四个约束对图进行划分：\n\n在子图（图中阴影部分）得出的最优解为：1->2->3->9->10->13，最后收益为 9325。即策略 A 的收益为 9539，策略 B 的收益为 9325，按上述方法，以此类推，得出： 策略 C：1->5->6->13，收益为 9535\n\n（3） 计算支付矩阵\n\n上述收益均为基础收益，还需按照上述公式计算最终收益：\n\n|      |       A        |       B        |       C        |\n| :--: | :------------: | :------------: | :------------: |\n|  A   | (8140 ，8140 ) | (9535 ，9525 ) | (9370， 9370 ) |\n|  B   | (9535 ，9525 ) | (6400 ，6400 ) | (9535 ，9525 ) |\n|  C   | (9370， 9370 ) | (9535 ，9525 ) | (8140 ，8140 ) |\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/7.png\" width=\"400\"/>    <img src=\"2020全国大学生数学建模比赛B题/8.png\" width=\"400\"/> </center>\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第5关模型和路线结果</center>\n\n玩家 1（行）选择 A 的概率为 p1，选择 B 的概率为 p2，选择 C 的概率为 p3；\n$$\np1 + p2 + p3 = 1\n$$\n玩家 2（列）选择 A 的概率为 s1，选择 B 的概率为 s2，选择 C 的概率为 s3;\n$$\ns1 + s2 + s3 = 1\n$$\n玩家 1 选择 A 的期望收益等于玩家 1 选择 B 的期望收益等于玩家 1 选择 C 的期望收益，玩家 2 同理。\n\n利用LINGO 求解得到玩家 1 选择A 策略的概率p1 = 0.4012，p2 = 0.1977，p3=0.4012， 期望收益为 8910.402。\n\n玩家 2 选择 A 策略的概率 s1=0.4404，s2=1992，s3=0.4404;\n\n从博弈论的角度来看，两名玩家均选择策略 A 或均选择策略 C 对自己一方的效益最大；题目要求给出一般情况下玩家应采取的策略，由于 A，C 策略期望和概率是相同的，并且都是最大的，那么该名玩家可以选择 A 或者 C。\n\n但从团体最优的角度来看，为了使整体利益最大，应该一名玩家选择A，一名玩家选择 B\n\n#### 第三题第二问求解\n\n本问规定所有玩家仅知道当天的天气状况，从第天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。\n\n本问在第二问所建立的模型基础上，建立多阶段博弈模型，多阶段博弈扩展形也称为“博弈树”。动态博弈各个博弈方的选择行为有先后次序，多阶段博弈第一个行动选择对应的决策节称为初始节，多阶段博弈一个选择节点所包含的所有信息叫做“信息集”。各博弈方的选择行为会依次形成相连的博弈阶段，因此动态博弈中博弈方的一次选禅行为常称为一个“阶段”。一个动态博弈至少有两个阶段. 因此动态博弃有时也称为“多阶段博弈”。此外. 也有称动态博弈为“序贯博弈”的，多阶段博弈多阶段博弈序贯博弈是指博弈方选择策略有时间先后的博弈形式。同矩阵表示法相比扩展式所扩展的主要是博弈方的策略空间，多阶段博弈即某个博弈方在什么时候行动，多阶段博弈行动时有哪些策略可以选择，以及知道哪些关于博弈的信息在多阶段博弈模型中，当局中人的策略在每一个子博弈中都构成纳什均衡时，则形成“子博弈精炼纳什均衡”。\n\n因此，问题简化为求解每一步博弈的纳什均衡。对于每一步博弈的纳什均衡，我们采用第三题第一问的方法，即依次确定决策集、支付函数。\n\n在求解问题二所建立的模型中，我们为了得到最优方案，需要计算玩家在每一步距离终点的效益期望，然后选择效益期望最大的作为下一步的策略选择。因此，在本问中， 我们利用问题二所建立的模型中所得到的“每一步的效益期望”，作为子博弈过程中的效益矩阵中的元素，进而求解每一步的纳什均衡。具体步骤如下：\n\n（1） 利用问题二的模型求解该图模型“每一步的效益期望”\n\n（2） 将每一步的效益期望作为该步博弈中的支付矩阵，求解其纳什均衡（求解方法同问题二第一问）\n\n（3） 重复（2）的过程，求解每一步博弈的纳什均衡，直到归纳到第一个阶段的博弈\n\n输出最后的博弈结果流程图如下：\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/9.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 多阶段博弈流程图</center>\n\n（1）由于第六关和第四关的地图完全一致，故第六关基于(1)(2)问所建立的图模型以及求解该图模型所得到的结果，即“每一步的效益期望”求解。\n\n（2）在第二问我们所得到的结果中，最后一个状态为 [20,20,200,200]，即玩家在第 20 天到达区域20 所拥有的水的箱数为 200，所拥有的食物的箱数为 200，该状态下所有状态的集合为 [25,21,194,192],[19,21,194,192],[20,21,197,196] 该集合中元素的期望效益所构成的元\n\n组为 [515.67,1256.33,811.67]。在第二问中，我们选择最大期望收益作为策略。但在此问中，我们考虑的是一个动态博弈过程，因此我们将这些期望收益作为玩家的支付矩阵中的对应策略集。\n\n得到效益矩阵如下：\n\n|      | A              | B                 | C               |\n| ---- | -------------- | ----------------- | --------------- |\n| A    | (515.7,515.7 ) | (515.7,1256.3)    | (515.7,811.7)   |\n| B    | (515.7,1256.3) | (1256.3, 1256.3)  | (1256.3,811.7 ) |\n| C    | (515.7,811.7 ) | (1256.3 , 811.7 ) | (811.7,811.7 )  |\n\n（3） 重复步骤二：我们可以得到每一步博弈后玩家的效益矩阵与选择概率\n\n（4） 综合考虑这些选择概率，我们得到三名玩家在博弈情况下相对最优路径分别为：\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/10.png\" width=\"400\"/> </center>\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 第6关结果图</center>\n\n### 模型优缺点及改进\n\n#### 优点\n\n* 第一题的 OLBA 模型使用了带队列优化的BellmanFord 模型求最短路，同时对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，这一点大大改进了解决该问的时间复杂度和空间复杂度。并且利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，完善了对模型的情况进行了限定 (如：到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解)。在 c++ 编程下以最快的速度解决同类型问题。该模型适用于所有可能情况，鲁棒性强。\n\n* 第二题基于第一问建立的 OLBA 模型进行改进, 将每个连接分成三种天气进行讨论：在不同天气下，在天气 k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f， 如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值，如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值。这样的数学建模过程，思路严谨并且顺畅，是比较合理的一种改进方法，在第 3,4 关模型中取得了非常好的效果。\n\n* 第三题第一问采用基于改进的 OLBA 和混合博弈模型的多玩家同策略集模型(MNSM 模型)，相对于纯决策博弈更加严谨和适用，策略集选择更加合理，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上。采用收益相等法，来计算纳什均衡，在得出概率情况之后，具体通过收益来线性权衡每个人选择不同策略的概率，得出最优决策模型，建模过程合理简单但不失合理性，代码运行速度快。\n\n  第三题第二问采用基于多阶段纳什均衡和子博弈完美均衡的博弈模型 (MNSE 模型), 算法的选取契合本文动态博弈的机制, 每一步的效益，就用第二大问的算法直接得出，这样就得出每一阶段的支付矩阵, 算法符合实际情况，最终得出每一步的玩家最优决策模型。\n\n#### 缺点\n\n* 第三题第一问中将图划分为若干子图的过程尽管有严谨的逻辑推导与理论基础，但在实际操作过程中，若图的规模特别大，操作起来时间复杂度会特别高，从而导致求解效率较低。\n* 第三题第二问的博弈模型对效益考虑的模型存在一定的主观性，如果能够对所有路线的效益进行实时的收益考虑，第三题的准确性将大大提升，这样需要改进算法的时间复杂度以应对规模更大的一般情况。\n\n#### 改进\n\n* 能够在本文的 OLBA 模型下，研究严密的数学逻辑，对图进行一定的缩小，再通过合理减少连边以减小模型的复杂度。在本文建立的 MNSE 模型，在玩家较多的时候，对期望收益进行考虑的复杂度太大，希望能够通过优化模型思路，让模型更加适用于一般情况。\n\n## 关于答辩\n\n在答辩的前第二天的晚上才收到了答辩的通知，作为工具人1号，被安排上了主答辩的位置。匆匆忙忙地整理了套很久没洗的正装，熬夜做PPT到凌晨2点，睡醒了又得知...貌似不用PPT答辩，虽然人傻了，但是生活还得继续嘛。\n\n由于答辩前的第二天(在还没有接到答辩消息的时候)答应了和朋友出去看电影，于是在答辩前一天地上午急急忙忙地整理好了稿子放在了手机里，便出门赴约了，回来的时候已经大概晚上九点了。才开始急急忙忙地背稿子，关键是两千多字的稿子对我来说就...太离谱了。对于一个早年英语单词认不得和语文古诗默写常年丢分的人来说，背书是不可能背的，于是记了个大概，就睡了。\n\n时间来到答辩当天，早上五点闹钟响了，现在看来还挺佩服那个时候竟然能起得来。跟着学校其他答辩的人(一共四个组)来到了西南交大希望学院，逛了会校园，便在候场室门口准备着答辩。由于早上忘换鞋了，于是有了经典的一幕，西装配运动鞋，带着这么一身时髦的打扮走进了答辩室。\n\n答辩过程非常的刺激，才说了不到100个字就被打断了，老师说你别说那么多废话(现在想来也不应该说什么客套话哈哈)。那个数学学院的老师开始了精彩地发问，首先问我们代码是不是自己写的，当然这个问题没有价值。然后问我们第一题解题过程是如何推导的？？？我直接黑人问号\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/1.jpg\" width=\"400\"/> </center>\n\n\n\n这不是个算法吗，就是建立了一个通用的模型，伪代码也交待地非常清楚。但是老师还是不依不饶，问我们一些非常沙雕的数学公式问题，想了想就一个最短路模型哪来的公式，damn。可能是我才学疏漏吧。\n\n然后老师问了一个全场最佳的问题，他指着我们的一行c++代码，提问这行语句是干嘛的。卿卿宝贝很认真解释了这段代码在整个程序的作用。老师操着一口四川话一脸正经地说：“我想问的不是这个，我只想问这段话什么意思”，于是我们开始了七嘴八舌地回答，没有回答到点子上。直到卿卿宝贝灵机一动告诉他：“这是个if语句，如何前面的括号里面的条件为真.......，那么程序就会执行这个if语句里面的内容......”，老师心满意足地点了点头.......，直到这一刻我才明白，可能这样的答辩确实也不需要准备吧。涛哥等待了很久的第三题的问答环节也没有上演，实际上整个答辩过程老师也只问了第一题的解答。\n\n在十五分钟的煎熬之后，我们走出了答辩室，虽然大家人傻了，但是这段经历也告诉了我们，如何和各个学院的老师进行生动地代码解释是多么重要。毕竟各行各业嘛，你觉得甚至不需要解释的一个点，别人也可能不懂，他想知道的，也仅仅是那一个点而已。\n\n整个答辩的核心也就是：证明这些东西是我们自己完成的就行了。\n\n答辩结束，下一组是夏大佬和涵哥的答辩(还是为:chicken:拔占领了川大建模的半B江山骄傲哈），他们出答辩室之前，我精准预测，夏哥见我们第一句必定是抱怨那个老师。一会过后，果不其然，隔着一个走廊便传出了一阵熟悉声音：“这老师是xx吧”。整个答辩过程在一阵欢声笑语中打出了GG。\n\n走出来教学楼，逛了逛校园，合影留念，第一次应该也是最后一次的国赛经历便写到了最后。\n\n临走前，我开始回忆起这段经历，能走到这里挺意外的，要不是建模题出在了ACM题头上，我相信我们应该并不会来到这里，而我个人在整个建模过程付出的努力也就普普通通，甚至让我觉得自己也不配这份荣誉。这时天空下起了小雨，望着远处来来往往的人群，只是觉得这一切很不真实，很玄幻，而这种感觉，没想到会持续一整个学期(当然这是后话了)。\n\n## 后记\n\n现在回想起建模那几天也算是一段非常精彩的回忆，那周好像是身体与心理的双重暴击吧。前阵子刚从学校的心理辅导室走出来，长达一个多月的失眠还有掉头发让我的身体也是拉响了警钟。建模过程中也生了一些小病，而在建模最后一天的下午由于去参加CSP考试导致我们浪费了一下午的时间，论文也是匆匆生成便提交上去，这也可能是我们与一等奖无缘的原因吧，现在倒回去看那篇论文的排版确实也是漏洞百出，实属工作失误害。\n\n在论文截止提交前的两个小时，还和代总联系着要不要去演协的最后一次聚餐，那时我们的论文并没有很完善，但是我心里想着可能这次不去，有些人大概是永远都再见不到了吧，匆匆忙忙地离开了建模的现场，去见了想见的人，也算没有留下遗憾吧。\n\n这里得着重感谢两位队友的付出，幸好结果是令人满意的。\n\n附这张亮堂堂的奖状：\n\n![11](2020全国大学生数学建模比赛B题/11.png)","source":"_posts/2020全国大学生数学建模比赛B题.md","raw":"---\ntitle: 2020全国大学生数学建模比赛B题\ncatalog: true\ndate: 2021-01-27 11:56:51\nsubtitle: 沙漠掘金的利益最大化研究\ntop: 3\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- C++\n- Matlab\n- Latex\n- Python\ncategories:\n- 数学建模\n---\n\n> 于2020年的9月份参加了全国大学生数学建模比赛，第二次参加建模比赛，主要负责论文撰写、模型的设计和验证。在团队中担任了一名相对划水的角色，参赛的时间段正值个人心态爆炸的阶段，导致状态不太靠谱，好在队友非常给力。B题是一道ACM中求最短路的题目，第一问是有标答的，估计后来进国赛也是因为第一问的答案正确，最终在及其神奇的一场答辩中获得了国家二等奖，也算是为我的建模生涯画上了一个比较不错的句号(当然也就参加了两场:smiley:)。\n\n\n\n## 题目大意\n\n考虑如下的小游戏：玩家凭借一张地图，利用初始资金购买一定数量的水和食物（包括食品和其他日常用品），从起点出发，在沙漠中行走。途中会遇到不同的天气，也可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。\n游戏的基本规则如下：\n（1）以天为基本时间单位，游戏的开始时间为第0天，玩家位于起点。玩家必须在截止日期或之前到达终点，到达终点后该玩家的游戏结束。\n（2）穿越沙漠需水和食物两种资源，它们的最小计量单位均为箱。每天玩家拥有的水和食物质量之和不能超过负重上限。若未到达终点而水或食物已耗尽，视为游戏失败。\n（3）每天的天气为“晴朗”、“高温”、“沙暴”三种状况之一，沙漠中所有区域的天气相同。\n（4）每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。沙暴日必须在原地停留。\n（5）玩家在原地停留一天消耗的资源数量称为基础消耗量，行走一天消耗的资源数量为基础消耗量的 倍。\n（6）玩家第0天可在起点处用初始资金以基准价格购买水和食物。玩家可在起点停留或回到起点，但不能多次在起点购买资源。玩家到达终点后可退回剩余的水和食物，每箱退回价格为基准价格的一半。\n（7）玩家在矿山停留时，可通过挖矿获得资金，挖矿一天获得的资金量称为基础收益。如果挖矿，消耗的资源数量为基础消耗量的 倍；如果不挖矿，消耗的资源数量为基础消耗量。到达矿山当天不能挖矿。沙暴日也可挖矿。\n（8）玩家经过或在村庄停留时可用剩余的初始资金或挖矿获得的资金随时购买水和食物，每箱价格为基准价格的2倍。\n请根据游戏的不同设定，建立数学模型，解决以下问题。\n\n* 假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入Result.xlsx。\n\n* 假设只有一名玩家，玩家仅知道当天的天气状况，可据此决定当天的行动方案，试给出一般情况下玩家的最佳策略，并对附件中的“第三关”和“第四关”进行具体讨论。\n\n* 现有 名玩家，他们有相同的初始资金，且同时从起点出发。若某天其中的任意 名玩家均从区域A行走到区域B( )，则他们中的任一位消耗的资源数量均为基础消耗量的 倍；若某天其中的任意 名玩家在同一矿山挖矿，则他们中的任一位消耗的资源数量均为基础消耗量的 倍，且每名玩家一天可通过挖矿获得的资金是基础收益的 ；若某天其中的任意 名玩家在同一村庄购买资源，每箱价格均为基准价格的 倍。其他情况下消耗资源数量与资源价格与单人游戏相同。\n  （1）假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案需在第 天确定且此后不能更改。试给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行具体讨论。\n  （2）假设所有玩家仅知道当天的天气状况，从第 天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。\n\n  注1：附件所给地图中，有公共边界的两个区域称为相邻，仅有公共顶点而没有公共边界的两个区域不视作相邻。\n  注2：Result.xlsx中剩余资金数（剩余水量、剩余食物量）指当日所需资源全部消耗完毕后的资金数（水量、食物量）。若当日还有购买行为，则指完成购买后的资金数（水量、食物量）。\n\n## 题目解答\n\n第一二问的核心是建立一个最短路模型，当然在后面和夏大佬的讨论中，我们得知建图的方法不唯一，所谓条条大路通罗马嘛。我甚至怀疑在四川赛区的国赛答辩中，有人是通过非常玄学的方式手算进的答辩，而这只是个人推测嘛，事实如何也并不重要。然后题目的第三问是一道非常扯的题目，很多人都初步了解过博弈这个知识点，但是我们通常了解的都是双人博弈，在过去的ACM训练中，我感觉这是很难弄懂的一个板块，会涉及到一定的数学推导。但事实上第三问并非双人博弈，而是多人博弈模型，所以...\n\n我们在搜集了大量的资料后，对第三问的解法还是一知半解，于是最终采用了相对比较合理的多人博弈模型，但是也仅供大家参考。\n\n### 摘要\n\n考虑如下的小游戏:玩家凭借一张地图，利用初始资金购买一定数量的水和食物 (包括食品和其他日常用品)，从起点出发，在沙漠中行走，途中会遇到不同的天气，也 可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。\n\n本文主要尝试建立一种在算法和逻辑层面都优化的最短路算法(OLBA模型)，在此 基础上进行适当的改进已应对各种不同的参数设定情况，给出了附件excel 表格的解决方案。同时使用了博弈论来求解第三题中的两个问题，根据实际题目的情况，给出了一般情况下玩家应采取的策略。\n\n对问题一，建立了OLBA模型并使用了带队列优化的BellmanFord模型求最短路， 对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，对模型的情况进行了优化。该模型适用于所有可能情况，鲁棒性强，最后用附件中的样例来验证模型是否正确。第1关最优路径结论:在起点购买178 箱水和 333 箱食物，走如图2的路线到终点资金数最大，为10470。第2关最优路径结论:在起点购买130 箱水和405箱食物，走如图2的路线到终点资金数最大，为12730。\n\n对问题二，基于第一问建立的OLBA模型进行改进， 将每个连接分成三种天气进行讨论，对边权进行更新和推导，输出任意区域的任意天数下的最大期望收益，从而给出一般情况下的最优决策，得到最终模型(W-OLBA模型)这是一种合理的一种改进模型，核心是求策略集合中期望收益最大的状态，该状态即为玩家的最佳策略下的选择， 具体情况需要具体分析。\n\n对问题三，针对第一问建立了基于改进的OLBA和混合博弈模型的多玩家同策略集模型(MCSM模型)，使用收益相等法计算纳什均衡，为了避免非最优策略和最优策略 有过多的重复路径，将原始图模型G划分成了n个子图 最终在一般情况下玩家应该选择本文图5所展示的A或者C策略的任意一条。针对第二问建立了多阶段纳什均衡和子博弈完美均衡的博弈模型(MNSE模型)，基于W-OLBA模型在利用逆向归纳法求解子博弈纳什均衡的过程中，从动态博弈的最后一个阶段或最后一个子博弈开始，逐步向前倒推，从而达到求解动态博弈均衡的目的。\n\n### 符号说明\n\n![1](2020全国大学生数学建模比赛B题/1.png)\n\n### 第一题求解\n\n题目要求假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入 Result.xlsx。\n\n由于我们要给出一般情况下玩家的最优策略，所以第一问的思路是先建立数学模型，最后用附件中的样例来验证答案是否正确。我们根据参数设定、天气状况和地图综合考虑到达终点的所有情况，这里便涉及到了非常多的问题，是否去村庄，是否去矿山， 是否停留。当然如果仅仅从第一关和第二关给出的数据去讨论到达终点的情况是非常片面而且麻烦的。所以我们首先想到基于动态规划模型 (DP 模型) 来思考这道题的结题思路，这样我们的目标终点就不仅仅是某个点，而是一般情况的所有点，同时可以根据不同的参数设定、天气状况和地图去改变 DP 的过程，符合题目要求。\n\n我们考虑状态的定义，就是最终 DP 的过程量，我们发现第一问影响到结论的不仅仅是到达终点的位置，同样也有负重上限 (水的限制、食物的限制) 和时间上限，因为在保持到某个点的最大收益的同时也要保证负重上限和时间上限没有被超过。如果将这四个数组都搜索一遍，这道题的时间复杂度将达到 O($TnM_{water}M_{food}log(TnM_{water}M_{food})$)， 我们假设普通计算机一秒运算$10^{8}$左右次，在这个复杂度的限制下，我们所能处理的最大的数据规模将被限制在  $TnM_{water}M_{food}$的乘积在$5\\times10^{5}$个数据以内，仅仅处理这道题的所有问题显然足够，但是并非最优，所有我们考虑优化这个时间复杂度。于是我们对图的数据进行了预处理缩点，将最短路直接连边。\n\n![1](2020全国大学生数学建模比赛B题/2.png)\n\n由于题目中的第四个条件规定了每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。不难看出这是一个建图的过程，我们将位置信息和时间信息作为图的节点加入图 中，然后设动态规划过程量以位置和负重上限作为标记，而这个数组的值，便是在某个负重上限的限制里到某一节点的最大收益，即:\n\nd[i] [j] [k]= 在水和食物的箱数分别至少备 j 箱和 k 箱的情况下，从起点到第 i 个点的最小花销。\n\n有向图模型得出后，转化这道题的题意，将核心从在规定时间内到达终点，并保留尽可能多的资金，转化为在规定时间内到达终点，并尽可能减少花销。这道题将转化为求最短路，我们采用队列优化带限制的 BellmanFord 算法。我们将所有的目标终点的但不同时间的节点都连到一个最终节点，我们求得最短路就是将出发点的第 0 天作为起点，将刚刚提到的最终节点作为终点，求得的一个最短路径，每个边权就是这一天的花销(可能为负)。同时由于在终点卖出食物和水的价格是原价的一半，所以我们优化模型在最后达到终点后的水和食物剩余量为 0。\n\n建图规则：\n\n* 每条边保存三个值，分别为边的权值、消耗的水的箱数、消耗的食物的箱数。\n* 连节点的方法，边的种类有三种，分别为相同区域相邻天数节点之间的连边（原地停留）、相邻区域相邻天数节点的连边、挖矿连边。其中相同区域相邻天数节点的连边的权值为 0，消耗的水和食物的箱数为基础消耗，相邻区域相邻天数节点的连边的权值为 0，消耗的水和食物为基础消耗的 2 倍，挖矿连边的权值为基础工资，消耗的水和食物的箱数为基础消耗的 3 倍，相邻区域由当前节点 (第 i 个位置，第 j 天) 可以到达相邻点节点 (相邻点的位置，第 j+1 天) 或者原地停留到 (第 i 个位置，第 j+1 天)。\n* 初始位置为起点的第 0 天。如果不能走到终点，那么最终节点的最小花销值将是INF(无穷大)，如果能走到终点，终点的每一天与最终节点相连，取$D^{i}_{destination}$  ( $1\\leq i \\leq T$)。\n\nOLBA 模型伪代码如下:\n\n \n\n------\n\n输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：\n\nn， m 区域以及相邻区域关系的数目\n\nK：负重上限\n\nInit S: 初始资金\n\nDDL：截止日期\n\nIncome： 基础收入 \n\nWater：一箱水的重量和价格\n\nFood：一箱食物的重量和价格\n\nConsume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴\n\nWeather[DDL]： 当前天气       \n\nMine[n]：区域的类别，其中 1 代表矿山，2 代表村庄\n\nD[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益\n\n输出：最优路线\n\n------\n\n带限制的 BellmanFord\n\n------\n\n算法：\n\n初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。\n\n------\n\n建图：\n\n------\n\n顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。\n\n边：存储 3 个值，分别为权值 val（权值为从上一个状态到当前状态所需的花费，其中只有挖矿边有权值，其余为 0）、从上一个状态到下一个状态所消耗的水的箱数 W、从上一个状态到下一个状态所消耗的食物的箱数 F。\n\n建边规则：\n\n同一区域相邻天数顶点之间的边：权值为 0，消耗的水和食物箱数为基础消耗。\n\n矿山顶点直接按挖矿事件的边：权值为基础收入，消耗的水和食物箱数为基础消耗的 2\n\n倍。\n\n相邻区域相邻天数顶点（同时天气不为沙暴）之间的边：权值为 0，消耗的水和食物箱数为基础消耗的 3 倍。\n\n* 步骤一：队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。（由于本小题天气情况已知，因此到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解），将状态（T，j，0，0，0）放进队列中，其中 T 为终点区域，j 为日期天数。\n* 步骤二：\n\n1. 从队列中取出顶点 x。\n\n2. 判断该状态是否为属于起点区域中的第一天，如果是，更新答案ans = max(ans， 该状态的 d 值减去水和食物的价格)。\n\n3. 判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：\n\n（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n4. 更新同一区域相邻天数和相邻区域相邻天数的 d 值，如果同一区域相邻天数的 d 值或相邻区域相邻天数的d 值大于在当前状态下d 值加上两者之间边的权值，则更新同一区域相邻天数的d 值或相邻区域相邻天数的d 值，如果该状态不在队列中，则将其加入队列。\n\n* 步骤三：重复步骤二，直至优先队列为空。\n* 步骤四：输出最优路线\n\n------\n\n\n\n我们使用c++ 代码，在使用了队列优化带限制的BellmanFord 算法，后我们得出了每天的一个行动轨迹和最终的金额。第 1 关和第 2 关的路线图如下:\n\n![3](2020全国大学生数学建模比赛B题/3.png)\n\n具体每一步的资金消耗图如下:\n\n![4](2020全国大学生数学建模比赛B题/4.png)\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第一二关的过程图</center>\n\n最终的结论是，如图所示，结合 Result.xls 中表格。\n\n玩家在第一关的最优方案可表述为：\n\n玩家在起点购买 178 箱水和 333 箱食物，从此处出发，第 13 天依次走到区域 25、24、23，第 4 天停留在 23 区域，第 5、6 天依次走到区域 22、9；第 7 天在区域 9 停留后，第 8 天走到区域 15，即村庄，在此购买 163 箱水；第 9、10 天依次走到区域 14、12，然后第 11 天开始在区域 12 挖矿；连续挖矿 9 天后，第 20 天离开矿区进入区域 14，然后走到村庄（区域 15），并购买 36 箱水和 40 箱食物，以满足行程最后三天所需；第 22天从村庄走到区域 9，途径区域 21，在第 24 天抵达终点（即区域 27）。\n\n此时剩余资金数最大，为 10470，没有剩余的水和食物。\n\n第二关的最优方案表示为：\n\n玩家在起点购买 130 箱水和 405 箱食物，依次经过区域 9/10/19/20/28/30，到达村庄1（即区域 39），玩家在此处购买 168 箱水和 54 箱食物，然后途径区域 47 到达矿区 1（区域 55）挖矿；从第 14 天（到达矿区我的第二天）开始，连续挖矿 5 天，然后去村庄2（区域 62）购买 185 箱水和 8 箱食物，然后回到矿区 1（区域 55）挖矿 8 天；在第 29 天的时候，离开矿区 1（区域 55），经区域 56 到达终点（区域 64）。\n\n到达终点时剩余资金数为 12730，无剩余的水和食物。\n\n### 第二题求解\n\nW-OLBA 模型伪代码如下:\n\n------\n\n输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：\n\nn， m 区域以及相邻区域关系的数目\n\nK：负重上限\n\nInit S: 初始资金\n\nDDL：截止日期\n\nIncome：基础收入\n\nWater：一箱水的重量和价格\n\nFood：一箱食物的重量和价格\n\nConsume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴 \n\nMine[n]：区域的类别，其中 1 代表矿山，2 代表村庄\n\nD[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大期望利益\n\nDp[i] [j] [k] [t]：代表该状态 i 下拥有 j 箱水和 k 箱食物在天气 t 下所能取得的最大期望收益\n\n输出：输出任意区域的任意天数下的最大期望收益\n\n------\n\n概率 DP 算法：\n\n------\n\n初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。\n\n------\n\n建图：\n\n------\n\n顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。\n\n边：权值为从上一个状态到当前状态所需的花费。\n\n* 步骤一：\n\n队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。将状态（T，j，w，f）放进优先队列中，其中 T 为终点区域，j 为任意天数，w， f 为任意满足条件的值，同时更新该状态下的 d 值。\n\n* 步骤二：\n\n1. 从队列中取出顶点 x。\n\n2. 判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：\n\n（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。\n\n3. 更新同一区域相邻天数和相邻区域相邻天数的 dp 值:\n\n每个连接分成三种天气进行讨论：\n\n在不同天气下，在天气k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f，如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值。\n\n如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值，如果该状态不在队列中，则将其加入队列\n\n* 步骤三：重复步骤二，直至优先队列为空。\n\n* 步骤四：输出任意区域的任意天数下的最大期望收益\n\n------\n\n 状态 [i，j，w，f] 代表区域 i 第 j 天玩家拥有的水的箱数 w 以及食物箱数 f，d 值代表该状态下的最大期望收益。\n\n首先根据算法 2 计算出所有的 d 值，然后进行决策，决策过程如下：\n\n找出该状态下的所有相邻状态集合，然后找出集合中 d 值最大的状态，该状态即为玩家的最佳策略下的选择。\n\n![5](2020全国大学生数学建模比赛B题/5.png)\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第3关动态决策示例</center>\n\n本文在第三关中共取出来 4 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。\n\n1. 状态[1，1，200，200] 在晴朗天气的情况下有相邻状态为[4，2，194，192]，[1，2，197，196]，其d 值分别为 [868.00，574.00]， 因此在该状态下最佳策略的选择为状态 [4，2，194，192]； \n\n2. 状态[3，5，200，200] 在高温天气的情况下有相邻状态为[9，6，182，182]，[4，6，182，182]，[3，6，191，191] 其d 值分别为 [1971.00，860.00，1310.67]， 因此在该状态下最佳策略的选择为状态 [9，6，182，182]；\n\n3. 状态[6，15，200，200] 在高温天气的情况下有相邻状态为[13，16，182，182]，[4，16，182，182]，其d 值分别为[860.00，860.00，569.66]， 因此在该状态下最佳策略的选择为状态[13，16，182，182]或 [4，16，182，182]；\n\n4. 状态[9，20，200，200] 在晴朗天气的情况下有相邻状态为[11，21，194，192]，[3，21，194，192]， [9，21，191，188] 其d 值分别为 [1282.33，1282.33，1948.67]， 因此在该状态下最佳策略的选择为状态 [9，21，191，188]；\n\n本文在第四关中共取出来 5 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。\n\n1. 状态 [1，1，150，200] 在晴朗天气的情况下有相邻状态为 [6，2，144，192]，[1，2，147，196]，其 d 值分别为 [324.67， 193.33]， 因此在该状态下最佳策略的选择为状态 [6，2，144，192]；\n\n2. 状态 [7，5，200，200] 在高温天气的情况下有相邻状态为 [8，6，182，182]，[6，6，182，182]，[7，6，191，191] 其d 值分别为 [362.33，362.33，237.67]， 因此在该状态下最佳策略的选择为状态 [8，6，182，182] 或 [6，6，182，182]；\n\n3. 状态[14，10，200，200] 在沙暴天气的情况下有相邻状态为[19，11，180，180]，[9，11，180，180]，[14，11，190，190] 其d 值分别为 [1298.67， 558.00， 863.00]， 因此在该状态下最佳策略的选择为状态 [19，11，180，180]；\n\n4. 状态[18，15，200，200] 在高温天气的情况下有相邻状态为[19，16，182，182]，[17，16，182，182]， [18，16，173，173] 其 d 值分别为 [1297.67，1297.67，1954.00]， 因此在该状态下最佳策略的选择为状态 [18，16，173，173]；\n\n5. 状态[20，20，200，200] 在晴朗天气的情况下有相邻状态为[25，21，194，192]，[19，21，194，192]，其d 值分别为[515.67，1256.33，811.67]， 因此在该状态下最佳策略的选择为状态[19，21，194，192]；\n\n### 第三题求解\n\n#### 第三题第一问求解\n\n题目给定了新的多人掘金游戏模型，假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案在第 0 天确定且此后不能更改。我们了给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行了具体讨论。\n\n该问基于改进的 OLBA 和混合博弈模型（完全信息的静态博弈），建立了多玩家同策略集模型 (MNSM 模型)。\n\n在这种情况下可以视每位玩家都有心中的一个最优策略，那么当多人参加这个游戏时，就涉及到了相互之间的博弈。参加斗争或竞争的各方各自具有不同的目标和利益。为了达到各自的目标和利益，各方必须考虑对手的各种可能的行动方案，并力图选取对自己最为有利或最为合理的方案。博弈论就是研究对策行为中斗争各方是否存在着最合理的行动方案，以及如何找到这个合理的行动方案的数学理论和方法。同时由于所有信息都给定，这可以看作完全信息博弈。\n\n我们确定了本问中博弈论的三大要素：\n\n(1). 局中人数: 根据题目要求，玩家人数为 n。\n\n(2). 策略集: 本题的策略集采用第一问的 OLBA 模型，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上，将会有次优策略、第三优策略等等，每一个新的最优策略建立在已经加入策略集的策略之上， 我们一步步挑选这些策略加入策略集，直到当一个策略满足: 该策略的收益$E_{cur}$小于等于直接从起点走带限制的最短路径到达终点的收益$E_{direct}$。此时如果再将操作继续下去将没有实际意义，故可以不考虑，对算法进行剪枝。将直接从起点走带限制的最短路径到达终点的策略也加入策略集，当前策略集中便是最终的本问所要使用的策略集S。设策略集的个数为 m，玩家 i 的有限纯策略集合可视作：\n$$\nS_{i}=s_{i 1}, s_{i 2}, \\cdots, s_{i m}\n$$\n为了避免次优策略等非最优策略和最优策略有过多的重复路径，我们需要对原始图模型G 进行划分，即求图G 中顶点集V 的划分 V1， V2， ...， Vn，将 G 分成n 个生成子图G[V1]， G[V2]， ...，G[Vn]， 使得：\n\n![6](2020全国大学生数学建模比赛B题/6.png)\n\n(3). 支付函数: 由于是多人的博弈，求支付函数的过程，也就是求纳什均衡的过程。支付函数由每个玩家的收益期望根据纳什均衡决定，故首先我们需要定义玩家 p 做决策i 的收益 Upi。\n\n该收益 Upi 由两大部分组成：\n\na. 基础收益：在只有一个玩家的情况下，玩家 p 做决策 i 的最后剩余资金量 Bpi\n\nb. 综合损耗：在其他玩家的影响下所减少的资金。该损耗由两大影响因素决定：\n\n* 选择该决策 i 的玩家人数 K（假设选择决策 i 的人数为 Ki）\n* 其他决策 j 对该决策的固有损耗以及选择决策 j 的玩家人数 Kj\n\n对于本问，我们首先需要得出策略集。纯策略纳什均衡是指在一个纯策略组合中， 如果给定其他的策略不变，该节点不会单方面改变自己的策略，否则不会使节点访问代价变小。由于策略集可能会比较大，使用纯策略纳什均衡会难以选出最优策略，这时我们考虑加入混合策略纳什均衡博弈的模型。混合策略纳什均衡是面对其他博弈者选择的不确定性的一个理性对策，其主要特征是作为混合策略一部分的每一个纯策略有相同的期望值，否则，一个博弈者会选择那个期望值最高的策略而排除所有其他策略，这意味着原初的状态不是一个均衡。我们设定游戏中每个人都会选择混合策略来考虑自己一开始的路线。\n\n我们将采用收益相等法，来计算纳什均衡，在得出概率情况之后，由于要给出一般情况下的最优策略，我们需要去具体去衡量每个人选择不同策略的概率，我们通过收益来权衡每个人选择不同策略的概率。将每个人选择不同策略的概率与纳什均衡得出的概率比较，得出一般情况下的最优决策模型。\n\n在上述模型建立的基础上，我们对附件中的“第五关”进行具体求解：\n\n（1） 确定局中人数 n=2。\n\n（2） 根据第一问 OLBA 模型确定策略集。\n\n首先加入的是最优策略，第 5 关最优策略如图:\n\n根据第一问的 OLBA 模型确定最优解为 1->4->6->13，最后收益为 9535。如图所示，按模型中的四个约束对图进行划分：\n\n在子图（图中阴影部分）得出的最优解为：1->2->3->9->10->13，最后收益为 9325。即策略 A 的收益为 9539，策略 B 的收益为 9325，按上述方法，以此类推，得出： 策略 C：1->5->6->13，收益为 9535\n\n（3） 计算支付矩阵\n\n上述收益均为基础收益，还需按照上述公式计算最终收益：\n\n|      |       A        |       B        |       C        |\n| :--: | :------------: | :------------: | :------------: |\n|  A   | (8140 ，8140 ) | (9535 ，9525 ) | (9370， 9370 ) |\n|  B   | (9535 ，9525 ) | (6400 ，6400 ) | (9535 ，9525 ) |\n|  C   | (9370， 9370 ) | (9535 ，9525 ) | (8140 ，8140 ) |\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/7.png\" width=\"400\"/>    <img src=\"2020全国大学生数学建模比赛B题/8.png\" width=\"400\"/> </center>\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第5关模型和路线结果</center>\n\n玩家 1（行）选择 A 的概率为 p1，选择 B 的概率为 p2，选择 C 的概率为 p3；\n$$\np1 + p2 + p3 = 1\n$$\n玩家 2（列）选择 A 的概率为 s1，选择 B 的概率为 s2，选择 C 的概率为 s3;\n$$\ns1 + s2 + s3 = 1\n$$\n玩家 1 选择 A 的期望收益等于玩家 1 选择 B 的期望收益等于玩家 1 选择 C 的期望收益，玩家 2 同理。\n\n利用LINGO 求解得到玩家 1 选择A 策略的概率p1 = 0.4012，p2 = 0.1977，p3=0.4012， 期望收益为 8910.402。\n\n玩家 2 选择 A 策略的概率 s1=0.4404，s2=1992，s3=0.4404;\n\n从博弈论的角度来看，两名玩家均选择策略 A 或均选择策略 C 对自己一方的效益最大；题目要求给出一般情况下玩家应采取的策略，由于 A，C 策略期望和概率是相同的，并且都是最大的，那么该名玩家可以选择 A 或者 C。\n\n但从团体最优的角度来看，为了使整体利益最大，应该一名玩家选择A，一名玩家选择 B\n\n#### 第三题第二问求解\n\n本问规定所有玩家仅知道当天的天气状况，从第天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。\n\n本问在第二问所建立的模型基础上，建立多阶段博弈模型，多阶段博弈扩展形也称为“博弈树”。动态博弈各个博弈方的选择行为有先后次序，多阶段博弈第一个行动选择对应的决策节称为初始节，多阶段博弈一个选择节点所包含的所有信息叫做“信息集”。各博弈方的选择行为会依次形成相连的博弈阶段，因此动态博弈中博弈方的一次选禅行为常称为一个“阶段”。一个动态博弈至少有两个阶段. 因此动态博弃有时也称为“多阶段博弈”。此外. 也有称动态博弈为“序贯博弈”的，多阶段博弈多阶段博弈序贯博弈是指博弈方选择策略有时间先后的博弈形式。同矩阵表示法相比扩展式所扩展的主要是博弈方的策略空间，多阶段博弈即某个博弈方在什么时候行动，多阶段博弈行动时有哪些策略可以选择，以及知道哪些关于博弈的信息在多阶段博弈模型中，当局中人的策略在每一个子博弈中都构成纳什均衡时，则形成“子博弈精炼纳什均衡”。\n\n因此，问题简化为求解每一步博弈的纳什均衡。对于每一步博弈的纳什均衡，我们采用第三题第一问的方法，即依次确定决策集、支付函数。\n\n在求解问题二所建立的模型中，我们为了得到最优方案，需要计算玩家在每一步距离终点的效益期望，然后选择效益期望最大的作为下一步的策略选择。因此，在本问中， 我们利用问题二所建立的模型中所得到的“每一步的效益期望”，作为子博弈过程中的效益矩阵中的元素，进而求解每一步的纳什均衡。具体步骤如下：\n\n（1） 利用问题二的模型求解该图模型“每一步的效益期望”\n\n（2） 将每一步的效益期望作为该步博弈中的支付矩阵，求解其纳什均衡（求解方法同问题二第一问）\n\n（3） 重复（2）的过程，求解每一步博弈的纳什均衡，直到归纳到第一个阶段的博弈\n\n输出最后的博弈结果流程图如下：\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/9.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 多阶段博弈流程图</center>\n\n（1）由于第六关和第四关的地图完全一致，故第六关基于(1)(2)问所建立的图模型以及求解该图模型所得到的结果，即“每一步的效益期望”求解。\n\n（2）在第二问我们所得到的结果中，最后一个状态为 [20,20,200,200]，即玩家在第 20 天到达区域20 所拥有的水的箱数为 200，所拥有的食物的箱数为 200，该状态下所有状态的集合为 [25,21,194,192],[19,21,194,192],[20,21,197,196] 该集合中元素的期望效益所构成的元\n\n组为 [515.67,1256.33,811.67]。在第二问中，我们选择最大期望收益作为策略。但在此问中，我们考虑的是一个动态博弈过程，因此我们将这些期望收益作为玩家的支付矩阵中的对应策略集。\n\n得到效益矩阵如下：\n\n|      | A              | B                 | C               |\n| ---- | -------------- | ----------------- | --------------- |\n| A    | (515.7,515.7 ) | (515.7,1256.3)    | (515.7,811.7)   |\n| B    | (515.7,1256.3) | (1256.3, 1256.3)  | (1256.3,811.7 ) |\n| C    | (515.7,811.7 ) | (1256.3 , 811.7 ) | (811.7,811.7 )  |\n\n（3） 重复步骤二：我们可以得到每一步博弈后玩家的效益矩阵与选择概率\n\n（4） 综合考虑这些选择概率，我们得到三名玩家在博弈情况下相对最优路径分别为：\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/10.png\" width=\"400\"/> </center>\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 第6关结果图</center>\n\n### 模型优缺点及改进\n\n#### 优点\n\n* 第一题的 OLBA 模型使用了带队列优化的BellmanFord 模型求最短路，同时对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，这一点大大改进了解决该问的时间复杂度和空间复杂度。并且利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，完善了对模型的情况进行了限定 (如：到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解)。在 c++ 编程下以最快的速度解决同类型问题。该模型适用于所有可能情况，鲁棒性强。\n\n* 第二题基于第一问建立的 OLBA 模型进行改进, 将每个连接分成三种天气进行讨论：在不同天气下，在天气 k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f， 如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值，如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值。这样的数学建模过程，思路严谨并且顺畅，是比较合理的一种改进方法，在第 3,4 关模型中取得了非常好的效果。\n\n* 第三题第一问采用基于改进的 OLBA 和混合博弈模型的多玩家同策略集模型(MNSM 模型)，相对于纯决策博弈更加严谨和适用，策略集选择更加合理，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上。采用收益相等法，来计算纳什均衡，在得出概率情况之后，具体通过收益来线性权衡每个人选择不同策略的概率，得出最优决策模型，建模过程合理简单但不失合理性，代码运行速度快。\n\n  第三题第二问采用基于多阶段纳什均衡和子博弈完美均衡的博弈模型 (MNSE 模型), 算法的选取契合本文动态博弈的机制, 每一步的效益，就用第二大问的算法直接得出，这样就得出每一阶段的支付矩阵, 算法符合实际情况，最终得出每一步的玩家最优决策模型。\n\n#### 缺点\n\n* 第三题第一问中将图划分为若干子图的过程尽管有严谨的逻辑推导与理论基础，但在实际操作过程中，若图的规模特别大，操作起来时间复杂度会特别高，从而导致求解效率较低。\n* 第三题第二问的博弈模型对效益考虑的模型存在一定的主观性，如果能够对所有路线的效益进行实时的收益考虑，第三题的准确性将大大提升，这样需要改进算法的时间复杂度以应对规模更大的一般情况。\n\n#### 改进\n\n* 能够在本文的 OLBA 模型下，研究严密的数学逻辑，对图进行一定的缩小，再通过合理减少连边以减小模型的复杂度。在本文建立的 MNSE 模型，在玩家较多的时候，对期望收益进行考虑的复杂度太大，希望能够通过优化模型思路，让模型更加适用于一般情况。\n\n## 关于答辩\n\n在答辩的前第二天的晚上才收到了答辩的通知，作为工具人1号，被安排上了主答辩的位置。匆匆忙忙地整理了套很久没洗的正装，熬夜做PPT到凌晨2点，睡醒了又得知...貌似不用PPT答辩，虽然人傻了，但是生活还得继续嘛。\n\n由于答辩前的第二天(在还没有接到答辩消息的时候)答应了和朋友出去看电影，于是在答辩前一天地上午急急忙忙地整理好了稿子放在了手机里，便出门赴约了，回来的时候已经大概晚上九点了。才开始急急忙忙地背稿子，关键是两千多字的稿子对我来说就...太离谱了。对于一个早年英语单词认不得和语文古诗默写常年丢分的人来说，背书是不可能背的，于是记了个大概，就睡了。\n\n时间来到答辩当天，早上五点闹钟响了，现在看来还挺佩服那个时候竟然能起得来。跟着学校其他答辩的人(一共四个组)来到了西南交大希望学院，逛了会校园，便在候场室门口准备着答辩。由于早上忘换鞋了，于是有了经典的一幕，西装配运动鞋，带着这么一身时髦的打扮走进了答辩室。\n\n答辩过程非常的刺激，才说了不到100个字就被打断了，老师说你别说那么多废话(现在想来也不应该说什么客套话哈哈)。那个数学学院的老师开始了精彩地发问，首先问我们代码是不是自己写的，当然这个问题没有价值。然后问我们第一题解题过程是如何推导的？？？我直接黑人问号\n\n<center class=\"half\">    <img src=\"2020全国大学生数学建模比赛B题/1.jpg\" width=\"400\"/> </center>\n\n\n\n这不是个算法吗，就是建立了一个通用的模型，伪代码也交待地非常清楚。但是老师还是不依不饶，问我们一些非常沙雕的数学公式问题，想了想就一个最短路模型哪来的公式，damn。可能是我才学疏漏吧。\n\n然后老师问了一个全场最佳的问题，他指着我们的一行c++代码，提问这行语句是干嘛的。卿卿宝贝很认真解释了这段代码在整个程序的作用。老师操着一口四川话一脸正经地说：“我想问的不是这个，我只想问这段话什么意思”，于是我们开始了七嘴八舌地回答，没有回答到点子上。直到卿卿宝贝灵机一动告诉他：“这是个if语句，如何前面的括号里面的条件为真.......，那么程序就会执行这个if语句里面的内容......”，老师心满意足地点了点头.......，直到这一刻我才明白，可能这样的答辩确实也不需要准备吧。涛哥等待了很久的第三题的问答环节也没有上演，实际上整个答辩过程老师也只问了第一题的解答。\n\n在十五分钟的煎熬之后，我们走出了答辩室，虽然大家人傻了，但是这段经历也告诉了我们，如何和各个学院的老师进行生动地代码解释是多么重要。毕竟各行各业嘛，你觉得甚至不需要解释的一个点，别人也可能不懂，他想知道的，也仅仅是那一个点而已。\n\n整个答辩的核心也就是：证明这些东西是我们自己完成的就行了。\n\n答辩结束，下一组是夏大佬和涵哥的答辩(还是为:chicken:拔占领了川大建模的半B江山骄傲哈），他们出答辩室之前，我精准预测，夏哥见我们第一句必定是抱怨那个老师。一会过后，果不其然，隔着一个走廊便传出了一阵熟悉声音：“这老师是xx吧”。整个答辩过程在一阵欢声笑语中打出了GG。\n\n走出来教学楼，逛了逛校园，合影留念，第一次应该也是最后一次的国赛经历便写到了最后。\n\n临走前，我开始回忆起这段经历，能走到这里挺意外的，要不是建模题出在了ACM题头上，我相信我们应该并不会来到这里，而我个人在整个建模过程付出的努力也就普普通通，甚至让我觉得自己也不配这份荣誉。这时天空下起了小雨，望着远处来来往往的人群，只是觉得这一切很不真实，很玄幻，而这种感觉，没想到会持续一整个学期(当然这是后话了)。\n\n## 后记\n\n现在回想起建模那几天也算是一段非常精彩的回忆，那周好像是身体与心理的双重暴击吧。前阵子刚从学校的心理辅导室走出来，长达一个多月的失眠还有掉头发让我的身体也是拉响了警钟。建模过程中也生了一些小病，而在建模最后一天的下午由于去参加CSP考试导致我们浪费了一下午的时间，论文也是匆匆生成便提交上去，这也可能是我们与一等奖无缘的原因吧，现在倒回去看那篇论文的排版确实也是漏洞百出，实属工作失误害。\n\n在论文截止提交前的两个小时，还和代总联系着要不要去演协的最后一次聚餐，那时我们的论文并没有很完善，但是我心里想着可能这次不去，有些人大概是永远都再见不到了吧，匆匆忙忙地离开了建模的现场，去见了想见的人，也算没有留下遗憾吧。\n\n这里得着重感谢两位队友的付出，幸好结果是令人满意的。\n\n附这张亮堂堂的奖状：\n\n![11](2020全国大学生数学建模比赛B题/11.png)","slug":"2020全国大学生数学建模比赛B题","published":1,"updated":"2022-01-13T09:01:08.743Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxwk00013oue4napg7a0","content":"<blockquote>\n<p>于2020年的9月份参加了全国大学生数学建模比赛，第二次参加建模比赛，主要负责论文撰写、模型的设计和验证。在团队中担任了一名相对划水的角色，参赛的时间段正值个人心态爆炸的阶段，导致状态不太靠谱，好在队友非常给力。B题是一道ACM中求最短路的题目，第一问是有标答的，估计后来进国赛也是因为第一问的答案正确，最终在及其神奇的一场答辩中获得了国家二等奖，也算是为我的建模生涯画上了一个比较不错的句号(当然也就参加了两场:smiley:)。</p>\n</blockquote>\n<h2 id=\"题目大意\"><a href=\"#题目大意\" class=\"headerlink\" title=\"题目大意\"></a>题目大意</h2><p>考虑如下的小游戏：玩家凭借一张地图，利用初始资金购买一定数量的水和食物（包括食品和其他日常用品），从起点出发，在沙漠中行走。途中会遇到不同的天气，也可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。<br>游戏的基本规则如下：<br>（1）以天为基本时间单位，游戏的开始时间为第0天，玩家位于起点。玩家必须在截止日期或之前到达终点，到达终点后该玩家的游戏结束。<br>（2）穿越沙漠需水和食物两种资源，它们的最小计量单位均为箱。每天玩家拥有的水和食物质量之和不能超过负重上限。若未到达终点而水或食物已耗尽，视为游戏失败。<br>（3）每天的天气为“晴朗”、“高温”、“沙暴”三种状况之一，沙漠中所有区域的天气相同。<br>（4）每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。沙暴日必须在原地停留。<br>（5）玩家在原地停留一天消耗的资源数量称为基础消耗量，行走一天消耗的资源数量为基础消耗量的 倍。<br>（6）玩家第0天可在起点处用初始资金以基准价格购买水和食物。玩家可在起点停留或回到起点，但不能多次在起点购买资源。玩家到达终点后可退回剩余的水和食物，每箱退回价格为基准价格的一半。<br>（7）玩家在矿山停留时，可通过挖矿获得资金，挖矿一天获得的资金量称为基础收益。如果挖矿，消耗的资源数量为基础消耗量的 倍；如果不挖矿，消耗的资源数量为基础消耗量。到达矿山当天不能挖矿。沙暴日也可挖矿。<br>（8）玩家经过或在村庄停留时可用剩余的初始资金或挖矿获得的资金随时购买水和食物，每箱价格为基准价格的2倍。<br>请根据游戏的不同设定，建立数学模型，解决以下问题。</p>\n<ul>\n<li><p>假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入Result.xlsx。</p>\n</li>\n<li><p>假设只有一名玩家，玩家仅知道当天的天气状况，可据此决定当天的行动方案，试给出一般情况下玩家的最佳策略，并对附件中的“第三关”和“第四关”进行具体讨论。</p>\n</li>\n<li><p>现有 名玩家，他们有相同的初始资金，且同时从起点出发。若某天其中的任意 名玩家均从区域A行走到区域B( )，则他们中的任一位消耗的资源数量均为基础消耗量的 倍；若某天其中的任意 名玩家在同一矿山挖矿，则他们中的任一位消耗的资源数量均为基础消耗量的 倍，且每名玩家一天可通过挖矿获得的资金是基础收益的 ；若某天其中的任意 名玩家在同一村庄购买资源，每箱价格均为基准价格的 倍。其他情况下消耗资源数量与资源价格与单人游戏相同。<br>（1）假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案需在第 天确定且此后不能更改。试给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行具体讨论。<br>（2）假设所有玩家仅知道当天的天气状况，从第 天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。</p>\n<p>注1：附件所给地图中，有公共边界的两个区域称为相邻，仅有公共顶点而没有公共边界的两个区域不视作相邻。<br>注2：Result.xlsx中剩余资金数（剩余水量、剩余食物量）指当日所需资源全部消耗完毕后的资金数（水量、食物量）。若当日还有购买行为，则指完成购买后的资金数（水量、食物量）。</p>\n</li>\n</ul>\n<h2 id=\"题目解答\"><a href=\"#题目解答\" class=\"headerlink\" title=\"题目解答\"></a>题目解答</h2><p>第一二问的核心是建立一个最短路模型，当然在后面和夏大佬的讨论中，我们得知建图的方法不唯一，所谓条条大路通罗马嘛。我甚至怀疑在四川赛区的国赛答辩中，有人是通过非常玄学的方式手算进的答辩，而这只是个人推测嘛，事实如何也并不重要。然后题目的第三问是一道非常扯的题目，很多人都初步了解过博弈这个知识点，但是我们通常了解的都是双人博弈，在过去的ACM训练中，我感觉这是很难弄懂的一个板块，会涉及到一定的数学推导。但事实上第三问并非双人博弈，而是多人博弈模型，所以…</p>\n<p>我们在搜集了大量的资料后，对第三问的解法还是一知半解，于是最终采用了相对比较合理的多人博弈模型，但是也仅供大家参考。</p>\n<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>考虑如下的小游戏:玩家凭借一张地图，利用初始资金购买一定数量的水和食物 (包括食品和其他日常用品)，从起点出发，在沙漠中行走，途中会遇到不同的天气，也 可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。</p>\n<p>本文主要尝试建立一种在算法和逻辑层面都优化的最短路算法(OLBA模型)，在此 基础上进行适当的改进已应对各种不同的参数设定情况，给出了附件excel 表格的解决方案。同时使用了博弈论来求解第三题中的两个问题，根据实际题目的情况，给出了一般情况下玩家应采取的策略。</p>\n<p>对问题一，建立了OLBA模型并使用了带队列优化的BellmanFord模型求最短路， 对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，对模型的情况进行了优化。该模型适用于所有可能情况，鲁棒性强，最后用附件中的样例来验证模型是否正确。第1关最优路径结论:在起点购买178 箱水和 333 箱食物，走如图2的路线到终点资金数最大，为10470。第2关最优路径结论:在起点购买130 箱水和405箱食物，走如图2的路线到终点资金数最大，为12730。</p>\n<p>对问题二，基于第一问建立的OLBA模型进行改进， 将每个连接分成三种天气进行讨论，对边权进行更新和推导，输出任意区域的任意天数下的最大期望收益，从而给出一般情况下的最优决策，得到最终模型(W-OLBA模型)这是一种合理的一种改进模型，核心是求策略集合中期望收益最大的状态，该状态即为玩家的最佳策略下的选择， 具体情况需要具体分析。</p>\n<p>对问题三，针对第一问建立了基于改进的OLBA和混合博弈模型的多玩家同策略集模型(MCSM模型)，使用收益相等法计算纳什均衡，为了避免非最优策略和最优策略 有过多的重复路径，将原始图模型G划分成了n个子图 最终在一般情况下玩家应该选择本文图5所展示的A或者C策略的任意一条。针对第二问建立了多阶段纳什均衡和子博弈完美均衡的博弈模型(MNSE模型)，基于W-OLBA模型在利用逆向归纳法求解子博弈纳什均衡的过程中，从动态博弈的最后一个阶段或最后一个子博弈开始，逐步向前倒推，从而达到求解动态博弈均衡的目的。</p>\n<h3 id=\"符号说明\"><a href=\"#符号说明\" class=\"headerlink\" title=\"符号说明\"></a>符号说明</h3><p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/1.png\" alt=\"1\"></p>\n<h3 id=\"第一题求解\"><a href=\"#第一题求解\" class=\"headerlink\" title=\"第一题求解\"></a>第一题求解</h3><p>题目要求假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入 Result.xlsx。</p>\n<p>由于我们要给出一般情况下玩家的最优策略，所以第一问的思路是先建立数学模型，最后用附件中的样例来验证答案是否正确。我们根据参数设定、天气状况和地图综合考虑到达终点的所有情况，这里便涉及到了非常多的问题，是否去村庄，是否去矿山， 是否停留。当然如果仅仅从第一关和第二关给出的数据去讨论到达终点的情况是非常片面而且麻烦的。所以我们首先想到基于动态规划模型 (DP 模型) 来思考这道题的结题思路，这样我们的目标终点就不仅仅是某个点，而是一般情况的所有点，同时可以根据不同的参数设定、天气状况和地图去改变 DP 的过程，符合题目要求。</p>\n<p>我们考虑状态的定义，就是最终 DP 的过程量，我们发现第一问影响到结论的不仅仅是到达终点的位置，同样也有负重上限 (水的限制、食物的限制) 和时间上限，因为在保持到某个点的最大收益的同时也要保证负重上限和时间上限没有被超过。如果将这四个数组都搜索一遍，这道题的时间复杂度将达到 O($TnM_{water}M_{food}log(TnM_{water}M_{food})$)， 我们假设普通计算机一秒运算$10^{8}$左右次，在这个复杂度的限制下，我们所能处理的最大的数据规模将被限制在  $TnM_{water}M_{food}$的乘积在$5\\times10^{5}$个数据以内，仅仅处理这道题的所有问题显然足够，但是并非最优，所有我们考虑优化这个时间复杂度。于是我们对图的数据进行了预处理缩点，将最短路直接连边。</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/2.png\" alt=\"1\"></p>\n<p>由于题目中的第四个条件规定了每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。不难看出这是一个建图的过程，我们将位置信息和时间信息作为图的节点加入图 中，然后设动态规划过程量以位置和负重上限作为标记，而这个数组的值，便是在某个负重上限的限制里到某一节点的最大收益，即:</p>\n<p>d[i] [j] [k]= 在水和食物的箱数分别至少备 j 箱和 k 箱的情况下，从起点到第 i 个点的最小花销。</p>\n<p>有向图模型得出后，转化这道题的题意，将核心从在规定时间内到达终点，并保留尽可能多的资金，转化为在规定时间内到达终点，并尽可能减少花销。这道题将转化为求最短路，我们采用队列优化带限制的 BellmanFord 算法。我们将所有的目标终点的但不同时间的节点都连到一个最终节点，我们求得最短路就是将出发点的第 0 天作为起点，将刚刚提到的最终节点作为终点，求得的一个最短路径，每个边权就是这一天的花销(可能为负)。同时由于在终点卖出食物和水的价格是原价的一半，所以我们优化模型在最后达到终点后的水和食物剩余量为 0。</p>\n<p>建图规则：</p>\n<ul>\n<li>每条边保存三个值，分别为边的权值、消耗的水的箱数、消耗的食物的箱数。</li>\n<li>连节点的方法，边的种类有三种，分别为相同区域相邻天数节点之间的连边（原地停留）、相邻区域相邻天数节点的连边、挖矿连边。其中相同区域相邻天数节点的连边的权值为 0，消耗的水和食物的箱数为基础消耗，相邻区域相邻天数节点的连边的权值为 0，消耗的水和食物为基础消耗的 2 倍，挖矿连边的权值为基础工资，消耗的水和食物的箱数为基础消耗的 3 倍，相邻区域由当前节点 (第 i 个位置，第 j 天) 可以到达相邻点节点 (相邻点的位置，第 j+1 天) 或者原地停留到 (第 i 个位置，第 j+1 天)。</li>\n<li>初始位置为起点的第 0 天。如果不能走到终点，那么最终节点的最小花销值将是INF(无穷大)，如果能走到终点，终点的每一天与最终节点相连，取$D^{i}_{destination}$  ( $1\\leq i \\leq T$)。</li>\n</ul>\n<p>OLBA 模型伪代码如下:</p>\n<hr>\n<p>输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：</p>\n<p>n， m 区域以及相邻区域关系的数目</p>\n<p>K：负重上限</p>\n<p>Init S: 初始资金</p>\n<p>DDL：截止日期</p>\n<p>Income： 基础收入 </p>\n<p>Water：一箱水的重量和价格</p>\n<p>Food：一箱食物的重量和价格</p>\n<p>Consume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴</p>\n<p>Weather[DDL]： 当前天气       </p>\n<p>Mine[n]：区域的类别，其中 1 代表矿山，2 代表村庄</p>\n<p>D[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益</p>\n<p>输出：最优路线</p>\n<hr>\n<p>带限制的 BellmanFord</p>\n<hr>\n<p>算法：</p>\n<p>初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。</p>\n<hr>\n<p>建图：</p>\n<hr>\n<p>顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。</p>\n<p>边：存储 3 个值，分别为权值 val（权值为从上一个状态到当前状态所需的花费，其中只有挖矿边有权值，其余为 0）、从上一个状态到下一个状态所消耗的水的箱数 W、从上一个状态到下一个状态所消耗的食物的箱数 F。</p>\n<p>建边规则：</p>\n<p>同一区域相邻天数顶点之间的边：权值为 0，消耗的水和食物箱数为基础消耗。</p>\n<p>矿山顶点直接按挖矿事件的边：权值为基础收入，消耗的水和食物箱数为基础消耗的 2</p>\n<p>倍。</p>\n<p>相邻区域相邻天数顶点（同时天气不为沙暴）之间的边：权值为 0，消耗的水和食物箱数为基础消耗的 3 倍。</p>\n<ul>\n<li>步骤一：队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。（由于本小题天气情况已知，因此到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解），将状态（T，j，0，0，0）放进队列中，其中 T 为终点区域，j 为日期天数。</li>\n<li>步骤二：</li>\n</ul>\n<ol>\n<li><p>从队列中取出顶点 x。</p>\n</li>\n<li><p>判断该状态是否为属于起点区域中的第一天，如果是，更新答案ans = max(ans， 该状态的 d 值减去水和食物的价格)。</p>\n</li>\n<li><p>判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：</p>\n</li>\n</ol>\n<p>（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<p>（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<ol>\n<li>更新同一区域相邻天数和相邻区域相邻天数的 d 值，如果同一区域相邻天数的 d 值或相邻区域相邻天数的d 值大于在当前状态下d 值加上两者之间边的权值，则更新同一区域相邻天数的d 值或相邻区域相邻天数的d 值，如果该状态不在队列中，则将其加入队列。</li>\n</ol>\n<ul>\n<li>步骤三：重复步骤二，直至优先队列为空。</li>\n<li>步骤四：输出最优路线</li>\n</ul>\n<hr>\n<p>我们使用c++ 代码，在使用了队列优化带限制的BellmanFord 算法，后我们得出了每天的一个行动轨迹和最终的金额。第 1 关和第 2 关的路线图如下:</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/3.png\" alt=\"3\"></p>\n<p>具体每一步的资金消耗图如下:</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/4.png\" alt=\"4\"></p>\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第一二关的过程图</center>\n\n<p>最终的结论是，如图所示，结合 Result.xls 中表格。</p>\n<p>玩家在第一关的最优方案可表述为：</p>\n<p>玩家在起点购买 178 箱水和 333 箱食物，从此处出发，第 13 天依次走到区域 25、24、23，第 4 天停留在 23 区域，第 5、6 天依次走到区域 22、9；第 7 天在区域 9 停留后，第 8 天走到区域 15，即村庄，在此购买 163 箱水；第 9、10 天依次走到区域 14、12，然后第 11 天开始在区域 12 挖矿；连续挖矿 9 天后，第 20 天离开矿区进入区域 14，然后走到村庄（区域 15），并购买 36 箱水和 40 箱食物，以满足行程最后三天所需；第 22天从村庄走到区域 9，途径区域 21，在第 24 天抵达终点（即区域 27）。</p>\n<p>此时剩余资金数最大，为 10470，没有剩余的水和食物。</p>\n<p>第二关的最优方案表示为：</p>\n<p>玩家在起点购买 130 箱水和 405 箱食物，依次经过区域 9/10/19/20/28/30，到达村庄1（即区域 39），玩家在此处购买 168 箱水和 54 箱食物，然后途径区域 47 到达矿区 1（区域 55）挖矿；从第 14 天（到达矿区我的第二天）开始，连续挖矿 5 天，然后去村庄2（区域 62）购买 185 箱水和 8 箱食物，然后回到矿区 1（区域 55）挖矿 8 天；在第 29 天的时候，离开矿区 1（区域 55），经区域 56 到达终点（区域 64）。</p>\n<p>到达终点时剩余资金数为 12730，无剩余的水和食物。</p>\n<h3 id=\"第二题求解\"><a href=\"#第二题求解\" class=\"headerlink\" title=\"第二题求解\"></a>第二题求解</h3><p>W-OLBA 模型伪代码如下:</p>\n<hr>\n<p>输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：</p>\n<p>n， m 区域以及相邻区域关系的数目</p>\n<p>K：负重上限</p>\n<p>Init S: 初始资金</p>\n<p>DDL：截止日期</p>\n<p>Income：基础收入</p>\n<p>Water：一箱水的重量和价格</p>\n<p>Food：一箱食物的重量和价格</p>\n<p>Consume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴 </p>\n<p>Mine[n]：区域的类别，其中 1 代表矿山，2 代表村庄</p>\n<p>D[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大期望利益</p>\n<p>Dp[i] [j] [k] [t]：代表该状态 i 下拥有 j 箱水和 k 箱食物在天气 t 下所能取得的最大期望收益</p>\n<p>输出：输出任意区域的任意天数下的最大期望收益</p>\n<hr>\n<p>概率 DP 算法：</p>\n<hr>\n<p>初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。</p>\n<hr>\n<p>建图：</p>\n<hr>\n<p>顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。</p>\n<p>边：权值为从上一个状态到当前状态所需的花费。</p>\n<ul>\n<li>步骤一：</li>\n</ul>\n<p>队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。将状态（T，j，w，f）放进优先队列中，其中 T 为终点区域，j 为任意天数，w， f 为任意满足条件的值，同时更新该状态下的 d 值。</p>\n<ul>\n<li>步骤二：</li>\n</ul>\n<ol>\n<li><p>从队列中取出顶点 x。</p>\n</li>\n<li><p>判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：</p>\n</li>\n</ol>\n<p>（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<p>（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<ol>\n<li>更新同一区域相邻天数和相邻区域相邻天数的 dp 值:</li>\n</ol>\n<p>每个连接分成三种天气进行讨论：</p>\n<p>在不同天气下，在天气k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f，如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值。</p>\n<p>如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值，如果该状态不在队列中，则将其加入队列</p>\n<ul>\n<li><p>步骤三：重复步骤二，直至优先队列为空。</p>\n</li>\n<li><p>步骤四：输出任意区域的任意天数下的最大期望收益</p>\n</li>\n</ul>\n<hr>\n<p> 状态 [i，j，w，f] 代表区域 i 第 j 天玩家拥有的水的箱数 w 以及食物箱数 f，d 值代表该状态下的最大期望收益。</p>\n<p>首先根据算法 2 计算出所有的 d 值，然后进行决策，决策过程如下：</p>\n<p>找出该状态下的所有相邻状态集合，然后找出集合中 d 值最大的状态，该状态即为玩家的最佳策略下的选择。</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/5.png\" alt=\"5\"></p>\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第3关动态决策示例</center>\n\n<p>本文在第三关中共取出来 4 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。</p>\n<ol>\n<li><p>状态[1，1，200，200] 在晴朗天气的情况下有相邻状态为[4，2，194，192]，[1，2，197，196]，其d 值分别为 [868.00，574.00]， 因此在该状态下最佳策略的选择为状态 [4，2，194，192]； </p>\n</li>\n<li><p>状态[3，5，200，200] 在高温天气的情况下有相邻状态为[9，6，182，182]，[4，6，182，182]，[3，6，191，191] 其d 值分别为 [1971.00，860.00，1310.67]， 因此在该状态下最佳策略的选择为状态 [9，6，182，182]；</p>\n</li>\n<li><p>状态[6，15，200，200] 在高温天气的情况下有相邻状态为[13，16，182，182]，[4，16，182，182]，其d 值分别为[860.00，860.00，569.66]， 因此在该状态下最佳策略的选择为状态[13，16，182，182]或 [4，16，182，182]；</p>\n</li>\n<li><p>状态[9，20，200，200] 在晴朗天气的情况下有相邻状态为[11，21，194，192]，[3，21，194，192]， [9，21，191，188] 其d 值分别为 [1282.33，1282.33，1948.67]， 因此在该状态下最佳策略的选择为状态 [9，21，191，188]；</p>\n</li>\n</ol>\n<p>本文在第四关中共取出来 5 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。</p>\n<ol>\n<li><p>状态 [1，1，150，200] 在晴朗天气的情况下有相邻状态为 [6，2，144，192]，[1，2，147，196]，其 d 值分别为 [324.67， 193.33]， 因此在该状态下最佳策略的选择为状态 [6，2，144，192]；</p>\n</li>\n<li><p>状态 [7，5，200，200] 在高温天气的情况下有相邻状态为 [8，6，182，182]，[6，6，182，182]，[7，6，191，191] 其d 值分别为 [362.33，362.33，237.67]， 因此在该状态下最佳策略的选择为状态 [8，6，182，182] 或 [6，6，182，182]；</p>\n</li>\n<li><p>状态[14，10，200，200] 在沙暴天气的情况下有相邻状态为[19，11，180，180]，[9，11，180，180]，[14，11，190，190] 其d 值分别为 [1298.67， 558.00， 863.00]， 因此在该状态下最佳策略的选择为状态 [19，11，180，180]；</p>\n</li>\n<li><p>状态[18，15，200，200] 在高温天气的情况下有相邻状态为[19，16，182，182]，[17，16，182，182]， [18，16，173，173] 其 d 值分别为 [1297.67，1297.67，1954.00]， 因此在该状态下最佳策略的选择为状态 [18，16，173，173]；</p>\n</li>\n<li><p>状态[20，20，200，200] 在晴朗天气的情况下有相邻状态为[25，21，194，192]，[19，21，194，192]，其d 值分别为[515.67，1256.33，811.67]， 因此在该状态下最佳策略的选择为状态[19，21，194，192]；</p>\n</li>\n</ol>\n<h3 id=\"第三题求解\"><a href=\"#第三题求解\" class=\"headerlink\" title=\"第三题求解\"></a>第三题求解</h3><h4 id=\"第三题第一问求解\"><a href=\"#第三题第一问求解\" class=\"headerlink\" title=\"第三题第一问求解\"></a>第三题第一问求解</h4><p>题目给定了新的多人掘金游戏模型，假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案在第 0 天确定且此后不能更改。我们了给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行了具体讨论。</p>\n<p>该问基于改进的 OLBA 和混合博弈模型（完全信息的静态博弈），建立了多玩家同策略集模型 (MNSM 模型)。</p>\n<p>在这种情况下可以视每位玩家都有心中的一个最优策略，那么当多人参加这个游戏时，就涉及到了相互之间的博弈。参加斗争或竞争的各方各自具有不同的目标和利益。为了达到各自的目标和利益，各方必须考虑对手的各种可能的行动方案，并力图选取对自己最为有利或最为合理的方案。博弈论就是研究对策行为中斗争各方是否存在着最合理的行动方案，以及如何找到这个合理的行动方案的数学理论和方法。同时由于所有信息都给定，这可以看作完全信息博弈。</p>\n<p>我们确定了本问中博弈论的三大要素：</p>\n<p>(1). 局中人数: 根据题目要求，玩家人数为 n。</p>\n<p>(2). 策略集: 本题的策略集采用第一问的 OLBA 模型，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上，将会有次优策略、第三优策略等等，每一个新的最优策略建立在已经加入策略集的策略之上， 我们一步步挑选这些策略加入策略集，直到当一个策略满足: 该策略的收益$E_{cur}$小于等于直接从起点走带限制的最短路径到达终点的收益$E_{direct}$。此时如果再将操作继续下去将没有实际意义，故可以不考虑，对算法进行剪枝。将直接从起点走带限制的最短路径到达终点的策略也加入策略集，当前策略集中便是最终的本问所要使用的策略集S。设策略集的个数为 m，玩家 i 的有限纯策略集合可视作：</p>\n<script type=\"math/tex; mode=display\">\nS_{i}=s_{i 1}, s_{i 2}, \\cdots, s_{i m}</script><p>为了避免次优策略等非最优策略和最优策略有过多的重复路径，我们需要对原始图模型G 进行划分，即求图G 中顶点集V 的划分 V1， V2， …， Vn，将 G 分成n 个生成子图G[V1]， G[V2]， …，G[Vn]， 使得：</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/6.png\" alt=\"6\"></p>\n<p>(3). 支付函数: 由于是多人的博弈，求支付函数的过程，也就是求纳什均衡的过程。支付函数由每个玩家的收益期望根据纳什均衡决定，故首先我们需要定义玩家 p 做决策i 的收益 Upi。</p>\n<p>该收益 Upi 由两大部分组成：</p>\n<p>a. 基础收益：在只有一个玩家的情况下，玩家 p 做决策 i 的最后剩余资金量 Bpi</p>\n<p>b. 综合损耗：在其他玩家的影响下所减少的资金。该损耗由两大影响因素决定：</p>\n<ul>\n<li>选择该决策 i 的玩家人数 K（假设选择决策 i 的人数为 Ki）</li>\n<li>其他决策 j 对该决策的固有损耗以及选择决策 j 的玩家人数 Kj</li>\n</ul>\n<p>对于本问，我们首先需要得出策略集。纯策略纳什均衡是指在一个纯策略组合中， 如果给定其他的策略不变，该节点不会单方面改变自己的策略，否则不会使节点访问代价变小。由于策略集可能会比较大，使用纯策略纳什均衡会难以选出最优策略，这时我们考虑加入混合策略纳什均衡博弈的模型。混合策略纳什均衡是面对其他博弈者选择的不确定性的一个理性对策，其主要特征是作为混合策略一部分的每一个纯策略有相同的期望值，否则，一个博弈者会选择那个期望值最高的策略而排除所有其他策略，这意味着原初的状态不是一个均衡。我们设定游戏中每个人都会选择混合策略来考虑自己一开始的路线。</p>\n<p>我们将采用收益相等法，来计算纳什均衡，在得出概率情况之后，由于要给出一般情况下的最优策略，我们需要去具体去衡量每个人选择不同策略的概率，我们通过收益来权衡每个人选择不同策略的概率。将每个人选择不同策略的概率与纳什均衡得出的概率比较，得出一般情况下的最优决策模型。</p>\n<p>在上述模型建立的基础上，我们对附件中的“第五关”进行具体求解：</p>\n<p>（1） 确定局中人数 n=2。</p>\n<p>（2） 根据第一问 OLBA 模型确定策略集。</p>\n<p>首先加入的是最优策略，第 5 关最优策略如图:</p>\n<p>根据第一问的 OLBA 模型确定最优解为 1-&gt;4-&gt;6-&gt;13，最后收益为 9535。如图所示，按模型中的四个约束对图进行划分：</p>\n<p>在子图（图中阴影部分）得出的最优解为：1-&gt;2-&gt;3-&gt;9-&gt;10-&gt;13，最后收益为 9325。即策略 A 的收益为 9539，策略 B 的收益为 9325，按上述方法，以此类推，得出： 策略 C：1-&gt;5-&gt;6-&gt;13，收益为 9535</p>\n<p>（3） 计算支付矩阵</p>\n<p>上述收益均为基础收益，还需按照上述公式计算最终收益：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">A</th>\n<th style=\"text-align:center\">B</th>\n<th style=\"text-align:center\">C</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">(8140 ，8140 )</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n<td style=\"text-align:center\">(9370， 9370 )</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">B</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n<td style=\"text-align:center\">(6400 ，6400 )</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">C</td>\n<td style=\"text-align:center\">(9370， 9370 )</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n<td style=\"text-align:center\">(8140 ，8140 )</td>\n</tr>\n</tbody>\n</table>\n</div>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/7.png\" width=\"400\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/8.png\" width=\"400\"> </center>\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第5关模型和路线结果</center>\n\n<p>玩家 1（行）选择 A 的概率为 p1，选择 B 的概率为 p2，选择 C 的概率为 p3；</p>\n<script type=\"math/tex; mode=display\">\np1 + p2 + p3 = 1</script><p>玩家 2（列）选择 A 的概率为 s1，选择 B 的概率为 s2，选择 C 的概率为 s3;</p>\n<script type=\"math/tex; mode=display\">\ns1 + s2 + s3 = 1</script><p>玩家 1 选择 A 的期望收益等于玩家 1 选择 B 的期望收益等于玩家 1 选择 C 的期望收益，玩家 2 同理。</p>\n<p>利用LINGO 求解得到玩家 1 选择A 策略的概率p1 = 0.4012，p2 = 0.1977，p3=0.4012， 期望收益为 8910.402。</p>\n<p>玩家 2 选择 A 策略的概率 s1=0.4404，s2=1992，s3=0.4404;</p>\n<p>从博弈论的角度来看，两名玩家均选择策略 A 或均选择策略 C 对自己一方的效益最大；题目要求给出一般情况下玩家应采取的策略，由于 A，C 策略期望和概率是相同的，并且都是最大的，那么该名玩家可以选择 A 或者 C。</p>\n<p>但从团体最优的角度来看，为了使整体利益最大，应该一名玩家选择A，一名玩家选择 B</p>\n<h4 id=\"第三题第二问求解\"><a href=\"#第三题第二问求解\" class=\"headerlink\" title=\"第三题第二问求解\"></a>第三题第二问求解</h4><p>本问规定所有玩家仅知道当天的天气状况，从第天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。</p>\n<p>本问在第二问所建立的模型基础上，建立多阶段博弈模型，多阶段博弈扩展形也称为“博弈树”。动态博弈各个博弈方的选择行为有先后次序，多阶段博弈第一个行动选择对应的决策节称为初始节，多阶段博弈一个选择节点所包含的所有信息叫做“信息集”。各博弈方的选择行为会依次形成相连的博弈阶段，因此动态博弈中博弈方的一次选禅行为常称为一个“阶段”。一个动态博弈至少有两个阶段. 因此动态博弃有时也称为“多阶段博弈”。此外. 也有称动态博弈为“序贯博弈”的，多阶段博弈多阶段博弈序贯博弈是指博弈方选择策略有时间先后的博弈形式。同矩阵表示法相比扩展式所扩展的主要是博弈方的策略空间，多阶段博弈即某个博弈方在什么时候行动，多阶段博弈行动时有哪些策略可以选择，以及知道哪些关于博弈的信息在多阶段博弈模型中，当局中人的策略在每一个子博弈中都构成纳什均衡时，则形成“子博弈精炼纳什均衡”。</p>\n<p>因此，问题简化为求解每一步博弈的纳什均衡。对于每一步博弈的纳什均衡，我们采用第三题第一问的方法，即依次确定决策集、支付函数。</p>\n<p>在求解问题二所建立的模型中，我们为了得到最优方案，需要计算玩家在每一步距离终点的效益期望，然后选择效益期望最大的作为下一步的策略选择。因此，在本问中， 我们利用问题二所建立的模型中所得到的“每一步的效益期望”，作为子博弈过程中的效益矩阵中的元素，进而求解每一步的纳什均衡。具体步骤如下：</p>\n<p>（1） 利用问题二的模型求解该图模型“每一步的效益期望”</p>\n<p>（2） 将每一步的效益期望作为该步博弈中的支付矩阵，求解其纳什均衡（求解方法同问题二第一问）</p>\n<p>（3） 重复（2）的过程，求解每一步博弈的纳什均衡，直到归纳到第一个阶段的博弈</p>\n<p>输出最后的博弈结果流程图如下：</p>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/9.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 多阶段博弈流程图</center>\n\n<p>（1）由于第六关和第四关的地图完全一致，故第六关基于(1)(2)问所建立的图模型以及求解该图模型所得到的结果，即“每一步的效益期望”求解。</p>\n<p>（2）在第二问我们所得到的结果中，最后一个状态为 [20,20,200,200]，即玩家在第 20 天到达区域20 所拥有的水的箱数为 200，所拥有的食物的箱数为 200，该状态下所有状态的集合为 [25,21,194,192],[19,21,194,192],[20,21,197,196] 该集合中元素的期望效益所构成的元</p>\n<p>组为 [515.67,1256.33,811.67]。在第二问中，我们选择最大期望收益作为策略。但在此问中，我们考虑的是一个动态博弈过程，因此我们将这些期望收益作为玩家的支付矩阵中的对应策略集。</p>\n<p>得到效益矩阵如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>A</th>\n<th>B</th>\n<th>C</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>(515.7,515.7 )</td>\n<td>(515.7,1256.3)</td>\n<td>(515.7,811.7)</td>\n</tr>\n<tr>\n<td>B</td>\n<td>(515.7,1256.3)</td>\n<td>(1256.3, 1256.3)</td>\n<td>(1256.3,811.7 )</td>\n</tr>\n<tr>\n<td>C</td>\n<td>(515.7,811.7 )</td>\n<td>(1256.3 , 811.7 )</td>\n<td>(811.7,811.7 )</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>（3） 重复步骤二：我们可以得到每一步博弈后玩家的效益矩阵与选择概率</p>\n<p>（4） 综合考虑这些选择概率，我们得到三名玩家在博弈情况下相对最优路径分别为：</p>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/10.png\" width=\"400\"> </center>\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 第6关结果图</center>\n\n<h3 id=\"模型优缺点及改进\"><a href=\"#模型优缺点及改进\" class=\"headerlink\" title=\"模型优缺点及改进\"></a>模型优缺点及改进</h3><h4 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h4><ul>\n<li><p>第一题的 OLBA 模型使用了带队列优化的BellmanFord 模型求最短路，同时对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，这一点大大改进了解决该问的时间复杂度和空间复杂度。并且利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，完善了对模型的情况进行了限定 (如：到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解)。在 c++ 编程下以最快的速度解决同类型问题。该模型适用于所有可能情况，鲁棒性强。</p>\n</li>\n<li><p>第二题基于第一问建立的 OLBA 模型进行改进, 将每个连接分成三种天气进行讨论：在不同天气下，在天气 k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f， 如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值，如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值。这样的数学建模过程，思路严谨并且顺畅，是比较合理的一种改进方法，在第 3,4 关模型中取得了非常好的效果。</p>\n</li>\n<li><p>第三题第一问采用基于改进的 OLBA 和混合博弈模型的多玩家同策略集模型(MNSM 模型)，相对于纯决策博弈更加严谨和适用，策略集选择更加合理，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上。采用收益相等法，来计算纳什均衡，在得出概率情况之后，具体通过收益来线性权衡每个人选择不同策略的概率，得出最优决策模型，建模过程合理简单但不失合理性，代码运行速度快。</p>\n<p>第三题第二问采用基于多阶段纳什均衡和子博弈完美均衡的博弈模型 (MNSE 模型), 算法的选取契合本文动态博弈的机制, 每一步的效益，就用第二大问的算法直接得出，这样就得出每一阶段的支付矩阵, 算法符合实际情况，最终得出每一步的玩家最优决策模型。</p>\n</li>\n</ul>\n<h4 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h4><ul>\n<li>第三题第一问中将图划分为若干子图的过程尽管有严谨的逻辑推导与理论基础，但在实际操作过程中，若图的规模特别大，操作起来时间复杂度会特别高，从而导致求解效率较低。</li>\n<li>第三题第二问的博弈模型对效益考虑的模型存在一定的主观性，如果能够对所有路线的效益进行实时的收益考虑，第三题的准确性将大大提升，这样需要改进算法的时间复杂度以应对规模更大的一般情况。</li>\n</ul>\n<h4 id=\"改进\"><a href=\"#改进\" class=\"headerlink\" title=\"改进\"></a>改进</h4><ul>\n<li>能够在本文的 OLBA 模型下，研究严密的数学逻辑，对图进行一定的缩小，再通过合理减少连边以减小模型的复杂度。在本文建立的 MNSE 模型，在玩家较多的时候，对期望收益进行考虑的复杂度太大，希望能够通过优化模型思路，让模型更加适用于一般情况。</li>\n</ul>\n<h2 id=\"关于答辩\"><a href=\"#关于答辩\" class=\"headerlink\" title=\"关于答辩\"></a>关于答辩</h2><p>在答辩的前第二天的晚上才收到了答辩的通知，作为工具人1号，被安排上了主答辩的位置。匆匆忙忙地整理了套很久没洗的正装，熬夜做PPT到凌晨2点，睡醒了又得知…貌似不用PPT答辩，虽然人傻了，但是生活还得继续嘛。</p>\n<p>由于答辩前的第二天(在还没有接到答辩消息的时候)答应了和朋友出去看电影，于是在答辩前一天地上午急急忙忙地整理好了稿子放在了手机里，便出门赴约了，回来的时候已经大概晚上九点了。才开始急急忙忙地背稿子，关键是两千多字的稿子对我来说就…太离谱了。对于一个早年英语单词认不得和语文古诗默写常年丢分的人来说，背书是不可能背的，于是记了个大概，就睡了。</p>\n<p>时间来到答辩当天，早上五点闹钟响了，现在看来还挺佩服那个时候竟然能起得来。跟着学校其他答辩的人(一共四个组)来到了西南交大希望学院，逛了会校园，便在候场室门口准备着答辩。由于早上忘换鞋了，于是有了经典的一幕，西装配运动鞋，带着这么一身时髦的打扮走进了答辩室。</p>\n<p>答辩过程非常的刺激，才说了不到100个字就被打断了，老师说你别说那么多废话(现在想来也不应该说什么客套话哈哈)。那个数学学院的老师开始了精彩地发问，首先问我们代码是不是自己写的，当然这个问题没有价值。然后问我们第一题解题过程是如何推导的？？？我直接黑人问号</p>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/1.jpg\" width=\"400\"> </center>\n\n\n\n<p>这不是个算法吗，就是建立了一个通用的模型，伪代码也交待地非常清楚。但是老师还是不依不饶，问我们一些非常沙雕的数学公式问题，想了想就一个最短路模型哪来的公式，damn。可能是我才学疏漏吧。</p>\n<p>然后老师问了一个全场最佳的问题，他指着我们的一行c++代码，提问这行语句是干嘛的。卿卿宝贝很认真解释了这段代码在整个程序的作用。老师操着一口四川话一脸正经地说：“我想问的不是这个，我只想问这段话什么意思”，于是我们开始了七嘴八舌地回答，没有回答到点子上。直到卿卿宝贝灵机一动告诉他：“这是个if语句，如何前面的括号里面的条件为真…….，那么程序就会执行这个if语句里面的内容……”，老师心满意足地点了点头…….，直到这一刻我才明白，可能这样的答辩确实也不需要准备吧。涛哥等待了很久的第三题的问答环节也没有上演，实际上整个答辩过程老师也只问了第一题的解答。</p>\n<p>在十五分钟的煎熬之后，我们走出了答辩室，虽然大家人傻了，但是这段经历也告诉了我们，如何和各个学院的老师进行生动地代码解释是多么重要。毕竟各行各业嘛，你觉得甚至不需要解释的一个点，别人也可能不懂，他想知道的，也仅仅是那一个点而已。</p>\n<p>整个答辩的核心也就是：证明这些东西是我们自己完成的就行了。</p>\n<p>答辩结束，下一组是夏大佬和涵哥的答辩(还是为:chicken:拔占领了川大建模的半B江山骄傲哈），他们出答辩室之前，我精准预测，夏哥见我们第一句必定是抱怨那个老师。一会过后，果不其然，隔着一个走廊便传出了一阵熟悉声音：“这老师是xx吧”。整个答辩过程在一阵欢声笑语中打出了GG。</p>\n<p>走出来教学楼，逛了逛校园，合影留念，第一次应该也是最后一次的国赛经历便写到了最后。</p>\n<p>临走前，我开始回忆起这段经历，能走到这里挺意外的，要不是建模题出在了ACM题头上，我相信我们应该并不会来到这里，而我个人在整个建模过程付出的努力也就普普通通，甚至让我觉得自己也不配这份荣誉。这时天空下起了小雨，望着远处来来往往的人群，只是觉得这一切很不真实，很玄幻，而这种感觉，没想到会持续一整个学期(当然这是后话了)。</p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>现在回想起建模那几天也算是一段非常精彩的回忆，那周好像是身体与心理的双重暴击吧。前阵子刚从学校的心理辅导室走出来，长达一个多月的失眠还有掉头发让我的身体也是拉响了警钟。建模过程中也生了一些小病，而在建模最后一天的下午由于去参加CSP考试导致我们浪费了一下午的时间，论文也是匆匆生成便提交上去，这也可能是我们与一等奖无缘的原因吧，现在倒回去看那篇论文的排版确实也是漏洞百出，实属工作失误害。</p>\n<p>在论文截止提交前的两个小时，还和代总联系着要不要去演协的最后一次聚餐，那时我们的论文并没有很完善，但是我心里想着可能这次不去，有些人大概是永远都再见不到了吧，匆匆忙忙地离开了建模的现场，去见了想见的人，也算没有留下遗憾吧。</p>\n<p>这里得着重感谢两位队友的付出，幸好结果是令人满意的。</p>\n<p>附这张亮堂堂的奖状：</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/11.png\" alt=\"11\"></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>于2020年的9月份参加了全国大学生数学建模比赛，第二次参加建模比赛，主要负责论文撰写、模型的设计和验证。在团队中担任了一名相对划水的角色，参赛的时间段正值个人心态爆炸的阶段，导致状态不太靠谱，好在队友非常给力。B题是一道ACM中求最短路的题目，第一问是有标答的，估计后来进国赛也是因为第一问的答案正确，最终在及其神奇的一场答辩中获得了国家二等奖，也算是为我的建模生涯画上了一个比较不错的句号(当然也就参加了两场:smiley:)。</p>\n</blockquote>\n<h2 id=\"题目大意\"><a href=\"#题目大意\" class=\"headerlink\" title=\"题目大意\"></a>题目大意</h2><p>考虑如下的小游戏：玩家凭借一张地图，利用初始资金购买一定数量的水和食物（包括食品和其他日常用品），从起点出发，在沙漠中行走。途中会遇到不同的天气，也可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。<br>游戏的基本规则如下：<br>（1）以天为基本时间单位，游戏的开始时间为第0天，玩家位于起点。玩家必须在截止日期或之前到达终点，到达终点后该玩家的游戏结束。<br>（2）穿越沙漠需水和食物两种资源，它们的最小计量单位均为箱。每天玩家拥有的水和食物质量之和不能超过负重上限。若未到达终点而水或食物已耗尽，视为游戏失败。<br>（3）每天的天气为“晴朗”、“高温”、“沙暴”三种状况之一，沙漠中所有区域的天气相同。<br>（4）每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。沙暴日必须在原地停留。<br>（5）玩家在原地停留一天消耗的资源数量称为基础消耗量，行走一天消耗的资源数量为基础消耗量的 倍。<br>（6）玩家第0天可在起点处用初始资金以基准价格购买水和食物。玩家可在起点停留或回到起点，但不能多次在起点购买资源。玩家到达终点后可退回剩余的水和食物，每箱退回价格为基准价格的一半。<br>（7）玩家在矿山停留时，可通过挖矿获得资金，挖矿一天获得的资金量称为基础收益。如果挖矿，消耗的资源数量为基础消耗量的 倍；如果不挖矿，消耗的资源数量为基础消耗量。到达矿山当天不能挖矿。沙暴日也可挖矿。<br>（8）玩家经过或在村庄停留时可用剩余的初始资金或挖矿获得的资金随时购买水和食物，每箱价格为基准价格的2倍。<br>请根据游戏的不同设定，建立数学模型，解决以下问题。</p>\n<ul>\n<li><p>假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入Result.xlsx。</p>\n</li>\n<li><p>假设只有一名玩家，玩家仅知道当天的天气状况，可据此决定当天的行动方案，试给出一般情况下玩家的最佳策略，并对附件中的“第三关”和“第四关”进行具体讨论。</p>\n</li>\n<li><p>现有 名玩家，他们有相同的初始资金，且同时从起点出发。若某天其中的任意 名玩家均从区域A行走到区域B( )，则他们中的任一位消耗的资源数量均为基础消耗量的 倍；若某天其中的任意 名玩家在同一矿山挖矿，则他们中的任一位消耗的资源数量均为基础消耗量的 倍，且每名玩家一天可通过挖矿获得的资金是基础收益的 ；若某天其中的任意 名玩家在同一村庄购买资源，每箱价格均为基准价格的 倍。其他情况下消耗资源数量与资源价格与单人游戏相同。<br>（1）假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案需在第 天确定且此后不能更改。试给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行具体讨论。<br>（2）假设所有玩家仅知道当天的天气状况，从第 天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。</p>\n<p>注1：附件所给地图中，有公共边界的两个区域称为相邻，仅有公共顶点而没有公共边界的两个区域不视作相邻。<br>注2：Result.xlsx中剩余资金数（剩余水量、剩余食物量）指当日所需资源全部消耗完毕后的资金数（水量、食物量）。若当日还有购买行为，则指完成购买后的资金数（水量、食物量）。</p>\n</li>\n</ul>\n<h2 id=\"题目解答\"><a href=\"#题目解答\" class=\"headerlink\" title=\"题目解答\"></a>题目解答</h2><p>第一二问的核心是建立一个最短路模型，当然在后面和夏大佬的讨论中，我们得知建图的方法不唯一，所谓条条大路通罗马嘛。我甚至怀疑在四川赛区的国赛答辩中，有人是通过非常玄学的方式手算进的答辩，而这只是个人推测嘛，事实如何也并不重要。然后题目的第三问是一道非常扯的题目，很多人都初步了解过博弈这个知识点，但是我们通常了解的都是双人博弈，在过去的ACM训练中，我感觉这是很难弄懂的一个板块，会涉及到一定的数学推导。但事实上第三问并非双人博弈，而是多人博弈模型，所以…</p>\n<p>我们在搜集了大量的资料后，对第三问的解法还是一知半解，于是最终采用了相对比较合理的多人博弈模型，但是也仅供大家参考。</p>\n<h3 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h3><p>考虑如下的小游戏:玩家凭借一张地图，利用初始资金购买一定数量的水和食物 (包括食品和其他日常用品)，从起点出发，在沙漠中行走，途中会遇到不同的天气，也 可在矿山、村庄补充资金或资源，目标是在规定时间内到达终点，并保留尽可能多的资金。</p>\n<p>本文主要尝试建立一种在算法和逻辑层面都优化的最短路算法(OLBA模型)，在此 基础上进行适当的改进已应对各种不同的参数设定情况，给出了附件excel 表格的解决方案。同时使用了博弈论来求解第三题中的两个问题，根据实际题目的情况，给出了一般情况下玩家应采取的策略。</p>\n<p>对问题一，建立了OLBA模型并使用了带队列优化的BellmanFord模型求最短路， 对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，对模型的情况进行了优化。该模型适用于所有可能情况，鲁棒性强，最后用附件中的样例来验证模型是否正确。第1关最优路径结论:在起点购买178 箱水和 333 箱食物，走如图2的路线到终点资金数最大，为10470。第2关最优路径结论:在起点购买130 箱水和405箱食物，走如图2的路线到终点资金数最大，为12730。</p>\n<p>对问题二，基于第一问建立的OLBA模型进行改进， 将每个连接分成三种天气进行讨论，对边权进行更新和推导，输出任意区域的任意天数下的最大期望收益，从而给出一般情况下的最优决策，得到最终模型(W-OLBA模型)这是一种合理的一种改进模型，核心是求策略集合中期望收益最大的状态，该状态即为玩家的最佳策略下的选择， 具体情况需要具体分析。</p>\n<p>对问题三，针对第一问建立了基于改进的OLBA和混合博弈模型的多玩家同策略集模型(MCSM模型)，使用收益相等法计算纳什均衡，为了避免非最优策略和最优策略 有过多的重复路径，将原始图模型G划分成了n个子图 最终在一般情况下玩家应该选择本文图5所展示的A或者C策略的任意一条。针对第二问建立了多阶段纳什均衡和子博弈完美均衡的博弈模型(MNSE模型)，基于W-OLBA模型在利用逆向归纳法求解子博弈纳什均衡的过程中，从动态博弈的最后一个阶段或最后一个子博弈开始，逐步向前倒推，从而达到求解动态博弈均衡的目的。</p>\n<h3 id=\"符号说明\"><a href=\"#符号说明\" class=\"headerlink\" title=\"符号说明\"></a>符号说明</h3><p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/1.png\" alt=\"1\"></p>\n<h3 id=\"第一题求解\"><a href=\"#第一题求解\" class=\"headerlink\" title=\"第一题求解\"></a>第一题求解</h3><p>题目要求假设只有一名玩家，在整个游戏时段内每天天气状况事先全部已知，试给出一般情况下玩家的最优策略。求解附件中的“第一关”和“第二关”，并将相应结果分别填入 Result.xlsx。</p>\n<p>由于我们要给出一般情况下玩家的最优策略，所以第一问的思路是先建立数学模型，最后用附件中的样例来验证答案是否正确。我们根据参数设定、天气状况和地图综合考虑到达终点的所有情况，这里便涉及到了非常多的问题，是否去村庄，是否去矿山， 是否停留。当然如果仅仅从第一关和第二关给出的数据去讨论到达终点的情况是非常片面而且麻烦的。所以我们首先想到基于动态规划模型 (DP 模型) 来思考这道题的结题思路，这样我们的目标终点就不仅仅是某个点，而是一般情况的所有点，同时可以根据不同的参数设定、天气状况和地图去改变 DP 的过程，符合题目要求。</p>\n<p>我们考虑状态的定义，就是最终 DP 的过程量，我们发现第一问影响到结论的不仅仅是到达终点的位置，同样也有负重上限 (水的限制、食物的限制) 和时间上限，因为在保持到某个点的最大收益的同时也要保证负重上限和时间上限没有被超过。如果将这四个数组都搜索一遍，这道题的时间复杂度将达到 O($TnM_{water}M_{food}log(TnM_{water}M_{food})$)， 我们假设普通计算机一秒运算$10^{8}$左右次，在这个复杂度的限制下，我们所能处理的最大的数据规模将被限制在  $TnM_{water}M_{food}$的乘积在$5\\times10^{5}$个数据以内，仅仅处理这道题的所有问题显然足够，但是并非最优，所有我们考虑优化这个时间复杂度。于是我们对图的数据进行了预处理缩点，将最短路直接连边。</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/2.png\" alt=\"1\"></p>\n<p>由于题目中的第四个条件规定了每天玩家可从地图中的某个区域到达与之相邻的另一个区域，也可在原地停留。不难看出这是一个建图的过程，我们将位置信息和时间信息作为图的节点加入图 中，然后设动态规划过程量以位置和负重上限作为标记，而这个数组的值，便是在某个负重上限的限制里到某一节点的最大收益，即:</p>\n<p>d[i] [j] [k]= 在水和食物的箱数分别至少备 j 箱和 k 箱的情况下，从起点到第 i 个点的最小花销。</p>\n<p>有向图模型得出后，转化这道题的题意，将核心从在规定时间内到达终点，并保留尽可能多的资金，转化为在规定时间内到达终点，并尽可能减少花销。这道题将转化为求最短路，我们采用队列优化带限制的 BellmanFord 算法。我们将所有的目标终点的但不同时间的节点都连到一个最终节点，我们求得最短路就是将出发点的第 0 天作为起点，将刚刚提到的最终节点作为终点，求得的一个最短路径，每个边权就是这一天的花销(可能为负)。同时由于在终点卖出食物和水的价格是原价的一半，所以我们优化模型在最后达到终点后的水和食物剩余量为 0。</p>\n<p>建图规则：</p>\n<ul>\n<li>每条边保存三个值，分别为边的权值、消耗的水的箱数、消耗的食物的箱数。</li>\n<li>连节点的方法，边的种类有三种，分别为相同区域相邻天数节点之间的连边（原地停留）、相邻区域相邻天数节点的连边、挖矿连边。其中相同区域相邻天数节点的连边的权值为 0，消耗的水和食物的箱数为基础消耗，相邻区域相邻天数节点的连边的权值为 0，消耗的水和食物为基础消耗的 2 倍，挖矿连边的权值为基础工资，消耗的水和食物的箱数为基础消耗的 3 倍，相邻区域由当前节点 (第 i 个位置，第 j 天) 可以到达相邻点节点 (相邻点的位置，第 j+1 天) 或者原地停留到 (第 i 个位置，第 j+1 天)。</li>\n<li>初始位置为起点的第 0 天。如果不能走到终点，那么最终节点的最小花销值将是INF(无穷大)，如果能走到终点，终点的每一天与最终节点相连，取$D^{i}_{destination}$  ( $1\\leq i \\leq T$)。</li>\n</ul>\n<p>OLBA 模型伪代码如下:</p>\n<hr>\n<p>输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：</p>\n<p>n， m 区域以及相邻区域关系的数目</p>\n<p>K：负重上限</p>\n<p>Init S: 初始资金</p>\n<p>DDL：截止日期</p>\n<p>Income： 基础收入 </p>\n<p>Water：一箱水的重量和价格</p>\n<p>Food：一箱食物的重量和价格</p>\n<p>Consume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴</p>\n<p>Weather[DDL]： 当前天气       </p>\n<p>Mine[n]：区域的类别，其中 1 代表矿山，2 代表村庄</p>\n<p>D[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益</p>\n<p>输出：最优路线</p>\n<hr>\n<p>带限制的 BellmanFord</p>\n<hr>\n<p>算法：</p>\n<p>初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。</p>\n<hr>\n<p>建图：</p>\n<hr>\n<p>顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。</p>\n<p>边：存储 3 个值，分别为权值 val（权值为从上一个状态到当前状态所需的花费，其中只有挖矿边有权值，其余为 0）、从上一个状态到下一个状态所消耗的水的箱数 W、从上一个状态到下一个状态所消耗的食物的箱数 F。</p>\n<p>建边规则：</p>\n<p>同一区域相邻天数顶点之间的边：权值为 0，消耗的水和食物箱数为基础消耗。</p>\n<p>矿山顶点直接按挖矿事件的边：权值为基础收入，消耗的水和食物箱数为基础消耗的 2</p>\n<p>倍。</p>\n<p>相邻区域相邻天数顶点（同时天气不为沙暴）之间的边：权值为 0，消耗的水和食物箱数为基础消耗的 3 倍。</p>\n<ul>\n<li>步骤一：队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。（由于本小题天气情况已知，因此到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解），将状态（T，j，0，0，0）放进队列中，其中 T 为终点区域，j 为日期天数。</li>\n<li>步骤二：</li>\n</ul>\n<ol>\n<li><p>从队列中取出顶点 x。</p>\n</li>\n<li><p>判断该状态是否为属于起点区域中的第一天，如果是，更新答案ans = max(ans， 该状态的 d 值减去水和食物的价格)。</p>\n</li>\n<li><p>判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：</p>\n</li>\n</ol>\n<p>（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<p>（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<ol>\n<li>更新同一区域相邻天数和相邻区域相邻天数的 d 值，如果同一区域相邻天数的 d 值或相邻区域相邻天数的d 值大于在当前状态下d 值加上两者之间边的权值，则更新同一区域相邻天数的d 值或相邻区域相邻天数的d 值，如果该状态不在队列中，则将其加入队列。</li>\n</ol>\n<ul>\n<li>步骤三：重复步骤二，直至优先队列为空。</li>\n<li>步骤四：输出最优路线</li>\n</ul>\n<hr>\n<p>我们使用c++ 代码，在使用了队列优化带限制的BellmanFord 算法，后我们得出了每天的一个行动轨迹和最终的金额。第 1 关和第 2 关的路线图如下:</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/3.png\" alt=\"3\"></p>\n<p>具体每一步的资金消耗图如下:</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/4.png\" alt=\"4\"></p>\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第一二关的过程图</center>\n\n<p>最终的结论是，如图所示，结合 Result.xls 中表格。</p>\n<p>玩家在第一关的最优方案可表述为：</p>\n<p>玩家在起点购买 178 箱水和 333 箱食物，从此处出发，第 13 天依次走到区域 25、24、23，第 4 天停留在 23 区域，第 5、6 天依次走到区域 22、9；第 7 天在区域 9 停留后，第 8 天走到区域 15，即村庄，在此购买 163 箱水；第 9、10 天依次走到区域 14、12，然后第 11 天开始在区域 12 挖矿；连续挖矿 9 天后，第 20 天离开矿区进入区域 14，然后走到村庄（区域 15），并购买 36 箱水和 40 箱食物，以满足行程最后三天所需；第 22天从村庄走到区域 9，途径区域 21，在第 24 天抵达终点（即区域 27）。</p>\n<p>此时剩余资金数最大，为 10470，没有剩余的水和食物。</p>\n<p>第二关的最优方案表示为：</p>\n<p>玩家在起点购买 130 箱水和 405 箱食物，依次经过区域 9/10/19/20/28/30，到达村庄1（即区域 39），玩家在此处购买 168 箱水和 54 箱食物，然后途径区域 47 到达矿区 1（区域 55）挖矿；从第 14 天（到达矿区我的第二天）开始，连续挖矿 5 天，然后去村庄2（区域 62）购买 185 箱水和 8 箱食物，然后回到矿区 1（区域 55）挖矿 8 天；在第 29 天的时候，离开矿区 1（区域 55），经区域 56 到达终点（区域 64）。</p>\n<p>到达终点时剩余资金数为 12730，无剩余的水和食物。</p>\n<h3 id=\"第二题求解\"><a href=\"#第二题求解\" class=\"headerlink\" title=\"第二题求解\"></a>第二题求解</h3><p>W-OLBA 模型伪代码如下:</p>\n<hr>\n<p>输入：地图数据、天气数据、水和食物的基础消耗数据、初始资金与基础收益数据变量：</p>\n<p>n， m 区域以及相邻区域关系的数目</p>\n<p>K：负重上限</p>\n<p>Init S: 初始资金</p>\n<p>DDL：截止日期</p>\n<p>Income：基础收入</p>\n<p>Water：一箱水的重量和价格</p>\n<p>Food：一箱食物的重量和价格</p>\n<p>Consume[3] [2]：不同天气下水和食物的消耗量，其中 0 代表晴朗，1 代表高温，2 代表沙暴 </p>\n<p>Mine[n]：区域的类别，其中 1 代表矿山，2 代表村庄</p>\n<p>D[i] [j] [k]：代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大期望利益</p>\n<p>Dp[i] [j] [k] [t]：代表该状态 i 下拥有 j 箱水和 k 箱食物在天气 t 下所能取得的最大期望收益</p>\n<p>输出：输出任意区域的任意天数下的最大期望收益</p>\n<hr>\n<p>概率 DP 算法：</p>\n<hr>\n<p>初始化：将 d 初始化为正无穷大，d 值代表状态 i 下拥有 j 箱水和 k 箱食物所能取得的最大利益。</p>\n<hr>\n<p>建图：</p>\n<hr>\n<p>顶点：将一个区域拆分成 DDL+1 个点，DDL 为截止天数，即每一个顶点（i， j）代表着区域 i 第 j 天。</p>\n<p>边：权值为从上一个状态到当前状态所需的花费。</p>\n<ul>\n<li>步骤一：</li>\n</ul>\n<p>队列中保存状态（u，j，w，f），其中 u 为区域，j 为日期天数，w，f 该状态下拥有的水和食物。将状态（T，j，w，f）放进优先队列中，其中 T 为终点区域，j 为任意天数，w， f 为任意满足条件的值，同时更新该状态下的 d 值。</p>\n<ul>\n<li>步骤二：</li>\n</ul>\n<ol>\n<li><p>从队列中取出顶点 x。</p>\n</li>\n<li><p>判断该顶点是否为村庄区域，如果是，根据购买事件对购买完一个水箱或者食物箱后的 d 值，更新规则如下：</p>\n</li>\n</ol>\n<p>（1） 购买一个水箱，如果在 w-1 个水箱和f 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上水的价格，则更新在 w-1 个水箱和f 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<p>（2） 购买一个食物箱，如果在w 个水箱和 f-1 个食物箱的d 值大于在w 个水箱和f 个食物箱的d 值加上食物的价格，则更新在w 个水箱和 f-1 个食物箱的d 值，如果该状态不在队列中，则将其加入队列。</p>\n<ol>\n<li>更新同一区域相邻天数和相邻区域相邻天数的 dp 值:</li>\n</ol>\n<p>每个连接分成三种天气进行讨论：</p>\n<p>在不同天气下，在天气k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f，如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值。</p>\n<p>如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值，如果该状态不在队列中，则将其加入队列</p>\n<ul>\n<li><p>步骤三：重复步骤二，直至优先队列为空。</p>\n</li>\n<li><p>步骤四：输出任意区域的任意天数下的最大期望收益</p>\n</li>\n</ul>\n<hr>\n<p> 状态 [i，j，w，f] 代表区域 i 第 j 天玩家拥有的水的箱数 w 以及食物箱数 f，d 值代表该状态下的最大期望收益。</p>\n<p>首先根据算法 2 计算出所有的 d 值，然后进行决策，决策过程如下：</p>\n<p>找出该状态下的所有相邻状态集合，然后找出集合中 d 值最大的状态，该状态即为玩家的最佳策略下的选择。</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/5.png\" alt=\"5\"></p>\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第3关动态决策示例</center>\n\n<p>本文在第三关中共取出来 4 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。</p>\n<ol>\n<li><p>状态[1，1，200，200] 在晴朗天气的情况下有相邻状态为[4，2，194，192]，[1，2，197，196]，其d 值分别为 [868.00，574.00]， 因此在该状态下最佳策略的选择为状态 [4，2，194，192]； </p>\n</li>\n<li><p>状态[3，5，200，200] 在高温天气的情况下有相邻状态为[9，6，182，182]，[4，6，182，182]，[3，6，191，191] 其d 值分别为 [1971.00，860.00，1310.67]， 因此在该状态下最佳策略的选择为状态 [9，6，182，182]；</p>\n</li>\n<li><p>状态[6，15，200，200] 在高温天气的情况下有相邻状态为[13，16，182，182]，[4，16，182，182]，其d 值分别为[860.00，860.00，569.66]， 因此在该状态下最佳策略的选择为状态[13，16，182，182]或 [4，16，182，182]；</p>\n</li>\n<li><p>状态[9，20，200，200] 在晴朗天气的情况下有相邻状态为[11，21，194，192]，[3，21，194，192]， [9，21，191，188] 其d 值分别为 [1282.33，1282.33，1948.67]， 因此在该状态下最佳策略的选择为状态 [9，21，191，188]；</p>\n</li>\n</ol>\n<p>本文在第四关中共取出来 5 个状态观察其相邻状态的取值，并给出在该状态下的最优策略。</p>\n<ol>\n<li><p>状态 [1，1，150，200] 在晴朗天气的情况下有相邻状态为 [6，2，144，192]，[1，2，147，196]，其 d 值分别为 [324.67， 193.33]， 因此在该状态下最佳策略的选择为状态 [6，2，144，192]；</p>\n</li>\n<li><p>状态 [7，5，200，200] 在高温天气的情况下有相邻状态为 [8，6，182，182]，[6，6，182，182]，[7，6，191，191] 其d 值分别为 [362.33，362.33，237.67]， 因此在该状态下最佳策略的选择为状态 [8，6，182，182] 或 [6，6，182，182]；</p>\n</li>\n<li><p>状态[14，10，200，200] 在沙暴天气的情况下有相邻状态为[19，11，180，180]，[9，11，180，180]，[14，11，190，190] 其d 值分别为 [1298.67， 558.00， 863.00]， 因此在该状态下最佳策略的选择为状态 [19，11，180，180]；</p>\n</li>\n<li><p>状态[18，15，200，200] 在高温天气的情况下有相邻状态为[19，16，182，182]，[17，16，182，182]， [18，16，173，173] 其 d 值分别为 [1297.67，1297.67，1954.00]， 因此在该状态下最佳策略的选择为状态 [18，16，173，173]；</p>\n</li>\n<li><p>状态[20，20，200，200] 在晴朗天气的情况下有相邻状态为[25，21，194，192]，[19，21，194，192]，其d 值分别为[515.67，1256.33，811.67]， 因此在该状态下最佳策略的选择为状态[19，21，194，192]；</p>\n</li>\n</ol>\n<h3 id=\"第三题求解\"><a href=\"#第三题求解\" class=\"headerlink\" title=\"第三题求解\"></a>第三题求解</h3><h4 id=\"第三题第一问求解\"><a href=\"#第三题第一问求解\" class=\"headerlink\" title=\"第三题第一问求解\"></a>第三题第一问求解</h4><p>题目给定了新的多人掘金游戏模型，假设在整个游戏时段内每天天气状况事先全部已知，每名玩家的行动方案在第 0 天确定且此后不能更改。我们了给出一般情况下玩家应采取的策略，并对附件中的“第五关”进行了具体讨论。</p>\n<p>该问基于改进的 OLBA 和混合博弈模型（完全信息的静态博弈），建立了多玩家同策略集模型 (MNSM 模型)。</p>\n<p>在这种情况下可以视每位玩家都有心中的一个最优策略，那么当多人参加这个游戏时，就涉及到了相互之间的博弈。参加斗争或竞争的各方各自具有不同的目标和利益。为了达到各自的目标和利益，各方必须考虑对手的各种可能的行动方案，并力图选取对自己最为有利或最为合理的方案。博弈论就是研究对策行为中斗争各方是否存在着最合理的行动方案，以及如何找到这个合理的行动方案的数学理论和方法。同时由于所有信息都给定，这可以看作完全信息博弈。</p>\n<p>我们确定了本问中博弈论的三大要素：</p>\n<p>(1). 局中人数: 根据题目要求，玩家人数为 n。</p>\n<p>(2). 策略集: 本题的策略集采用第一问的 OLBA 模型，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上，将会有次优策略、第三优策略等等，每一个新的最优策略建立在已经加入策略集的策略之上， 我们一步步挑选这些策略加入策略集，直到当一个策略满足: 该策略的收益$E_{cur}$小于等于直接从起点走带限制的最短路径到达终点的收益$E_{direct}$。此时如果再将操作继续下去将没有实际意义，故可以不考虑，对算法进行剪枝。将直接从起点走带限制的最短路径到达终点的策略也加入策略集，当前策略集中便是最终的本问所要使用的策略集S。设策略集的个数为 m，玩家 i 的有限纯策略集合可视作：</p>\n<script type=\"math/tex; mode=display\">\nS_{i}=s_{i 1}, s_{i 2}, \\cdots, s_{i m}</script><p>为了避免次优策略等非最优策略和最优策略有过多的重复路径，我们需要对原始图模型G 进行划分，即求图G 中顶点集V 的划分 V1， V2， …， Vn，将 G 分成n 个生成子图G[V1]， G[V2]， …，G[Vn]， 使得：</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/6.png\" alt=\"6\"></p>\n<p>(3). 支付函数: 由于是多人的博弈，求支付函数的过程，也就是求纳什均衡的过程。支付函数由每个玩家的收益期望根据纳什均衡决定，故首先我们需要定义玩家 p 做决策i 的收益 Upi。</p>\n<p>该收益 Upi 由两大部分组成：</p>\n<p>a. 基础收益：在只有一个玩家的情况下，玩家 p 做决策 i 的最后剩余资金量 Bpi</p>\n<p>b. 综合损耗：在其他玩家的影响下所减少的资金。该损耗由两大影响因素决定：</p>\n<ul>\n<li>选择该决策 i 的玩家人数 K（假设选择决策 i 的人数为 Ki）</li>\n<li>其他决策 j 对该决策的固有损耗以及选择决策 j 的玩家人数 Kj</li>\n</ul>\n<p>对于本问，我们首先需要得出策略集。纯策略纳什均衡是指在一个纯策略组合中， 如果给定其他的策略不变，该节点不会单方面改变自己的策略，否则不会使节点访问代价变小。由于策略集可能会比较大，使用纯策略纳什均衡会难以选出最优策略，这时我们考虑加入混合策略纳什均衡博弈的模型。混合策略纳什均衡是面对其他博弈者选择的不确定性的一个理性对策，其主要特征是作为混合策略一部分的每一个纯策略有相同的期望值，否则，一个博弈者会选择那个期望值最高的策略而排除所有其他策略，这意味着原初的状态不是一个均衡。我们设定游戏中每个人都会选择混合策略来考虑自己一开始的路线。</p>\n<p>我们将采用收益相等法，来计算纳什均衡，在得出概率情况之后，由于要给出一般情况下的最优策略，我们需要去具体去衡量每个人选择不同策略的概率，我们通过收益来权衡每个人选择不同策略的概率。将每个人选择不同策略的概率与纳什均衡得出的概率比较，得出一般情况下的最优决策模型。</p>\n<p>在上述模型建立的基础上，我们对附件中的“第五关”进行具体求解：</p>\n<p>（1） 确定局中人数 n=2。</p>\n<p>（2） 根据第一问 OLBA 模型确定策略集。</p>\n<p>首先加入的是最优策略，第 5 关最优策略如图:</p>\n<p>根据第一问的 OLBA 模型确定最优解为 1-&gt;4-&gt;6-&gt;13，最后收益为 9535。如图所示，按模型中的四个约束对图进行划分：</p>\n<p>在子图（图中阴影部分）得出的最优解为：1-&gt;2-&gt;3-&gt;9-&gt;10-&gt;13，最后收益为 9325。即策略 A 的收益为 9539，策略 B 的收益为 9325，按上述方法，以此类推，得出： 策略 C：1-&gt;5-&gt;6-&gt;13，收益为 9535</p>\n<p>（3） 计算支付矩阵</p>\n<p>上述收益均为基础收益，还需按照上述公式计算最终收益：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">A</th>\n<th style=\"text-align:center\">B</th>\n<th style=\"text-align:center\">C</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">(8140 ，8140 )</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n<td style=\"text-align:center\">(9370， 9370 )</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">B</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n<td style=\"text-align:center\">(6400 ，6400 )</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">C</td>\n<td style=\"text-align:center\">(9370， 9370 )</td>\n<td style=\"text-align:center\">(9535 ，9525 )</td>\n<td style=\"text-align:center\">(8140 ，8140 )</td>\n</tr>\n</tbody>\n</table>\n</div>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/7.png\" width=\"400\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/8.png\" width=\"400\"> </center>\n\n <center style=\"color:#C0C0C0;text-decoration:underline\">图. 第5关模型和路线结果</center>\n\n<p>玩家 1（行）选择 A 的概率为 p1，选择 B 的概率为 p2，选择 C 的概率为 p3；</p>\n<script type=\"math/tex; mode=display\">\np1 + p2 + p3 = 1</script><p>玩家 2（列）选择 A 的概率为 s1，选择 B 的概率为 s2，选择 C 的概率为 s3;</p>\n<script type=\"math/tex; mode=display\">\ns1 + s2 + s3 = 1</script><p>玩家 1 选择 A 的期望收益等于玩家 1 选择 B 的期望收益等于玩家 1 选择 C 的期望收益，玩家 2 同理。</p>\n<p>利用LINGO 求解得到玩家 1 选择A 策略的概率p1 = 0.4012，p2 = 0.1977，p3=0.4012， 期望收益为 8910.402。</p>\n<p>玩家 2 选择 A 策略的概率 s1=0.4404，s2=1992，s3=0.4404;</p>\n<p>从博弈论的角度来看，两名玩家均选择策略 A 或均选择策略 C 对自己一方的效益最大；题目要求给出一般情况下玩家应采取的策略，由于 A，C 策略期望和概率是相同的，并且都是最大的，那么该名玩家可以选择 A 或者 C。</p>\n<p>但从团体最优的角度来看，为了使整体利益最大，应该一名玩家选择A，一名玩家选择 B</p>\n<h4 id=\"第三题第二问求解\"><a href=\"#第三题第二问求解\" class=\"headerlink\" title=\"第三题第二问求解\"></a>第三题第二问求解</h4><p>本问规定所有玩家仅知道当天的天气状况，从第天起，每名玩家在当天行动结束后均知道其余玩家当天的行动方案和剩余的资源数量，随后确定各自第二天的行动方案。试给出一般情况下玩家应采取的策略，并对附件中的“第六关”进行具体讨论。</p>\n<p>本问在第二问所建立的模型基础上，建立多阶段博弈模型，多阶段博弈扩展形也称为“博弈树”。动态博弈各个博弈方的选择行为有先后次序，多阶段博弈第一个行动选择对应的决策节称为初始节，多阶段博弈一个选择节点所包含的所有信息叫做“信息集”。各博弈方的选择行为会依次形成相连的博弈阶段，因此动态博弈中博弈方的一次选禅行为常称为一个“阶段”。一个动态博弈至少有两个阶段. 因此动态博弃有时也称为“多阶段博弈”。此外. 也有称动态博弈为“序贯博弈”的，多阶段博弈多阶段博弈序贯博弈是指博弈方选择策略有时间先后的博弈形式。同矩阵表示法相比扩展式所扩展的主要是博弈方的策略空间，多阶段博弈即某个博弈方在什么时候行动，多阶段博弈行动时有哪些策略可以选择，以及知道哪些关于博弈的信息在多阶段博弈模型中，当局中人的策略在每一个子博弈中都构成纳什均衡时，则形成“子博弈精炼纳什均衡”。</p>\n<p>因此，问题简化为求解每一步博弈的纳什均衡。对于每一步博弈的纳什均衡，我们采用第三题第一问的方法，即依次确定决策集、支付函数。</p>\n<p>在求解问题二所建立的模型中，我们为了得到最优方案，需要计算玩家在每一步距离终点的效益期望，然后选择效益期望最大的作为下一步的策略选择。因此，在本问中， 我们利用问题二所建立的模型中所得到的“每一步的效益期望”，作为子博弈过程中的效益矩阵中的元素，进而求解每一步的纳什均衡。具体步骤如下：</p>\n<p>（1） 利用问题二的模型求解该图模型“每一步的效益期望”</p>\n<p>（2） 将每一步的效益期望作为该步博弈中的支付矩阵，求解其纳什均衡（求解方法同问题二第一问）</p>\n<p>（3） 重复（2）的过程，求解每一步博弈的纳什均衡，直到归纳到第一个阶段的博弈</p>\n<p>输出最后的博弈结果流程图如下：</p>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/9.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 多阶段博弈流程图</center>\n\n<p>（1）由于第六关和第四关的地图完全一致，故第六关基于(1)(2)问所建立的图模型以及求解该图模型所得到的结果，即“每一步的效益期望”求解。</p>\n<p>（2）在第二问我们所得到的结果中，最后一个状态为 [20,20,200,200]，即玩家在第 20 天到达区域20 所拥有的水的箱数为 200，所拥有的食物的箱数为 200，该状态下所有状态的集合为 [25,21,194,192],[19,21,194,192],[20,21,197,196] 该集合中元素的期望效益所构成的元</p>\n<p>组为 [515.67,1256.33,811.67]。在第二问中，我们选择最大期望收益作为策略。但在此问中，我们考虑的是一个动态博弈过程，因此我们将这些期望收益作为玩家的支付矩阵中的对应策略集。</p>\n<p>得到效益矩阵如下：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>A</th>\n<th>B</th>\n<th>C</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>(515.7,515.7 )</td>\n<td>(515.7,1256.3)</td>\n<td>(515.7,811.7)</td>\n</tr>\n<tr>\n<td>B</td>\n<td>(515.7,1256.3)</td>\n<td>(1256.3, 1256.3)</td>\n<td>(1256.3,811.7 )</td>\n</tr>\n<tr>\n<td>C</td>\n<td>(515.7,811.7 )</td>\n<td>(1256.3 , 811.7 )</td>\n<td>(811.7,811.7 )</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>（3） 重复步骤二：我们可以得到每一步博弈后玩家的效益矩阵与选择概率</p>\n<p>（4） 综合考虑这些选择概率，我们得到三名玩家在博弈情况下相对最优路径分别为：</p>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/10.png\" width=\"400\"> </center>\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图. 第6关结果图</center>\n\n<h3 id=\"模型优缺点及改进\"><a href=\"#模型优缺点及改进\" class=\"headerlink\" title=\"模型优缺点及改进\"></a>模型优缺点及改进</h3><h4 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h4><ul>\n<li><p>第一题的 OLBA 模型使用了带队列优化的BellmanFord 模型求最短路，同时对图进行了预处理缩点，将最短路直接连边，并且抽象地将时间信息和地点信息作为建图的节点，这一点大大改进了解决该问的时间复杂度和空间复杂度。并且利用了数学模型得出了一些不可能的连边情况，从而进行模型剪枝，在辅助结论的推导下，完善了对模型的情况进行了限定 (如：到达终点后剩余的水和食物的箱数都为 0 的状态下取得最优解)。在 c++ 编程下以最快的速度解决同类型问题。该模型适用于所有可能情况，鲁棒性强。</p>\n</li>\n<li><p>第二题基于第一问建立的 OLBA 模型进行改进, 将每个连接分成三种天气进行讨论：在不同天气下，在天气 k 和当前状态推断出上一个状态的水箱数w 以及食物箱数f， 如果上一个状态在天气 k 的 dp 值大于在当前状态下 d 值加上两者之间边的权值，则更新上一个状态在天气 k 下的 dp 值，如果上一个状态的所有天气情况都已经计算过，则上一个状态的 d 值为三种天气情况下的 dp 值的均值。这样的数学建模过程，思路严谨并且顺畅，是比较合理的一种改进方法，在第 3,4 关模型中取得了非常好的效果。</p>\n</li>\n<li><p>第三题第一问采用基于改进的 OLBA 和混合博弈模型的多玩家同策略集模型(MNSM 模型)，相对于纯决策博弈更加严谨和适用，策略集选择更加合理，策略集中的最优策略就是第一问中” 一般情况下玩家的最优策略”，其他策略建立在最优策略存在的基础上。采用收益相等法，来计算纳什均衡，在得出概率情况之后，具体通过收益来线性权衡每个人选择不同策略的概率，得出最优决策模型，建模过程合理简单但不失合理性，代码运行速度快。</p>\n<p>第三题第二问采用基于多阶段纳什均衡和子博弈完美均衡的博弈模型 (MNSE 模型), 算法的选取契合本文动态博弈的机制, 每一步的效益，就用第二大问的算法直接得出，这样就得出每一阶段的支付矩阵, 算法符合实际情况，最终得出每一步的玩家最优决策模型。</p>\n</li>\n</ul>\n<h4 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h4><ul>\n<li>第三题第一问中将图划分为若干子图的过程尽管有严谨的逻辑推导与理论基础，但在实际操作过程中，若图的规模特别大，操作起来时间复杂度会特别高，从而导致求解效率较低。</li>\n<li>第三题第二问的博弈模型对效益考虑的模型存在一定的主观性，如果能够对所有路线的效益进行实时的收益考虑，第三题的准确性将大大提升，这样需要改进算法的时间复杂度以应对规模更大的一般情况。</li>\n</ul>\n<h4 id=\"改进\"><a href=\"#改进\" class=\"headerlink\" title=\"改进\"></a>改进</h4><ul>\n<li>能够在本文的 OLBA 模型下，研究严密的数学逻辑，对图进行一定的缩小，再通过合理减少连边以减小模型的复杂度。在本文建立的 MNSE 模型，在玩家较多的时候，对期望收益进行考虑的复杂度太大，希望能够通过优化模型思路，让模型更加适用于一般情况。</li>\n</ul>\n<h2 id=\"关于答辩\"><a href=\"#关于答辩\" class=\"headerlink\" title=\"关于答辩\"></a>关于答辩</h2><p>在答辩的前第二天的晚上才收到了答辩的通知，作为工具人1号，被安排上了主答辩的位置。匆匆忙忙地整理了套很久没洗的正装，熬夜做PPT到凌晨2点，睡醒了又得知…貌似不用PPT答辩，虽然人傻了，但是生活还得继续嘛。</p>\n<p>由于答辩前的第二天(在还没有接到答辩消息的时候)答应了和朋友出去看电影，于是在答辩前一天地上午急急忙忙地整理好了稿子放在了手机里，便出门赴约了，回来的时候已经大概晚上九点了。才开始急急忙忙地背稿子，关键是两千多字的稿子对我来说就…太离谱了。对于一个早年英语单词认不得和语文古诗默写常年丢分的人来说，背书是不可能背的，于是记了个大概，就睡了。</p>\n<p>时间来到答辩当天，早上五点闹钟响了，现在看来还挺佩服那个时候竟然能起得来。跟着学校其他答辩的人(一共四个组)来到了西南交大希望学院，逛了会校园，便在候场室门口准备着答辩。由于早上忘换鞋了，于是有了经典的一幕，西装配运动鞋，带着这么一身时髦的打扮走进了答辩室。</p>\n<p>答辩过程非常的刺激，才说了不到100个字就被打断了，老师说你别说那么多废话(现在想来也不应该说什么客套话哈哈)。那个数学学院的老师开始了精彩地发问，首先问我们代码是不是自己写的，当然这个问题没有价值。然后问我们第一题解题过程是如何推导的？？？我直接黑人问号</p>\n<center class=\"half\">    <img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/1.jpg\" width=\"400\"> </center>\n\n\n\n<p>这不是个算法吗，就是建立了一个通用的模型，伪代码也交待地非常清楚。但是老师还是不依不饶，问我们一些非常沙雕的数学公式问题，想了想就一个最短路模型哪来的公式，damn。可能是我才学疏漏吧。</p>\n<p>然后老师问了一个全场最佳的问题，他指着我们的一行c++代码，提问这行语句是干嘛的。卿卿宝贝很认真解释了这段代码在整个程序的作用。老师操着一口四川话一脸正经地说：“我想问的不是这个，我只想问这段话什么意思”，于是我们开始了七嘴八舌地回答，没有回答到点子上。直到卿卿宝贝灵机一动告诉他：“这是个if语句，如何前面的括号里面的条件为真…….，那么程序就会执行这个if语句里面的内容……”，老师心满意足地点了点头…….，直到这一刻我才明白，可能这样的答辩确实也不需要准备吧。涛哥等待了很久的第三题的问答环节也没有上演，实际上整个答辩过程老师也只问了第一题的解答。</p>\n<p>在十五分钟的煎熬之后，我们走出了答辩室，虽然大家人傻了，但是这段经历也告诉了我们，如何和各个学院的老师进行生动地代码解释是多么重要。毕竟各行各业嘛，你觉得甚至不需要解释的一个点，别人也可能不懂，他想知道的，也仅仅是那一个点而已。</p>\n<p>整个答辩的核心也就是：证明这些东西是我们自己完成的就行了。</p>\n<p>答辩结束，下一组是夏大佬和涵哥的答辩(还是为:chicken:拔占领了川大建模的半B江山骄傲哈），他们出答辩室之前，我精准预测，夏哥见我们第一句必定是抱怨那个老师。一会过后，果不其然，隔着一个走廊便传出了一阵熟悉声音：“这老师是xx吧”。整个答辩过程在一阵欢声笑语中打出了GG。</p>\n<p>走出来教学楼，逛了逛校园，合影留念，第一次应该也是最后一次的国赛经历便写到了最后。</p>\n<p>临走前，我开始回忆起这段经历，能走到这里挺意外的，要不是建模题出在了ACM题头上，我相信我们应该并不会来到这里，而我个人在整个建模过程付出的努力也就普普通通，甚至让我觉得自己也不配这份荣誉。这时天空下起了小雨，望着远处来来往往的人群，只是觉得这一切很不真实，很玄幻，而这种感觉，没想到会持续一整个学期(当然这是后话了)。</p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>现在回想起建模那几天也算是一段非常精彩的回忆，那周好像是身体与心理的双重暴击吧。前阵子刚从学校的心理辅导室走出来，长达一个多月的失眠还有掉头发让我的身体也是拉响了警钟。建模过程中也生了一些小病，而在建模最后一天的下午由于去参加CSP考试导致我们浪费了一下午的时间，论文也是匆匆生成便提交上去，这也可能是我们与一等奖无缘的原因吧，现在倒回去看那篇论文的排版确实也是漏洞百出，实属工作失误害。</p>\n<p>在论文截止提交前的两个小时，还和代总联系着要不要去演协的最后一次聚餐，那时我们的论文并没有很完善，但是我心里想着可能这次不去，有些人大概是永远都再见不到了吧，匆匆忙忙地离开了建模的现场，去见了想见的人，也算没有留下遗憾吧。</p>\n<p>这里得着重感谢两位队友的付出，幸好结果是令人满意的。</p>\n<p>附这张亮堂堂的奖状：</p>\n<p><img src=\"/2021/01/27/2020%E5%85%A8%E5%9B%BD%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%AF%94%E8%B5%9BB%E9%A2%98/11.png\" alt=\"11\"></p>\n"},{"title":"20岁那年的一些故事","catalog":true,"date":"2021-02-19T06:36:49.000Z","subtitle":"在发光的岁月里...","top":7,"header-img":"/img/header_img/1.jpg","_content":"\n### 前言\n\n自疫情以后就很少发动态和朋友圈了，加之上学期待在VR馆的时间比较多，跟大家见面的时间就相对少了，前段时间甚至有好几位老友问我近来如此沉默，是不是心理出什么问题了:joy:。\n\n虽然事到如今我也会偶尔感叹生活不太顺心，但过去一年的经历给了我太多的成长，这些就已经足够了，毕竟生活并不是以结果来作为唯一的衡量标准。现在看着身边朋友们过得风生水起，是有些羡慕，不过更多的还是为大家都能取得自己想要的东西而高兴，在这里也衷心为大家祝福！\n\n在可预见的未来里，一切都会好起来的。\n\n### 零零散散的一些收获\n\n* 顺利地完成了青志队长的工作，历史性地获得了非常好的评分，没有辜负大家的期待！\n* 从零开始学习深度学习的一些相关算法，完成了两个算法工程项目，项目在各项计算机大赛中获得了一些优异的成绩，也算为校争光了！\n* 完成了第一篇论文的撰写和发表，虽然并没有投中很好的会议，但对于大二的我已经非常满足了。\n* 在年末面试了院长的实验室，最终选择了进入大数据组来开始我下一个阶段的学习。\n* 综合排名前五，申请到了一些奖学金，大概三万左右，后来在家长的掌控下拿去买基金了，然后暴跌:sob: 。\n* 在二餐对面，原洗浴中心的VR馆，找到了新的工位，希望在未来的日子里能布置一下，欢迎大家来这里找我玩啊。\n* 最后一轮留班之后压力可能就没有那么大了，至少以后有书读了。\n* 寒假建立了自己的个人博客（虽然很简陋）。\n* 渐渐开始学习非社团性质的社交，组织或者参加了一些团建活动，希望大家以后能带我玩啊。团建气氛组，铁头工具人，闪亮电灯泡，临时摄影师一定不拉跨！\n* 做了一些有意义的事，疫情参与了社区的服务工作、期末在学校抓狗狗送去了爱心基地。\n* 没有认识很多新朋友，但是身边的大家都挺nice的，感谢大家对我的照顾啊啊啊！！！\n\n\n\n### 一段视频\n\n视频资源大部分来自于过去的一年，部分片段来自于2019年，一来是为毕业视频做个铺垫嘛，二来我收集的大多数是照片，第一次剪vlog素材也不是很够hh。\n\n对于我，该知道的都知道，不该知道的慢慢了解嘛。\n\n最后还是感谢我身边的朋友们，我一直觉得有大家是我一生的幸运。\n\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\"          src=\"//player.bilibili.com/player.html?aid=501821936&bvid=BV1AN41197DR&cid=299652862&page=1\"          scrolling=\"no\"          border=\"0\"          frameborder=\"no\"          framespacing=\"0\"          allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n### 心路历程\n\n2020年的前六个月基本上就是在家上网课，和所有人的生活都一样。只不过那时候得同时面临着学业和比赛，做比赛当负责人是真的真的非常累，不规律的作息时间和能否留班的多重压力让我的身体在七八九月份的时候就...彻底拉跨了。集中的表现就是疯狂掉头发、失眠，但那段时间还得操心各种答辩，也顾不上那么多了，硬着头皮把所有事情处理完了。\n\n之后带着一身疲惫见了心理医生，解决完失眠的问题，已经十月份了，然后开始了在VR馆自闭的日子，直到12月份去杭州回来之后，开始思考自己长期以来心态不好的原因，努力没有白费，问题也得到了解决。\n\n期间印象比较深刻的是，在主席团换届后，团委老师在聊学生工作时，有顺便和我探讨过关于我的一些问题，老师觉得我应该多出去见一些人，学习如何去和人相处，与不同的人社交。以前的我一直以为这方面是没有问题，但后来我发现如果只是在社团做做事什么的，可能还是能应付，但是社交并不只是有这些。于是在各位朋友的带领下，又开始了新一轮的学习。\n\n时间来到2021年的二月份，寒假并没有做什么有关学习的事，但身边的朋友们教会了我很多道理，而我也渐渐有了信心去面对以前我束手无策的一些事情了。自信这一点来说对于以前的我是缺乏的，自信需要什么作为资本吗？一定需要一个优异的成绩或者良好的朋友圈又或者是高情商的为人处世吗？并不是这样的，自信是一种状态，是要用你在未来对事情的态度和做法来证明的，而不是用过去的一些东西来证明的。\n\n\n\n### 展望\n\n* 希望家人和朋友们能身体健康，开开心心。\n* 希望疫情快快过去。\n* 能想清楚未来想做什么方向的研究吧！！！\n* 其他的一切随缘吧，别做任何一个会后悔的决定。","source":"_posts/20岁那年的一些故事.md","raw":"---\ntitle: 20岁那年的一些故事\ncatalog: true\ndate: 2021-02-19 14:36:49\nsubtitle: 在发光的岁月里...\ntop: 7\nheader-img: /img/header_img/1.jpg\ntags:\n- Premiere Pro CC\n- Osmo Mobile3\ncategories:\n- 生活日常\n---\n\n### 前言\n\n自疫情以后就很少发动态和朋友圈了，加之上学期待在VR馆的时间比较多，跟大家见面的时间就相对少了，前段时间甚至有好几位老友问我近来如此沉默，是不是心理出什么问题了:joy:。\n\n虽然事到如今我也会偶尔感叹生活不太顺心，但过去一年的经历给了我太多的成长，这些就已经足够了，毕竟生活并不是以结果来作为唯一的衡量标准。现在看着身边朋友们过得风生水起，是有些羡慕，不过更多的还是为大家都能取得自己想要的东西而高兴，在这里也衷心为大家祝福！\n\n在可预见的未来里，一切都会好起来的。\n\n### 零零散散的一些收获\n\n* 顺利地完成了青志队长的工作，历史性地获得了非常好的评分，没有辜负大家的期待！\n* 从零开始学习深度学习的一些相关算法，完成了两个算法工程项目，项目在各项计算机大赛中获得了一些优异的成绩，也算为校争光了！\n* 完成了第一篇论文的撰写和发表，虽然并没有投中很好的会议，但对于大二的我已经非常满足了。\n* 在年末面试了院长的实验室，最终选择了进入大数据组来开始我下一个阶段的学习。\n* 综合排名前五，申请到了一些奖学金，大概三万左右，后来在家长的掌控下拿去买基金了，然后暴跌:sob: 。\n* 在二餐对面，原洗浴中心的VR馆，找到了新的工位，希望在未来的日子里能布置一下，欢迎大家来这里找我玩啊。\n* 最后一轮留班之后压力可能就没有那么大了，至少以后有书读了。\n* 寒假建立了自己的个人博客（虽然很简陋）。\n* 渐渐开始学习非社团性质的社交，组织或者参加了一些团建活动，希望大家以后能带我玩啊。团建气氛组，铁头工具人，闪亮电灯泡，临时摄影师一定不拉跨！\n* 做了一些有意义的事，疫情参与了社区的服务工作、期末在学校抓狗狗送去了爱心基地。\n* 没有认识很多新朋友，但是身边的大家都挺nice的，感谢大家对我的照顾啊啊啊！！！\n\n\n\n### 一段视频\n\n视频资源大部分来自于过去的一年，部分片段来自于2019年，一来是为毕业视频做个铺垫嘛，二来我收集的大多数是照片，第一次剪vlog素材也不是很够hh。\n\n对于我，该知道的都知道，不该知道的慢慢了解嘛。\n\n最后还是感谢我身边的朋友们，我一直觉得有大家是我一生的幸运。\n\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\"          src=\"//player.bilibili.com/player.html?aid=501821936&bvid=BV1AN41197DR&cid=299652862&page=1\"          scrolling=\"no\"          border=\"0\"          frameborder=\"no\"          framespacing=\"0\"          allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n### 心路历程\n\n2020年的前六个月基本上就是在家上网课，和所有人的生活都一样。只不过那时候得同时面临着学业和比赛，做比赛当负责人是真的真的非常累，不规律的作息时间和能否留班的多重压力让我的身体在七八九月份的时候就...彻底拉跨了。集中的表现就是疯狂掉头发、失眠，但那段时间还得操心各种答辩，也顾不上那么多了，硬着头皮把所有事情处理完了。\n\n之后带着一身疲惫见了心理医生，解决完失眠的问题，已经十月份了，然后开始了在VR馆自闭的日子，直到12月份去杭州回来之后，开始思考自己长期以来心态不好的原因，努力没有白费，问题也得到了解决。\n\n期间印象比较深刻的是，在主席团换届后，团委老师在聊学生工作时，有顺便和我探讨过关于我的一些问题，老师觉得我应该多出去见一些人，学习如何去和人相处，与不同的人社交。以前的我一直以为这方面是没有问题，但后来我发现如果只是在社团做做事什么的，可能还是能应付，但是社交并不只是有这些。于是在各位朋友的带领下，又开始了新一轮的学习。\n\n时间来到2021年的二月份，寒假并没有做什么有关学习的事，但身边的朋友们教会了我很多道理，而我也渐渐有了信心去面对以前我束手无策的一些事情了。自信这一点来说对于以前的我是缺乏的，自信需要什么作为资本吗？一定需要一个优异的成绩或者良好的朋友圈又或者是高情商的为人处世吗？并不是这样的，自信是一种状态，是要用你在未来对事情的态度和做法来证明的，而不是用过去的一些东西来证明的。\n\n\n\n### 展望\n\n* 希望家人和朋友们能身体健康，开开心心。\n* 希望疫情快快过去。\n* 能想清楚未来想做什么方向的研究吧！！！\n* 其他的一切随缘吧，别做任何一个会后悔的决定。","slug":"20岁那年的一些故事","published":1,"updated":"2022-01-13T09:01:13.267Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxwn00033oue85nqa4v5","content":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>自疫情以后就很少发动态和朋友圈了，加之上学期待在VR馆的时间比较多，跟大家见面的时间就相对少了，前段时间甚至有好几位老友问我近来如此沉默，是不是心理出什么问题了:joy:。</p>\n<p>虽然事到如今我也会偶尔感叹生活不太顺心，但过去一年的经历给了我太多的成长，这些就已经足够了，毕竟生活并不是以结果来作为唯一的衡量标准。现在看着身边朋友们过得风生水起，是有些羡慕，不过更多的还是为大家都能取得自己想要的东西而高兴，在这里也衷心为大家祝福！</p>\n<p>在可预见的未来里，一切都会好起来的。</p>\n<h3 id=\"零零散散的一些收获\"><a href=\"#零零散散的一些收获\" class=\"headerlink\" title=\"零零散散的一些收获\"></a>零零散散的一些收获</h3><ul>\n<li>顺利地完成了青志队长的工作，历史性地获得了非常好的评分，没有辜负大家的期待！</li>\n<li>从零开始学习深度学习的一些相关算法，完成了两个算法工程项目，项目在各项计算机大赛中获得了一些优异的成绩，也算为校争光了！</li>\n<li>完成了第一篇论文的撰写和发表，虽然并没有投中很好的会议，但对于大二的我已经非常满足了。</li>\n<li>在年末面试了院长的实验室，最终选择了进入大数据组来开始我下一个阶段的学习。</li>\n<li>综合排名前五，申请到了一些奖学金，大概三万左右，后来在家长的掌控下拿去买基金了，然后暴跌:sob: 。</li>\n<li>在二餐对面，原洗浴中心的VR馆，找到了新的工位，希望在未来的日子里能布置一下，欢迎大家来这里找我玩啊。</li>\n<li>最后一轮留班之后压力可能就没有那么大了，至少以后有书读了。</li>\n<li>寒假建立了自己的个人博客（虽然很简陋）。</li>\n<li>渐渐开始学习非社团性质的社交，组织或者参加了一些团建活动，希望大家以后能带我玩啊。团建气氛组，铁头工具人，闪亮电灯泡，临时摄影师一定不拉跨！</li>\n<li>做了一些有意义的事，疫情参与了社区的服务工作、期末在学校抓狗狗送去了爱心基地。</li>\n<li>没有认识很多新朋友，但是身边的大家都挺nice的，感谢大家对我的照顾啊啊啊！！！</li>\n</ul>\n<h3 id=\"一段视频\"><a href=\"#一段视频\" class=\"headerlink\" title=\"一段视频\"></a>一段视频</h3><p>视频资源大部分来自于过去的一年，部分片段来自于2019年，一来是为毕业视频做个铺垫嘛，二来我收集的大多数是照片，第一次剪vlog素材也不是很够hh。</p>\n<p>对于我，该知道的都知道，不该知道的慢慢了解嘛。</p>\n<p>最后还是感谢我身边的朋友们，我一直觉得有大家是我一生的幸运。</p>\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\" src=\"//player.bilibili.com/player.html?aid=501821936&bvid=BV1AN41197DR&cid=299652862&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n<h3 id=\"心路历程\"><a href=\"#心路历程\" class=\"headerlink\" title=\"心路历程\"></a>心路历程</h3><p>2020年的前六个月基本上就是在家上网课，和所有人的生活都一样。只不过那时候得同时面临着学业和比赛，做比赛当负责人是真的真的非常累，不规律的作息时间和能否留班的多重压力让我的身体在七八九月份的时候就…彻底拉跨了。集中的表现就是疯狂掉头发、失眠，但那段时间还得操心各种答辩，也顾不上那么多了，硬着头皮把所有事情处理完了。</p>\n<p>之后带着一身疲惫见了心理医生，解决完失眠的问题，已经十月份了，然后开始了在VR馆自闭的日子，直到12月份去杭州回来之后，开始思考自己长期以来心态不好的原因，努力没有白费，问题也得到了解决。</p>\n<p>期间印象比较深刻的是，在主席团换届后，团委老师在聊学生工作时，有顺便和我探讨过关于我的一些问题，老师觉得我应该多出去见一些人，学习如何去和人相处，与不同的人社交。以前的我一直以为这方面是没有问题，但后来我发现如果只是在社团做做事什么的，可能还是能应付，但是社交并不只是有这些。于是在各位朋友的带领下，又开始了新一轮的学习。</p>\n<p>时间来到2021年的二月份，寒假并没有做什么有关学习的事，但身边的朋友们教会了我很多道理，而我也渐渐有了信心去面对以前我束手无策的一些事情了。自信这一点来说对于以前的我是缺乏的，自信需要什么作为资本吗？一定需要一个优异的成绩或者良好的朋友圈又或者是高情商的为人处世吗？并不是这样的，自信是一种状态，是要用你在未来对事情的态度和做法来证明的，而不是用过去的一些东西来证明的。</p>\n<h3 id=\"展望\"><a href=\"#展望\" class=\"headerlink\" title=\"展望\"></a>展望</h3><ul>\n<li>希望家人和朋友们能身体健康，开开心心。</li>\n<li>希望疫情快快过去。</li>\n<li>能想清楚未来想做什么方向的研究吧！！！</li>\n<li>其他的一切随缘吧，别做任何一个会后悔的决定。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>自疫情以后就很少发动态和朋友圈了，加之上学期待在VR馆的时间比较多，跟大家见面的时间就相对少了，前段时间甚至有好几位老友问我近来如此沉默，是不是心理出什么问题了:joy:。</p>\n<p>虽然事到如今我也会偶尔感叹生活不太顺心，但过去一年的经历给了我太多的成长，这些就已经足够了，毕竟生活并不是以结果来作为唯一的衡量标准。现在看着身边朋友们过得风生水起，是有些羡慕，不过更多的还是为大家都能取得自己想要的东西而高兴，在这里也衷心为大家祝福！</p>\n<p>在可预见的未来里，一切都会好起来的。</p>\n<h3 id=\"零零散散的一些收获\"><a href=\"#零零散散的一些收获\" class=\"headerlink\" title=\"零零散散的一些收获\"></a>零零散散的一些收获</h3><ul>\n<li>顺利地完成了青志队长的工作，历史性地获得了非常好的评分，没有辜负大家的期待！</li>\n<li>从零开始学习深度学习的一些相关算法，完成了两个算法工程项目，项目在各项计算机大赛中获得了一些优异的成绩，也算为校争光了！</li>\n<li>完成了第一篇论文的撰写和发表，虽然并没有投中很好的会议，但对于大二的我已经非常满足了。</li>\n<li>在年末面试了院长的实验室，最终选择了进入大数据组来开始我下一个阶段的学习。</li>\n<li>综合排名前五，申请到了一些奖学金，大概三万左右，后来在家长的掌控下拿去买基金了，然后暴跌:sob: 。</li>\n<li>在二餐对面，原洗浴中心的VR馆，找到了新的工位，希望在未来的日子里能布置一下，欢迎大家来这里找我玩啊。</li>\n<li>最后一轮留班之后压力可能就没有那么大了，至少以后有书读了。</li>\n<li>寒假建立了自己的个人博客（虽然很简陋）。</li>\n<li>渐渐开始学习非社团性质的社交，组织或者参加了一些团建活动，希望大家以后能带我玩啊。团建气氛组，铁头工具人，闪亮电灯泡，临时摄影师一定不拉跨！</li>\n<li>做了一些有意义的事，疫情参与了社区的服务工作、期末在学校抓狗狗送去了爱心基地。</li>\n<li>没有认识很多新朋友，但是身边的大家都挺nice的，感谢大家对我的照顾啊啊啊！！！</li>\n</ul>\n<h3 id=\"一段视频\"><a href=\"#一段视频\" class=\"headerlink\" title=\"一段视频\"></a>一段视频</h3><p>视频资源大部分来自于过去的一年，部分片段来自于2019年，一来是为毕业视频做个铺垫嘛，二来我收集的大多数是照片，第一次剪vlog素材也不是很够hh。</p>\n<p>对于我，该知道的都知道，不该知道的慢慢了解嘛。</p>\n<p>最后还是感谢我身边的朋友们，我一直觉得有大家是我一生的幸运。</p>\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\" src=\"//player.bilibili.com/player.html?aid=501821936&bvid=BV1AN41197DR&cid=299652862&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n<h3 id=\"心路历程\"><a href=\"#心路历程\" class=\"headerlink\" title=\"心路历程\"></a>心路历程</h3><p>2020年的前六个月基本上就是在家上网课，和所有人的生活都一样。只不过那时候得同时面临着学业和比赛，做比赛当负责人是真的真的非常累，不规律的作息时间和能否留班的多重压力让我的身体在七八九月份的时候就…彻底拉跨了。集中的表现就是疯狂掉头发、失眠，但那段时间还得操心各种答辩，也顾不上那么多了，硬着头皮把所有事情处理完了。</p>\n<p>之后带着一身疲惫见了心理医生，解决完失眠的问题，已经十月份了，然后开始了在VR馆自闭的日子，直到12月份去杭州回来之后，开始思考自己长期以来心态不好的原因，努力没有白费，问题也得到了解决。</p>\n<p>期间印象比较深刻的是，在主席团换届后，团委老师在聊学生工作时，有顺便和我探讨过关于我的一些问题，老师觉得我应该多出去见一些人，学习如何去和人相处，与不同的人社交。以前的我一直以为这方面是没有问题，但后来我发现如果只是在社团做做事什么的，可能还是能应付，但是社交并不只是有这些。于是在各位朋友的带领下，又开始了新一轮的学习。</p>\n<p>时间来到2021年的二月份，寒假并没有做什么有关学习的事，但身边的朋友们教会了我很多道理，而我也渐渐有了信心去面对以前我束手无策的一些事情了。自信这一点来说对于以前的我是缺乏的，自信需要什么作为资本吗？一定需要一个优异的成绩或者良好的朋友圈又或者是高情商的为人处世吗？并不是这样的，自信是一种状态，是要用你在未来对事情的态度和做法来证明的，而不是用过去的一些东西来证明的。</p>\n<h3 id=\"展望\"><a href=\"#展望\" class=\"headerlink\" title=\"展望\"></a>展望</h3><ul>\n<li>希望家人和朋友们能身体健康，开开心心。</li>\n<li>希望疫情快快过去。</li>\n<li>能想清楚未来想做什么方向的研究吧！！！</li>\n<li>其他的一切随缘吧，别做任何一个会后悔的决定。</li>\n</ul>\n"},{"title":"2020年数学建模美赛A题","catalog":true,"date":"2021-01-26T04:24:17.000Z","subtitle":"Moving North","top":2,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 于2020年的情人节参加的第一次建模比赛，选择了一道很常规的题目：向北移动。使用了现在看起来非常不靠谱的一些算法，好在作图水平还算不错，最终获得了H奖，也算是为自己的第一次建模比赛画上了一个句号。\n\n# 题目大意：\n\n全球海洋温度影响某些海洋生物的栖息地质量。当温度变化太大，它们无法继续繁荣时，这些物种就会迁移到其他更适合它们现在和未来生活和繁殖成功的栖息地。其中一个例子就是美国缅因州的龙虾种群，它们正缓慢地向北迁移到加拿大，那里的海洋温度较低，为它们提供了更合适的栖息地。这种地理种群的转移可能会严重影响依赖海洋生物稳定性的公司的生计。\n您的团队已被苏格兰北大西洋渔业管理协会聘请为顾问。该协会希望在全球海洋温度升高的情况下，更好地了解与苏格兰鲱鱼和鲭鱼从它们目前的栖息地苏格兰附近迁移有关的问题。这两种鱼类为苏格兰渔业做出了巨大的经济贡献。鲱鱼和鲭鱼种群分布位置的变化，可能会让规模较小的苏格兰渔业公司在经济上变得不切实际。这些公司使用渔船，但船上没有冷藏设备。\n\n1. 建立一个数学模型来确定这两种鱼类在未来50年最有可能生存的位置，假设水温将发生足够大的变化，导致种群迁移。\n\n2. 基于速度的海水温度变化发生时，用你的模型来预测最好的情况下，坏的情况下，最有可能的运行时间(s)，直到这些人口会太远了小型渔业公司收获如果小渔公司继续运营的当前位置。\n\n3. 根据你的预测分析，这些小的渔业公司应该改变他们的经营方式吗?\n   如果是，请使用您的模型来识别和评估对小型渔业公司具有实际和经济吸引力的战略。你的策略应该考虑，但不限于，现实的选择，包括:\n   -将渔业公司的部分或全部资产从苏格兰港口的现有地点迁往更靠近两种鱼类都在迁移的地方;\n   -使用一定比例的小型渔船，这些渔船能够在一段时间内不依靠陆上支助而作业，同时仍能确保渔获物的新鲜和高质量。\n   -您的团队可能识别和建模的其他选项。\n   如果您的团队拒绝任何变更的需求，根据您的建模结果为您的拒绝找理由，因为它们与您的团队所做的假设相关。\n   \n4. 使用您的模型来处理如果一定比例的渔业进入另一个国家的领海(海洋)，您的提案将受到怎样的影响。\n\n5. 除了你的技术报告，准备一到两页的文章，为钩线和沉鱼杂志，以帮助渔民了解问题的严重性，以及你的解决方案将如何改善他们未来的业务前景。\n   你的意见书应包括:\n\n   * 一页的总结页\n\n   + 目录\n   + 一到两页的文章\n   + 您的解决方案不超过20页，最多24页，包括摘要、目录和文章。\n     参考列表和任何附件不计入页面限制，应该出现在你完成的解决方案。你不应该使用未经授权的图像和材料，其使用受到版权法的限制。确保你在报告中引用了你的观点和材料。\n\n# 解题过程：\n\n## 数据来源：\n\n在科学上网的前提下，花了一下午和一晚上的时间在寻找合适的数据集(论数学建模如何从入门到放弃)，幸运的是在一个记录了苏格兰海域的CTD数据的网站上找到了一份完整的数据。数据是一个excel表格，包含了苏格兰地区很多地点的不同时间的温度数据。当然这份数据存在着不完整性(比如很多年份和月份的数据缺失)和随机性(地点并不明确)。我下载了近40年的数据，于是洋洋洒洒23万条记录的数据预处理:joy:，成为了我第二天上午主要的工作。\n\n## 解题思路：\n\n\n\n![0](2020年数学建模美赛A题/0.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1.解题思路</center>\n\n为了探究水温变化对鲭鱼、鲱鱼和苏格兰渔业造成的全球气候变化，我们构建了一个面向数据的全球变暖(DMEM)背景下渔业产业多层次评价模型。利用谷歌地球卫星数据，对苏格兰水域的42个点和30个区域建立了预测模型。并通过对相关领域的综合条件的预测，我们就题目的五个问题写了技术报告。最后，我们写信给Hook Line and Sinker，展示了关于我们对苏格兰渔业和渔民的建议。\n\n### 数据预处理和假设\n\n通过主成分分析，忽略了一些次要因素的影响，从而达到如何处理渔业分析和种群迁移的核心。本题中我们筛选出了四个与鱼群迁移密切相关的因素：温度、磷含量、叶绿素和食物的丰富度。在分析过程中我们发现海洋中磷含量、叶绿素含量与浮游生物含量之间存在正比关系，而影响这些东西最大的因素便是温度。在PCA分析过后，我更加坚定了这个想法。于是本文致力于通过海洋**温度**的变化来推测鱼群的迁移方向。\n\n### 第一问求解\n\n我们提取了1990年至2019年期间苏格兰42个点的海水温度变化，并在预测之前对数据进行优化，这使模型能够更好地处理数据并预测未来的变化。由于我们只能用过去30年的温度数据来预测未来50年的数据，所以我们选择了用较少数据就可以预测未来趋势的灰度预测模型。分别使用GM(1，1)、GM(2，1)和DGM(1，1)模型对数据进行预测。在比较了所有的模仿效果后，我们最终选择了模仿效果最好的G(1，1)模型。\n\n![1](2020年数学建模美赛A题/1.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-1. G(1，1)模型预测海水温度</center>\n\n\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/2.png\" width=\"400\"/>    <img src=\"2020年数学建模美赛A题/3.png\" width=\"400\"/> </center>\n\n\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-2. G(1，1)模型分区域预测海水温度</center>\n\n为了更好地了解鱼群的移动方向和去向，我们在二维热图上显示了2019年和2070年的海洋温度，以便更好地分析。\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/4.png\" width=\"400\"/>    <img src=\"2020年数学建模美赛A题/5.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-3.左图为2019年的海水热力图，右图为2070年的海水热力图</center>\n\n最后，根据实测卫星图像和谷歌earth显示的热图，对鱼类迁移后的范围进行了分析和预测。结果如下图所示。\n\n![6](2020年数学建模美赛A题/6.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-4.鱼群迁移图像</center>\n\n### 第二问求解\n\n建立了基于非线性规划和粒子群算法(PSO)的鱼群迁移模型。使用真实数据和现实方法对单个渔业进行建模和预测。同时，该模型也可以应用于其他类似鱼类的预测，并利用粒子群算法模拟出直观的鱼类迁移图像。\n\n#### 参数设定\n\n以下数据均来自于《2019年苏格兰渔业报告》。\n\n我们假设渔场中剩下的鱼的数量取决于:\n\n* 最舒适的鲱鱼和鲭鱼的中心离开渔场所需的时间\n* 鱼群可能迁移到渔场以外的时间\n* 渔船航行时间和鱼的检测时间。\n\n![7](2020年数学建模美赛A题/7.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-1.参数设定</center>\n\n据调查，出海的平均时间是一个月，其中一半是作业时间，另一半是往返时间。单程时间约7天。大型渔船的平均巡航速度为7.5km/h，全单程航程为:\n$$\n7\\times24\\times7.5 = 1260km\n$$\n一个渔场最多可达数公里，平均渔场达一公里，说明渔场的分布很窄。2018年苏格兰海洋渔业统计数据显示，苏格兰舰队的捕捞量为44.6万吨，占欧盟总量的8%。鲭鱼占渔获量的30.2%，鲱鱼占19.6%。根据维基百科，成年鲭鱼的重量在150至400克之间，而成年鲱鱼的重量在250至450克之间。我们根据鲱鱼和鲭鱼的重量以及这些重量的个体所占的比例得到一个合理的估计。成年鲱鱼的平均重量为m2=350克。成年鲭鱼的平均重量为m1=275克。由鲭鱼和鲱鱼的捕捞量，我们可以计算出鲭鱼的捕捞吨位W1 = 132000吨。捕捞鲱鱼数为w2= 8.8万吨。\n\n#### Logistic模型的建立\n\n我们研究渔业的连续收获模型，横轴为鲭鱼或鲱鱼种群，纵轴为鲭鱼和鲱鱼种群增长率和趋势。我们假设鱼类的生长遵循logistics增长模型:\n$$\n\\mathrm{x}(t)=f(x)=r x\\left(1-\\frac{x}{N}\\right)\n$$\n当x = N/2，渔获率= r/2时，单位时间的渔获量可以得到最大的连续产量，且稳定。假设苏格兰政府的渔获量限制在总渔获量的10%，也就是说每年的渔获量保持在总渔获量的55%到45%之间。\n\n鲭鱼的捕捞数量约为:\n$$\nQ 1=w 1 / m 1 \\times 10=2.4 \\times 10^{8}\n$$\n鲱鱼的捕捞数量约为:\n$$\nQ 2=w 2 / m 2 \\times 10=1.26 \\times 10^{8}\n$$\n由数据得到的模型如下图所示:\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/8.png\" width=\"300\"/>    <img src=\"2020年数学建模美赛A题/9.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-2.苏格兰地区鲱鱼的logistics模型</center>\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/10.png\" width=\"300\"/>    <img src=\"2020年数学建模美赛A题/11.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-3.苏格兰地区鲭鱼的logistics模型</center>\n\n在21世纪的苏格兰，一种常见的捕鱼方法是Seine fishing。假设一个正常的渔场，s = 300平方公里，假设渔场是一个圆，半径为r = 10km。我们选取了半径为1000m的平均塞纳河数据，高度为半径的1/10，即100m。围网捕鱼70%-80%的时间用于检测鱼群，记录为P1，数据查询后的平均时间为6天。假设一次探测鱼群的准确率为a1，约为80%，随着声纳系统的发展，准确率也在不断提高。由于鲱鱼和鲭鱼群比较集中，所以a1可以直接认为是捕鱼的概率。\n\n![12](2020年数学建模美赛A题/12.png)\n\n纬度约为110公里，在纬度60度，经度约为55.5公里。根据模型1的结果，鱼群在50年内从北纬59度和东经3度迁移到北纬60度和东经3度， L1=100km。我们计算了在一个正方形区域内北纬59度和东经3度到北纬60度和东经4度不同条件下的海温变化率。\n\n#### PSO优化算法估计鱼群的迁移率\n\n假设当适当区域的中心离开渔场时，鱼开始移动。根据第一个问题，海水温度变化范围和增长率的灰色模型，得出海洋温度的变化率在最坏的情况下是$V_{\\text {worst}}=g_{1}(t)$，在最好的情况下是$2$，最可能的情况是$V_{\\text {normal}}=g_{3}(t)$。\n\n根据粒子群优化算法，如果有500条鱼的学校，我们能算出鱼学校留在原来的渔业的比例随着适用性的中心(该中心在一个二维平面上变化)，鱼的比例在最初的渔业遗留下来的，在最坏的情况下是$μ_{1}(t)$，在最好的情况下是$μ_{2}(t)$，最可能的情况是$μ_{3}(t)$。\n\n然后我们取这三种情况的一阶导数的绝对值，我们得到鱼离开渔场的速率(百分比)，最坏的情况是$α_{1}(t)$，最好的情况是$α_{2}(t)$，最有可能的情况是$α_{3}(t)$。\n\n![1314](2020年数学建模美赛A题/1314.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-4.鱼群迁移的PSO模型</center>\n\n我们假设渔业是正常的fernand fishery，估计有$10^{6}$条鲭鱼和$8\\times10^{6}$条鲱鱼。假设该船为中型渔船，正常捕获量为100吨至300吨，捕获量为正常最低捕获量的十分之一，即M = 10吨。翻译过来就是$2\\times10^{5}$条鲭鱼和$1.6\\times10^{5}$条鲱鱼。\n\n ####  建立非线性规划模型：\n\n规划目标:找到满足条件的最大t值。\n\n![15](2020年数学建模美赛A题/15.png)\n\n![1617](2020年数学建模美赛A题/1617.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-5.非线性规划模型</center>\n\n从结果可以看出，捕捞鲭鱼最糟糕的情况是在第7年左右，最好的情况是在第12年左右，最正常的情况是在第9年左右。(准确数据分别为7.12年、11.98年和9.23年)鲱鱼捕捞最差的是第6年附近，最好的是第11年附近，最正常的是第9年附近。(准确数字分别为5.86岁、10.73岁和8.89岁)\n\n### 第三问求解\n\n做出改变绝对不是一个随意的决定，特别是对公司来说，我们不能仅仅通过预测海洋表面温度就得出小公司是否需要在他们目前的地点之外运营的结论，因此有更多的影响需要考虑。在本文中，我们将考虑以下影响因素:温度，距离海岸的距离，竞争程度，可达性，成本。我们将建立多层次模糊综合评价模型，以决定小公司是否需要转移或哪个地点最适合转移。\n\n根据模糊综合评价模型，因子集U = (T, DFC, DC, A, C, S)，T表示温度，DFC表示距离海岸的距离，DC表示竞争程度，A表示可达性，C表示成本。S是一个0-1的值，0代表土地，1代表水土地。\n\n如果我们在苏格兰寻找大型渔业公司的位置，我们会找到的几乎都远离我们限定的区域，这意味着所有位置的DC都可以设为零，以简化计算。\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/18.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-1.苏格兰渔场位置</center>\n\n然后，我们构建评估集。假设评估集V = (v1, v2, v3, v4, v5)， v1代表优秀，v2代表很好，v3代表好，v4代表不错，v5代表不好。因此，得到的模糊综合评价矩阵如下：\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/19.png\" width=\"300\"/> </center>\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/20.png\" width=\"500\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-2.因子权重向量矩阵</center>\n\n将A和R相乘，我们可以得出(59，-3)是最适合捕鱼的地点，原因如下:\n\n* 适应性：根据我们的预测，在2050年(59，-3)将有一个非常适合苏格兰鲱鱼和鲭鱼的温度，大约13度。另一方面，根据[数据集]，2020年(59，-4)也有一个非常适合苏格兰鲱鱼和鲭鱼的温度，这意味着鲱鱼和鲭鱼很可能在未来30年定居在这个地方。\n* 竞争少：大多数主要的捕鱼公司都在苏格兰中部捕鱼，这意味着如果一家捕鱼公司在(59，-3)捕鱼，基本上没有竞争。\n* Thurso是离(59，-3)最近的城市，人们从瑟索到爱丁堡只需4个半小时，更不用说货运火车了。\n\n根据这一事实(59，-3)的平均DFC是约50公里,渔船的平均速度大约是每小时20公里,公司钓鱼有建议使用一些bug渔船的比例能够操作没有陆地的支持一段时间以及装备一些小型渔船。提出此建议是为了确保2020年渔船在(59，-4)的捕捞能力，因为小岛较多。它还可以提高渔业生产力。\n\n### 第四问解答\n\n我们将使用与问题3相同的模糊综合评价模型。然而，有一些小的变化。\n\n首先，对大多数人来说，我们必须考虑领海因素。简单地说，由于领海存在一定的限制，我们必须重新进行评估，在12英里范围内增加更多的权重。\n\n第二，受苏格兰政府保护的地区必须被排除在我们的结果之外。特别是,(57,-2),(57,-1),(57,0),(57,1),(58,-2),(58,-1),(59,-2),(59,0),(59,1),(60 0),(60,1),(61,1),(62,-5),(62 1)\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/21.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-1.苏格兰政府保护区域</center>\n\n因此，模糊综合评价矩阵为：\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/22.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-2.模糊评价矩阵</center>\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/23.png\" width=\"500\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-3.因子权重向量矩阵</center>\n\n我们可以得出这样的结论:领海因素进行考虑后,(59,-4)是我们最好的钓鱼位置,因此在2050年(59,-4)略接近主要的土地相比(59,-3)和更少的小岛,我们建议小型渔业公司可以使用中型渔船以确保最高的性价比以及生产力表现。\n\n### 敏感性分析，误差分析以及模型优化\n\n额，关于以下内容都是我写的，但是...你懂的。模型优化部分基本比较扯，在这里就不放出来让大家耻笑了。简单给出一些当时的分析过程：\n\n* 敏感性分析\n\n我们考虑三个变量对预测时间t的影响:海温变化率V、经济增长率g(t)和渔业中鱼的数量。我们探究了0-20%的水温变化速度V(最差)加减速对结果的影响。\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/24.png\" width=\"500\"/> </center>\n\n* 误差分析：\n\n  <center class=\"half\">    <img src=\"2020年数学建模美赛A题/25.png\" width=\"500\"/> </center>\n\n### 优缺点分析\n\n懒得翻译了，感觉这部分不是很重要哈哈。\n\n#### 优点：\n\n* The optimized grey prediction model fills in the shortcomings of the model due to the lack of data. 30 regions are divided around the most important north sea fishery in scotland, and the temperature changes in the sea area of scotland are intuitively perceived by using two-dimensional thermal maps.\n* Using differential equations to account for the population of the scotland shoal, the model is more reasonable with the addition of many practical factors.The analysis of errors in the prediction results also makes the data more convincing, and the sensitivity analysis of nonlinear programming also addresses the effect of faster and slower changes in sea temperature on fish migration.\n* The evaluation result of the model is in the form of vector instead of a specific value point, so it can reflect the fuzzy state of things accurately.Each step in the modeling process is quantified.Each layer of modeling will directly or indirectly affect the results, so that the evaluation of the target is relatively clear.\n* The analysis model of a fishery can be applied to another fishery by changing the distance parameter, which can solve the problem of future migration of multiple fisheries.\n\n#### 缺点：\n\n* Since CTD data cannot provide the data of each location comprehensively, and even the data of 42 points have up to 21.1% missing data, the data preprocessing we adopted is relatively simple, so the model in this paper cannot fully represent the most accurate results.\n\n* Not taking into account changes in ocean currents, climate and other factors, the actual state of the fishery, the annual fishing trips of fishermen and government policies, all lead to a lack of practicality in the model.\n\n* The function of the analytic hierarchy process (AHP), which cannot provide a new scheme for decision making, is to choose the better of the alternatives.This function just explains that the analytic hierarchy process can only be selected from the original plan, but can not provide the decision maker with a new plan to solve the problem.\n\n* The individual fishery model has little practical significance for the whole fishery.\n\n* In today s evaluation of scientific methods, it is generally accepted that a science requires rigorous mathematical reasoning and a sound quantitative approach. But problems in the real world and how the human brain thinks about them are often not simply Numbers.\n\n  \n\n### 来自周哥的一封信：\n\n信是周哥写的，茜姐翻译的，没我啥事，鉴于在最后的一个夜晚还是通宵调试Latex，最后生成论文，这份辛苦还是值得展示出来：\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/26.png\" width=\"600\"/> </center>\n\n# 后记^\\_^\n\n鉴于已经是快一年前的东西了，很多细节已经记不清了，文章如果有一些问题欢迎大家指出。本人比较懒，对于修改这个工作，只能说：**下次一定**。:slightly_smiling_face:\n\n最后感谢自己的两位队友，周哥和茜姐。本人第一次应该也是最后一次的美赛经历大抵如此了，希望以后的情人节大家都是陪着npy，而不是对着一堆数据。","source":"_posts/2020年数学建模美赛A题.md","raw":"---\ntitle: 2020年数学建模美赛A题\ncatalog: true\ndate: 2021-01-26 12:24:17\nsubtitle: Moving North\ntop: 2\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Matlab\n- Google earth\n- Latex\ncategories:\n- 数学建模\n---\n\n> 于2020年的情人节参加的第一次建模比赛，选择了一道很常规的题目：向北移动。使用了现在看起来非常不靠谱的一些算法，好在作图水平还算不错，最终获得了H奖，也算是为自己的第一次建模比赛画上了一个句号。\n\n# 题目大意：\n\n全球海洋温度影响某些海洋生物的栖息地质量。当温度变化太大，它们无法继续繁荣时，这些物种就会迁移到其他更适合它们现在和未来生活和繁殖成功的栖息地。其中一个例子就是美国缅因州的龙虾种群，它们正缓慢地向北迁移到加拿大，那里的海洋温度较低，为它们提供了更合适的栖息地。这种地理种群的转移可能会严重影响依赖海洋生物稳定性的公司的生计。\n您的团队已被苏格兰北大西洋渔业管理协会聘请为顾问。该协会希望在全球海洋温度升高的情况下，更好地了解与苏格兰鲱鱼和鲭鱼从它们目前的栖息地苏格兰附近迁移有关的问题。这两种鱼类为苏格兰渔业做出了巨大的经济贡献。鲱鱼和鲭鱼种群分布位置的变化，可能会让规模较小的苏格兰渔业公司在经济上变得不切实际。这些公司使用渔船，但船上没有冷藏设备。\n\n1. 建立一个数学模型来确定这两种鱼类在未来50年最有可能生存的位置，假设水温将发生足够大的变化，导致种群迁移。\n\n2. 基于速度的海水温度变化发生时，用你的模型来预测最好的情况下，坏的情况下，最有可能的运行时间(s)，直到这些人口会太远了小型渔业公司收获如果小渔公司继续运营的当前位置。\n\n3. 根据你的预测分析，这些小的渔业公司应该改变他们的经营方式吗?\n   如果是，请使用您的模型来识别和评估对小型渔业公司具有实际和经济吸引力的战略。你的策略应该考虑，但不限于，现实的选择，包括:\n   -将渔业公司的部分或全部资产从苏格兰港口的现有地点迁往更靠近两种鱼类都在迁移的地方;\n   -使用一定比例的小型渔船，这些渔船能够在一段时间内不依靠陆上支助而作业，同时仍能确保渔获物的新鲜和高质量。\n   -您的团队可能识别和建模的其他选项。\n   如果您的团队拒绝任何变更的需求，根据您的建模结果为您的拒绝找理由，因为它们与您的团队所做的假设相关。\n   \n4. 使用您的模型来处理如果一定比例的渔业进入另一个国家的领海(海洋)，您的提案将受到怎样的影响。\n\n5. 除了你的技术报告，准备一到两页的文章，为钩线和沉鱼杂志，以帮助渔民了解问题的严重性，以及你的解决方案将如何改善他们未来的业务前景。\n   你的意见书应包括:\n\n   * 一页的总结页\n\n   + 目录\n   + 一到两页的文章\n   + 您的解决方案不超过20页，最多24页，包括摘要、目录和文章。\n     参考列表和任何附件不计入页面限制，应该出现在你完成的解决方案。你不应该使用未经授权的图像和材料，其使用受到版权法的限制。确保你在报告中引用了你的观点和材料。\n\n# 解题过程：\n\n## 数据来源：\n\n在科学上网的前提下，花了一下午和一晚上的时间在寻找合适的数据集(论数学建模如何从入门到放弃)，幸运的是在一个记录了苏格兰海域的CTD数据的网站上找到了一份完整的数据。数据是一个excel表格，包含了苏格兰地区很多地点的不同时间的温度数据。当然这份数据存在着不完整性(比如很多年份和月份的数据缺失)和随机性(地点并不明确)。我下载了近40年的数据，于是洋洋洒洒23万条记录的数据预处理:joy:，成为了我第二天上午主要的工作。\n\n## 解题思路：\n\n\n\n![0](2020年数学建模美赛A题/0.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1.解题思路</center>\n\n为了探究水温变化对鲭鱼、鲱鱼和苏格兰渔业造成的全球气候变化，我们构建了一个面向数据的全球变暖(DMEM)背景下渔业产业多层次评价模型。利用谷歌地球卫星数据，对苏格兰水域的42个点和30个区域建立了预测模型。并通过对相关领域的综合条件的预测，我们就题目的五个问题写了技术报告。最后，我们写信给Hook Line and Sinker，展示了关于我们对苏格兰渔业和渔民的建议。\n\n### 数据预处理和假设\n\n通过主成分分析，忽略了一些次要因素的影响，从而达到如何处理渔业分析和种群迁移的核心。本题中我们筛选出了四个与鱼群迁移密切相关的因素：温度、磷含量、叶绿素和食物的丰富度。在分析过程中我们发现海洋中磷含量、叶绿素含量与浮游生物含量之间存在正比关系，而影响这些东西最大的因素便是温度。在PCA分析过后，我更加坚定了这个想法。于是本文致力于通过海洋**温度**的变化来推测鱼群的迁移方向。\n\n### 第一问求解\n\n我们提取了1990年至2019年期间苏格兰42个点的海水温度变化，并在预测之前对数据进行优化，这使模型能够更好地处理数据并预测未来的变化。由于我们只能用过去30年的温度数据来预测未来50年的数据，所以我们选择了用较少数据就可以预测未来趋势的灰度预测模型。分别使用GM(1，1)、GM(2，1)和DGM(1，1)模型对数据进行预测。在比较了所有的模仿效果后，我们最终选择了模仿效果最好的G(1，1)模型。\n\n![1](2020年数学建模美赛A题/1.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-1. G(1，1)模型预测海水温度</center>\n\n\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/2.png\" width=\"400\"/>    <img src=\"2020年数学建模美赛A题/3.png\" width=\"400\"/> </center>\n\n\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-2. G(1，1)模型分区域预测海水温度</center>\n\n为了更好地了解鱼群的移动方向和去向，我们在二维热图上显示了2019年和2070年的海洋温度，以便更好地分析。\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/4.png\" width=\"400\"/>    <img src=\"2020年数学建模美赛A题/5.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-3.左图为2019年的海水热力图，右图为2070年的海水热力图</center>\n\n最后，根据实测卫星图像和谷歌earth显示的热图，对鱼类迁移后的范围进行了分析和预测。结果如下图所示。\n\n![6](2020年数学建模美赛A题/6.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-4.鱼群迁移图像</center>\n\n### 第二问求解\n\n建立了基于非线性规划和粒子群算法(PSO)的鱼群迁移模型。使用真实数据和现实方法对单个渔业进行建模和预测。同时，该模型也可以应用于其他类似鱼类的预测，并利用粒子群算法模拟出直观的鱼类迁移图像。\n\n#### 参数设定\n\n以下数据均来自于《2019年苏格兰渔业报告》。\n\n我们假设渔场中剩下的鱼的数量取决于:\n\n* 最舒适的鲱鱼和鲭鱼的中心离开渔场所需的时间\n* 鱼群可能迁移到渔场以外的时间\n* 渔船航行时间和鱼的检测时间。\n\n![7](2020年数学建模美赛A题/7.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-1.参数设定</center>\n\n据调查，出海的平均时间是一个月，其中一半是作业时间，另一半是往返时间。单程时间约7天。大型渔船的平均巡航速度为7.5km/h，全单程航程为:\n$$\n7\\times24\\times7.5 = 1260km\n$$\n一个渔场最多可达数公里，平均渔场达一公里，说明渔场的分布很窄。2018年苏格兰海洋渔业统计数据显示，苏格兰舰队的捕捞量为44.6万吨，占欧盟总量的8%。鲭鱼占渔获量的30.2%，鲱鱼占19.6%。根据维基百科，成年鲭鱼的重量在150至400克之间，而成年鲱鱼的重量在250至450克之间。我们根据鲱鱼和鲭鱼的重量以及这些重量的个体所占的比例得到一个合理的估计。成年鲱鱼的平均重量为m2=350克。成年鲭鱼的平均重量为m1=275克。由鲭鱼和鲱鱼的捕捞量，我们可以计算出鲭鱼的捕捞吨位W1 = 132000吨。捕捞鲱鱼数为w2= 8.8万吨。\n\n#### Logistic模型的建立\n\n我们研究渔业的连续收获模型，横轴为鲭鱼或鲱鱼种群，纵轴为鲭鱼和鲱鱼种群增长率和趋势。我们假设鱼类的生长遵循logistics增长模型:\n$$\n\\mathrm{x}(t)=f(x)=r x\\left(1-\\frac{x}{N}\\right)\n$$\n当x = N/2，渔获率= r/2时，单位时间的渔获量可以得到最大的连续产量，且稳定。假设苏格兰政府的渔获量限制在总渔获量的10%，也就是说每年的渔获量保持在总渔获量的55%到45%之间。\n\n鲭鱼的捕捞数量约为:\n$$\nQ 1=w 1 / m 1 \\times 10=2.4 \\times 10^{8}\n$$\n鲱鱼的捕捞数量约为:\n$$\nQ 2=w 2 / m 2 \\times 10=1.26 \\times 10^{8}\n$$\n由数据得到的模型如下图所示:\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/8.png\" width=\"300\"/>    <img src=\"2020年数学建模美赛A题/9.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-2.苏格兰地区鲱鱼的logistics模型</center>\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/10.png\" width=\"300\"/>    <img src=\"2020年数学建模美赛A题/11.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-3.苏格兰地区鲭鱼的logistics模型</center>\n\n在21世纪的苏格兰，一种常见的捕鱼方法是Seine fishing。假设一个正常的渔场，s = 300平方公里，假设渔场是一个圆，半径为r = 10km。我们选取了半径为1000m的平均塞纳河数据，高度为半径的1/10，即100m。围网捕鱼70%-80%的时间用于检测鱼群，记录为P1，数据查询后的平均时间为6天。假设一次探测鱼群的准确率为a1，约为80%，随着声纳系统的发展，准确率也在不断提高。由于鲱鱼和鲭鱼群比较集中，所以a1可以直接认为是捕鱼的概率。\n\n![12](2020年数学建模美赛A题/12.png)\n\n纬度约为110公里，在纬度60度，经度约为55.5公里。根据模型1的结果，鱼群在50年内从北纬59度和东经3度迁移到北纬60度和东经3度， L1=100km。我们计算了在一个正方形区域内北纬59度和东经3度到北纬60度和东经4度不同条件下的海温变化率。\n\n#### PSO优化算法估计鱼群的迁移率\n\n假设当适当区域的中心离开渔场时，鱼开始移动。根据第一个问题，海水温度变化范围和增长率的灰色模型，得出海洋温度的变化率在最坏的情况下是$V_{\\text {worst}}=g_{1}(t)$，在最好的情况下是$2$，最可能的情况是$V_{\\text {normal}}=g_{3}(t)$。\n\n根据粒子群优化算法，如果有500条鱼的学校，我们能算出鱼学校留在原来的渔业的比例随着适用性的中心(该中心在一个二维平面上变化)，鱼的比例在最初的渔业遗留下来的，在最坏的情况下是$μ_{1}(t)$，在最好的情况下是$μ_{2}(t)$，最可能的情况是$μ_{3}(t)$。\n\n然后我们取这三种情况的一阶导数的绝对值，我们得到鱼离开渔场的速率(百分比)，最坏的情况是$α_{1}(t)$，最好的情况是$α_{2}(t)$，最有可能的情况是$α_{3}(t)$。\n\n![1314](2020年数学建模美赛A题/1314.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-4.鱼群迁移的PSO模型</center>\n\n我们假设渔业是正常的fernand fishery，估计有$10^{6}$条鲭鱼和$8\\times10^{6}$条鲱鱼。假设该船为中型渔船，正常捕获量为100吨至300吨，捕获量为正常最低捕获量的十分之一，即M = 10吨。翻译过来就是$2\\times10^{5}$条鲭鱼和$1.6\\times10^{5}$条鲱鱼。\n\n ####  建立非线性规划模型：\n\n规划目标:找到满足条件的最大t值。\n\n![15](2020年数学建模美赛A题/15.png)\n\n![1617](2020年数学建模美赛A题/1617.png)\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-5.非线性规划模型</center>\n\n从结果可以看出，捕捞鲭鱼最糟糕的情况是在第7年左右，最好的情况是在第12年左右，最正常的情况是在第9年左右。(准确数据分别为7.12年、11.98年和9.23年)鲱鱼捕捞最差的是第6年附近，最好的是第11年附近，最正常的是第9年附近。(准确数字分别为5.86岁、10.73岁和8.89岁)\n\n### 第三问求解\n\n做出改变绝对不是一个随意的决定，特别是对公司来说，我们不能仅仅通过预测海洋表面温度就得出小公司是否需要在他们目前的地点之外运营的结论，因此有更多的影响需要考虑。在本文中，我们将考虑以下影响因素:温度，距离海岸的距离，竞争程度，可达性，成本。我们将建立多层次模糊综合评价模型，以决定小公司是否需要转移或哪个地点最适合转移。\n\n根据模糊综合评价模型，因子集U = (T, DFC, DC, A, C, S)，T表示温度，DFC表示距离海岸的距离，DC表示竞争程度，A表示可达性，C表示成本。S是一个0-1的值，0代表土地，1代表水土地。\n\n如果我们在苏格兰寻找大型渔业公司的位置，我们会找到的几乎都远离我们限定的区域，这意味着所有位置的DC都可以设为零，以简化计算。\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/18.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-1.苏格兰渔场位置</center>\n\n然后，我们构建评估集。假设评估集V = (v1, v2, v3, v4, v5)， v1代表优秀，v2代表很好，v3代表好，v4代表不错，v5代表不好。因此，得到的模糊综合评价矩阵如下：\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/19.png\" width=\"300\"/> </center>\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/20.png\" width=\"500\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-2.因子权重向量矩阵</center>\n\n将A和R相乘，我们可以得出(59，-3)是最适合捕鱼的地点，原因如下:\n\n* 适应性：根据我们的预测，在2050年(59，-3)将有一个非常适合苏格兰鲱鱼和鲭鱼的温度，大约13度。另一方面，根据[数据集]，2020年(59，-4)也有一个非常适合苏格兰鲱鱼和鲭鱼的温度，这意味着鲱鱼和鲭鱼很可能在未来30年定居在这个地方。\n* 竞争少：大多数主要的捕鱼公司都在苏格兰中部捕鱼，这意味着如果一家捕鱼公司在(59，-3)捕鱼，基本上没有竞争。\n* Thurso是离(59，-3)最近的城市，人们从瑟索到爱丁堡只需4个半小时，更不用说货运火车了。\n\n根据这一事实(59，-3)的平均DFC是约50公里,渔船的平均速度大约是每小时20公里,公司钓鱼有建议使用一些bug渔船的比例能够操作没有陆地的支持一段时间以及装备一些小型渔船。提出此建议是为了确保2020年渔船在(59，-4)的捕捞能力，因为小岛较多。它还可以提高渔业生产力。\n\n### 第四问解答\n\n我们将使用与问题3相同的模糊综合评价模型。然而，有一些小的变化。\n\n首先，对大多数人来说，我们必须考虑领海因素。简单地说，由于领海存在一定的限制，我们必须重新进行评估，在12英里范围内增加更多的权重。\n\n第二，受苏格兰政府保护的地区必须被排除在我们的结果之外。特别是,(57,-2),(57,-1),(57,0),(57,1),(58,-2),(58,-1),(59,-2),(59,0),(59,1),(60 0),(60,1),(61,1),(62,-5),(62 1)\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/21.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-1.苏格兰政府保护区域</center>\n\n因此，模糊综合评价矩阵为：\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/22.png\" width=\"300\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-2.模糊评价矩阵</center>\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/23.png\" width=\"500\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-3.因子权重向量矩阵</center>\n\n我们可以得出这样的结论:领海因素进行考虑后,(59,-4)是我们最好的钓鱼位置,因此在2050年(59,-4)略接近主要的土地相比(59,-3)和更少的小岛,我们建议小型渔业公司可以使用中型渔船以确保最高的性价比以及生产力表现。\n\n### 敏感性分析，误差分析以及模型优化\n\n额，关于以下内容都是我写的，但是...你懂的。模型优化部分基本比较扯，在这里就不放出来让大家耻笑了。简单给出一些当时的分析过程：\n\n* 敏感性分析\n\n我们考虑三个变量对预测时间t的影响:海温变化率V、经济增长率g(t)和渔业中鱼的数量。我们探究了0-20%的水温变化速度V(最差)加减速对结果的影响。\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/24.png\" width=\"500\"/> </center>\n\n* 误差分析：\n\n  <center class=\"half\">    <img src=\"2020年数学建模美赛A题/25.png\" width=\"500\"/> </center>\n\n### 优缺点分析\n\n懒得翻译了，感觉这部分不是很重要哈哈。\n\n#### 优点：\n\n* The optimized grey prediction model fills in the shortcomings of the model due to the lack of data. 30 regions are divided around the most important north sea fishery in scotland, and the temperature changes in the sea area of scotland are intuitively perceived by using two-dimensional thermal maps.\n* Using differential equations to account for the population of the scotland shoal, the model is more reasonable with the addition of many practical factors.The analysis of errors in the prediction results also makes the data more convincing, and the sensitivity analysis of nonlinear programming also addresses the effect of faster and slower changes in sea temperature on fish migration.\n* The evaluation result of the model is in the form of vector instead of a specific value point, so it can reflect the fuzzy state of things accurately.Each step in the modeling process is quantified.Each layer of modeling will directly or indirectly affect the results, so that the evaluation of the target is relatively clear.\n* The analysis model of a fishery can be applied to another fishery by changing the distance parameter, which can solve the problem of future migration of multiple fisheries.\n\n#### 缺点：\n\n* Since CTD data cannot provide the data of each location comprehensively, and even the data of 42 points have up to 21.1% missing data, the data preprocessing we adopted is relatively simple, so the model in this paper cannot fully represent the most accurate results.\n\n* Not taking into account changes in ocean currents, climate and other factors, the actual state of the fishery, the annual fishing trips of fishermen and government policies, all lead to a lack of practicality in the model.\n\n* The function of the analytic hierarchy process (AHP), which cannot provide a new scheme for decision making, is to choose the better of the alternatives.This function just explains that the analytic hierarchy process can only be selected from the original plan, but can not provide the decision maker with a new plan to solve the problem.\n\n* The individual fishery model has little practical significance for the whole fishery.\n\n* In today s evaluation of scientific methods, it is generally accepted that a science requires rigorous mathematical reasoning and a sound quantitative approach. But problems in the real world and how the human brain thinks about them are often not simply Numbers.\n\n  \n\n### 来自周哥的一封信：\n\n信是周哥写的，茜姐翻译的，没我啥事，鉴于在最后的一个夜晚还是通宵调试Latex，最后生成论文，这份辛苦还是值得展示出来：\n\n<center class=\"half\">    <img src=\"2020年数学建模美赛A题/26.png\" width=\"600\"/> </center>\n\n# 后记^\\_^\n\n鉴于已经是快一年前的东西了，很多细节已经记不清了，文章如果有一些问题欢迎大家指出。本人比较懒，对于修改这个工作，只能说：**下次一定**。:slightly_smiling_face:\n\n最后感谢自己的两位队友，周哥和茜姐。本人第一次应该也是最后一次的美赛经历大抵如此了，希望以后的情人节大家都是陪着npy，而不是对着一堆数据。","slug":"2020年数学建模美赛A题","published":1,"updated":"2022-01-13T09:01:10.318Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxws00073oue6l8l4mbz","content":"<blockquote>\n<p>于2020年的情人节参加的第一次建模比赛，选择了一道很常规的题目：向北移动。使用了现在看起来非常不靠谱的一些算法，好在作图水平还算不错，最终获得了H奖，也算是为自己的第一次建模比赛画上了一个句号。</p>\n</blockquote>\n<h1 id=\"题目大意：\"><a href=\"#题目大意：\" class=\"headerlink\" title=\"题目大意：\"></a>题目大意：</h1><p>全球海洋温度影响某些海洋生物的栖息地质量。当温度变化太大，它们无法继续繁荣时，这些物种就会迁移到其他更适合它们现在和未来生活和繁殖成功的栖息地。其中一个例子就是美国缅因州的龙虾种群，它们正缓慢地向北迁移到加拿大，那里的海洋温度较低，为它们提供了更合适的栖息地。这种地理种群的转移可能会严重影响依赖海洋生物稳定性的公司的生计。<br>您的团队已被苏格兰北大西洋渔业管理协会聘请为顾问。该协会希望在全球海洋温度升高的情况下，更好地了解与苏格兰鲱鱼和鲭鱼从它们目前的栖息地苏格兰附近迁移有关的问题。这两种鱼类为苏格兰渔业做出了巨大的经济贡献。鲱鱼和鲭鱼种群分布位置的变化，可能会让规模较小的苏格兰渔业公司在经济上变得不切实际。这些公司使用渔船，但船上没有冷藏设备。</p>\n<ol>\n<li><p>建立一个数学模型来确定这两种鱼类在未来50年最有可能生存的位置，假设水温将发生足够大的变化，导致种群迁移。</p>\n</li>\n<li><p>基于速度的海水温度变化发生时，用你的模型来预测最好的情况下，坏的情况下，最有可能的运行时间(s)，直到这些人口会太远了小型渔业公司收获如果小渔公司继续运营的当前位置。</p>\n</li>\n<li><p>根据你的预测分析，这些小的渔业公司应该改变他们的经营方式吗?<br>如果是，请使用您的模型来识别和评估对小型渔业公司具有实际和经济吸引力的战略。你的策略应该考虑，但不限于，现实的选择，包括:<br>-将渔业公司的部分或全部资产从苏格兰港口的现有地点迁往更靠近两种鱼类都在迁移的地方;<br>-使用一定比例的小型渔船，这些渔船能够在一段时间内不依靠陆上支助而作业，同时仍能确保渔获物的新鲜和高质量。<br>-您的团队可能识别和建模的其他选项。<br>如果您的团队拒绝任何变更的需求，根据您的建模结果为您的拒绝找理由，因为它们与您的团队所做的假设相关。</p>\n</li>\n<li><p>使用您的模型来处理如果一定比例的渔业进入另一个国家的领海(海洋)，您的提案将受到怎样的影响。</p>\n</li>\n<li><p>除了你的技术报告，准备一到两页的文章，为钩线和沉鱼杂志，以帮助渔民了解问题的严重性，以及你的解决方案将如何改善他们未来的业务前景。<br>你的意见书应包括:</p>\n<ul>\n<li>一页的总结页</li>\n</ul>\n<ul>\n<li>目录</li>\n<li>一到两页的文章</li>\n<li>您的解决方案不超过20页，最多24页，包括摘要、目录和文章。<br>参考列表和任何附件不计入页面限制，应该出现在你完成的解决方案。你不应该使用未经授权的图像和材料，其使用受到版权法的限制。确保你在报告中引用了你的观点和材料。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"解题过程：\"><a href=\"#解题过程：\" class=\"headerlink\" title=\"解题过程：\"></a>解题过程：</h1><h2 id=\"数据来源：\"><a href=\"#数据来源：\" class=\"headerlink\" title=\"数据来源：\"></a>数据来源：</h2><p>在科学上网的前提下，花了一下午和一晚上的时间在寻找合适的数据集(论数学建模如何从入门到放弃)，幸运的是在一个记录了苏格兰海域的CTD数据的网站上找到了一份完整的数据。数据是一个excel表格，包含了苏格兰地区很多地点的不同时间的温度数据。当然这份数据存在着不完整性(比如很多年份和月份的数据缺失)和随机性(地点并不明确)。我下载了近40年的数据，于是洋洋洒洒23万条记录的数据预处理:joy:，成为了我第二天上午主要的工作。</p>\n<h2 id=\"解题思路：\"><a href=\"#解题思路：\" class=\"headerlink\" title=\"解题思路：\"></a>解题思路：</h2><p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/0.png\" alt=\"0\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1.解题思路</center>\n\n<p>为了探究水温变化对鲭鱼、鲱鱼和苏格兰渔业造成的全球气候变化，我们构建了一个面向数据的全球变暖(DMEM)背景下渔业产业多层次评价模型。利用谷歌地球卫星数据，对苏格兰水域的42个点和30个区域建立了预测模型。并通过对相关领域的综合条件的预测，我们就题目的五个问题写了技术报告。最后，我们写信给Hook Line and Sinker，展示了关于我们对苏格兰渔业和渔民的建议。</p>\n<h3 id=\"数据预处理和假设\"><a href=\"#数据预处理和假设\" class=\"headerlink\" title=\"数据预处理和假设\"></a>数据预处理和假设</h3><p>通过主成分分析，忽略了一些次要因素的影响，从而达到如何处理渔业分析和种群迁移的核心。本题中我们筛选出了四个与鱼群迁移密切相关的因素：温度、磷含量、叶绿素和食物的丰富度。在分析过程中我们发现海洋中磷含量、叶绿素含量与浮游生物含量之间存在正比关系，而影响这些东西最大的因素便是温度。在PCA分析过后，我更加坚定了这个想法。于是本文致力于通过海洋<strong>温度</strong>的变化来推测鱼群的迁移方向。</p>\n<h3 id=\"第一问求解\"><a href=\"#第一问求解\" class=\"headerlink\" title=\"第一问求解\"></a>第一问求解</h3><p>我们提取了1990年至2019年期间苏格兰42个点的海水温度变化，并在预测之前对数据进行优化，这使模型能够更好地处理数据并预测未来的变化。由于我们只能用过去30年的温度数据来预测未来50年的数据，所以我们选择了用较少数据就可以预测未来趋势的灰度预测模型。分别使用GM(1，1)、GM(2，1)和DGM(1，1)模型对数据进行预测。在比较了所有的模仿效果后，我们最终选择了模仿效果最好的G(1，1)模型。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/1.png\" alt=\"1\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-1. G(1，1)模型预测海水温度</center>\n\n\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/2.png\" width=\"400\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/3.png\" width=\"400\"> </center>\n\n\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-2. G(1，1)模型分区域预测海水温度</center>\n\n<p>为了更好地了解鱼群的移动方向和去向，我们在二维热图上显示了2019年和2070年的海洋温度，以便更好地分析。</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/4.png\" width=\"400\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/5.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-3.左图为2019年的海水热力图，右图为2070年的海水热力图</center>\n\n<p>最后，根据实测卫星图像和谷歌earth显示的热图，对鱼类迁移后的范围进行了分析和预测。结果如下图所示。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/6.png\" alt=\"6\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-4.鱼群迁移图像</center>\n\n<h3 id=\"第二问求解\"><a href=\"#第二问求解\" class=\"headerlink\" title=\"第二问求解\"></a>第二问求解</h3><p>建立了基于非线性规划和粒子群算法(PSO)的鱼群迁移模型。使用真实数据和现实方法对单个渔业进行建模和预测。同时，该模型也可以应用于其他类似鱼类的预测，并利用粒子群算法模拟出直观的鱼类迁移图像。</p>\n<h4 id=\"参数设定\"><a href=\"#参数设定\" class=\"headerlink\" title=\"参数设定\"></a>参数设定</h4><p>以下数据均来自于《2019年苏格兰渔业报告》。</p>\n<p>我们假设渔场中剩下的鱼的数量取决于:</p>\n<ul>\n<li>最舒适的鲱鱼和鲭鱼的中心离开渔场所需的时间</li>\n<li>鱼群可能迁移到渔场以外的时间</li>\n<li>渔船航行时间和鱼的检测时间。</li>\n</ul>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/7.png\" alt=\"7\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-1.参数设定</center>\n\n<p>据调查，出海的平均时间是一个月，其中一半是作业时间，另一半是往返时间。单程时间约7天。大型渔船的平均巡航速度为7.5km/h，全单程航程为:</p>\n<script type=\"math/tex; mode=display\">\n7\\times24\\times7.5 = 1260km</script><p>一个渔场最多可达数公里，平均渔场达一公里，说明渔场的分布很窄。2018年苏格兰海洋渔业统计数据显示，苏格兰舰队的捕捞量为44.6万吨，占欧盟总量的8%。鲭鱼占渔获量的30.2%，鲱鱼占19.6%。根据维基百科，成年鲭鱼的重量在150至400克之间，而成年鲱鱼的重量在250至450克之间。我们根据鲱鱼和鲭鱼的重量以及这些重量的个体所占的比例得到一个合理的估计。成年鲱鱼的平均重量为m2=350克。成年鲭鱼的平均重量为m1=275克。由鲭鱼和鲱鱼的捕捞量，我们可以计算出鲭鱼的捕捞吨位W1 = 132000吨。捕捞鲱鱼数为w2= 8.8万吨。</p>\n<h4 id=\"Logistic模型的建立\"><a href=\"#Logistic模型的建立\" class=\"headerlink\" title=\"Logistic模型的建立\"></a>Logistic模型的建立</h4><p>我们研究渔业的连续收获模型，横轴为鲭鱼或鲱鱼种群，纵轴为鲭鱼和鲱鱼种群增长率和趋势。我们假设鱼类的生长遵循logistics增长模型:</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{x}(t)=f(x)=r x\\left(1-\\frac{x}{N}\\right)</script><p>当x = N/2，渔获率= r/2时，单位时间的渔获量可以得到最大的连续产量，且稳定。假设苏格兰政府的渔获量限制在总渔获量的10%，也就是说每年的渔获量保持在总渔获量的55%到45%之间。</p>\n<p>鲭鱼的捕捞数量约为:</p>\n<script type=\"math/tex; mode=display\">\nQ 1=w 1 / m 1 \\times 10=2.4 \\times 10^{8}</script><p>鲱鱼的捕捞数量约为:</p>\n<script type=\"math/tex; mode=display\">\nQ 2=w 2 / m 2 \\times 10=1.26 \\times 10^{8}</script><p>由数据得到的模型如下图所示:</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/8.png\" width=\"300\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/9.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-2.苏格兰地区鲱鱼的logistics模型</center>\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/10.png\" width=\"300\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/11.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-3.苏格兰地区鲭鱼的logistics模型</center>\n\n<p>在21世纪的苏格兰，一种常见的捕鱼方法是Seine fishing。假设一个正常的渔场，s = 300平方公里，假设渔场是一个圆，半径为r = 10km。我们选取了半径为1000m的平均塞纳河数据，高度为半径的1/10，即100m。围网捕鱼70%-80%的时间用于检测鱼群，记录为P1，数据查询后的平均时间为6天。假设一次探测鱼群的准确率为a1，约为80%，随着声纳系统的发展，准确率也在不断提高。由于鲱鱼和鲭鱼群比较集中，所以a1可以直接认为是捕鱼的概率。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/12.png\" alt=\"12\"></p>\n<p>纬度约为110公里，在纬度60度，经度约为55.5公里。根据模型1的结果，鱼群在50年内从北纬59度和东经3度迁移到北纬60度和东经3度， L1=100km。我们计算了在一个正方形区域内北纬59度和东经3度到北纬60度和东经4度不同条件下的海温变化率。</p>\n<h4 id=\"PSO优化算法估计鱼群的迁移率\"><a href=\"#PSO优化算法估计鱼群的迁移率\" class=\"headerlink\" title=\"PSO优化算法估计鱼群的迁移率\"></a>PSO优化算法估计鱼群的迁移率</h4><p>假设当适当区域的中心离开渔场时，鱼开始移动。根据第一个问题，海水温度变化范围和增长率的灰色模型，得出海洋温度的变化率在最坏的情况下是$V_{\\text {worst}}=g_{1}(t)$，在最好的情况下是$2$，最可能的情况是$V_{\\text {normal}}=g_{3}(t)$。</p>\n<p>根据粒子群优化算法，如果有500条鱼的学校，我们能算出鱼学校留在原来的渔业的比例随着适用性的中心(该中心在一个二维平面上变化)，鱼的比例在最初的渔业遗留下来的，在最坏的情况下是$μ_{1}(t)$，在最好的情况下是$μ_{2}(t)$，最可能的情况是$μ_{3}(t)$。</p>\n<p>然后我们取这三种情况的一阶导数的绝对值，我们得到鱼离开渔场的速率(百分比)，最坏的情况是$α_{1}(t)$，最好的情况是$α_{2}(t)$，最有可能的情况是$α_{3}(t)$。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/1314.png\" alt=\"1314\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-4.鱼群迁移的PSO模型</center>\n\n<p>我们假设渔业是正常的fernand fishery，估计有$10^{6}$条鲭鱼和$8\\times10^{6}$条鲱鱼。假设该船为中型渔船，正常捕获量为100吨至300吨，捕获量为正常最低捕获量的十分之一，即M = 10吨。翻译过来就是$2\\times10^{5}$条鲭鱼和$1.6\\times10^{5}$条鲱鱼。</p>\n<h4 id=\"建立非线性规划模型：\"><a href=\"#建立非线性规划模型：\" class=\"headerlink\" title=\"建立非线性规划模型：\"></a>建立非线性规划模型：</h4><p>规划目标:找到满足条件的最大t值。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/15.png\" alt=\"15\"></p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/1617.png\" alt=\"1617\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-5.非线性规划模型</center>\n\n<p>从结果可以看出，捕捞鲭鱼最糟糕的情况是在第7年左右，最好的情况是在第12年左右，最正常的情况是在第9年左右。(准确数据分别为7.12年、11.98年和9.23年)鲱鱼捕捞最差的是第6年附近，最好的是第11年附近，最正常的是第9年附近。(准确数字分别为5.86岁、10.73岁和8.89岁)</p>\n<h3 id=\"第三问求解\"><a href=\"#第三问求解\" class=\"headerlink\" title=\"第三问求解\"></a>第三问求解</h3><p>做出改变绝对不是一个随意的决定，特别是对公司来说，我们不能仅仅通过预测海洋表面温度就得出小公司是否需要在他们目前的地点之外运营的结论，因此有更多的影响需要考虑。在本文中，我们将考虑以下影响因素:温度，距离海岸的距离，竞争程度，可达性，成本。我们将建立多层次模糊综合评价模型，以决定小公司是否需要转移或哪个地点最适合转移。</p>\n<p>根据模糊综合评价模型，因子集U = (T, DFC, DC, A, C, S)，T表示温度，DFC表示距离海岸的距离，DC表示竞争程度，A表示可达性，C表示成本。S是一个0-1的值，0代表土地，1代表水土地。</p>\n<p>如果我们在苏格兰寻找大型渔业公司的位置，我们会找到的几乎都远离我们限定的区域，这意味着所有位置的DC都可以设为零，以简化计算。</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/18.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-1.苏格兰渔场位置</center>\n\n<p>然后，我们构建评估集。假设评估集V = (v1, v2, v3, v4, v5)， v1代表优秀，v2代表很好，v3代表好，v4代表不错，v5代表不好。因此，得到的模糊综合评价矩阵如下：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/19.png\" width=\"300\"> </center>\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/20.png\" width=\"500\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-2.因子权重向量矩阵</center>\n\n<p>将A和R相乘，我们可以得出(59，-3)是最适合捕鱼的地点，原因如下:</p>\n<ul>\n<li>适应性：根据我们的预测，在2050年(59，-3)将有一个非常适合苏格兰鲱鱼和鲭鱼的温度，大约13度。另一方面，根据[数据集]，2020年(59，-4)也有一个非常适合苏格兰鲱鱼和鲭鱼的温度，这意味着鲱鱼和鲭鱼很可能在未来30年定居在这个地方。</li>\n<li>竞争少：大多数主要的捕鱼公司都在苏格兰中部捕鱼，这意味着如果一家捕鱼公司在(59，-3)捕鱼，基本上没有竞争。</li>\n<li>Thurso是离(59，-3)最近的城市，人们从瑟索到爱丁堡只需4个半小时，更不用说货运火车了。</li>\n</ul>\n<p>根据这一事实(59，-3)的平均DFC是约50公里,渔船的平均速度大约是每小时20公里,公司钓鱼有建议使用一些bug渔船的比例能够操作没有陆地的支持一段时间以及装备一些小型渔船。提出此建议是为了确保2020年渔船在(59，-4)的捕捞能力，因为小岛较多。它还可以提高渔业生产力。</p>\n<h3 id=\"第四问解答\"><a href=\"#第四问解答\" class=\"headerlink\" title=\"第四问解答\"></a>第四问解答</h3><p>我们将使用与问题3相同的模糊综合评价模型。然而，有一些小的变化。</p>\n<p>首先，对大多数人来说，我们必须考虑领海因素。简单地说，由于领海存在一定的限制，我们必须重新进行评估，在12英里范围内增加更多的权重。</p>\n<p>第二，受苏格兰政府保护的地区必须被排除在我们的结果之外。特别是,(57,-2),(57,-1),(57,0),(57,1),(58,-2),(58,-1),(59,-2),(59,0),(59,1),(60 0),(60,1),(61,1),(62,-5),(62 1)</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/21.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-1.苏格兰政府保护区域</center>\n\n<p>因此，模糊综合评价矩阵为：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/22.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-2.模糊评价矩阵</center>\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/23.png\" width=\"500\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-3.因子权重向量矩阵</center>\n\n<p>我们可以得出这样的结论:领海因素进行考虑后,(59,-4)是我们最好的钓鱼位置,因此在2050年(59,-4)略接近主要的土地相比(59,-3)和更少的小岛,我们建议小型渔业公司可以使用中型渔船以确保最高的性价比以及生产力表现。</p>\n<h3 id=\"敏感性分析，误差分析以及模型优化\"><a href=\"#敏感性分析，误差分析以及模型优化\" class=\"headerlink\" title=\"敏感性分析，误差分析以及模型优化\"></a>敏感性分析，误差分析以及模型优化</h3><p>额，关于以下内容都是我写的，但是…你懂的。模型优化部分基本比较扯，在这里就不放出来让大家耻笑了。简单给出一些当时的分析过程：</p>\n<ul>\n<li>敏感性分析</li>\n</ul>\n<p>我们考虑三个变量对预测时间t的影响:海温变化率V、经济增长率g(t)和渔业中鱼的数量。我们探究了0-20%的水温变化速度V(最差)加减速对结果的影响。</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/24.png\" width=\"500\"> </center>\n\n<ul>\n<li><p>误差分析：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/25.png\" width=\"500\"> </center>\n\n</li>\n</ul>\n<h3 id=\"优缺点分析\"><a href=\"#优缺点分析\" class=\"headerlink\" title=\"优缺点分析\"></a>优缺点分析</h3><p>懒得翻译了，感觉这部分不是很重要哈哈。</p>\n<h4 id=\"优点：\"><a href=\"#优点：\" class=\"headerlink\" title=\"优点：\"></a>优点：</h4><ul>\n<li>The optimized grey prediction model fills in the shortcomings of the model due to the lack of data. 30 regions are divided around the most important north sea fishery in scotland, and the temperature changes in the sea area of scotland are intuitively perceived by using two-dimensional thermal maps.</li>\n<li>Using differential equations to account for the population of the scotland shoal, the model is more reasonable with the addition of many practical factors.The analysis of errors in the prediction results also makes the data more convincing, and the sensitivity analysis of nonlinear programming also addresses the effect of faster and slower changes in sea temperature on fish migration.</li>\n<li>The evaluation result of the model is in the form of vector instead of a specific value point, so it can reflect the fuzzy state of things accurately.Each step in the modeling process is quantified.Each layer of modeling will directly or indirectly affect the results, so that the evaluation of the target is relatively clear.</li>\n<li>The analysis model of a fishery can be applied to another fishery by changing the distance parameter, which can solve the problem of future migration of multiple fisheries.</li>\n</ul>\n<h4 id=\"缺点：\"><a href=\"#缺点：\" class=\"headerlink\" title=\"缺点：\"></a>缺点：</h4><ul>\n<li><p>Since CTD data cannot provide the data of each location comprehensively, and even the data of 42 points have up to 21.1% missing data, the data preprocessing we adopted is relatively simple, so the model in this paper cannot fully represent the most accurate results.</p>\n</li>\n<li><p>Not taking into account changes in ocean currents, climate and other factors, the actual state of the fishery, the annual fishing trips of fishermen and government policies, all lead to a lack of practicality in the model.</p>\n</li>\n<li><p>The function of the analytic hierarchy process (AHP), which cannot provide a new scheme for decision making, is to choose the better of the alternatives.This function just explains that the analytic hierarchy process can only be selected from the original plan, but can not provide the decision maker with a new plan to solve the problem.</p>\n</li>\n<li><p>The individual fishery model has little practical significance for the whole fishery.</p>\n</li>\n<li><p>In today s evaluation of scientific methods, it is generally accepted that a science requires rigorous mathematical reasoning and a sound quantitative approach. But problems in the real world and how the human brain thinks about them are often not simply Numbers.</p>\n</li>\n</ul>\n<h3 id=\"来自周哥的一封信：\"><a href=\"#来自周哥的一封信：\" class=\"headerlink\" title=\"来自周哥的一封信：\"></a>来自周哥的一封信：</h3><p>信是周哥写的，茜姐翻译的，没我啥事，鉴于在最后的一个夜晚还是通宵调试Latex，最后生成论文，这份辛苦还是值得展示出来：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/26.png\" width=\"600\"> </center>\n\n<h1 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记^_^\"></a>后记^_^</h1><p>鉴于已经是快一年前的东西了，很多细节已经记不清了，文章如果有一些问题欢迎大家指出。本人比较懒，对于修改这个工作，只能说：<strong>下次一定</strong>。:slightly_smiling_face:</p>\n<p>最后感谢自己的两位队友，周哥和茜姐。本人第一次应该也是最后一次的美赛经历大抵如此了，希望以后的情人节大家都是陪着npy，而不是对着一堆数据。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>于2020年的情人节参加的第一次建模比赛，选择了一道很常规的题目：向北移动。使用了现在看起来非常不靠谱的一些算法，好在作图水平还算不错，最终获得了H奖，也算是为自己的第一次建模比赛画上了一个句号。</p>\n</blockquote>\n<h1 id=\"题目大意：\"><a href=\"#题目大意：\" class=\"headerlink\" title=\"题目大意：\"></a>题目大意：</h1><p>全球海洋温度影响某些海洋生物的栖息地质量。当温度变化太大，它们无法继续繁荣时，这些物种就会迁移到其他更适合它们现在和未来生活和繁殖成功的栖息地。其中一个例子就是美国缅因州的龙虾种群，它们正缓慢地向北迁移到加拿大，那里的海洋温度较低，为它们提供了更合适的栖息地。这种地理种群的转移可能会严重影响依赖海洋生物稳定性的公司的生计。<br>您的团队已被苏格兰北大西洋渔业管理协会聘请为顾问。该协会希望在全球海洋温度升高的情况下，更好地了解与苏格兰鲱鱼和鲭鱼从它们目前的栖息地苏格兰附近迁移有关的问题。这两种鱼类为苏格兰渔业做出了巨大的经济贡献。鲱鱼和鲭鱼种群分布位置的变化，可能会让规模较小的苏格兰渔业公司在经济上变得不切实际。这些公司使用渔船，但船上没有冷藏设备。</p>\n<ol>\n<li><p>建立一个数学模型来确定这两种鱼类在未来50年最有可能生存的位置，假设水温将发生足够大的变化，导致种群迁移。</p>\n</li>\n<li><p>基于速度的海水温度变化发生时，用你的模型来预测最好的情况下，坏的情况下，最有可能的运行时间(s)，直到这些人口会太远了小型渔业公司收获如果小渔公司继续运营的当前位置。</p>\n</li>\n<li><p>根据你的预测分析，这些小的渔业公司应该改变他们的经营方式吗?<br>如果是，请使用您的模型来识别和评估对小型渔业公司具有实际和经济吸引力的战略。你的策略应该考虑，但不限于，现实的选择，包括:<br>-将渔业公司的部分或全部资产从苏格兰港口的现有地点迁往更靠近两种鱼类都在迁移的地方;<br>-使用一定比例的小型渔船，这些渔船能够在一段时间内不依靠陆上支助而作业，同时仍能确保渔获物的新鲜和高质量。<br>-您的团队可能识别和建模的其他选项。<br>如果您的团队拒绝任何变更的需求，根据您的建模结果为您的拒绝找理由，因为它们与您的团队所做的假设相关。</p>\n</li>\n<li><p>使用您的模型来处理如果一定比例的渔业进入另一个国家的领海(海洋)，您的提案将受到怎样的影响。</p>\n</li>\n<li><p>除了你的技术报告，准备一到两页的文章，为钩线和沉鱼杂志，以帮助渔民了解问题的严重性，以及你的解决方案将如何改善他们未来的业务前景。<br>你的意见书应包括:</p>\n<ul>\n<li>一页的总结页</li>\n</ul>\n<ul>\n<li>目录</li>\n<li>一到两页的文章</li>\n<li>您的解决方案不超过20页，最多24页，包括摘要、目录和文章。<br>参考列表和任何附件不计入页面限制，应该出现在你完成的解决方案。你不应该使用未经授权的图像和材料，其使用受到版权法的限制。确保你在报告中引用了你的观点和材料。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"解题过程：\"><a href=\"#解题过程：\" class=\"headerlink\" title=\"解题过程：\"></a>解题过程：</h1><h2 id=\"数据来源：\"><a href=\"#数据来源：\" class=\"headerlink\" title=\"数据来源：\"></a>数据来源：</h2><p>在科学上网的前提下，花了一下午和一晚上的时间在寻找合适的数据集(论数学建模如何从入门到放弃)，幸运的是在一个记录了苏格兰海域的CTD数据的网站上找到了一份完整的数据。数据是一个excel表格，包含了苏格兰地区很多地点的不同时间的温度数据。当然这份数据存在着不完整性(比如很多年份和月份的数据缺失)和随机性(地点并不明确)。我下载了近40年的数据，于是洋洋洒洒23万条记录的数据预处理:joy:，成为了我第二天上午主要的工作。</p>\n<h2 id=\"解题思路：\"><a href=\"#解题思路：\" class=\"headerlink\" title=\"解题思路：\"></a>解题思路：</h2><p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/0.png\" alt=\"0\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1.解题思路</center>\n\n<p>为了探究水温变化对鲭鱼、鲱鱼和苏格兰渔业造成的全球气候变化，我们构建了一个面向数据的全球变暖(DMEM)背景下渔业产业多层次评价模型。利用谷歌地球卫星数据，对苏格兰水域的42个点和30个区域建立了预测模型。并通过对相关领域的综合条件的预测，我们就题目的五个问题写了技术报告。最后，我们写信给Hook Line and Sinker，展示了关于我们对苏格兰渔业和渔民的建议。</p>\n<h3 id=\"数据预处理和假设\"><a href=\"#数据预处理和假设\" class=\"headerlink\" title=\"数据预处理和假设\"></a>数据预处理和假设</h3><p>通过主成分分析，忽略了一些次要因素的影响，从而达到如何处理渔业分析和种群迁移的核心。本题中我们筛选出了四个与鱼群迁移密切相关的因素：温度、磷含量、叶绿素和食物的丰富度。在分析过程中我们发现海洋中磷含量、叶绿素含量与浮游生物含量之间存在正比关系，而影响这些东西最大的因素便是温度。在PCA分析过后，我更加坚定了这个想法。于是本文致力于通过海洋<strong>温度</strong>的变化来推测鱼群的迁移方向。</p>\n<h3 id=\"第一问求解\"><a href=\"#第一问求解\" class=\"headerlink\" title=\"第一问求解\"></a>第一问求解</h3><p>我们提取了1990年至2019年期间苏格兰42个点的海水温度变化，并在预测之前对数据进行优化，这使模型能够更好地处理数据并预测未来的变化。由于我们只能用过去30年的温度数据来预测未来50年的数据，所以我们选择了用较少数据就可以预测未来趋势的灰度预测模型。分别使用GM(1，1)、GM(2，1)和DGM(1，1)模型对数据进行预测。在比较了所有的模仿效果后，我们最终选择了模仿效果最好的G(1，1)模型。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/1.png\" alt=\"1\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-1. G(1，1)模型预测海水温度</center>\n\n\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/2.png\" width=\"400\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/3.png\" width=\"400\"> </center>\n\n\n\n\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-2. G(1，1)模型分区域预测海水温度</center>\n\n<p>为了更好地了解鱼群的移动方向和去向，我们在二维热图上显示了2019年和2070年的海洋温度，以便更好地分析。</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/4.png\" width=\"400\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/5.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-3.左图为2019年的海水热力图，右图为2070年的海水热力图</center>\n\n<p>最后，根据实测卫星图像和谷歌earth显示的热图，对鱼类迁移后的范围进行了分析和预测。结果如下图所示。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/6.png\" alt=\"6\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2-4.鱼群迁移图像</center>\n\n<h3 id=\"第二问求解\"><a href=\"#第二问求解\" class=\"headerlink\" title=\"第二问求解\"></a>第二问求解</h3><p>建立了基于非线性规划和粒子群算法(PSO)的鱼群迁移模型。使用真实数据和现实方法对单个渔业进行建模和预测。同时，该模型也可以应用于其他类似鱼类的预测，并利用粒子群算法模拟出直观的鱼类迁移图像。</p>\n<h4 id=\"参数设定\"><a href=\"#参数设定\" class=\"headerlink\" title=\"参数设定\"></a>参数设定</h4><p>以下数据均来自于《2019年苏格兰渔业报告》。</p>\n<p>我们假设渔场中剩下的鱼的数量取决于:</p>\n<ul>\n<li>最舒适的鲱鱼和鲭鱼的中心离开渔场所需的时间</li>\n<li>鱼群可能迁移到渔场以外的时间</li>\n<li>渔船航行时间和鱼的检测时间。</li>\n</ul>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/7.png\" alt=\"7\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-1.参数设定</center>\n\n<p>据调查，出海的平均时间是一个月，其中一半是作业时间，另一半是往返时间。单程时间约7天。大型渔船的平均巡航速度为7.5km/h，全单程航程为:</p>\n<script type=\"math/tex; mode=display\">\n7\\times24\\times7.5 = 1260km</script><p>一个渔场最多可达数公里，平均渔场达一公里，说明渔场的分布很窄。2018年苏格兰海洋渔业统计数据显示，苏格兰舰队的捕捞量为44.6万吨，占欧盟总量的8%。鲭鱼占渔获量的30.2%，鲱鱼占19.6%。根据维基百科，成年鲭鱼的重量在150至400克之间，而成年鲱鱼的重量在250至450克之间。我们根据鲱鱼和鲭鱼的重量以及这些重量的个体所占的比例得到一个合理的估计。成年鲱鱼的平均重量为m2=350克。成年鲭鱼的平均重量为m1=275克。由鲭鱼和鲱鱼的捕捞量，我们可以计算出鲭鱼的捕捞吨位W1 = 132000吨。捕捞鲱鱼数为w2= 8.8万吨。</p>\n<h4 id=\"Logistic模型的建立\"><a href=\"#Logistic模型的建立\" class=\"headerlink\" title=\"Logistic模型的建立\"></a>Logistic模型的建立</h4><p>我们研究渔业的连续收获模型，横轴为鲭鱼或鲱鱼种群，纵轴为鲭鱼和鲱鱼种群增长率和趋势。我们假设鱼类的生长遵循logistics增长模型:</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{x}(t)=f(x)=r x\\left(1-\\frac{x}{N}\\right)</script><p>当x = N/2，渔获率= r/2时，单位时间的渔获量可以得到最大的连续产量，且稳定。假设苏格兰政府的渔获量限制在总渔获量的10%，也就是说每年的渔获量保持在总渔获量的55%到45%之间。</p>\n<p>鲭鱼的捕捞数量约为:</p>\n<script type=\"math/tex; mode=display\">\nQ 1=w 1 / m 1 \\times 10=2.4 \\times 10^{8}</script><p>鲱鱼的捕捞数量约为:</p>\n<script type=\"math/tex; mode=display\">\nQ 2=w 2 / m 2 \\times 10=1.26 \\times 10^{8}</script><p>由数据得到的模型如下图所示:</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/8.png\" width=\"300\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/9.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-2.苏格兰地区鲱鱼的logistics模型</center>\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/10.png\" width=\"300\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/11.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-3.苏格兰地区鲭鱼的logistics模型</center>\n\n<p>在21世纪的苏格兰，一种常见的捕鱼方法是Seine fishing。假设一个正常的渔场，s = 300平方公里，假设渔场是一个圆，半径为r = 10km。我们选取了半径为1000m的平均塞纳河数据，高度为半径的1/10，即100m。围网捕鱼70%-80%的时间用于检测鱼群，记录为P1，数据查询后的平均时间为6天。假设一次探测鱼群的准确率为a1，约为80%，随着声纳系统的发展，准确率也在不断提高。由于鲱鱼和鲭鱼群比较集中，所以a1可以直接认为是捕鱼的概率。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/12.png\" alt=\"12\"></p>\n<p>纬度约为110公里，在纬度60度，经度约为55.5公里。根据模型1的结果，鱼群在50年内从北纬59度和东经3度迁移到北纬60度和东经3度， L1=100km。我们计算了在一个正方形区域内北纬59度和东经3度到北纬60度和东经4度不同条件下的海温变化率。</p>\n<h4 id=\"PSO优化算法估计鱼群的迁移率\"><a href=\"#PSO优化算法估计鱼群的迁移率\" class=\"headerlink\" title=\"PSO优化算法估计鱼群的迁移率\"></a>PSO优化算法估计鱼群的迁移率</h4><p>假设当适当区域的中心离开渔场时，鱼开始移动。根据第一个问题，海水温度变化范围和增长率的灰色模型，得出海洋温度的变化率在最坏的情况下是$V_{\\text {worst}}=g_{1}(t)$，在最好的情况下是$2$，最可能的情况是$V_{\\text {normal}}=g_{3}(t)$。</p>\n<p>根据粒子群优化算法，如果有500条鱼的学校，我们能算出鱼学校留在原来的渔业的比例随着适用性的中心(该中心在一个二维平面上变化)，鱼的比例在最初的渔业遗留下来的，在最坏的情况下是$μ_{1}(t)$，在最好的情况下是$μ_{2}(t)$，最可能的情况是$μ_{3}(t)$。</p>\n<p>然后我们取这三种情况的一阶导数的绝对值，我们得到鱼离开渔场的速率(百分比)，最坏的情况是$α_{1}(t)$，最好的情况是$α_{2}(t)$，最有可能的情况是$α_{3}(t)$。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/1314.png\" alt=\"1314\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-4.鱼群迁移的PSO模型</center>\n\n<p>我们假设渔业是正常的fernand fishery，估计有$10^{6}$条鲭鱼和$8\\times10^{6}$条鲱鱼。假设该船为中型渔船，正常捕获量为100吨至300吨，捕获量为正常最低捕获量的十分之一，即M = 10吨。翻译过来就是$2\\times10^{5}$条鲭鱼和$1.6\\times10^{5}$条鲱鱼。</p>\n<h4 id=\"建立非线性规划模型：\"><a href=\"#建立非线性规划模型：\" class=\"headerlink\" title=\"建立非线性规划模型：\"></a>建立非线性规划模型：</h4><p>规划目标:找到满足条件的最大t值。</p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/15.png\" alt=\"15\"></p>\n<p><img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/1617.png\" alt=\"1617\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3-5.非线性规划模型</center>\n\n<p>从结果可以看出，捕捞鲭鱼最糟糕的情况是在第7年左右，最好的情况是在第12年左右，最正常的情况是在第9年左右。(准确数据分别为7.12年、11.98年和9.23年)鲱鱼捕捞最差的是第6年附近，最好的是第11年附近，最正常的是第9年附近。(准确数字分别为5.86岁、10.73岁和8.89岁)</p>\n<h3 id=\"第三问求解\"><a href=\"#第三问求解\" class=\"headerlink\" title=\"第三问求解\"></a>第三问求解</h3><p>做出改变绝对不是一个随意的决定，特别是对公司来说，我们不能仅仅通过预测海洋表面温度就得出小公司是否需要在他们目前的地点之外运营的结论，因此有更多的影响需要考虑。在本文中，我们将考虑以下影响因素:温度，距离海岸的距离，竞争程度，可达性，成本。我们将建立多层次模糊综合评价模型，以决定小公司是否需要转移或哪个地点最适合转移。</p>\n<p>根据模糊综合评价模型，因子集U = (T, DFC, DC, A, C, S)，T表示温度，DFC表示距离海岸的距离，DC表示竞争程度，A表示可达性，C表示成本。S是一个0-1的值，0代表土地，1代表水土地。</p>\n<p>如果我们在苏格兰寻找大型渔业公司的位置，我们会找到的几乎都远离我们限定的区域，这意味着所有位置的DC都可以设为零，以简化计算。</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/18.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-1.苏格兰渔场位置</center>\n\n<p>然后，我们构建评估集。假设评估集V = (v1, v2, v3, v4, v5)， v1代表优秀，v2代表很好，v3代表好，v4代表不错，v5代表不好。因此，得到的模糊综合评价矩阵如下：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/19.png\" width=\"300\"> </center>\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/20.png\" width=\"500\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4-2.因子权重向量矩阵</center>\n\n<p>将A和R相乘，我们可以得出(59，-3)是最适合捕鱼的地点，原因如下:</p>\n<ul>\n<li>适应性：根据我们的预测，在2050年(59，-3)将有一个非常适合苏格兰鲱鱼和鲭鱼的温度，大约13度。另一方面，根据[数据集]，2020年(59，-4)也有一个非常适合苏格兰鲱鱼和鲭鱼的温度，这意味着鲱鱼和鲭鱼很可能在未来30年定居在这个地方。</li>\n<li>竞争少：大多数主要的捕鱼公司都在苏格兰中部捕鱼，这意味着如果一家捕鱼公司在(59，-3)捕鱼，基本上没有竞争。</li>\n<li>Thurso是离(59，-3)最近的城市，人们从瑟索到爱丁堡只需4个半小时，更不用说货运火车了。</li>\n</ul>\n<p>根据这一事实(59，-3)的平均DFC是约50公里,渔船的平均速度大约是每小时20公里,公司钓鱼有建议使用一些bug渔船的比例能够操作没有陆地的支持一段时间以及装备一些小型渔船。提出此建议是为了确保2020年渔船在(59，-4)的捕捞能力，因为小岛较多。它还可以提高渔业生产力。</p>\n<h3 id=\"第四问解答\"><a href=\"#第四问解答\" class=\"headerlink\" title=\"第四问解答\"></a>第四问解答</h3><p>我们将使用与问题3相同的模糊综合评价模型。然而，有一些小的变化。</p>\n<p>首先，对大多数人来说，我们必须考虑领海因素。简单地说，由于领海存在一定的限制，我们必须重新进行评估，在12英里范围内增加更多的权重。</p>\n<p>第二，受苏格兰政府保护的地区必须被排除在我们的结果之外。特别是,(57,-2),(57,-1),(57,0),(57,1),(58,-2),(58,-1),(59,-2),(59,0),(59,1),(60 0),(60,1),(61,1),(62,-5),(62 1)</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/21.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-1.苏格兰政府保护区域</center>\n\n<p>因此，模糊综合评价矩阵为：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/22.png\" width=\"300\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-2.模糊评价矩阵</center>\n\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/23.png\" width=\"500\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5-3.因子权重向量矩阵</center>\n\n<p>我们可以得出这样的结论:领海因素进行考虑后,(59,-4)是我们最好的钓鱼位置,因此在2050年(59,-4)略接近主要的土地相比(59,-3)和更少的小岛,我们建议小型渔业公司可以使用中型渔船以确保最高的性价比以及生产力表现。</p>\n<h3 id=\"敏感性分析，误差分析以及模型优化\"><a href=\"#敏感性分析，误差分析以及模型优化\" class=\"headerlink\" title=\"敏感性分析，误差分析以及模型优化\"></a>敏感性分析，误差分析以及模型优化</h3><p>额，关于以下内容都是我写的，但是…你懂的。模型优化部分基本比较扯，在这里就不放出来让大家耻笑了。简单给出一些当时的分析过程：</p>\n<ul>\n<li>敏感性分析</li>\n</ul>\n<p>我们考虑三个变量对预测时间t的影响:海温变化率V、经济增长率g(t)和渔业中鱼的数量。我们探究了0-20%的水温变化速度V(最差)加减速对结果的影响。</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/24.png\" width=\"500\"> </center>\n\n<ul>\n<li><p>误差分析：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/25.png\" width=\"500\"> </center>\n\n</li>\n</ul>\n<h3 id=\"优缺点分析\"><a href=\"#优缺点分析\" class=\"headerlink\" title=\"优缺点分析\"></a>优缺点分析</h3><p>懒得翻译了，感觉这部分不是很重要哈哈。</p>\n<h4 id=\"优点：\"><a href=\"#优点：\" class=\"headerlink\" title=\"优点：\"></a>优点：</h4><ul>\n<li>The optimized grey prediction model fills in the shortcomings of the model due to the lack of data. 30 regions are divided around the most important north sea fishery in scotland, and the temperature changes in the sea area of scotland are intuitively perceived by using two-dimensional thermal maps.</li>\n<li>Using differential equations to account for the population of the scotland shoal, the model is more reasonable with the addition of many practical factors.The analysis of errors in the prediction results also makes the data more convincing, and the sensitivity analysis of nonlinear programming also addresses the effect of faster and slower changes in sea temperature on fish migration.</li>\n<li>The evaluation result of the model is in the form of vector instead of a specific value point, so it can reflect the fuzzy state of things accurately.Each step in the modeling process is quantified.Each layer of modeling will directly or indirectly affect the results, so that the evaluation of the target is relatively clear.</li>\n<li>The analysis model of a fishery can be applied to another fishery by changing the distance parameter, which can solve the problem of future migration of multiple fisheries.</li>\n</ul>\n<h4 id=\"缺点：\"><a href=\"#缺点：\" class=\"headerlink\" title=\"缺点：\"></a>缺点：</h4><ul>\n<li><p>Since CTD data cannot provide the data of each location comprehensively, and even the data of 42 points have up to 21.1% missing data, the data preprocessing we adopted is relatively simple, so the model in this paper cannot fully represent the most accurate results.</p>\n</li>\n<li><p>Not taking into account changes in ocean currents, climate and other factors, the actual state of the fishery, the annual fishing trips of fishermen and government policies, all lead to a lack of practicality in the model.</p>\n</li>\n<li><p>The function of the analytic hierarchy process (AHP), which cannot provide a new scheme for decision making, is to choose the better of the alternatives.This function just explains that the analytic hierarchy process can only be selected from the original plan, but can not provide the decision maker with a new plan to solve the problem.</p>\n</li>\n<li><p>The individual fishery model has little practical significance for the whole fishery.</p>\n</li>\n<li><p>In today s evaluation of scientific methods, it is generally accepted that a science requires rigorous mathematical reasoning and a sound quantitative approach. But problems in the real world and how the human brain thinks about them are often not simply Numbers.</p>\n</li>\n</ul>\n<h3 id=\"来自周哥的一封信：\"><a href=\"#来自周哥的一封信：\" class=\"headerlink\" title=\"来自周哥的一封信：\"></a>来自周哥的一封信：</h3><p>信是周哥写的，茜姐翻译的，没我啥事，鉴于在最后的一个夜晚还是通宵调试Latex，最后生成论文，这份辛苦还是值得展示出来：</p>\n<center class=\"half\">    <img src=\"/2021/01/26/2020%E5%B9%B4%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%BE%8E%E8%B5%9BA%E9%A2%98/26.png\" width=\"600\"> </center>\n\n<h1 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记^_^\"></a>后记^_^</h1><p>鉴于已经是快一年前的东西了，很多细节已经记不清了，文章如果有一些问题欢迎大家指出。本人比较懒，对于修改这个工作，只能说：<strong>下次一定</strong>。:slightly_smiling_face:</p>\n<p>最后感谢自己的两位队友，周哥和茜姐。本人第一次应该也是最后一次的美赛经历大抵如此了，希望以后的情人节大家都是陪着npy，而不是对着一堆数据。</p>\n"},{"title":"Hexo-Theme-LiveMyLife","catalog":true,"date":"2020-04-16T18:34:17.000Z","subtitle":"A succinct hexo theme...","top":1,"header-img":"/img/header_img/lml_bg.jpg","_content":"\n\n> Ported Theme of [Hux Blog](https://github.com/Huxpro/huxpro.github.io), Thank [Huxpro](https://github.com/Huxpro) for designing such a flawless theme.\n>\n> This LiveMyLife theme created by [Vincent](https://v-vincen.github.io/) modified from the original Porter [YenYuHsuan](https://github.com/YenYuHsuan/hexo-theme-beantech) , refer to the Themes of [dusign](https://github.com/dusign/hexo-theme-snail)、[Utone](https://github.com/shixiaohu2206/hexo-theme-huhu), Thanks [dusign](https://github.com/dusign/hexo-theme-snail)、[Utone](https://github.com/shixiaohu2206/hexo-theme-huhu).\n>   \n\n## Repo\n\nGithub Repo: https://github.com/V-Vincen/hexo-theme-livemylife\n\nGitee Repo: https://gitee.com/V_Vincen/hexo-theme-livemylife\n\n## [View Live LiveMyLife Blog →](https://v-vincen.github.io/)\n\n![LiveMyLife Desktop](livemylife-desktop.png)\n\n## Quick Start\n\nI publish the whole project for your convenience, so you can just follow the instruction down below, then you can easily customiz your own blog!\n\nLet's begin!!!\n\n### Install Node.js and Git\n```shell\n#For Mac\nbrew install node\nbrew install git\n```\n> Windows: Download & install Node.js. -> [Node.js](https://nodejs.org/zh-cn/download/)\n>\n> Windows: Download & install Git. -> [Git](https://git-scm.com/download/win)\n\n### Install Hexo\n```shell\n$ npm install -g hexo-cli\n```\n> What is [Hexo](https://hexo.io/docs/)?\n>\n> Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other markup languages) and Hexo generates static files with a beautiful theme in seconds.\n\n### Setup your blog\n```shell\n$ hexo init blog\n```\n> More Commands -> [Hexo Commands](https://hexo.io/docs/commands)\n\n\n## Theme Usage\n### Init\n```shell\ncd bolg\nrm -rf _config.yml package.json scaffolds source themes yarn.lock #just keep node_modules\ngit clone https://github.com/V-Vincen/hexo-theme-livemylife.git\nmv hexo-theme-livemylife/* ./\nrm -rf hexo-theme-livemylife\nnpm install\n```\n\n### Set Theme\nModify the value of `theme`: in `_config.yml`\n```yml\n# Extensions\n## Themes: https://hexo.io/themes/\n## Plugins: https://hexo.io/plugins/\ntheme: livemylife\n```\n\n### Start the Server\n```shell\nhexo generate # or hexo g\nhexo server   # or hexo s\n```\nStarts a local server. By default, this is at `http://localhost:4000/`.\n> More Commands -> [Hexo Commands](https://hexo.io/docs/commands)\n\n## Configuration\nModify `_config.yml` file with your own info, Especially the section:\n\n### Site\nReplace the following information with your own.\n```yml\n# Site\ntitle: Live My Life\nsubtitle: 淡而无味也是一种味道\nauthor: Mr.Vincent\nlanguage: zh-CN\ntimezone:\n```\n\n### CDN Settings\nJsDelivr is A free CDN for Open Source fast、reliable and automated. If Github Pages deploy，you can config CDN settings. The images of the Hexo-theme-livemylife has added JsDelivr CDN Setting. How to use Jsdelivr? -> Docs：[免费 CDN 提速 Github 静态资源访问](https://v-vincen.github.io/2020/07/15/Github-%E5%8A%A0%E9%80%9F%E4%BC%98%E5%8C%96/#%E5%85%8D%E8%B4%B9-CDN-%E6%8F%90%E9%80%9F-Github-%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE)\n```yml\n# CDN Setting\n# Docs: https://www.jsdelivr.com/?docs=gh\n# If Github Pages deploy，you can ues jsdelivr settings\n#\njsdelivr:\n  jsdelivr_url: https://cdn.jsdelivr.net/gh/\n  github_username: V-Vincen\n```\n\n### Site Settings\nPut customized pictures in img directory.\n```yml\n# Site settings\nSEOTitle: JavaDev | 一如Java深似海\nemail: hexo-theme-livemylife@mail.com\ndescription: \"It's an IT blog...\"\nkeyword: \"Java,v-vincen,v-vincen,livemylife,IT  blog,Blog\"\nheader-img: img/header_img/newhome_bg.jpg\narchives-img: img/header_img/archive_bg2.jpg\n```\n\n### Favicon Settings\n```yml\nfavicon: img/avatar/favicon.jpg\n```\n\n### Signature Settings\nCopy your signature image to `<root>/img/signature` and modify the `_config.yml`.\n```yml\nsignature: true   # show signature\nsignature-img: img/signature/<your-signature>\n```\n> How to create signature -> [Free Online Signature](https://fontmeme.com/signature-fonts/)\n\n### Wave Settings\n```yml\n# Wave settings\nwave: true\n```\nExample:\n\n![wave](wave.png)\n\n\n### SNS Settings\nIf you don’t want to display it, you can delete it directly.\n```yml\n# SNS settings\n# RSS: true\ngithub_username: V-Vincen\ntwitter_username: V_Vincen_\ninstagram_username: V_Vincen_\n# facebook_username:  yourAccount\n# linkedin_username:  yourAccount\n# zhihu_username: yourAccount\nweibo_username: WVincen\n```\n\n### Sidebar Settings\nCopy your avatar image to `<root>/img/avatar` and modify the `_config.yml`:\n```yml\nsidebar: true   # whether or not using Sidebar.\nsidebar-about-description: \"I don't know where I am going ,but I am on my way...\"\nsidebar-avatar: img/avatar/vincnet.jpg    # use absolute URL, seeing it's used in both `/` and `/about/`\nwidgets:\n- visitor   # busuanzi: https://busuanzi.ibruce.info/\n- featured-tags\n- short-about\n- recent-posts\n- friends-blog\n- archive\n- category\n\n# widget behavior\n## Archive\narchive_type: 'monthly'\nshow_count: true\n\n## Featured Tags\nfeatured-tags: true   # whether or not using Feature-Tags\nfeatured-condition-size: 0    # A tag will be featured if the size of it is more than this\n\n## Friends\nfriends: [\n    {\n        title: \"V_Vincen\",\n        href: \"https://v-vincen.life/\"\n    },{\n        title: \"Teacher Ye\",\n        href: \"http://teacherye.com/\"\n    }\n]\n```\n\n### Comment Settings\nHexo-Theme-LiveMyLife temporarily supports three Comments. I use gitalk comment system.\n\n#### Gitalk\nGitalk is a modern comment component based on GitHub Issue and Preact. See [Gitalk](https://github.com/gitalk/gitalk) for detailed configuration method.\n```yml\n# Gitalk Settings\n# Doc: https://github.com/gitalk/gitalk/blob/master/readme-cn.md\ngitalk:\n  owner:                          # 'GitHub repo owner'\n  admin:                          # 'GitHub repo'\n  repo:                           # ['GitHub repo owner and collaborators, only these guys can initialize github issues']\n  clientID:                       # 'GitHub Application Client ID'\n  clientSecret:                   # 'GitHub Application Client Secret'\n  perPage: 10                     # Pagination size, with maximum 100.\n  pagerDirection: last            # Comment sorting direction, available values are last and first.\n  createIssueManually: false      # By default, Gitalk will create a corresponding github issue for your every single page automatically when the logined user is belong to the admin users. You can create it manually by setting this option to true\n  language: en                    # Localization language key, en, zh-CN and zh-TW are currently available.\n  maxCommentHeight: 250           # An optional number to limit comments' max height, over which comments will be folded.Default 250.\n```\n\n#### Gitment\nGitment is a comment system based on GitHub Issues, which can be used in the frontend without any server-side implementation. See [Gitment](https://github.com/imsun/gitment) for detailed configuration method.\n```yml\n## Gitment Settings\n## Doc: https://github.com/imsun/gitment\ngitment:\n  owner:                          # Your GitHub ID. Required.\n  repo:                           # The repository to store your comments. Make sure you're repo's owner. Required.\n  client_id:                      # GitHub client ID. Required.\n  client_secret:                  # GitHub client secret. Required.\n  desc:                           # An optional description for your page, used in issue's body. Default ''.\n  perPage: 10                     # An optional number to which comments will be paginated. Default 20.\n  maxCommentHeight: 250           # An optional number to limit comments' max height, over which comments will be folded. Default 250.\n```\n\n#### Disqus\nIf you want use [Disqus](https://disqus.com/), you must have a circumvention (proxy, clime over the firewall) technology.\n```yml\n# Disqus settings\ndisqus_username: your-disqus-ID\n```\n\n\n### Analytics Settings\nHow to config analytics? -> Docs：[Analytics and Sitemap Settings](https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/)\n```yml\n# Analytics settings\n# Google Analytics\nga_track_id: UA-xxxxxx-xx   # Format: UA-xxxxxx-xx\n\n# Baidu Analytics\nba_track_id: ba_track_id\n```\n\n### Sitemap Settings\nHow to config sitemap? -> Docs：[Analytics and Sitemap Settings](https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/)\n```yml\n# Google sitemap\nsitemap:\n  path: sitemap.xml\n\n# Baidu sitemap\nbaidusitemap:\n  path: baidusitemap.xml\n\nbaidu_push: true\n```\n\n\n### Go to top icon Setup\nMy icon is using point, you can change to your own icon at `sourcre/css/images`.\n\n### Post tag\nYou can decide to show post tags or not.\n```yml\nhome_posts_tag: true\n```\nExample:\n\n![home_posts_tag-true](home_posts_tag-true.png)\n\n\n### Markdown render\nMy markdown render engine plugin is [hexo-renderer-markdown-it](https://github.com/celsomiranda/hexo-renderer-markdown-it).\n```yml\n# Markdown-it config\n## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki\nmarkdown:\n  render:\n    html: true\n    xhtmlOut: false\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: '“”‘’'\n```\n\n### Anchorjs Settings\nAnd if you want to change the header anchor '❡', you can go to `layout/_partial/anchorjs.ejs` to change it. How to use anchorjs, see [AnchorJS](https://www.bryanbraun.com/anchorjs/#examples) for detailed examples.\n```yml\n# Anchorjs Settings\nanchorjs: true    # if you want to customize anchor. check out line:26 of `anchorjs.ejs`\n```\n\n```javascript\nasync(\"//cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\",function(){\n        anchors.options = {\n          visible: 'hover',\n          placement: 'left',\n          icon: '❡'\n          // icon: 'ℬ'\n        };\n        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');\n    })\n```\n\n### Article Top\n```yml\n# article top\ntop: true\n```\nHexo-theme-livemylife has added the article top function, just add `top: number` configuration to your markdown notes, articles are sorted by this number.\n\nExample:\n\n![top](top.png)\n\n### WordCount Settings\nA Word Count Plugin for Hexo. See [WordCount](https://github.com/willin/hexo-wordcount) for detailed configuration method.\n```yml\n# Dependencies: https://github.com/willin/hexo-wordcount\n# Docs: https://www.npmjs.com/package/hexo-wordcount\nwordcount: true\n```\n\n### Top scroll progress\n```yml\n# top scroll progress\nscroll: true\n```\n\n### Tip\n```yml\ntip:\n  enable: true\n  copyright: Say what you think...\n```\n\n### Social Share Post\n```yml\n#Docs: https://github.com/overtrue/share.js\nshare: true\n```\n\n### Viewer Config\nViewer is a simple jQuery image viewing plugin. Let us first look at a [demo](https://fengyuanchen.github.io/viewer/). See [Viewer](https://github.com/fengyuanchen/viewer) for detailed configuration. If you want to modify the [options](https://github.com/fengyuanchen/viewerjs#options) of Viewer, you can go to `sourcre/js/viewer/pic-viewer.js` to change it.\n```yml\n# Viewer config\nviewer: true\n```\n\n### Theme Color Config\nHexo-Theme-LiveMyLife temporarily supports two themes color.\n```yml\nthemecolor: true\n```\nLight theme preview：\n![light theme](light.png)\n\nDark theme preview：\n![dark theme](dark.png)\n\n\n\n### Search Settings\n```yml\n# Dependencies: https://github.com/V-Vincen/hexo-generator-zip-search\nsearch:\n  enable: true\n  path: search.json\n  zipPath: search.flv\n  versionPath: searchVersion.json\n  field: post\n  # if auto, trigger search by changing input\n  # if manual, trigger search by pressing enter key or search button\n  trigger: auto\n  # show top n results per article, show all results by setting to -1\n  top_n_per_article: 1\n```\n\n### Gitter\nGitter is a chat and network platform that helps manage, develop and connect communities through messages, content and discovery. See [Gitter](https://gitter.im/) for detailed configuration method.\n```yml\n## Docs:https://gitter.im/?utm_source=left-menu-logo\n##\ngitter:\n  room: your-community/your-room\n```\n\n### Deployment\nReplace to your own repo!\n```yml\ndeploy:\n  type: git\n  repo: https://github.com/<yourAccount>/<repo> # or https://gitee.com/<yourAccount>/<repo>\n  branch: <your-branch>\n```\n\n## Hexo Basics\n\nSome hexo command:\n\n```bash\nhexo new post \"<post name>\"   # you can change post to another layout if you want\nhexo clean && hexo generate   # generate the static file\nhexo server   # run hexo in local environment\nhexo deploy   # hexo will push the static files automatically into the specific branch(gh-pages) of your repo!\n```\n\n## Have fun ^\\_^\n\nPlease [Star](https://github.com/V-Vincen/hexo-theme-livemylife) this Project if you like it! [Follow](https://github.com/V-Vincen) would also be appreciated! Peace!\n","source":"_posts/Hexo-Theme-LiveMyLife.md","raw":"---\ntitle: Hexo-Theme-LiveMyLife\ncatalog: true\ndate: 2020-04-17 02:34:17\nsubtitle: A succinct hexo theme...\ntop: 1\nheader-img: /img/header_img/lml_bg.jpg\ntags:\n- Hexo\n- Hexo-Theme-LiveMyLife\ncategories:\n- Hexo-Theme-LiveMyLife\n---\n\n\n> Ported Theme of [Hux Blog](https://github.com/Huxpro/huxpro.github.io), Thank [Huxpro](https://github.com/Huxpro) for designing such a flawless theme.\n>\n> This LiveMyLife theme created by [Vincent](https://v-vincen.github.io/) modified from the original Porter [YenYuHsuan](https://github.com/YenYuHsuan/hexo-theme-beantech) , refer to the Themes of [dusign](https://github.com/dusign/hexo-theme-snail)、[Utone](https://github.com/shixiaohu2206/hexo-theme-huhu), Thanks [dusign](https://github.com/dusign/hexo-theme-snail)、[Utone](https://github.com/shixiaohu2206/hexo-theme-huhu).\n>   \n\n## Repo\n\nGithub Repo: https://github.com/V-Vincen/hexo-theme-livemylife\n\nGitee Repo: https://gitee.com/V_Vincen/hexo-theme-livemylife\n\n## [View Live LiveMyLife Blog →](https://v-vincen.github.io/)\n\n![LiveMyLife Desktop](livemylife-desktop.png)\n\n## Quick Start\n\nI publish the whole project for your convenience, so you can just follow the instruction down below, then you can easily customiz your own blog!\n\nLet's begin!!!\n\n### Install Node.js and Git\n```shell\n#For Mac\nbrew install node\nbrew install git\n```\n> Windows: Download & install Node.js. -> [Node.js](https://nodejs.org/zh-cn/download/)\n>\n> Windows: Download & install Git. -> [Git](https://git-scm.com/download/win)\n\n### Install Hexo\n```shell\n$ npm install -g hexo-cli\n```\n> What is [Hexo](https://hexo.io/docs/)?\n>\n> Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other markup languages) and Hexo generates static files with a beautiful theme in seconds.\n\n### Setup your blog\n```shell\n$ hexo init blog\n```\n> More Commands -> [Hexo Commands](https://hexo.io/docs/commands)\n\n\n## Theme Usage\n### Init\n```shell\ncd bolg\nrm -rf _config.yml package.json scaffolds source themes yarn.lock #just keep node_modules\ngit clone https://github.com/V-Vincen/hexo-theme-livemylife.git\nmv hexo-theme-livemylife/* ./\nrm -rf hexo-theme-livemylife\nnpm install\n```\n\n### Set Theme\nModify the value of `theme`: in `_config.yml`\n```yml\n# Extensions\n## Themes: https://hexo.io/themes/\n## Plugins: https://hexo.io/plugins/\ntheme: livemylife\n```\n\n### Start the Server\n```shell\nhexo generate # or hexo g\nhexo server   # or hexo s\n```\nStarts a local server. By default, this is at `http://localhost:4000/`.\n> More Commands -> [Hexo Commands](https://hexo.io/docs/commands)\n\n## Configuration\nModify `_config.yml` file with your own info, Especially the section:\n\n### Site\nReplace the following information with your own.\n```yml\n# Site\ntitle: Live My Life\nsubtitle: 淡而无味也是一种味道\nauthor: Mr.Vincent\nlanguage: zh-CN\ntimezone:\n```\n\n### CDN Settings\nJsDelivr is A free CDN for Open Source fast、reliable and automated. If Github Pages deploy，you can config CDN settings. The images of the Hexo-theme-livemylife has added JsDelivr CDN Setting. How to use Jsdelivr? -> Docs：[免费 CDN 提速 Github 静态资源访问](https://v-vincen.github.io/2020/07/15/Github-%E5%8A%A0%E9%80%9F%E4%BC%98%E5%8C%96/#%E5%85%8D%E8%B4%B9-CDN-%E6%8F%90%E9%80%9F-Github-%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE)\n```yml\n# CDN Setting\n# Docs: https://www.jsdelivr.com/?docs=gh\n# If Github Pages deploy，you can ues jsdelivr settings\n#\njsdelivr:\n  jsdelivr_url: https://cdn.jsdelivr.net/gh/\n  github_username: V-Vincen\n```\n\n### Site Settings\nPut customized pictures in img directory.\n```yml\n# Site settings\nSEOTitle: JavaDev | 一如Java深似海\nemail: hexo-theme-livemylife@mail.com\ndescription: \"It's an IT blog...\"\nkeyword: \"Java,v-vincen,v-vincen,livemylife,IT  blog,Blog\"\nheader-img: img/header_img/newhome_bg.jpg\narchives-img: img/header_img/archive_bg2.jpg\n```\n\n### Favicon Settings\n```yml\nfavicon: img/avatar/favicon.jpg\n```\n\n### Signature Settings\nCopy your signature image to `<root>/img/signature` and modify the `_config.yml`.\n```yml\nsignature: true   # show signature\nsignature-img: img/signature/<your-signature>\n```\n> How to create signature -> [Free Online Signature](https://fontmeme.com/signature-fonts/)\n\n### Wave Settings\n```yml\n# Wave settings\nwave: true\n```\nExample:\n\n![wave](wave.png)\n\n\n### SNS Settings\nIf you don’t want to display it, you can delete it directly.\n```yml\n# SNS settings\n# RSS: true\ngithub_username: V-Vincen\ntwitter_username: V_Vincen_\ninstagram_username: V_Vincen_\n# facebook_username:  yourAccount\n# linkedin_username:  yourAccount\n# zhihu_username: yourAccount\nweibo_username: WVincen\n```\n\n### Sidebar Settings\nCopy your avatar image to `<root>/img/avatar` and modify the `_config.yml`:\n```yml\nsidebar: true   # whether or not using Sidebar.\nsidebar-about-description: \"I don't know where I am going ,but I am on my way...\"\nsidebar-avatar: img/avatar/vincnet.jpg    # use absolute URL, seeing it's used in both `/` and `/about/`\nwidgets:\n- visitor   # busuanzi: https://busuanzi.ibruce.info/\n- featured-tags\n- short-about\n- recent-posts\n- friends-blog\n- archive\n- category\n\n# widget behavior\n## Archive\narchive_type: 'monthly'\nshow_count: true\n\n## Featured Tags\nfeatured-tags: true   # whether or not using Feature-Tags\nfeatured-condition-size: 0    # A tag will be featured if the size of it is more than this\n\n## Friends\nfriends: [\n    {\n        title: \"V_Vincen\",\n        href: \"https://v-vincen.life/\"\n    },{\n        title: \"Teacher Ye\",\n        href: \"http://teacherye.com/\"\n    }\n]\n```\n\n### Comment Settings\nHexo-Theme-LiveMyLife temporarily supports three Comments. I use gitalk comment system.\n\n#### Gitalk\nGitalk is a modern comment component based on GitHub Issue and Preact. See [Gitalk](https://github.com/gitalk/gitalk) for detailed configuration method.\n```yml\n# Gitalk Settings\n# Doc: https://github.com/gitalk/gitalk/blob/master/readme-cn.md\ngitalk:\n  owner:                          # 'GitHub repo owner'\n  admin:                          # 'GitHub repo'\n  repo:                           # ['GitHub repo owner and collaborators, only these guys can initialize github issues']\n  clientID:                       # 'GitHub Application Client ID'\n  clientSecret:                   # 'GitHub Application Client Secret'\n  perPage: 10                     # Pagination size, with maximum 100.\n  pagerDirection: last            # Comment sorting direction, available values are last and first.\n  createIssueManually: false      # By default, Gitalk will create a corresponding github issue for your every single page automatically when the logined user is belong to the admin users. You can create it manually by setting this option to true\n  language: en                    # Localization language key, en, zh-CN and zh-TW are currently available.\n  maxCommentHeight: 250           # An optional number to limit comments' max height, over which comments will be folded.Default 250.\n```\n\n#### Gitment\nGitment is a comment system based on GitHub Issues, which can be used in the frontend without any server-side implementation. See [Gitment](https://github.com/imsun/gitment) for detailed configuration method.\n```yml\n## Gitment Settings\n## Doc: https://github.com/imsun/gitment\ngitment:\n  owner:                          # Your GitHub ID. Required.\n  repo:                           # The repository to store your comments. Make sure you're repo's owner. Required.\n  client_id:                      # GitHub client ID. Required.\n  client_secret:                  # GitHub client secret. Required.\n  desc:                           # An optional description for your page, used in issue's body. Default ''.\n  perPage: 10                     # An optional number to which comments will be paginated. Default 20.\n  maxCommentHeight: 250           # An optional number to limit comments' max height, over which comments will be folded. Default 250.\n```\n\n#### Disqus\nIf you want use [Disqus](https://disqus.com/), you must have a circumvention (proxy, clime over the firewall) technology.\n```yml\n# Disqus settings\ndisqus_username: your-disqus-ID\n```\n\n\n### Analytics Settings\nHow to config analytics? -> Docs：[Analytics and Sitemap Settings](https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/)\n```yml\n# Analytics settings\n# Google Analytics\nga_track_id: UA-xxxxxx-xx   # Format: UA-xxxxxx-xx\n\n# Baidu Analytics\nba_track_id: ba_track_id\n```\n\n### Sitemap Settings\nHow to config sitemap? -> Docs：[Analytics and Sitemap Settings](https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/)\n```yml\n# Google sitemap\nsitemap:\n  path: sitemap.xml\n\n# Baidu sitemap\nbaidusitemap:\n  path: baidusitemap.xml\n\nbaidu_push: true\n```\n\n\n### Go to top icon Setup\nMy icon is using point, you can change to your own icon at `sourcre/css/images`.\n\n### Post tag\nYou can decide to show post tags or not.\n```yml\nhome_posts_tag: true\n```\nExample:\n\n![home_posts_tag-true](home_posts_tag-true.png)\n\n\n### Markdown render\nMy markdown render engine plugin is [hexo-renderer-markdown-it](https://github.com/celsomiranda/hexo-renderer-markdown-it).\n```yml\n# Markdown-it config\n## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki\nmarkdown:\n  render:\n    html: true\n    xhtmlOut: false\n    breaks: true\n    linkify: true\n    typographer: true\n    quotes: '“”‘’'\n```\n\n### Anchorjs Settings\nAnd if you want to change the header anchor '❡', you can go to `layout/_partial/anchorjs.ejs` to change it. How to use anchorjs, see [AnchorJS](https://www.bryanbraun.com/anchorjs/#examples) for detailed examples.\n```yml\n# Anchorjs Settings\nanchorjs: true    # if you want to customize anchor. check out line:26 of `anchorjs.ejs`\n```\n\n```javascript\nasync(\"//cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js\",function(){\n        anchors.options = {\n          visible: 'hover',\n          placement: 'left',\n          icon: '❡'\n          // icon: 'ℬ'\n        };\n        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');\n    })\n```\n\n### Article Top\n```yml\n# article top\ntop: true\n```\nHexo-theme-livemylife has added the article top function, just add `top: number` configuration to your markdown notes, articles are sorted by this number.\n\nExample:\n\n![top](top.png)\n\n### WordCount Settings\nA Word Count Plugin for Hexo. See [WordCount](https://github.com/willin/hexo-wordcount) for detailed configuration method.\n```yml\n# Dependencies: https://github.com/willin/hexo-wordcount\n# Docs: https://www.npmjs.com/package/hexo-wordcount\nwordcount: true\n```\n\n### Top scroll progress\n```yml\n# top scroll progress\nscroll: true\n```\n\n### Tip\n```yml\ntip:\n  enable: true\n  copyright: Say what you think...\n```\n\n### Social Share Post\n```yml\n#Docs: https://github.com/overtrue/share.js\nshare: true\n```\n\n### Viewer Config\nViewer is a simple jQuery image viewing plugin. Let us first look at a [demo](https://fengyuanchen.github.io/viewer/). See [Viewer](https://github.com/fengyuanchen/viewer) for detailed configuration. If you want to modify the [options](https://github.com/fengyuanchen/viewerjs#options) of Viewer, you can go to `sourcre/js/viewer/pic-viewer.js` to change it.\n```yml\n# Viewer config\nviewer: true\n```\n\n### Theme Color Config\nHexo-Theme-LiveMyLife temporarily supports two themes color.\n```yml\nthemecolor: true\n```\nLight theme preview：\n![light theme](light.png)\n\nDark theme preview：\n![dark theme](dark.png)\n\n\n\n### Search Settings\n```yml\n# Dependencies: https://github.com/V-Vincen/hexo-generator-zip-search\nsearch:\n  enable: true\n  path: search.json\n  zipPath: search.flv\n  versionPath: searchVersion.json\n  field: post\n  # if auto, trigger search by changing input\n  # if manual, trigger search by pressing enter key or search button\n  trigger: auto\n  # show top n results per article, show all results by setting to -1\n  top_n_per_article: 1\n```\n\n### Gitter\nGitter is a chat and network platform that helps manage, develop and connect communities through messages, content and discovery. See [Gitter](https://gitter.im/) for detailed configuration method.\n```yml\n## Docs:https://gitter.im/?utm_source=left-menu-logo\n##\ngitter:\n  room: your-community/your-room\n```\n\n### Deployment\nReplace to your own repo!\n```yml\ndeploy:\n  type: git\n  repo: https://github.com/<yourAccount>/<repo> # or https://gitee.com/<yourAccount>/<repo>\n  branch: <your-branch>\n```\n\n## Hexo Basics\n\nSome hexo command:\n\n```bash\nhexo new post \"<post name>\"   # you can change post to another layout if you want\nhexo clean && hexo generate   # generate the static file\nhexo server   # run hexo in local environment\nhexo deploy   # hexo will push the static files automatically into the specific branch(gh-pages) of your repo!\n```\n\n## Have fun ^\\_^\n\nPlease [Star](https://github.com/V-Vincen/hexo-theme-livemylife) this Project if you like it! [Follow](https://github.com/V-Vincen) would also be appreciated! Peace!\n","slug":"Hexo-Theme-LiveMyLife","published":1,"updated":"2022-01-13T09:01:13.267Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxwt00093oue2u0t5fqh","content":"<blockquote>\n<p>Ported Theme of <a href=\"https://github.com/Huxpro/huxpro.github.io\">Hux Blog</a>, Thank <a href=\"https://github.com/Huxpro\">Huxpro</a> for designing such a flawless theme.</p>\n<p>This LiveMyLife theme created by <a href=\"https://v-vincen.github.io/\">Vincent</a> modified from the original Porter <a href=\"https://github.com/YenYuHsuan/hexo-theme-beantech\">YenYuHsuan</a> , refer to the Themes of <a href=\"https://github.com/dusign/hexo-theme-snail\">dusign</a>、<a href=\"https://github.com/shixiaohu2206/hexo-theme-huhu\">Utone</a>, Thanks <a href=\"https://github.com/dusign/hexo-theme-snail\">dusign</a>、<a href=\"https://github.com/shixiaohu2206/hexo-theme-huhu\">Utone</a>.</p>\n</blockquote>\n<h2 id=\"Repo\"><a href=\"#Repo\" class=\"headerlink\" title=\"Repo\"></a>Repo</h2><p>Github Repo: <a href=\"https://github.com/V-Vincen/hexo-theme-livemylife\">https://github.com/V-Vincen/hexo-theme-livemylife</a></p>\n<p>Gitee Repo: <a href=\"https://gitee.com/V_Vincen/hexo-theme-livemylife\">https://gitee.com/V_Vincen/hexo-theme-livemylife</a></p>\n<h2 id=\"View-Live-LiveMyLife-Blog-→\"><a href=\"#View-Live-LiveMyLife-Blog-→\" class=\"headerlink\" title=\"View Live LiveMyLife Blog →\"></a><a href=\"https://v-vincen.github.io/\">View Live LiveMyLife Blog →</a></h2><p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/livemylife-desktop.png\" alt=\"LiveMyLife Desktop\"></p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><p>I publish the whole project for your convenience, so you can just follow the instruction down below, then you can easily customiz your own blog!</p>\n<p>Let’s begin!!!</p>\n<h3 id=\"Install-Node-js-and-Git\"><a href=\"#Install-Node-js-and-Git\" class=\"headerlink\" title=\"Install Node.js and Git\"></a>Install Node.js and Git</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">For Mac</span></span><br><span class=\"line\">brew install node</span><br><span class=\"line\">brew install git</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Windows: Download &amp; install Node.js. -&gt; <a href=\"https://nodejs.org/zh-cn/download/\">Node.js</a></p>\n<p>Windows: Download &amp; install Git. -&gt; <a href=\"https://git-scm.com/download/win\">Git</a></p>\n</blockquote>\n<h3 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> npm install -g hexo-cli</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>What is <a href=\"https://hexo.io/docs/\">Hexo</a>?</p>\n<p>Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other markup languages) and Hexo generates static files with a beautiful theme in seconds.</p>\n</blockquote>\n<h3 id=\"Setup-your-blog\"><a href=\"#Setup-your-blog\" class=\"headerlink\" title=\"Setup your blog\"></a>Setup your blog</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> hexo init blog</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>More Commands -&gt; <a href=\"https://hexo.io/docs/commands\">Hexo Commands</a></p>\n</blockquote>\n<h2 id=\"Theme-Usage\"><a href=\"#Theme-Usage\" class=\"headerlink\" title=\"Theme Usage\"></a>Theme Usage</h2><h3 id=\"Init\"><a href=\"#Init\" class=\"headerlink\" title=\"Init\"></a>Init</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd bolg</span><br><span class=\"line\">rm -rf _config.yml package.json scaffolds source themes yarn.lock #just keep node_modules</span><br><span class=\"line\">git clone https://github.com/V-Vincen/hexo-theme-livemylife.git</span><br><span class=\"line\">mv hexo-theme-livemylife/* ./</span><br><span class=\"line\">rm -rf hexo-theme-livemylife</span><br><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n<h3 id=\"Set-Theme\"><a href=\"#Set-Theme\" class=\"headerlink\" title=\"Set Theme\"></a>Set Theme</h3><p>Modify the value of <code>theme</code>: in <code>_config.yml</code><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Extensions</span></span><br><span class=\"line\"><span class=\"comment\">## Themes: https://hexo.io/themes/</span></span><br><span class=\"line\"><span class=\"comment\">## Plugins: https://hexo.io/plugins/</span></span><br><span class=\"line\"><span class=\"attr\">theme:</span> <span class=\"string\">livemylife</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Start-the-Server\"><a href=\"#Start-the-Server\" class=\"headerlink\" title=\"Start the Server\"></a>Start the Server</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo generate # or hexo g</span><br><span class=\"line\">hexo server   # or hexo s</span><br></pre></td></tr></table></figure>\n<p>Starts a local server. By default, this is at <code>http://localhost:4000/</code>.</p>\n<blockquote>\n<p>More Commands -&gt; <a href=\"https://hexo.io/docs/commands\">Hexo Commands</a></p>\n</blockquote>\n<h2 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h2><p>Modify <code>_config.yml</code> file with your own info, Especially the section:</p>\n<h3 id=\"Site\"><a href=\"#Site\" class=\"headerlink\" title=\"Site\"></a>Site</h3><p>Replace the following information with your own.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Site</span></span><br><span class=\"line\"><span class=\"attr\">title:</span> <span class=\"string\">Live</span> <span class=\"string\">My</span> <span class=\"string\">Life</span></span><br><span class=\"line\"><span class=\"attr\">subtitle:</span> <span class=\"string\">淡而无味也是一种味道</span></span><br><span class=\"line\"><span class=\"attr\">author:</span> <span class=\"string\">Mr.Vincent</span></span><br><span class=\"line\"><span class=\"attr\">language:</span> <span class=\"string\">zh-CN</span></span><br><span class=\"line\"><span class=\"attr\">timezone:</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"CDN-Settings\"><a href=\"#CDN-Settings\" class=\"headerlink\" title=\"CDN Settings\"></a>CDN Settings</h3><p>JsDelivr is A free CDN for Open Source fast、reliable and automated. If Github Pages deploy，you can config CDN settings. The images of the Hexo-theme-livemylife has added JsDelivr CDN Setting. How to use Jsdelivr? -&gt; Docs：<a href=\"https://v-vincen.github.io/2020/07/15/Github-%E5%8A%A0%E9%80%9F%E4%BC%98%E5%8C%96/#%E5%85%8D%E8%B4%B9-CDN-%E6%8F%90%E9%80%9F-Github-%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE\">免费 CDN 提速 Github 静态资源访问</a><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CDN Setting</span></span><br><span class=\"line\"><span class=\"comment\"># Docs: https://www.jsdelivr.com/?docs=gh</span></span><br><span class=\"line\"><span class=\"comment\"># If Github Pages deploy，you can ues jsdelivr settings</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"attr\">jsdelivr:</span></span><br><span class=\"line\">  <span class=\"attr\">jsdelivr_url:</span> <span class=\"string\">https://cdn.jsdelivr.net/gh/</span></span><br><span class=\"line\">  <span class=\"attr\">github_username:</span> <span class=\"string\">V-Vincen</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Site-Settings\"><a href=\"#Site-Settings\" class=\"headerlink\" title=\"Site Settings\"></a>Site Settings</h3><p>Put customized pictures in img directory.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Site settings</span></span><br><span class=\"line\"><span class=\"attr\">SEOTitle:</span> <span class=\"string\">JavaDev</span> <span class=\"string\">|</span> <span class=\"string\">一如Java深似海</span></span><br><span class=\"line\"><span class=\"attr\">email:</span> <span class=\"string\">hexo-theme-livemylife@mail.com</span></span><br><span class=\"line\"><span class=\"attr\">description:</span> <span class=\"string\">&quot;It&#x27;s an IT blog...&quot;</span></span><br><span class=\"line\"><span class=\"attr\">keyword:</span> <span class=\"string\">&quot;Java,v-vincen,v-vincen,livemylife,IT  blog,Blog&quot;</span></span><br><span class=\"line\"><span class=\"attr\">header-img:</span> <span class=\"string\">img/header_img/newhome_bg.jpg</span></span><br><span class=\"line\"><span class=\"attr\">archives-img:</span> <span class=\"string\">img/header_img/archive_bg2.jpg</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Favicon-Settings\"><a href=\"#Favicon-Settings\" class=\"headerlink\" title=\"Favicon Settings\"></a>Favicon Settings</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">favicon:</span> <span class=\"string\">img/avatar/favicon.jpg</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Signature-Settings\"><a href=\"#Signature-Settings\" class=\"headerlink\" title=\"Signature Settings\"></a>Signature Settings</h3><p>Copy your signature image to <code>&lt;root&gt;/img/signature</code> and modify the <code>_config.yml</code>.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">signature:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># show signature</span></span><br><span class=\"line\"><span class=\"attr\">signature-img:</span> <span class=\"string\">img/signature/&lt;your-signature&gt;</span></span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>How to create signature -&gt; <a href=\"https://fontmeme.com/signature-fonts/\">Free Online Signature</a></p>\n</blockquote>\n<h3 id=\"Wave-Settings\"><a href=\"#Wave-Settings\" class=\"headerlink\" title=\"Wave Settings\"></a>Wave Settings</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Wave settings</span></span><br><span class=\"line\"><span class=\"attr\">wave:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>Example:</p>\n<p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/wave.png\" alt=\"wave\"></p>\n<h3 id=\"SNS-Settings\"><a href=\"#SNS-Settings\" class=\"headerlink\" title=\"SNS Settings\"></a>SNS Settings</h3><p>If you don’t want to display it, you can delete it directly.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># SNS settings</span></span><br><span class=\"line\"><span class=\"comment\"># RSS: true</span></span><br><span class=\"line\"><span class=\"attr\">github_username:</span> <span class=\"string\">V-Vincen</span></span><br><span class=\"line\"><span class=\"attr\">twitter_username:</span> <span class=\"string\">V_Vincen_</span></span><br><span class=\"line\"><span class=\"attr\">instagram_username:</span> <span class=\"string\">V_Vincen_</span></span><br><span class=\"line\"><span class=\"comment\"># facebook_username:  yourAccount</span></span><br><span class=\"line\"><span class=\"comment\"># linkedin_username:  yourAccount</span></span><br><span class=\"line\"><span class=\"comment\"># zhihu_username: yourAccount</span></span><br><span class=\"line\"><span class=\"attr\">weibo_username:</span> <span class=\"string\">WVincen</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Sidebar-Settings\"><a href=\"#Sidebar-Settings\" class=\"headerlink\" title=\"Sidebar Settings\"></a>Sidebar Settings</h3><p>Copy your avatar image to <code>&lt;root&gt;/img/avatar</code> and modify the <code>_config.yml</code>:<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">sidebar:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># whether or not using Sidebar.</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-about-description:</span> <span class=\"string\">&quot;I don&#x27;t know where I am going ,but I am on my way...&quot;</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-avatar:</span> <span class=\"string\">img/avatar/vincnet.jpg</span>    <span class=\"comment\"># use absolute URL, seeing it&#x27;s used in both `/` and `/about/`</span></span><br><span class=\"line\"><span class=\"attr\">widgets:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">visitor</span>   <span class=\"comment\"># busuanzi: https://busuanzi.ibruce.info/</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">featured-tags</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">short-about</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">recent-posts</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">friends-blog</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">archive</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">category</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># widget behavior</span></span><br><span class=\"line\"><span class=\"comment\">## Archive</span></span><br><span class=\"line\"><span class=\"attr\">archive_type:</span> <span class=\"string\">&#x27;monthly&#x27;</span></span><br><span class=\"line\"><span class=\"attr\">show_count:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Featured Tags</span></span><br><span class=\"line\"><span class=\"attr\">featured-tags:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># whether or not using Feature-Tags</span></span><br><span class=\"line\"><span class=\"attr\">featured-condition-size:</span> <span class=\"number\">0</span>    <span class=\"comment\"># A tag will be featured if the size of it is more than this</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Friends</span></span><br><span class=\"line\"><span class=\"attr\">friends:</span> [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"attr\">title:</span> <span class=\"string\">&quot;V_Vincen&quot;</span>,</span><br><span class=\"line\">        <span class=\"attr\">href:</span> <span class=\"string\">&quot;https://v-vincen.life/&quot;</span></span><br><span class=\"line\">    &#125;,&#123;</span><br><span class=\"line\">        <span class=\"attr\">title:</span> <span class=\"string\">&quot;Teacher Ye&quot;</span>,</span><br><span class=\"line\">        <span class=\"attr\">href:</span> <span class=\"string\">&quot;http://teacherye.com/&quot;</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Comment-Settings\"><a href=\"#Comment-Settings\" class=\"headerlink\" title=\"Comment Settings\"></a>Comment Settings</h3><p>Hexo-Theme-LiveMyLife temporarily supports three Comments. I use gitalk comment system.</p>\n<h4 id=\"Gitalk\"><a href=\"#Gitalk\" class=\"headerlink\" title=\"Gitalk\"></a>Gitalk</h4><p>Gitalk is a modern comment component based on GitHub Issue and Preact. See <a href=\"https://github.com/gitalk/gitalk\">Gitalk</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Gitalk Settings</span></span><br><span class=\"line\"><span class=\"comment\"># Doc: https://github.com/gitalk/gitalk/blob/master/readme-cn.md</span></span><br><span class=\"line\"><span class=\"attr\">gitalk:</span></span><br><span class=\"line\">  <span class=\"attr\">owner:</span>                          <span class=\"comment\"># &#x27;GitHub repo owner&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">admin:</span>                          <span class=\"comment\"># &#x27;GitHub repo&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">repo:</span>                           <span class=\"comment\"># [&#x27;GitHub repo owner and collaborators, only these guys can initialize github issues&#x27;]</span></span><br><span class=\"line\">  <span class=\"attr\">clientID:</span>                       <span class=\"comment\"># &#x27;GitHub Application Client ID&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">clientSecret:</span>                   <span class=\"comment\"># &#x27;GitHub Application Client Secret&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">perPage:</span> <span class=\"number\">10</span>                     <span class=\"comment\"># Pagination size, with maximum 100.</span></span><br><span class=\"line\">  <span class=\"attr\">pagerDirection:</span> <span class=\"string\">last</span>            <span class=\"comment\"># Comment sorting direction, available values are last and first.</span></span><br><span class=\"line\">  <span class=\"attr\">createIssueManually:</span> <span class=\"literal\">false</span>      <span class=\"comment\"># By default, Gitalk will create a corresponding github issue for your every single page automatically when the logined user is belong to the admin users. You can create it manually by setting this option to true</span></span><br><span class=\"line\">  <span class=\"attr\">language:</span> <span class=\"string\">en</span>                    <span class=\"comment\"># Localization language key, en, zh-CN and zh-TW are currently available.</span></span><br><span class=\"line\">  <span class=\"attr\">maxCommentHeight:</span> <span class=\"number\">250</span>           <span class=\"comment\"># An optional number to limit comments&#x27; max height, over which comments will be folded.Default 250.</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"Gitment\"><a href=\"#Gitment\" class=\"headerlink\" title=\"Gitment\"></a>Gitment</h4><p>Gitment is a comment system based on GitHub Issues, which can be used in the frontend without any server-side implementation. See <a href=\"https://github.com/imsun/gitment\">Gitment</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## Gitment Settings</span></span><br><span class=\"line\"><span class=\"comment\">## Doc: https://github.com/imsun/gitment</span></span><br><span class=\"line\"><span class=\"attr\">gitment:</span></span><br><span class=\"line\">  <span class=\"attr\">owner:</span>                          <span class=\"comment\"># Your GitHub ID. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">repo:</span>                           <span class=\"comment\"># The repository to store your comments. Make sure you&#x27;re repo&#x27;s owner. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">client_id:</span>                      <span class=\"comment\"># GitHub client ID. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">client_secret:</span>                  <span class=\"comment\"># GitHub client secret. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">desc:</span>                           <span class=\"comment\"># An optional description for your page, used in issue&#x27;s body. Default &#x27;&#x27;.</span></span><br><span class=\"line\">  <span class=\"attr\">perPage:</span> <span class=\"number\">10</span>                     <span class=\"comment\"># An optional number to which comments will be paginated. Default 20.</span></span><br><span class=\"line\">  <span class=\"attr\">maxCommentHeight:</span> <span class=\"number\">250</span>           <span class=\"comment\"># An optional number to limit comments&#x27; max height, over which comments will be folded. Default 250.</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"Disqus\"><a href=\"#Disqus\" class=\"headerlink\" title=\"Disqus\"></a>Disqus</h4><p>If you want use <a href=\"https://disqus.com/\">Disqus</a>, you must have a circumvention (proxy, clime over the firewall) technology.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Disqus settings</span></span><br><span class=\"line\"><span class=\"attr\">disqus_username:</span> <span class=\"string\">your-disqus-ID</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Analytics-Settings\"><a href=\"#Analytics-Settings\" class=\"headerlink\" title=\"Analytics Settings\"></a>Analytics Settings</h3><p>How to config analytics? -&gt; Docs：<a href=\"https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/\">Analytics and Sitemap Settings</a><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Analytics settings</span></span><br><span class=\"line\"><span class=\"comment\"># Google Analytics</span></span><br><span class=\"line\"><span class=\"attr\">ga_track_id:</span> <span class=\"string\">UA-xxxxxx-xx</span>   <span class=\"comment\"># Format: UA-xxxxxx-xx</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Baidu Analytics</span></span><br><span class=\"line\"><span class=\"attr\">ba_track_id:</span> <span class=\"string\">ba_track_id</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Sitemap-Settings\"><a href=\"#Sitemap-Settings\" class=\"headerlink\" title=\"Sitemap Settings\"></a>Sitemap Settings</h3><p>How to config sitemap? -&gt; Docs：<a href=\"https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/\">Analytics and Sitemap Settings</a><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Google sitemap</span></span><br><span class=\"line\"><span class=\"attr\">sitemap:</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">sitemap.xml</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Baidu sitemap</span></span><br><span class=\"line\"><span class=\"attr\">baidusitemap:</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">baidusitemap.xml</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">baidu_push:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Go-to-top-icon-Setup\"><a href=\"#Go-to-top-icon-Setup\" class=\"headerlink\" title=\"Go to top icon Setup\"></a>Go to top icon Setup</h3><p>My icon is using point, you can change to your own icon at <code>sourcre/css/images</code>.</p>\n<h3 id=\"Post-tag\"><a href=\"#Post-tag\" class=\"headerlink\" title=\"Post tag\"></a>Post tag</h3><p>You can decide to show post tags or not.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">home_posts_tag:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure><br>Example:</p>\n<p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/home_posts_tag-true.png\" alt=\"home_posts_tag-true\"></p>\n<h3 id=\"Markdown-render\"><a href=\"#Markdown-render\" class=\"headerlink\" title=\"Markdown render\"></a>Markdown render</h3><p>My markdown render engine plugin is <a href=\"https://github.com/celsomiranda/hexo-renderer-markdown-it\">hexo-renderer-markdown-it</a>.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Markdown-it config</span></span><br><span class=\"line\"><span class=\"comment\">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class=\"line\"><span class=\"attr\">markdown:</span></span><br><span class=\"line\">  <span class=\"attr\">render:</span></span><br><span class=\"line\">    <span class=\"attr\">html:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">xhtmlOut:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">    <span class=\"attr\">breaks:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">linkify:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">typographer:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">quotes:</span> <span class=\"string\">&#x27;“”‘’&#x27;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Anchorjs-Settings\"><a href=\"#Anchorjs-Settings\" class=\"headerlink\" title=\"Anchorjs Settings\"></a>Anchorjs Settings</h3><p>And if you want to change the header anchor ‘❡’, you can go to <code>layout/_partial/anchorjs.ejs</code> to change it. How to use anchorjs, see <a href=\"https://www.bryanbraun.com/anchorjs/#examples\">AnchorJS</a> for detailed examples.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Anchorjs Settings</span></span><br><span class=\"line\"><span class=\"attr\">anchorjs:</span> <span class=\"literal\">true</span>    <span class=\"comment\"># if you want to customize anchor. check out line:26 of `anchorjs.ejs`</span></span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">async</span>(<span class=\"string\">&quot;//cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js&quot;</span>,<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">        anchors.options = &#123;</span><br><span class=\"line\">          visible: <span class=\"string\">&#x27;hover&#x27;</span>,</span><br><span class=\"line\">          placement: <span class=\"string\">&#x27;left&#x27;</span>,</span><br><span class=\"line\">          icon: <span class=\"string\">&#x27;❡&#x27;</span></span><br><span class=\"line\">          <span class=\"comment\">// icon: &#x27;ℬ&#x27;</span></span><br><span class=\"line\">        &#125;;</span><br><span class=\"line\">        anchors.add().remove(<span class=\"string\">&#x27;.intro-header h1&#x27;</span>).remove(<span class=\"string\">&#x27;.subheading&#x27;</span>).remove(<span class=\"string\">&#x27;.sidebar-container h5&#x27;</span>);</span><br><span class=\"line\">    &#125;)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Article-Top\"><a href=\"#Article-Top\" class=\"headerlink\" title=\"Article Top\"></a>Article Top</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># article top</span></span><br><span class=\"line\"><span class=\"attr\">top:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>Hexo-theme-livemylife has added the article top function, just add <code>top: number</code> configuration to your markdown notes, articles are sorted by this number.</p>\n<p>Example:</p>\n<p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/top.png\" alt=\"top\"></p>\n<h3 id=\"WordCount-Settings\"><a href=\"#WordCount-Settings\" class=\"headerlink\" title=\"WordCount Settings\"></a>WordCount Settings</h3><p>A Word Count Plugin for Hexo. See <a href=\"https://github.com/willin/hexo-wordcount\">WordCount</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Dependencies: https://github.com/willin/hexo-wordcount</span></span><br><span class=\"line\"><span class=\"comment\"># Docs: https://www.npmjs.com/package/hexo-wordcount</span></span><br><span class=\"line\"><span class=\"attr\">wordcount:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Top-scroll-progress\"><a href=\"#Top-scroll-progress\" class=\"headerlink\" title=\"Top scroll progress\"></a>Top scroll progress</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># top scroll progress</span></span><br><span class=\"line\"><span class=\"attr\">scroll:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Tip\"><a href=\"#Tip\" class=\"headerlink\" title=\"Tip\"></a>Tip</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">tip:</span></span><br><span class=\"line\">  <span class=\"attr\">enable:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">copyright:</span> <span class=\"string\">Say</span> <span class=\"string\">what</span> <span class=\"string\">you</span> <span class=\"string\">think...</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Social-Share-Post\"><a href=\"#Social-Share-Post\" class=\"headerlink\" title=\"Social Share Post\"></a>Social Share Post</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Docs: https://github.com/overtrue/share.js</span></span><br><span class=\"line\"><span class=\"attr\">share:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Viewer-Config\"><a href=\"#Viewer-Config\" class=\"headerlink\" title=\"Viewer Config\"></a>Viewer Config</h3><p>Viewer is a simple jQuery image viewing plugin. Let us first look at a <a href=\"https://fengyuanchen.github.io/viewer/\">demo</a>. See <a href=\"https://github.com/fengyuanchen/viewer\">Viewer</a> for detailed configuration. If you want to modify the <a href=\"https://github.com/fengyuanchen/viewerjs#options\">options</a> of Viewer, you can go to <code>sourcre/js/viewer/pic-viewer.js</code> to change it.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Viewer config</span></span><br><span class=\"line\"><span class=\"attr\">viewer:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Theme-Color-Config\"><a href=\"#Theme-Color-Config\" class=\"headerlink\" title=\"Theme Color Config\"></a>Theme Color Config</h3><p>Hexo-Theme-LiveMyLife temporarily supports two themes color.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">themecolor:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure><br>Light theme preview：<br><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/light.png\" alt=\"light theme\"></p>\n<p>Dark theme preview：<br><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/dark.png\" alt=\"dark theme\"></p>\n<h3 id=\"Search-Settings\"><a href=\"#Search-Settings\" class=\"headerlink\" title=\"Search Settings\"></a>Search Settings</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Dependencies: https://github.com/V-Vincen/hexo-generator-zip-search</span></span><br><span class=\"line\"><span class=\"attr\">search:</span></span><br><span class=\"line\">  <span class=\"attr\">enable:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">search.json</span></span><br><span class=\"line\">  <span class=\"attr\">zipPath:</span> <span class=\"string\">search.flv</span></span><br><span class=\"line\">  <span class=\"attr\">versionPath:</span> <span class=\"string\">searchVersion.json</span></span><br><span class=\"line\">  <span class=\"attr\">field:</span> <span class=\"string\">post</span></span><br><span class=\"line\">  <span class=\"comment\"># if auto, trigger search by changing input</span></span><br><span class=\"line\">  <span class=\"comment\"># if manual, trigger search by pressing enter key or search button</span></span><br><span class=\"line\">  <span class=\"attr\">trigger:</span> <span class=\"string\">auto</span></span><br><span class=\"line\">  <span class=\"comment\"># show top n results per article, show all results by setting to -1</span></span><br><span class=\"line\">  <span class=\"attr\">top_n_per_article:</span> <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Gitter\"><a href=\"#Gitter\" class=\"headerlink\" title=\"Gitter\"></a>Gitter</h3><p>Gitter is a chat and network platform that helps manage, develop and connect communities through messages, content and discovery. See <a href=\"https://gitter.im/\">Gitter</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## Docs:https://gitter.im/?utm_source=left-menu-logo</span></span><br><span class=\"line\"><span class=\"comment\">##</span></span><br><span class=\"line\"><span class=\"attr\">gitter:</span></span><br><span class=\"line\">  <span class=\"attr\">room:</span> <span class=\"string\">your-community/your-room</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><p>Replace to your own repo!<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">git</span></span><br><span class=\"line\">  <span class=\"attr\">repo:</span> <span class=\"string\">https://github.com/&lt;yourAccount&gt;/&lt;repo&gt;</span> <span class=\"comment\"># or https://gitee.com/&lt;yourAccount&gt;/&lt;repo&gt;</span></span><br><span class=\"line\">  <span class=\"attr\">branch:</span> <span class=\"string\">&lt;your-branch&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Hexo-Basics\"><a href=\"#Hexo-Basics\" class=\"headerlink\" title=\"Hexo Basics\"></a>Hexo Basics</h2><p>Some hexo command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new post <span class=\"string\">&quot;&lt;post name&gt;&quot;</span>   <span class=\"comment\"># you can change post to another layout if you want</span></span><br><span class=\"line\">hexo clean &amp;&amp; hexo generate   <span class=\"comment\"># generate the static file</span></span><br><span class=\"line\">hexo server   <span class=\"comment\"># run hexo in local environment</span></span><br><span class=\"line\">hexo deploy   <span class=\"comment\"># hexo will push the static files automatically into the specific branch(gh-pages) of your repo!</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Have-fun\"><a href=\"#Have-fun\" class=\"headerlink\" title=\"Have fun ^_^\"></a>Have fun ^_^</h2><p>Please <a href=\"https://github.com/V-Vincen/hexo-theme-livemylife\">Star</a> this Project if you like it! <a href=\"https://github.com/V-Vincen\">Follow</a> would also be appreciated! Peace!</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Ported Theme of <a href=\"https://github.com/Huxpro/huxpro.github.io\">Hux Blog</a>, Thank <a href=\"https://github.com/Huxpro\">Huxpro</a> for designing such a flawless theme.</p>\n<p>This LiveMyLife theme created by <a href=\"https://v-vincen.github.io/\">Vincent</a> modified from the original Porter <a href=\"https://github.com/YenYuHsuan/hexo-theme-beantech\">YenYuHsuan</a> , refer to the Themes of <a href=\"https://github.com/dusign/hexo-theme-snail\">dusign</a>、<a href=\"https://github.com/shixiaohu2206/hexo-theme-huhu\">Utone</a>, Thanks <a href=\"https://github.com/dusign/hexo-theme-snail\">dusign</a>、<a href=\"https://github.com/shixiaohu2206/hexo-theme-huhu\">Utone</a>.</p>\n</blockquote>\n<h2 id=\"Repo\"><a href=\"#Repo\" class=\"headerlink\" title=\"Repo\"></a>Repo</h2><p>Github Repo: <a href=\"https://github.com/V-Vincen/hexo-theme-livemylife\">https://github.com/V-Vincen/hexo-theme-livemylife</a></p>\n<p>Gitee Repo: <a href=\"https://gitee.com/V_Vincen/hexo-theme-livemylife\">https://gitee.com/V_Vincen/hexo-theme-livemylife</a></p>\n<h2 id=\"View-Live-LiveMyLife-Blog-→\"><a href=\"#View-Live-LiveMyLife-Blog-→\" class=\"headerlink\" title=\"View Live LiveMyLife Blog →\"></a><a href=\"https://v-vincen.github.io/\">View Live LiveMyLife Blog →</a></h2><p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/livemylife-desktop.png\" alt=\"LiveMyLife Desktop\"></p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><p>I publish the whole project for your convenience, so you can just follow the instruction down below, then you can easily customiz your own blog!</p>\n<p>Let’s begin!!!</p>\n<h3 id=\"Install-Node-js-and-Git\"><a href=\"#Install-Node-js-and-Git\" class=\"headerlink\" title=\"Install Node.js and Git\"></a>Install Node.js and Git</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">For Mac</span></span><br><span class=\"line\">brew install node</span><br><span class=\"line\">brew install git</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>Windows: Download &amp; install Node.js. -&gt; <a href=\"https://nodejs.org/zh-cn/download/\">Node.js</a></p>\n<p>Windows: Download &amp; install Git. -&gt; <a href=\"https://git-scm.com/download/win\">Git</a></p>\n</blockquote>\n<h3 id=\"Install-Hexo\"><a href=\"#Install-Hexo\" class=\"headerlink\" title=\"Install Hexo\"></a>Install Hexo</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> npm install -g hexo-cli</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>What is <a href=\"https://hexo.io/docs/\">Hexo</a>?</p>\n<p>Hexo is a fast, simple and powerful blog framework. You write posts in Markdown (or other markup languages) and Hexo generates static files with a beautiful theme in seconds.</p>\n</blockquote>\n<h3 id=\"Setup-your-blog\"><a href=\"#Setup-your-blog\" class=\"headerlink\" title=\"Setup your blog\"></a>Setup your blog</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> hexo init blog</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>More Commands -&gt; <a href=\"https://hexo.io/docs/commands\">Hexo Commands</a></p>\n</blockquote>\n<h2 id=\"Theme-Usage\"><a href=\"#Theme-Usage\" class=\"headerlink\" title=\"Theme Usage\"></a>Theme Usage</h2><h3 id=\"Init\"><a href=\"#Init\" class=\"headerlink\" title=\"Init\"></a>Init</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd bolg</span><br><span class=\"line\">rm -rf _config.yml package.json scaffolds source themes yarn.lock #just keep node_modules</span><br><span class=\"line\">git clone https://github.com/V-Vincen/hexo-theme-livemylife.git</span><br><span class=\"line\">mv hexo-theme-livemylife/* ./</span><br><span class=\"line\">rm -rf hexo-theme-livemylife</span><br><span class=\"line\">npm install</span><br></pre></td></tr></table></figure>\n<h3 id=\"Set-Theme\"><a href=\"#Set-Theme\" class=\"headerlink\" title=\"Set Theme\"></a>Set Theme</h3><p>Modify the value of <code>theme</code>: in <code>_config.yml</code><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Extensions</span></span><br><span class=\"line\"><span class=\"comment\">## Themes: https://hexo.io/themes/</span></span><br><span class=\"line\"><span class=\"comment\">## Plugins: https://hexo.io/plugins/</span></span><br><span class=\"line\"><span class=\"attr\">theme:</span> <span class=\"string\">livemylife</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Start-the-Server\"><a href=\"#Start-the-Server\" class=\"headerlink\" title=\"Start the Server\"></a>Start the Server</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo generate # or hexo g</span><br><span class=\"line\">hexo server   # or hexo s</span><br></pre></td></tr></table></figure>\n<p>Starts a local server. By default, this is at <code>http://localhost:4000/</code>.</p>\n<blockquote>\n<p>More Commands -&gt; <a href=\"https://hexo.io/docs/commands\">Hexo Commands</a></p>\n</blockquote>\n<h2 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h2><p>Modify <code>_config.yml</code> file with your own info, Especially the section:</p>\n<h3 id=\"Site\"><a href=\"#Site\" class=\"headerlink\" title=\"Site\"></a>Site</h3><p>Replace the following information with your own.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Site</span></span><br><span class=\"line\"><span class=\"attr\">title:</span> <span class=\"string\">Live</span> <span class=\"string\">My</span> <span class=\"string\">Life</span></span><br><span class=\"line\"><span class=\"attr\">subtitle:</span> <span class=\"string\">淡而无味也是一种味道</span></span><br><span class=\"line\"><span class=\"attr\">author:</span> <span class=\"string\">Mr.Vincent</span></span><br><span class=\"line\"><span class=\"attr\">language:</span> <span class=\"string\">zh-CN</span></span><br><span class=\"line\"><span class=\"attr\">timezone:</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"CDN-Settings\"><a href=\"#CDN-Settings\" class=\"headerlink\" title=\"CDN Settings\"></a>CDN Settings</h3><p>JsDelivr is A free CDN for Open Source fast、reliable and automated. If Github Pages deploy，you can config CDN settings. The images of the Hexo-theme-livemylife has added JsDelivr CDN Setting. How to use Jsdelivr? -&gt; Docs：<a href=\"https://v-vincen.github.io/2020/07/15/Github-%E5%8A%A0%E9%80%9F%E4%BC%98%E5%8C%96/#%E5%85%8D%E8%B4%B9-CDN-%E6%8F%90%E9%80%9F-Github-%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E8%AE%BF%E9%97%AE\">免费 CDN 提速 Github 静态资源访问</a><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># CDN Setting</span></span><br><span class=\"line\"><span class=\"comment\"># Docs: https://www.jsdelivr.com/?docs=gh</span></span><br><span class=\"line\"><span class=\"comment\"># If Github Pages deploy，you can ues jsdelivr settings</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"attr\">jsdelivr:</span></span><br><span class=\"line\">  <span class=\"attr\">jsdelivr_url:</span> <span class=\"string\">https://cdn.jsdelivr.net/gh/</span></span><br><span class=\"line\">  <span class=\"attr\">github_username:</span> <span class=\"string\">V-Vincen</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Site-Settings\"><a href=\"#Site-Settings\" class=\"headerlink\" title=\"Site Settings\"></a>Site Settings</h3><p>Put customized pictures in img directory.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Site settings</span></span><br><span class=\"line\"><span class=\"attr\">SEOTitle:</span> <span class=\"string\">JavaDev</span> <span class=\"string\">|</span> <span class=\"string\">一如Java深似海</span></span><br><span class=\"line\"><span class=\"attr\">email:</span> <span class=\"string\">hexo-theme-livemylife@mail.com</span></span><br><span class=\"line\"><span class=\"attr\">description:</span> <span class=\"string\">&quot;It&#x27;s an IT blog...&quot;</span></span><br><span class=\"line\"><span class=\"attr\">keyword:</span> <span class=\"string\">&quot;Java,v-vincen,v-vincen,livemylife,IT  blog,Blog&quot;</span></span><br><span class=\"line\"><span class=\"attr\">header-img:</span> <span class=\"string\">img/header_img/newhome_bg.jpg</span></span><br><span class=\"line\"><span class=\"attr\">archives-img:</span> <span class=\"string\">img/header_img/archive_bg2.jpg</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Favicon-Settings\"><a href=\"#Favicon-Settings\" class=\"headerlink\" title=\"Favicon Settings\"></a>Favicon Settings</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">favicon:</span> <span class=\"string\">img/avatar/favicon.jpg</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Signature-Settings\"><a href=\"#Signature-Settings\" class=\"headerlink\" title=\"Signature Settings\"></a>Signature Settings</h3><p>Copy your signature image to <code>&lt;root&gt;/img/signature</code> and modify the <code>_config.yml</code>.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">signature:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># show signature</span></span><br><span class=\"line\"><span class=\"attr\">signature-img:</span> <span class=\"string\">img/signature/&lt;your-signature&gt;</span></span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<p>How to create signature -&gt; <a href=\"https://fontmeme.com/signature-fonts/\">Free Online Signature</a></p>\n</blockquote>\n<h3 id=\"Wave-Settings\"><a href=\"#Wave-Settings\" class=\"headerlink\" title=\"Wave Settings\"></a>Wave Settings</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Wave settings</span></span><br><span class=\"line\"><span class=\"attr\">wave:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>Example:</p>\n<p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/wave.png\" alt=\"wave\"></p>\n<h3 id=\"SNS-Settings\"><a href=\"#SNS-Settings\" class=\"headerlink\" title=\"SNS Settings\"></a>SNS Settings</h3><p>If you don’t want to display it, you can delete it directly.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># SNS settings</span></span><br><span class=\"line\"><span class=\"comment\"># RSS: true</span></span><br><span class=\"line\"><span class=\"attr\">github_username:</span> <span class=\"string\">V-Vincen</span></span><br><span class=\"line\"><span class=\"attr\">twitter_username:</span> <span class=\"string\">V_Vincen_</span></span><br><span class=\"line\"><span class=\"attr\">instagram_username:</span> <span class=\"string\">V_Vincen_</span></span><br><span class=\"line\"><span class=\"comment\"># facebook_username:  yourAccount</span></span><br><span class=\"line\"><span class=\"comment\"># linkedin_username:  yourAccount</span></span><br><span class=\"line\"><span class=\"comment\"># zhihu_username: yourAccount</span></span><br><span class=\"line\"><span class=\"attr\">weibo_username:</span> <span class=\"string\">WVincen</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Sidebar-Settings\"><a href=\"#Sidebar-Settings\" class=\"headerlink\" title=\"Sidebar Settings\"></a>Sidebar Settings</h3><p>Copy your avatar image to <code>&lt;root&gt;/img/avatar</code> and modify the <code>_config.yml</code>:<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">sidebar:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># whether or not using Sidebar.</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-about-description:</span> <span class=\"string\">&quot;I don&#x27;t know where I am going ,but I am on my way...&quot;</span></span><br><span class=\"line\"><span class=\"attr\">sidebar-avatar:</span> <span class=\"string\">img/avatar/vincnet.jpg</span>    <span class=\"comment\"># use absolute URL, seeing it&#x27;s used in both `/` and `/about/`</span></span><br><span class=\"line\"><span class=\"attr\">widgets:</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">visitor</span>   <span class=\"comment\"># busuanzi: https://busuanzi.ibruce.info/</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">featured-tags</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">short-about</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">recent-posts</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">friends-blog</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">archive</span></span><br><span class=\"line\"><span class=\"bullet\">-</span> <span class=\"string\">category</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># widget behavior</span></span><br><span class=\"line\"><span class=\"comment\">## Archive</span></span><br><span class=\"line\"><span class=\"attr\">archive_type:</span> <span class=\"string\">&#x27;monthly&#x27;</span></span><br><span class=\"line\"><span class=\"attr\">show_count:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Featured Tags</span></span><br><span class=\"line\"><span class=\"attr\">featured-tags:</span> <span class=\"literal\">true</span>   <span class=\"comment\"># whether or not using Feature-Tags</span></span><br><span class=\"line\"><span class=\"attr\">featured-condition-size:</span> <span class=\"number\">0</span>    <span class=\"comment\"># A tag will be featured if the size of it is more than this</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">## Friends</span></span><br><span class=\"line\"><span class=\"attr\">friends:</span> [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"attr\">title:</span> <span class=\"string\">&quot;V_Vincen&quot;</span>,</span><br><span class=\"line\">        <span class=\"attr\">href:</span> <span class=\"string\">&quot;https://v-vincen.life/&quot;</span></span><br><span class=\"line\">    &#125;,&#123;</span><br><span class=\"line\">        <span class=\"attr\">title:</span> <span class=\"string\">&quot;Teacher Ye&quot;</span>,</span><br><span class=\"line\">        <span class=\"attr\">href:</span> <span class=\"string\">&quot;http://teacherye.com/&quot;</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Comment-Settings\"><a href=\"#Comment-Settings\" class=\"headerlink\" title=\"Comment Settings\"></a>Comment Settings</h3><p>Hexo-Theme-LiveMyLife temporarily supports three Comments. I use gitalk comment system.</p>\n<h4 id=\"Gitalk\"><a href=\"#Gitalk\" class=\"headerlink\" title=\"Gitalk\"></a>Gitalk</h4><p>Gitalk is a modern comment component based on GitHub Issue and Preact. See <a href=\"https://github.com/gitalk/gitalk\">Gitalk</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Gitalk Settings</span></span><br><span class=\"line\"><span class=\"comment\"># Doc: https://github.com/gitalk/gitalk/blob/master/readme-cn.md</span></span><br><span class=\"line\"><span class=\"attr\">gitalk:</span></span><br><span class=\"line\">  <span class=\"attr\">owner:</span>                          <span class=\"comment\"># &#x27;GitHub repo owner&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">admin:</span>                          <span class=\"comment\"># &#x27;GitHub repo&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">repo:</span>                           <span class=\"comment\"># [&#x27;GitHub repo owner and collaborators, only these guys can initialize github issues&#x27;]</span></span><br><span class=\"line\">  <span class=\"attr\">clientID:</span>                       <span class=\"comment\"># &#x27;GitHub Application Client ID&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">clientSecret:</span>                   <span class=\"comment\"># &#x27;GitHub Application Client Secret&#x27;</span></span><br><span class=\"line\">  <span class=\"attr\">perPage:</span> <span class=\"number\">10</span>                     <span class=\"comment\"># Pagination size, with maximum 100.</span></span><br><span class=\"line\">  <span class=\"attr\">pagerDirection:</span> <span class=\"string\">last</span>            <span class=\"comment\"># Comment sorting direction, available values are last and first.</span></span><br><span class=\"line\">  <span class=\"attr\">createIssueManually:</span> <span class=\"literal\">false</span>      <span class=\"comment\"># By default, Gitalk will create a corresponding github issue for your every single page automatically when the logined user is belong to the admin users. You can create it manually by setting this option to true</span></span><br><span class=\"line\">  <span class=\"attr\">language:</span> <span class=\"string\">en</span>                    <span class=\"comment\"># Localization language key, en, zh-CN and zh-TW are currently available.</span></span><br><span class=\"line\">  <span class=\"attr\">maxCommentHeight:</span> <span class=\"number\">250</span>           <span class=\"comment\"># An optional number to limit comments&#x27; max height, over which comments will be folded.Default 250.</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"Gitment\"><a href=\"#Gitment\" class=\"headerlink\" title=\"Gitment\"></a>Gitment</h4><p>Gitment is a comment system based on GitHub Issues, which can be used in the frontend without any server-side implementation. See <a href=\"https://github.com/imsun/gitment\">Gitment</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## Gitment Settings</span></span><br><span class=\"line\"><span class=\"comment\">## Doc: https://github.com/imsun/gitment</span></span><br><span class=\"line\"><span class=\"attr\">gitment:</span></span><br><span class=\"line\">  <span class=\"attr\">owner:</span>                          <span class=\"comment\"># Your GitHub ID. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">repo:</span>                           <span class=\"comment\"># The repository to store your comments. Make sure you&#x27;re repo&#x27;s owner. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">client_id:</span>                      <span class=\"comment\"># GitHub client ID. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">client_secret:</span>                  <span class=\"comment\"># GitHub client secret. Required.</span></span><br><span class=\"line\">  <span class=\"attr\">desc:</span>                           <span class=\"comment\"># An optional description for your page, used in issue&#x27;s body. Default &#x27;&#x27;.</span></span><br><span class=\"line\">  <span class=\"attr\">perPage:</span> <span class=\"number\">10</span>                     <span class=\"comment\"># An optional number to which comments will be paginated. Default 20.</span></span><br><span class=\"line\">  <span class=\"attr\">maxCommentHeight:</span> <span class=\"number\">250</span>           <span class=\"comment\"># An optional number to limit comments&#x27; max height, over which comments will be folded. Default 250.</span></span><br></pre></td></tr></table></figure></p>\n<h4 id=\"Disqus\"><a href=\"#Disqus\" class=\"headerlink\" title=\"Disqus\"></a>Disqus</h4><p>If you want use <a href=\"https://disqus.com/\">Disqus</a>, you must have a circumvention (proxy, clime over the firewall) technology.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Disqus settings</span></span><br><span class=\"line\"><span class=\"attr\">disqus_username:</span> <span class=\"string\">your-disqus-ID</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Analytics-Settings\"><a href=\"#Analytics-Settings\" class=\"headerlink\" title=\"Analytics Settings\"></a>Analytics Settings</h3><p>How to config analytics? -&gt; Docs：<a href=\"https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/\">Analytics and Sitemap Settings</a><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Analytics settings</span></span><br><span class=\"line\"><span class=\"comment\"># Google Analytics</span></span><br><span class=\"line\"><span class=\"attr\">ga_track_id:</span> <span class=\"string\">UA-xxxxxx-xx</span>   <span class=\"comment\"># Format: UA-xxxxxx-xx</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Baidu Analytics</span></span><br><span class=\"line\"><span class=\"attr\">ba_track_id:</span> <span class=\"string\">ba_track_id</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Sitemap-Settings\"><a href=\"#Sitemap-Settings\" class=\"headerlink\" title=\"Sitemap Settings\"></a>Sitemap Settings</h3><p>How to config sitemap? -&gt; Docs：<a href=\"https://v-vincen.github.io/2020/07/21/Analytics-and-Sitemap-Settings/\">Analytics and Sitemap Settings</a><br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Google sitemap</span></span><br><span class=\"line\"><span class=\"attr\">sitemap:</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">sitemap.xml</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Baidu sitemap</span></span><br><span class=\"line\"><span class=\"attr\">baidusitemap:</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">baidusitemap.xml</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">baidu_push:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Go-to-top-icon-Setup\"><a href=\"#Go-to-top-icon-Setup\" class=\"headerlink\" title=\"Go to top icon Setup\"></a>Go to top icon Setup</h3><p>My icon is using point, you can change to your own icon at <code>sourcre/css/images</code>.</p>\n<h3 id=\"Post-tag\"><a href=\"#Post-tag\" class=\"headerlink\" title=\"Post tag\"></a>Post tag</h3><p>You can decide to show post tags or not.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">home_posts_tag:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure><br>Example:</p>\n<p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/home_posts_tag-true.png\" alt=\"home_posts_tag-true\"></p>\n<h3 id=\"Markdown-render\"><a href=\"#Markdown-render\" class=\"headerlink\" title=\"Markdown render\"></a>Markdown render</h3><p>My markdown render engine plugin is <a href=\"https://github.com/celsomiranda/hexo-renderer-markdown-it\">hexo-renderer-markdown-it</a>.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Markdown-it config</span></span><br><span class=\"line\"><span class=\"comment\">## Docs: https://github.com/celsomiranda/hexo-renderer-markdown-it/wiki</span></span><br><span class=\"line\"><span class=\"attr\">markdown:</span></span><br><span class=\"line\">  <span class=\"attr\">render:</span></span><br><span class=\"line\">    <span class=\"attr\">html:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">xhtmlOut:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">    <span class=\"attr\">breaks:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">linkify:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">typographer:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">    <span class=\"attr\">quotes:</span> <span class=\"string\">&#x27;“”‘’&#x27;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Anchorjs-Settings\"><a href=\"#Anchorjs-Settings\" class=\"headerlink\" title=\"Anchorjs Settings\"></a>Anchorjs Settings</h3><p>And if you want to change the header anchor ‘❡’, you can go to <code>layout/_partial/anchorjs.ejs</code> to change it. How to use anchorjs, see <a href=\"https://www.bryanbraun.com/anchorjs/#examples\">AnchorJS</a> for detailed examples.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Anchorjs Settings</span></span><br><span class=\"line\"><span class=\"attr\">anchorjs:</span> <span class=\"literal\">true</span>    <span class=\"comment\"># if you want to customize anchor. check out line:26 of `anchorjs.ejs`</span></span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">async</span>(<span class=\"string\">&quot;//cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js&quot;</span>,<span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\"></span>)</span>&#123;</span><br><span class=\"line\">        anchors.options = &#123;</span><br><span class=\"line\">          visible: <span class=\"string\">&#x27;hover&#x27;</span>,</span><br><span class=\"line\">          placement: <span class=\"string\">&#x27;left&#x27;</span>,</span><br><span class=\"line\">          icon: <span class=\"string\">&#x27;❡&#x27;</span></span><br><span class=\"line\">          <span class=\"comment\">// icon: &#x27;ℬ&#x27;</span></span><br><span class=\"line\">        &#125;;</span><br><span class=\"line\">        anchors.add().remove(<span class=\"string\">&#x27;.intro-header h1&#x27;</span>).remove(<span class=\"string\">&#x27;.subheading&#x27;</span>).remove(<span class=\"string\">&#x27;.sidebar-container h5&#x27;</span>);</span><br><span class=\"line\">    &#125;)</span><br></pre></td></tr></table></figure>\n<h3 id=\"Article-Top\"><a href=\"#Article-Top\" class=\"headerlink\" title=\"Article Top\"></a>Article Top</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># article top</span></span><br><span class=\"line\"><span class=\"attr\">top:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>Hexo-theme-livemylife has added the article top function, just add <code>top: number</code> configuration to your markdown notes, articles are sorted by this number.</p>\n<p>Example:</p>\n<p><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/top.png\" alt=\"top\"></p>\n<h3 id=\"WordCount-Settings\"><a href=\"#WordCount-Settings\" class=\"headerlink\" title=\"WordCount Settings\"></a>WordCount Settings</h3><p>A Word Count Plugin for Hexo. See <a href=\"https://github.com/willin/hexo-wordcount\">WordCount</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Dependencies: https://github.com/willin/hexo-wordcount</span></span><br><span class=\"line\"><span class=\"comment\"># Docs: https://www.npmjs.com/package/hexo-wordcount</span></span><br><span class=\"line\"><span class=\"attr\">wordcount:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Top-scroll-progress\"><a href=\"#Top-scroll-progress\" class=\"headerlink\" title=\"Top scroll progress\"></a>Top scroll progress</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># top scroll progress</span></span><br><span class=\"line\"><span class=\"attr\">scroll:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Tip\"><a href=\"#Tip\" class=\"headerlink\" title=\"Tip\"></a>Tip</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">tip:</span></span><br><span class=\"line\">  <span class=\"attr\">enable:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">copyright:</span> <span class=\"string\">Say</span> <span class=\"string\">what</span> <span class=\"string\">you</span> <span class=\"string\">think...</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Social-Share-Post\"><a href=\"#Social-Share-Post\" class=\"headerlink\" title=\"Social Share Post\"></a>Social Share Post</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#Docs: https://github.com/overtrue/share.js</span></span><br><span class=\"line\"><span class=\"attr\">share:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Viewer-Config\"><a href=\"#Viewer-Config\" class=\"headerlink\" title=\"Viewer Config\"></a>Viewer Config</h3><p>Viewer is a simple jQuery image viewing plugin. Let us first look at a <a href=\"https://fengyuanchen.github.io/viewer/\">demo</a>. See <a href=\"https://github.com/fengyuanchen/viewer\">Viewer</a> for detailed configuration. If you want to modify the <a href=\"https://github.com/fengyuanchen/viewerjs#options\">options</a> of Viewer, you can go to <code>sourcre/js/viewer/pic-viewer.js</code> to change it.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Viewer config</span></span><br><span class=\"line\"><span class=\"attr\">viewer:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Theme-Color-Config\"><a href=\"#Theme-Color-Config\" class=\"headerlink\" title=\"Theme Color Config\"></a>Theme Color Config</h3><p>Hexo-Theme-LiveMyLife temporarily supports two themes color.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">themecolor:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure><br>Light theme preview：<br><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/light.png\" alt=\"light theme\"></p>\n<p>Dark theme preview：<br><img src=\"/2020/04/17/Hexo-Theme-LiveMyLife/dark.png\" alt=\"dark theme\"></p>\n<h3 id=\"Search-Settings\"><a href=\"#Search-Settings\" class=\"headerlink\" title=\"Search Settings\"></a>Search Settings</h3><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Dependencies: https://github.com/V-Vincen/hexo-generator-zip-search</span></span><br><span class=\"line\"><span class=\"attr\">search:</span></span><br><span class=\"line\">  <span class=\"attr\">enable:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"attr\">path:</span> <span class=\"string\">search.json</span></span><br><span class=\"line\">  <span class=\"attr\">zipPath:</span> <span class=\"string\">search.flv</span></span><br><span class=\"line\">  <span class=\"attr\">versionPath:</span> <span class=\"string\">searchVersion.json</span></span><br><span class=\"line\">  <span class=\"attr\">field:</span> <span class=\"string\">post</span></span><br><span class=\"line\">  <span class=\"comment\"># if auto, trigger search by changing input</span></span><br><span class=\"line\">  <span class=\"comment\"># if manual, trigger search by pressing enter key or search button</span></span><br><span class=\"line\">  <span class=\"attr\">trigger:</span> <span class=\"string\">auto</span></span><br><span class=\"line\">  <span class=\"comment\"># show top n results per article, show all results by setting to -1</span></span><br><span class=\"line\">  <span class=\"attr\">top_n_per_article:</span> <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"Gitter\"><a href=\"#Gitter\" class=\"headerlink\" title=\"Gitter\"></a>Gitter</h3><p>Gitter is a chat and network platform that helps manage, develop and connect communities through messages, content and discovery. See <a href=\"https://gitter.im/\">Gitter</a> for detailed configuration method.<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">## Docs:https://gitter.im/?utm_source=left-menu-logo</span></span><br><span class=\"line\"><span class=\"comment\">##</span></span><br><span class=\"line\"><span class=\"attr\">gitter:</span></span><br><span class=\"line\">  <span class=\"attr\">room:</span> <span class=\"string\">your-community/your-room</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Deployment\"><a href=\"#Deployment\" class=\"headerlink\" title=\"Deployment\"></a>Deployment</h3><p>Replace to your own repo!<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">git</span></span><br><span class=\"line\">  <span class=\"attr\">repo:</span> <span class=\"string\">https://github.com/&lt;yourAccount&gt;/&lt;repo&gt;</span> <span class=\"comment\"># or https://gitee.com/&lt;yourAccount&gt;/&lt;repo&gt;</span></span><br><span class=\"line\">  <span class=\"attr\">branch:</span> <span class=\"string\">&lt;your-branch&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Hexo-Basics\"><a href=\"#Hexo-Basics\" class=\"headerlink\" title=\"Hexo Basics\"></a>Hexo Basics</h2><p>Some hexo command:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo new post <span class=\"string\">&quot;&lt;post name&gt;&quot;</span>   <span class=\"comment\"># you can change post to another layout if you want</span></span><br><span class=\"line\">hexo clean &amp;&amp; hexo generate   <span class=\"comment\"># generate the static file</span></span><br><span class=\"line\">hexo server   <span class=\"comment\"># run hexo in local environment</span></span><br><span class=\"line\">hexo deploy   <span class=\"comment\"># hexo will push the static files automatically into the specific branch(gh-pages) of your repo!</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"Have-fun\"><a href=\"#Have-fun\" class=\"headerlink\" title=\"Have fun ^_^\"></a>Have fun ^_^</h2><p>Please <a href=\"https://github.com/V-Vincen/hexo-theme-livemylife\">Star</a> this Project if you like it! <a href=\"https://github.com/V-Vincen\">Follow</a> would also be appreciated! Peace!</p>\n"},{"title":"关于使用Vercel和hexo搭建个人主页","catalog":true,"date":"2021-01-28T14:43:32.000Z","subtitle":"一篇从零开始的搭站博客","top":6,"header-img":"/img/header_img/6.jpg","_content":"\n> 在江安校区商业街的倒数声中跨过了2020年，新年伊始之际，想着作为未来的一个程序猿，也得需要有一个博客来记录下自己那些杂七杂八的想法了，于是在寒假中旬开始实现了搭建个人主页的任务。\n\n## 前言\n\n上学期在VR实验室的时候，在周哥的指导下，翻阅了相当一部分人的个人主页，还是蛮羡慕身边的很多大佬都有着自己的网站，展示和收集着自己过去的很多经历。但我本人又是一个非常懒的货，之前的弄的公众号便在热火朝天的开始之后没了声音，想坚持做一件事是真不容易。希望未来的日子里能够慢慢地为自己的网站添砖加瓦吧，孩子这一次一定能坚持下去555 。\n\n## 关于要使用的一些软件和工具\n\n* Git：无论是更新Github库还是嫖资源都需要使用的软件。\n\n* Vercel：Vercel 提供了一个云平台，可以优化整个项目开发和部署体验，它有很强大的功能值得去探索，个人使用是免费的，提供了域名，使用方便快捷。在本文中，我将域名换成了自己在阿里云上购买的域名。\n\n* Github账号：自己的代码库和嫖别人的代码库，*GitHub*是一个面向开源及私有软件项目的托管平台，因为只支持Git作为唯一的版本库格式进行托管。\n\n* Nodejs：因为 Hexo 需要 Nodejs 支持的、生成的，所以这是前置步骤。\n\n* 阿里云账号：购买域名\n* Hexo框架\n\n简单解释一下个人主页的运行流程：\n\nNodejs，npm和hexo框架的安装是进行博客开发的基础条件。\n\nGithub账号是通用的账号，而Git可以对Github上的资源进行操作，而我们的个人主页的所有代码(包括文章内容)便放在Github的仓库里，每一次我们想更新个人主页的内容就需要更新Github仓库里的代码。\n\nGithub.io是由github pages提供的服务，也就是可以在github pages上建立你自己的博客。但是由于是国外的，你懂，访问速度很慢。于是便引入了vercel，通过vercel与Github账号绑定，我们可以用vercel来建立自己的博客，访问速度会得到大幅度地提升。vercel会提供免费的域名，但是这个域名反正我个人不会用哈哈，于是便有了在阿里云官网上买域名这么一项操作，在vercel官网的操作中，会把买到的域名与免费的域名进行绑定，从而可以通过买的域名访问我们的个人主页。\n\n## 搭建过程\n\n### Git的安装和与GitHub账号的绑定\n\nGit安装网址：https://git-scm.com/download/win\n\nGithub官网：https://github.com/\n\n如何注册Github账号和进行一些基本操作参考：https://blog.csdn.net/qq_41782425/article/details/85179912\n\n注意：在Github填写邮箱信息的时候一定要使用非qq邮箱的其他邮箱，要不注册不了vercel的账户。\n\nGit安装流程以及与Github账号绑定参考：\n\nhttps://blog.csdn.net/huangqqdy/article/details/83032408?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\n\n### Nodejs和hexo框架的安装\n\n这部分推荐参考博客：https://www.cnblogs.com/qinghan123/p/14019115.html\n\n* 安装nodejs\n\n下载 nodejs：https://nodejs.org/en/\n\n![1](关于使用Vercel和hexo搭建个人主页/1.png)\n\n选择左边右边的安装都行，一直点默认就行。安装完以后会有两个组件：1.是 npm 包管理器；2.是 Nodejs 本身。\n\n查看 node 的版本：\n\n```\nnode -v\n```\n\n查看 npm 包管理器的版本：\n\n```\nnpm -v\n```\n\n* 安装hexo框架\n\n需借助 npm 包管理器来安装。因为国内安装镜像源很慢，所以利用 npm 安装 cnpm。我们选择使用淘宝链接安装比较快：\n\n```\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\n```\n\n查看 cnpm 管理器的版本：\n\n```\ncnpm -v\n```\n\n安装hexo：\n\n```\ncnpm install -g hexo-cli\n```\n\n验证hexo是否安装成功和查看hexo版本：\n\n```\nhexo -v\n```\n\n如果出现以下模样，那么恭喜你hexo安装成功。\n\n![2](关于使用Vercel和hexo搭建个人主页/2.png)\n\n### 使用vercel搭建个人网站\n\n推荐博客：https://blog.csdn.net/Aixiu1016/article/details/112356387\n\n以下描述很多话是直接复制粘贴的哈，原博主写得很到位。\n\n1. 在 Vercel 官网（https://vercel.com/）注册一个新账户，注册新用户最好使用 Github的账户，并绑定手机号。注册完成后，可以在配置页面修改自己的邮箱地址。这里建议使用 Github 进行授权登陆，后续可以选择 Github 上的项目直接部署也会很方便的。\n\n   ![3](关于使用Vercel和hexo搭建个人主页/3.png)\n\n2. 之后你就可以登录系统看到自己的一些东西啦。myblog是我搭载个人网站的项目，这里可以看到的是已经与我购买的域名绑定了，也就是：binbining.com，在这之前你看到你新建的项目都应该是xxxxxxxxx.app这样的域名。\n\n![4](关于使用Vercel和hexo搭建个人主页/4.png)\n\n3. 接下来一步就是创建你自己的项目，在上图右上角我们可以看到New Project这个选项，点击右下角这个Browsw All Templates你可以看到很多很多的模板，从里面选择hexo模型，也就是我们需要的模板。\n\n![5](关于使用Vercel和hexo搭建个人主页/5.png)\n\n![6](关于使用Vercel和hexo搭建个人主页/6.png)\n\n4. 选择模版后，进入创建项目位置选择，目前团队项目是需要专业版的，是需要收费的，选择个人，点击`PERSONAL ACCOUNT`后面的 select 按钮。\n\n![7](关于使用Vercel和hexo搭建个人主页/7.png)\n\n5. 这里可以选择使用什么仓库保存自己的代码，当然我们选择Github。\n\n![8](关于使用Vercel和hexo搭建个人主页/8.png)\n\n6. 选择 Github 后，因为我登陆的时候时使用了 Github 了授权，这里也就直接显示了我的 GitHub 名称，我们填入仓库名称为 hexo，你也可以填入其他的仓库名称，比如 blog、myblog 等。Create private Git Repository 可以勾选，也可以不勾选，勾选的话会创建私人仓库，这样别人看你的 Github 的时候不会看到这个仓库。选择好后，点击 Continue 进入下一步。\n\n![9](关于使用Vercel和hexo搭建个人主页/9.png)\n\n7. 以下这部分默认即可，选择Deploy即可进行创建，等待一分钟。\n\n![10](关于使用Vercel和hexo搭建个人主页/10.png)\n\n8. 项目就部署好了。会跳转到恭喜你，出现一个非常浮夸的界面。这时就可以点击 visit 按钮进行访问了，因为 vercel 提供了免费的域名，所以直接点击visit访问即可。\n\n![11](关于使用Vercel和hexo搭建个人主页/11.png)\n\n9. Hexo 博客就搭建完成了，在 GitHub 中也已经自动创建了这个博客项目。进入我们的Github账号，在个人项目可以看到同名的项目（按照刚刚的步骤名字应该是hexo，不过我之前创建的名字叫myblog）\n\n![12](关于使用Vercel和hexo搭建个人主页/12.png)\n\n### 在vercel上部署自己购买的域名\n\n在vercel的个人项目主页里点击个人网站项目，就可以看到项目的详细信息，右上角有View Domains，我们可以通过这个选项关联域名。\n\n![16](关于使用Vercel和hexo搭建个人主页/16.png)\n\n我们可以把购买的域名复制到中间的标签栏（就是那个有mywebsite.com的框框），然后点击Add就可以了。\n\n![17](关于使用Vercel和hexo搭建个人主页/17.png)\n\n这时你可能发现有红点，就是域名没有部署起，这是因为域名没有进行解析。在vercel的界面会提醒你，如何设置解析的一些信息。\n\n我是在阿里云购买的域名，于是你可以在阿里云看到自己的域名，在对应域名的右边你可以看到两个小字，也就是：解析。\n\n![18](关于使用Vercel和hexo搭建个人主页/18.png)\n\n根据在vercel上提示的信息填内容即可增加一条解析的信息。点击`增加记录`增加解析信息哈。不出意外在设置好了以后，vercel那边马上就能收到域名可以成功使用的信息。\n\n![20](关于使用Vercel和hexo搭建个人主页/20.png)\n\n### 切换主题\n\n切换主题这个东西在Github、博客上找资源或者在hexo官网找资源都行。我选择的是在hexo官网上找个中意的模板。\n\nhexo官网：https://hexo.io/\n\n左上角你可以看到一排标签，选择Themes，你就可以大大方方地挑选主题了。\n\n![13](关于使用Vercel和hexo搭建个人主页/13.png)\n\n选择一款自己喜欢的主题，然后在主题中找到作者的Github，在里面找项目一般就能找到如何操作的文档和代码。根据提示操作，就可以切换主题。\n\n![14](关于使用Vercel和hexo搭建个人主页/14.png)\n\n### 本地测试主页以及主页更新\n\n* #### 在本地测试主页\n\n将自己Github中的个人主页项目clone到本地，比如我的：git clone 仓库地址.git。地址可以在点击Code，在SSH下面的那一栏就是。\n\n![15](关于使用Vercel和hexo搭建个人主页/15.png)\n\n- 在搭建之前我们已经在本地安装了 hexo-cli 的脚手架，这个时候就可以使用了。在项目文件夹下，打开终端，首先需要安装项目依赖，通过`npm install` 或 `cnpm install` 或`yarn install`皆可安装依赖。\n- 依赖安装成功后，执行`hexo server -p $PORT`即可启动项目，其中$PORT 默认 4000，你也可以修改端口。hexo 也提供了简易方式启动命名：`hexo s`，启动后在浏览器访问：[http://localhosst:4000](http://localhosst:4000/)即可打开。\n\n* #### 主页更新\n\n在本地可以使用以下代码创建文章：\n\n```\nhexo new \"文章标题\"\n```\n\nhexo中各文件夹的作用建议参考：\n\n在typora中更新好文章之后，使用以下代码可以在本地查看修改后的个人主页：\n\n```\nhexo cl ##清除缓存\nhexo g  ##打包\nhexo s  ##启动本地服务\n```\n\n启动后在浏览器访问：[http://localhosst:4000](http://localhosst:4000/)即可打开，满意之后便可以部署到自己的博客上。\n\n这里有两条路，一条是直接使用Git更新对应仓库的代码，一条是直接通过hexo d来上传代码，我就不多说了，详细操作可以查看相关博客。\n\n\n\n## 后记\n\n文章写于博客搭建完成前，很多的细节可能并没有提及，在搭建网站的过程中呢，发现大多数博客展示的搭建过程都是本文的一个子集，于是搭建过程查看了很多的博客。本文算是比较完整的一个博客搭建过程，希望对大家有一些帮助，如有错误欢迎指出。\n\n\n\n\n\n","source":"_posts/关于使用Vercel和hexo搭建个人主页.md","raw":"---\ntitle: 关于使用Vercel和hexo搭建个人主页\ncatalog: true\ndate: 2021-01-28 22:43:32\nsubtitle: 一篇从零开始的搭站博客\ntop: 6\nheader-img: /img/header_img/6.jpg\ntags:\n- Javascript\n- Vercel\n- Hexo\ncategories:\n- 工程项目\n---\n\n> 在江安校区商业街的倒数声中跨过了2020年，新年伊始之际，想着作为未来的一个程序猿，也得需要有一个博客来记录下自己那些杂七杂八的想法了，于是在寒假中旬开始实现了搭建个人主页的任务。\n\n## 前言\n\n上学期在VR实验室的时候，在周哥的指导下，翻阅了相当一部分人的个人主页，还是蛮羡慕身边的很多大佬都有着自己的网站，展示和收集着自己过去的很多经历。但我本人又是一个非常懒的货，之前的弄的公众号便在热火朝天的开始之后没了声音，想坚持做一件事是真不容易。希望未来的日子里能够慢慢地为自己的网站添砖加瓦吧，孩子这一次一定能坚持下去555 。\n\n## 关于要使用的一些软件和工具\n\n* Git：无论是更新Github库还是嫖资源都需要使用的软件。\n\n* Vercel：Vercel 提供了一个云平台，可以优化整个项目开发和部署体验，它有很强大的功能值得去探索，个人使用是免费的，提供了域名，使用方便快捷。在本文中，我将域名换成了自己在阿里云上购买的域名。\n\n* Github账号：自己的代码库和嫖别人的代码库，*GitHub*是一个面向开源及私有软件项目的托管平台，因为只支持Git作为唯一的版本库格式进行托管。\n\n* Nodejs：因为 Hexo 需要 Nodejs 支持的、生成的，所以这是前置步骤。\n\n* 阿里云账号：购买域名\n* Hexo框架\n\n简单解释一下个人主页的运行流程：\n\nNodejs，npm和hexo框架的安装是进行博客开发的基础条件。\n\nGithub账号是通用的账号，而Git可以对Github上的资源进行操作，而我们的个人主页的所有代码(包括文章内容)便放在Github的仓库里，每一次我们想更新个人主页的内容就需要更新Github仓库里的代码。\n\nGithub.io是由github pages提供的服务，也就是可以在github pages上建立你自己的博客。但是由于是国外的，你懂，访问速度很慢。于是便引入了vercel，通过vercel与Github账号绑定，我们可以用vercel来建立自己的博客，访问速度会得到大幅度地提升。vercel会提供免费的域名，但是这个域名反正我个人不会用哈哈，于是便有了在阿里云官网上买域名这么一项操作，在vercel官网的操作中，会把买到的域名与免费的域名进行绑定，从而可以通过买的域名访问我们的个人主页。\n\n## 搭建过程\n\n### Git的安装和与GitHub账号的绑定\n\nGit安装网址：https://git-scm.com/download/win\n\nGithub官网：https://github.com/\n\n如何注册Github账号和进行一些基本操作参考：https://blog.csdn.net/qq_41782425/article/details/85179912\n\n注意：在Github填写邮箱信息的时候一定要使用非qq邮箱的其他邮箱，要不注册不了vercel的账户。\n\nGit安装流程以及与Github账号绑定参考：\n\nhttps://blog.csdn.net/huangqqdy/article/details/83032408?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\n\n### Nodejs和hexo框架的安装\n\n这部分推荐参考博客：https://www.cnblogs.com/qinghan123/p/14019115.html\n\n* 安装nodejs\n\n下载 nodejs：https://nodejs.org/en/\n\n![1](关于使用Vercel和hexo搭建个人主页/1.png)\n\n选择左边右边的安装都行，一直点默认就行。安装完以后会有两个组件：1.是 npm 包管理器；2.是 Nodejs 本身。\n\n查看 node 的版本：\n\n```\nnode -v\n```\n\n查看 npm 包管理器的版本：\n\n```\nnpm -v\n```\n\n* 安装hexo框架\n\n需借助 npm 包管理器来安装。因为国内安装镜像源很慢，所以利用 npm 安装 cnpm。我们选择使用淘宝链接安装比较快：\n\n```\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\n```\n\n查看 cnpm 管理器的版本：\n\n```\ncnpm -v\n```\n\n安装hexo：\n\n```\ncnpm install -g hexo-cli\n```\n\n验证hexo是否安装成功和查看hexo版本：\n\n```\nhexo -v\n```\n\n如果出现以下模样，那么恭喜你hexo安装成功。\n\n![2](关于使用Vercel和hexo搭建个人主页/2.png)\n\n### 使用vercel搭建个人网站\n\n推荐博客：https://blog.csdn.net/Aixiu1016/article/details/112356387\n\n以下描述很多话是直接复制粘贴的哈，原博主写得很到位。\n\n1. 在 Vercel 官网（https://vercel.com/）注册一个新账户，注册新用户最好使用 Github的账户，并绑定手机号。注册完成后，可以在配置页面修改自己的邮箱地址。这里建议使用 Github 进行授权登陆，后续可以选择 Github 上的项目直接部署也会很方便的。\n\n   ![3](关于使用Vercel和hexo搭建个人主页/3.png)\n\n2. 之后你就可以登录系统看到自己的一些东西啦。myblog是我搭载个人网站的项目，这里可以看到的是已经与我购买的域名绑定了，也就是：binbining.com，在这之前你看到你新建的项目都应该是xxxxxxxxx.app这样的域名。\n\n![4](关于使用Vercel和hexo搭建个人主页/4.png)\n\n3. 接下来一步就是创建你自己的项目，在上图右上角我们可以看到New Project这个选项，点击右下角这个Browsw All Templates你可以看到很多很多的模板，从里面选择hexo模型，也就是我们需要的模板。\n\n![5](关于使用Vercel和hexo搭建个人主页/5.png)\n\n![6](关于使用Vercel和hexo搭建个人主页/6.png)\n\n4. 选择模版后，进入创建项目位置选择，目前团队项目是需要专业版的，是需要收费的，选择个人，点击`PERSONAL ACCOUNT`后面的 select 按钮。\n\n![7](关于使用Vercel和hexo搭建个人主页/7.png)\n\n5. 这里可以选择使用什么仓库保存自己的代码，当然我们选择Github。\n\n![8](关于使用Vercel和hexo搭建个人主页/8.png)\n\n6. 选择 Github 后，因为我登陆的时候时使用了 Github 了授权，这里也就直接显示了我的 GitHub 名称，我们填入仓库名称为 hexo，你也可以填入其他的仓库名称，比如 blog、myblog 等。Create private Git Repository 可以勾选，也可以不勾选，勾选的话会创建私人仓库，这样别人看你的 Github 的时候不会看到这个仓库。选择好后，点击 Continue 进入下一步。\n\n![9](关于使用Vercel和hexo搭建个人主页/9.png)\n\n7. 以下这部分默认即可，选择Deploy即可进行创建，等待一分钟。\n\n![10](关于使用Vercel和hexo搭建个人主页/10.png)\n\n8. 项目就部署好了。会跳转到恭喜你，出现一个非常浮夸的界面。这时就可以点击 visit 按钮进行访问了，因为 vercel 提供了免费的域名，所以直接点击visit访问即可。\n\n![11](关于使用Vercel和hexo搭建个人主页/11.png)\n\n9. Hexo 博客就搭建完成了，在 GitHub 中也已经自动创建了这个博客项目。进入我们的Github账号，在个人项目可以看到同名的项目（按照刚刚的步骤名字应该是hexo，不过我之前创建的名字叫myblog）\n\n![12](关于使用Vercel和hexo搭建个人主页/12.png)\n\n### 在vercel上部署自己购买的域名\n\n在vercel的个人项目主页里点击个人网站项目，就可以看到项目的详细信息，右上角有View Domains，我们可以通过这个选项关联域名。\n\n![16](关于使用Vercel和hexo搭建个人主页/16.png)\n\n我们可以把购买的域名复制到中间的标签栏（就是那个有mywebsite.com的框框），然后点击Add就可以了。\n\n![17](关于使用Vercel和hexo搭建个人主页/17.png)\n\n这时你可能发现有红点，就是域名没有部署起，这是因为域名没有进行解析。在vercel的界面会提醒你，如何设置解析的一些信息。\n\n我是在阿里云购买的域名，于是你可以在阿里云看到自己的域名，在对应域名的右边你可以看到两个小字，也就是：解析。\n\n![18](关于使用Vercel和hexo搭建个人主页/18.png)\n\n根据在vercel上提示的信息填内容即可增加一条解析的信息。点击`增加记录`增加解析信息哈。不出意外在设置好了以后，vercel那边马上就能收到域名可以成功使用的信息。\n\n![20](关于使用Vercel和hexo搭建个人主页/20.png)\n\n### 切换主题\n\n切换主题这个东西在Github、博客上找资源或者在hexo官网找资源都行。我选择的是在hexo官网上找个中意的模板。\n\nhexo官网：https://hexo.io/\n\n左上角你可以看到一排标签，选择Themes，你就可以大大方方地挑选主题了。\n\n![13](关于使用Vercel和hexo搭建个人主页/13.png)\n\n选择一款自己喜欢的主题，然后在主题中找到作者的Github，在里面找项目一般就能找到如何操作的文档和代码。根据提示操作，就可以切换主题。\n\n![14](关于使用Vercel和hexo搭建个人主页/14.png)\n\n### 本地测试主页以及主页更新\n\n* #### 在本地测试主页\n\n将自己Github中的个人主页项目clone到本地，比如我的：git clone 仓库地址.git。地址可以在点击Code，在SSH下面的那一栏就是。\n\n![15](关于使用Vercel和hexo搭建个人主页/15.png)\n\n- 在搭建之前我们已经在本地安装了 hexo-cli 的脚手架，这个时候就可以使用了。在项目文件夹下，打开终端，首先需要安装项目依赖，通过`npm install` 或 `cnpm install` 或`yarn install`皆可安装依赖。\n- 依赖安装成功后，执行`hexo server -p $PORT`即可启动项目，其中$PORT 默认 4000，你也可以修改端口。hexo 也提供了简易方式启动命名：`hexo s`，启动后在浏览器访问：[http://localhosst:4000](http://localhosst:4000/)即可打开。\n\n* #### 主页更新\n\n在本地可以使用以下代码创建文章：\n\n```\nhexo new \"文章标题\"\n```\n\nhexo中各文件夹的作用建议参考：\n\n在typora中更新好文章之后，使用以下代码可以在本地查看修改后的个人主页：\n\n```\nhexo cl ##清除缓存\nhexo g  ##打包\nhexo s  ##启动本地服务\n```\n\n启动后在浏览器访问：[http://localhosst:4000](http://localhosst:4000/)即可打开，满意之后便可以部署到自己的博客上。\n\n这里有两条路，一条是直接使用Git更新对应仓库的代码，一条是直接通过hexo d来上传代码，我就不多说了，详细操作可以查看相关博客。\n\n\n\n## 后记\n\n文章写于博客搭建完成前，很多的细节可能并没有提及，在搭建网站的过程中呢，发现大多数博客展示的搭建过程都是本文的一个子集，于是搭建过程查看了很多的博客。本文算是比较完整的一个博客搭建过程，希望对大家有一些帮助，如有错误欢迎指出。\n\n\n\n\n\n","slug":"关于使用Vercel和hexo搭建个人主页","published":1,"updated":"2022-01-13T09:01:15.021Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxwu000b3oueducyg18e","content":"<blockquote>\n<p>在江安校区商业街的倒数声中跨过了2020年，新年伊始之际，想着作为未来的一个程序猿，也得需要有一个博客来记录下自己那些杂七杂八的想法了，于是在寒假中旬开始实现了搭建个人主页的任务。</p>\n</blockquote>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>上学期在VR实验室的时候，在周哥的指导下，翻阅了相当一部分人的个人主页，还是蛮羡慕身边的很多大佬都有着自己的网站，展示和收集着自己过去的很多经历。但我本人又是一个非常懒的货，之前的弄的公众号便在热火朝天的开始之后没了声音，想坚持做一件事是真不容易。希望未来的日子里能够慢慢地为自己的网站添砖加瓦吧，孩子这一次一定能坚持下去555 。</p>\n<h2 id=\"关于要使用的一些软件和工具\"><a href=\"#关于要使用的一些软件和工具\" class=\"headerlink\" title=\"关于要使用的一些软件和工具\"></a>关于要使用的一些软件和工具</h2><ul>\n<li><p>Git：无论是更新Github库还是嫖资源都需要使用的软件。</p>\n</li>\n<li><p>Vercel：Vercel 提供了一个云平台，可以优化整个项目开发和部署体验，它有很强大的功能值得去探索，个人使用是免费的，提供了域名，使用方便快捷。在本文中，我将域名换成了自己在阿里云上购买的域名。</p>\n</li>\n<li><p>Github账号：自己的代码库和嫖别人的代码库，<em>GitHub</em>是一个面向开源及私有软件项目的托管平台，因为只支持Git作为唯一的版本库格式进行托管。</p>\n</li>\n<li><p>Nodejs：因为 Hexo 需要 Nodejs 支持的、生成的，所以这是前置步骤。</p>\n</li>\n<li><p>阿里云账号：购买域名</p>\n</li>\n<li>Hexo框架</li>\n</ul>\n<p>简单解释一下个人主页的运行流程：</p>\n<p>Nodejs，npm和hexo框架的安装是进行博客开发的基础条件。</p>\n<p>Github账号是通用的账号，而Git可以对Github上的资源进行操作，而我们的个人主页的所有代码(包括文章内容)便放在Github的仓库里，每一次我们想更新个人主页的内容就需要更新Github仓库里的代码。</p>\n<p>Github.io是由github pages提供的服务，也就是可以在github pages上建立你自己的博客。但是由于是国外的，你懂，访问速度很慢。于是便引入了vercel，通过vercel与Github账号绑定，我们可以用vercel来建立自己的博客，访问速度会得到大幅度地提升。vercel会提供免费的域名，但是这个域名反正我个人不会用哈哈，于是便有了在阿里云官网上买域名这么一项操作，在vercel官网的操作中，会把买到的域名与免费的域名进行绑定，从而可以通过买的域名访问我们的个人主页。</p>\n<h2 id=\"搭建过程\"><a href=\"#搭建过程\" class=\"headerlink\" title=\"搭建过程\"></a>搭建过程</h2><h3 id=\"Git的安装和与GitHub账号的绑定\"><a href=\"#Git的安装和与GitHub账号的绑定\" class=\"headerlink\" title=\"Git的安装和与GitHub账号的绑定\"></a>Git的安装和与GitHub账号的绑定</h3><p>Git安装网址：<a href=\"https://git-scm.com/download/win\">https://git-scm.com/download/win</a></p>\n<p>Github官网：<a href=\"https://github.com/\">https://github.com/</a></p>\n<p>如何注册Github账号和进行一些基本操作参考：<a href=\"https://blog.csdn.net/qq_41782425/article/details/85179912\">https://blog.csdn.net/qq_41782425/article/details/85179912</a></p>\n<p>注意：在Github填写邮箱信息的时候一定要使用非qq邮箱的其他邮箱，要不注册不了vercel的账户。</p>\n<p>Git安装流程以及与Github账号绑定参考：</p>\n<p><a href=\"https://blog.csdn.net/huangqqdy/article/details/83032408?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\">https://blog.csdn.net/huangqqdy/article/details/83032408?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control</a></p>\n<h3 id=\"Nodejs和hexo框架的安装\"><a href=\"#Nodejs和hexo框架的安装\" class=\"headerlink\" title=\"Nodejs和hexo框架的安装\"></a>Nodejs和hexo框架的安装</h3><p>这部分推荐参考博客：<a href=\"https://www.cnblogs.com/qinghan123/p/14019115.html\">https://www.cnblogs.com/qinghan123/p/14019115.html</a></p>\n<ul>\n<li>安装nodejs</li>\n</ul>\n<p>下载 nodejs：<a href=\"https://nodejs.org/en/\">https://nodejs.org/en/</a></p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/1.png\" alt=\"1\"></p>\n<p>选择左边右边的安装都行，一直点默认就行。安装完以后会有两个组件：1.是 npm 包管理器；2.是 Nodejs 本身。</p>\n<p>查看 node 的版本：</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">node</span> <span class=\"title\">-v</span></span><br></pre></td></tr></table></figure>\n<p>查看 npm 包管理器的版本：</p>\n<figure class=\"highlight coffeescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">npm</span> -v</span><br></pre></td></tr></table></figure>\n<ul>\n<li>安装hexo框架</li>\n</ul>\n<p>需借助 npm 包管理器来安装。因为国内安装镜像源很慢，所以利用 npm 安装 cnpm。我们选择使用淘宝链接安装比较快：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g cnpm --registry=https:<span class=\"regexp\">//</span>registry.npm.taobao.org</span><br></pre></td></tr></table></figure>\n<p>查看 cnpm 管理器的版本：</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">cnpm -v</span></span><br></pre></td></tr></table></figure>\n<p>安装hexo：</p>\n<figure class=\"highlight avrasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cnpm install -g hexo-<span class=\"keyword\">cli</span></span><br></pre></td></tr></table></figure>\n<p>验证hexo是否安装成功和查看hexo版本：</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo -v</span></span><br></pre></td></tr></table></figure>\n<p>如果出现以下模样，那么恭喜你hexo安装成功。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/2.png\" alt=\"2\"></p>\n<h3 id=\"使用vercel搭建个人网站\"><a href=\"#使用vercel搭建个人网站\" class=\"headerlink\" title=\"使用vercel搭建个人网站\"></a>使用vercel搭建个人网站</h3><p>推荐博客：<a href=\"https://blog.csdn.net/Aixiu1016/article/details/112356387\">https://blog.csdn.net/Aixiu1016/article/details/112356387</a></p>\n<p>以下描述很多话是直接复制粘贴的哈，原博主写得很到位。</p>\n<ol>\n<li><p>在 Vercel 官网（<a href=\"https://vercel.com/）注册一个新账户，注册新用户最好使用\">https://vercel.com/）注册一个新账户，注册新用户最好使用</a> Github的账户，并绑定手机号。注册完成后，可以在配置页面修改自己的邮箱地址。这里建议使用 Github 进行授权登陆，后续可以选择 Github 上的项目直接部署也会很方便的。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/3.png\" alt=\"3\"></p>\n</li>\n<li><p>之后你就可以登录系统看到自己的一些东西啦。myblog是我搭载个人网站的项目，这里可以看到的是已经与我购买的域名绑定了，也就是：binbining.com，在这之前你看到你新建的项目都应该是xxxxxxxxx.app这样的域名。</p>\n</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/4.png\" alt=\"4\"></p>\n<ol>\n<li>接下来一步就是创建你自己的项目，在上图右上角我们可以看到New Project这个选项，点击右下角这个Browsw All Templates你可以看到很多很多的模板，从里面选择hexo模型，也就是我们需要的模板。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/5.png\" alt=\"5\"></p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/6.png\" alt=\"6\"></p>\n<ol>\n<li>选择模版后，进入创建项目位置选择，目前团队项目是需要专业版的，是需要收费的，选择个人，点击<code>PERSONAL ACCOUNT</code>后面的 select 按钮。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/7.png\" alt=\"7\"></p>\n<ol>\n<li>这里可以选择使用什么仓库保存自己的代码，当然我们选择Github。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/8.png\" alt=\"8\"></p>\n<ol>\n<li>选择 Github 后，因为我登陆的时候时使用了 Github 了授权，这里也就直接显示了我的 GitHub 名称，我们填入仓库名称为 hexo，你也可以填入其他的仓库名称，比如 blog、myblog 等。Create private Git Repository 可以勾选，也可以不勾选，勾选的话会创建私人仓库，这样别人看你的 Github 的时候不会看到这个仓库。选择好后，点击 Continue 进入下一步。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/9.png\" alt=\"9\"></p>\n<ol>\n<li>以下这部分默认即可，选择Deploy即可进行创建，等待一分钟。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/10.png\" alt=\"10\"></p>\n<ol>\n<li>项目就部署好了。会跳转到恭喜你，出现一个非常浮夸的界面。这时就可以点击 visit 按钮进行访问了，因为 vercel 提供了免费的域名，所以直接点击visit访问即可。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/11.png\" alt=\"11\"></p>\n<ol>\n<li>Hexo 博客就搭建完成了，在 GitHub 中也已经自动创建了这个博客项目。进入我们的Github账号，在个人项目可以看到同名的项目（按照刚刚的步骤名字应该是hexo，不过我之前创建的名字叫myblog）</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/12.png\" alt=\"12\"></p>\n<h3 id=\"在vercel上部署自己购买的域名\"><a href=\"#在vercel上部署自己购买的域名\" class=\"headerlink\" title=\"在vercel上部署自己购买的域名\"></a>在vercel上部署自己购买的域名</h3><p>在vercel的个人项目主页里点击个人网站项目，就可以看到项目的详细信息，右上角有View Domains，我们可以通过这个选项关联域名。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/16.png\" alt=\"16\"></p>\n<p>我们可以把购买的域名复制到中间的标签栏（就是那个有mywebsite.com的框框），然后点击Add就可以了。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/17.png\" alt=\"17\"></p>\n<p>这时你可能发现有红点，就是域名没有部署起，这是因为域名没有进行解析。在vercel的界面会提醒你，如何设置解析的一些信息。</p>\n<p>我是在阿里云购买的域名，于是你可以在阿里云看到自己的域名，在对应域名的右边你可以看到两个小字，也就是：解析。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/18.png\" alt=\"18\"></p>\n<p>根据在vercel上提示的信息填内容即可增加一条解析的信息。点击<code>增加记录</code>增加解析信息哈。不出意外在设置好了以后，vercel那边马上就能收到域名可以成功使用的信息。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/20.png\" alt=\"20\"></p>\n<h3 id=\"切换主题\"><a href=\"#切换主题\" class=\"headerlink\" title=\"切换主题\"></a>切换主题</h3><p>切换主题这个东西在Github、博客上找资源或者在hexo官网找资源都行。我选择的是在hexo官网上找个中意的模板。</p>\n<p>hexo官网：<a href=\"https://hexo.io/\">https://hexo.io/</a></p>\n<p>左上角你可以看到一排标签，选择Themes，你就可以大大方方地挑选主题了。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/13.png\" alt=\"13\"></p>\n<p>选择一款自己喜欢的主题，然后在主题中找到作者的Github，在里面找项目一般就能找到如何操作的文档和代码。根据提示操作，就可以切换主题。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/14.png\" alt=\"14\"></p>\n<h3 id=\"本地测试主页以及主页更新\"><a href=\"#本地测试主页以及主页更新\" class=\"headerlink\" title=\"本地测试主页以及主页更新\"></a>本地测试主页以及主页更新</h3><ul>\n<li><h4 id=\"在本地测试主页\"><a href=\"#在本地测试主页\" class=\"headerlink\" title=\"在本地测试主页\"></a>在本地测试主页</h4></li>\n</ul>\n<p>将自己Github中的个人主页项目clone到本地，比如我的：git clone 仓库地址.git。地址可以在点击Code，在SSH下面的那一栏就是。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/15.png\" alt=\"15\"></p>\n<ul>\n<li>在搭建之前我们已经在本地安装了 hexo-cli 的脚手架，这个时候就可以使用了。在项目文件夹下，打开终端，首先需要安装项目依赖，通过<code>npm install</code> 或 <code>cnpm install</code> 或<code>yarn install</code>皆可安装依赖。</li>\n<li>依赖安装成功后，执行<code>hexo server -p $PORT</code>即可启动项目，其中$PORT 默认 4000，你也可以修改端口。hexo 也提供了简易方式启动命名：<code>hexo s</code>，启动后在浏览器访问：<a href=\"http://localhosst:4000/\">http://localhosst:4000</a>即可打开。</li>\n</ul>\n<ul>\n<li><h4 id=\"主页更新\"><a href=\"#主页更新\" class=\"headerlink\" title=\"主页更新\"></a>主页更新</h4></li>\n</ul>\n<p>在本地可以使用以下代码创建文章：</p>\n<figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo <span class=\"keyword\">new</span> <span class=\"string\">&quot;文章标题&quot;</span></span><br></pre></td></tr></table></figure>\n<p>hexo中各文件夹的作用建议参考：</p>\n<p>在typora中更新好文章之后，使用以下代码可以在本地查看修改后的个人主页：</p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo cl ##清除缓存</span><br><span class=\"line\">hexo g  ##打包</span><br><span class=\"line\">hexo s  ##启动本地服务</span><br></pre></td></tr></table></figure>\n<p>启动后在浏览器访问：<a href=\"http://localhosst:4000/\">http://localhosst:4000</a>即可打开，满意之后便可以部署到自己的博客上。</p>\n<p>这里有两条路，一条是直接使用Git更新对应仓库的代码，一条是直接通过hexo d来上传代码，我就不多说了，详细操作可以查看相关博客。</p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>文章写于博客搭建完成前，很多的细节可能并没有提及，在搭建网站的过程中呢，发现大多数博客展示的搭建过程都是本文的一个子集，于是搭建过程查看了很多的博客。本文算是比较完整的一个博客搭建过程，希望对大家有一些帮助，如有错误欢迎指出。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>在江安校区商业街的倒数声中跨过了2020年，新年伊始之际，想着作为未来的一个程序猿，也得需要有一个博客来记录下自己那些杂七杂八的想法了，于是在寒假中旬开始实现了搭建个人主页的任务。</p>\n</blockquote>\n<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>上学期在VR实验室的时候，在周哥的指导下，翻阅了相当一部分人的个人主页，还是蛮羡慕身边的很多大佬都有着自己的网站，展示和收集着自己过去的很多经历。但我本人又是一个非常懒的货，之前的弄的公众号便在热火朝天的开始之后没了声音，想坚持做一件事是真不容易。希望未来的日子里能够慢慢地为自己的网站添砖加瓦吧，孩子这一次一定能坚持下去555 。</p>\n<h2 id=\"关于要使用的一些软件和工具\"><a href=\"#关于要使用的一些软件和工具\" class=\"headerlink\" title=\"关于要使用的一些软件和工具\"></a>关于要使用的一些软件和工具</h2><ul>\n<li><p>Git：无论是更新Github库还是嫖资源都需要使用的软件。</p>\n</li>\n<li><p>Vercel：Vercel 提供了一个云平台，可以优化整个项目开发和部署体验，它有很强大的功能值得去探索，个人使用是免费的，提供了域名，使用方便快捷。在本文中，我将域名换成了自己在阿里云上购买的域名。</p>\n</li>\n<li><p>Github账号：自己的代码库和嫖别人的代码库，<em>GitHub</em>是一个面向开源及私有软件项目的托管平台，因为只支持Git作为唯一的版本库格式进行托管。</p>\n</li>\n<li><p>Nodejs：因为 Hexo 需要 Nodejs 支持的、生成的，所以这是前置步骤。</p>\n</li>\n<li><p>阿里云账号：购买域名</p>\n</li>\n<li>Hexo框架</li>\n</ul>\n<p>简单解释一下个人主页的运行流程：</p>\n<p>Nodejs，npm和hexo框架的安装是进行博客开发的基础条件。</p>\n<p>Github账号是通用的账号，而Git可以对Github上的资源进行操作，而我们的个人主页的所有代码(包括文章内容)便放在Github的仓库里，每一次我们想更新个人主页的内容就需要更新Github仓库里的代码。</p>\n<p>Github.io是由github pages提供的服务，也就是可以在github pages上建立你自己的博客。但是由于是国外的，你懂，访问速度很慢。于是便引入了vercel，通过vercel与Github账号绑定，我们可以用vercel来建立自己的博客，访问速度会得到大幅度地提升。vercel会提供免费的域名，但是这个域名反正我个人不会用哈哈，于是便有了在阿里云官网上买域名这么一项操作，在vercel官网的操作中，会把买到的域名与免费的域名进行绑定，从而可以通过买的域名访问我们的个人主页。</p>\n<h2 id=\"搭建过程\"><a href=\"#搭建过程\" class=\"headerlink\" title=\"搭建过程\"></a>搭建过程</h2><h3 id=\"Git的安装和与GitHub账号的绑定\"><a href=\"#Git的安装和与GitHub账号的绑定\" class=\"headerlink\" title=\"Git的安装和与GitHub账号的绑定\"></a>Git的安装和与GitHub账号的绑定</h3><p>Git安装网址：<a href=\"https://git-scm.com/download/win\">https://git-scm.com/download/win</a></p>\n<p>Github官网：<a href=\"https://github.com/\">https://github.com/</a></p>\n<p>如何注册Github账号和进行一些基本操作参考：<a href=\"https://blog.csdn.net/qq_41782425/article/details/85179912\">https://blog.csdn.net/qq_41782425/article/details/85179912</a></p>\n<p>注意：在Github填写邮箱信息的时候一定要使用非qq邮箱的其他邮箱，要不注册不了vercel的账户。</p>\n<p>Git安装流程以及与Github账号绑定参考：</p>\n<p><a href=\"https://blog.csdn.net/huangqqdy/article/details/83032408?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control\">https://blog.csdn.net/huangqqdy/article/details/83032408?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control</a></p>\n<h3 id=\"Nodejs和hexo框架的安装\"><a href=\"#Nodejs和hexo框架的安装\" class=\"headerlink\" title=\"Nodejs和hexo框架的安装\"></a>Nodejs和hexo框架的安装</h3><p>这部分推荐参考博客：<a href=\"https://www.cnblogs.com/qinghan123/p/14019115.html\">https://www.cnblogs.com/qinghan123/p/14019115.html</a></p>\n<ul>\n<li>安装nodejs</li>\n</ul>\n<p>下载 nodejs：<a href=\"https://nodejs.org/en/\">https://nodejs.org/en/</a></p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/1.png\" alt=\"1\"></p>\n<p>选择左边右边的安装都行，一直点默认就行。安装完以后会有两个组件：1.是 npm 包管理器；2.是 Nodejs 本身。</p>\n<p>查看 node 的版本：</p>\n<figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">node</span> <span class=\"title\">-v</span></span><br></pre></td></tr></table></figure>\n<p>查看 npm 包管理器的版本：</p>\n<figure class=\"highlight coffeescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">npm</span> -v</span><br></pre></td></tr></table></figure>\n<ul>\n<li>安装hexo框架</li>\n</ul>\n<p>需借助 npm 包管理器来安装。因为国内安装镜像源很慢，所以利用 npm 安装 cnpm。我们选择使用淘宝链接安装比较快：</p>\n<figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install -g cnpm --registry=https:<span class=\"regexp\">//</span>registry.npm.taobao.org</span><br></pre></td></tr></table></figure>\n<p>查看 cnpm 管理器的版本：</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">cnpm -v</span></span><br></pre></td></tr></table></figure>\n<p>安装hexo：</p>\n<figure class=\"highlight avrasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cnpm install -g hexo-<span class=\"keyword\">cli</span></span><br></pre></td></tr></table></figure>\n<p>验证hexo是否安装成功和查看hexo版本：</p>\n<figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attribute\">hexo -v</span></span><br></pre></td></tr></table></figure>\n<p>如果出现以下模样，那么恭喜你hexo安装成功。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/2.png\" alt=\"2\"></p>\n<h3 id=\"使用vercel搭建个人网站\"><a href=\"#使用vercel搭建个人网站\" class=\"headerlink\" title=\"使用vercel搭建个人网站\"></a>使用vercel搭建个人网站</h3><p>推荐博客：<a href=\"https://blog.csdn.net/Aixiu1016/article/details/112356387\">https://blog.csdn.net/Aixiu1016/article/details/112356387</a></p>\n<p>以下描述很多话是直接复制粘贴的哈，原博主写得很到位。</p>\n<ol>\n<li><p>在 Vercel 官网（<a href=\"https://vercel.com/）注册一个新账户，注册新用户最好使用\">https://vercel.com/）注册一个新账户，注册新用户最好使用</a> Github的账户，并绑定手机号。注册完成后，可以在配置页面修改自己的邮箱地址。这里建议使用 Github 进行授权登陆，后续可以选择 Github 上的项目直接部署也会很方便的。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/3.png\" alt=\"3\"></p>\n</li>\n<li><p>之后你就可以登录系统看到自己的一些东西啦。myblog是我搭载个人网站的项目，这里可以看到的是已经与我购买的域名绑定了，也就是：binbining.com，在这之前你看到你新建的项目都应该是xxxxxxxxx.app这样的域名。</p>\n</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/4.png\" alt=\"4\"></p>\n<ol>\n<li>接下来一步就是创建你自己的项目，在上图右上角我们可以看到New Project这个选项，点击右下角这个Browsw All Templates你可以看到很多很多的模板，从里面选择hexo模型，也就是我们需要的模板。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/5.png\" alt=\"5\"></p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/6.png\" alt=\"6\"></p>\n<ol>\n<li>选择模版后，进入创建项目位置选择，目前团队项目是需要专业版的，是需要收费的，选择个人，点击<code>PERSONAL ACCOUNT</code>后面的 select 按钮。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/7.png\" alt=\"7\"></p>\n<ol>\n<li>这里可以选择使用什么仓库保存自己的代码，当然我们选择Github。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/8.png\" alt=\"8\"></p>\n<ol>\n<li>选择 Github 后，因为我登陆的时候时使用了 Github 了授权，这里也就直接显示了我的 GitHub 名称，我们填入仓库名称为 hexo，你也可以填入其他的仓库名称，比如 blog、myblog 等。Create private Git Repository 可以勾选，也可以不勾选，勾选的话会创建私人仓库，这样别人看你的 Github 的时候不会看到这个仓库。选择好后，点击 Continue 进入下一步。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/9.png\" alt=\"9\"></p>\n<ol>\n<li>以下这部分默认即可，选择Deploy即可进行创建，等待一分钟。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/10.png\" alt=\"10\"></p>\n<ol>\n<li>项目就部署好了。会跳转到恭喜你，出现一个非常浮夸的界面。这时就可以点击 visit 按钮进行访问了，因为 vercel 提供了免费的域名，所以直接点击visit访问即可。</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/11.png\" alt=\"11\"></p>\n<ol>\n<li>Hexo 博客就搭建完成了，在 GitHub 中也已经自动创建了这个博客项目。进入我们的Github账号，在个人项目可以看到同名的项目（按照刚刚的步骤名字应该是hexo，不过我之前创建的名字叫myblog）</li>\n</ol>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/12.png\" alt=\"12\"></p>\n<h3 id=\"在vercel上部署自己购买的域名\"><a href=\"#在vercel上部署自己购买的域名\" class=\"headerlink\" title=\"在vercel上部署自己购买的域名\"></a>在vercel上部署自己购买的域名</h3><p>在vercel的个人项目主页里点击个人网站项目，就可以看到项目的详细信息，右上角有View Domains，我们可以通过这个选项关联域名。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/16.png\" alt=\"16\"></p>\n<p>我们可以把购买的域名复制到中间的标签栏（就是那个有mywebsite.com的框框），然后点击Add就可以了。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/17.png\" alt=\"17\"></p>\n<p>这时你可能发现有红点，就是域名没有部署起，这是因为域名没有进行解析。在vercel的界面会提醒你，如何设置解析的一些信息。</p>\n<p>我是在阿里云购买的域名，于是你可以在阿里云看到自己的域名，在对应域名的右边你可以看到两个小字，也就是：解析。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/18.png\" alt=\"18\"></p>\n<p>根据在vercel上提示的信息填内容即可增加一条解析的信息。点击<code>增加记录</code>增加解析信息哈。不出意外在设置好了以后，vercel那边马上就能收到域名可以成功使用的信息。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/20.png\" alt=\"20\"></p>\n<h3 id=\"切换主题\"><a href=\"#切换主题\" class=\"headerlink\" title=\"切换主题\"></a>切换主题</h3><p>切换主题这个东西在Github、博客上找资源或者在hexo官网找资源都行。我选择的是在hexo官网上找个中意的模板。</p>\n<p>hexo官网：<a href=\"https://hexo.io/\">https://hexo.io/</a></p>\n<p>左上角你可以看到一排标签，选择Themes，你就可以大大方方地挑选主题了。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/13.png\" alt=\"13\"></p>\n<p>选择一款自己喜欢的主题，然后在主题中找到作者的Github，在里面找项目一般就能找到如何操作的文档和代码。根据提示操作，就可以切换主题。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/14.png\" alt=\"14\"></p>\n<h3 id=\"本地测试主页以及主页更新\"><a href=\"#本地测试主页以及主页更新\" class=\"headerlink\" title=\"本地测试主页以及主页更新\"></a>本地测试主页以及主页更新</h3><ul>\n<li><h4 id=\"在本地测试主页\"><a href=\"#在本地测试主页\" class=\"headerlink\" title=\"在本地测试主页\"></a>在本地测试主页</h4></li>\n</ul>\n<p>将自己Github中的个人主页项目clone到本地，比如我的：git clone 仓库地址.git。地址可以在点击Code，在SSH下面的那一栏就是。</p>\n<p><img src=\"/2021/01/28/%E5%85%B3%E4%BA%8E%E4%BD%BF%E7%94%A8Vercel%E5%92%8Chexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/15.png\" alt=\"15\"></p>\n<ul>\n<li>在搭建之前我们已经在本地安装了 hexo-cli 的脚手架，这个时候就可以使用了。在项目文件夹下，打开终端，首先需要安装项目依赖，通过<code>npm install</code> 或 <code>cnpm install</code> 或<code>yarn install</code>皆可安装依赖。</li>\n<li>依赖安装成功后，执行<code>hexo server -p $PORT</code>即可启动项目，其中$PORT 默认 4000，你也可以修改端口。hexo 也提供了简易方式启动命名：<code>hexo s</code>，启动后在浏览器访问：<a href=\"http://localhosst:4000/\">http://localhosst:4000</a>即可打开。</li>\n</ul>\n<ul>\n<li><h4 id=\"主页更新\"><a href=\"#主页更新\" class=\"headerlink\" title=\"主页更新\"></a>主页更新</h4></li>\n</ul>\n<p>在本地可以使用以下代码创建文章：</p>\n<figure class=\"highlight actionscript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo <span class=\"keyword\">new</span> <span class=\"string\">&quot;文章标题&quot;</span></span><br></pre></td></tr></table></figure>\n<p>hexo中各文件夹的作用建议参考：</p>\n<p>在typora中更新好文章之后，使用以下代码可以在本地查看修改后的个人主页：</p>\n<figure class=\"highlight clean\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo cl ##清除缓存</span><br><span class=\"line\">hexo g  ##打包</span><br><span class=\"line\">hexo s  ##启动本地服务</span><br></pre></td></tr></table></figure>\n<p>启动后在浏览器访问：<a href=\"http://localhosst:4000/\">http://localhosst:4000</a>即可打开，满意之后便可以部署到自己的博客上。</p>\n<p>这里有两条路，一条是直接使用Git更新对应仓库的代码，一条是直接通过hexo d来上传代码，我就不多说了，详细操作可以查看相关博客。</p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>文章写于博客搭建完成前，很多的细节可能并没有提及，在搭建网站的过程中呢，发现大多数博客展示的搭建过程都是本文的一个子集，于是搭建过程查看了很多的博客。本文算是比较完整的一个博客搭建过程，希望对大家有一些帮助，如有错误欢迎指出。</p>\n"},{"title":"基于Yolov4和Deepsort的智能交通场景应用","catalog":true,"date":"2021-01-27T03:58:51.000Z","subtitle":"中国软件杯参赛作品","top":3,"header-img":"/img/header_img/vehicle.jpg","mathjax":true,"_content":"\n> 在2019年的最后一个月开始尝试接触目标识别和跟踪的知识，那时候的我甚至连pycharm都没有用过，还不知道各个框架的概念。在盲目的代码复现和学习中，时间来到了2020年的三月份，了解到了中软杯的赛题，努力开始有了一个方向，也是我第一个负责和成功完成的项目。项目获得第九届中国软件杯大赛的全国二等奖，至于比赛的各种奇奇怪怪的事情我们暂且不用过多关注，最后能取得这么一个成绩，是我非常满意的。\n\n## 项目背景\n\n智慧交通建设是关系到我国国计民生的重要基础行业，我国政府对其发展极其重视。中共中央、国务院近两年先后颁布了《国家“物联网与智慧城市”研发计划2019年度项目申报指南》《关于进一步加快智慧城市建设的若干意见》等政策，明确提出推动大数据、信息共享和智慧社会的发展。\n\n基于对公共交通路口摄像头类似视角的影像数据进行处理，采用计算机视觉的算法对各种复杂的交通场景进行检测识别。项目使用计算机视觉技术打造了提供多功能智慧交通相关的软件。\n\n## 项目简介和功能描述\n\n本项目设计一种基于计算机视觉的智能摄像系统，运用了精确的单目标跟踪、多目标跟踪、实时目标识别、OCR技术、矩阵透视、射线法等多种技术，然后将技术整体展示，利用PYQT5开发出软件端，将数据可视化结果直接展示在用户眼前。\n\n中软杯官网赛题要求：\n\n* 程序实现基本的机动车检测、车牌识别和至少实现一种交通场景功能。\n* 该项目不仅实现了机动车检测、车牌识别，同时完成了如下交通场景功能。\n\n![1](基于Yolov4和Deepsort的智能交通场景应用/1.png)\n\n## 关键技术\n\n### 基于YOLO v4和Deep SORT的识别和跟踪\n\n![2](基于Yolov4和Deepsort的智能交通场景应用/2.png)\n\n* #### 车辆数据集单独训练\n\n本项目采用YOLOv4网络作为目标检测算法，采用Deep SORT网络作为多目标跟踪算法。我们使用KITTI训练集自己训练车辆数据集，该训练集可以识别80个不同的物体，能超实时地识别目标的类型。\n\n![3](基于Yolov4和Deepsort的智能交通场景应用/3.png)\n\n* #### 针对交通场景识别六类主流物体\n\n 应用在交通路口处理，可以识别人(person)、轿车(car)、货车(truck)、公交车(bus)、摩托车(motorbike)和红绿灯(traffic light)，并且将种类和置信度(CI)展示在视频处理结果中。\n\nYolov4基础模型和改进模型可以识别80类物体\n\n### 基于改进lPRnet和mtcnn的车牌识别\n\n这部分的操作是周哥主攻的哈，我们使用改进 MTCNN + SPL + LPRNet 结合的针对车牌识别的神经网络。可以到达实时的效果，并且车牌识别精度有所提高。\n\n经过自主改进的网络稳定性和识别能力大大增强，同时依旧维持了 LPRNet 的实时性。通过高效的动态规划对网络结果实时处理，是我们的算法兼顾可解释性和精度。在实践中，我们的车牌识别甚至可以实时对肉眼不可鉴别的目标作出准确识别。\n\n![4](基于Yolov4和Deepsort的智能交通场景应用/4.png)\n\n倾斜视角的车牌面积较小，将车牌变成正视图的视角后，车牌面积会增大，从而增加车牌的识别率。\n\n车牌校正\n\n设置resizing factor：\n\n![5](基于Yolov4和Deepsort的智能交通场景应用/5.png)\n\n### 基于透视变化的实时目标速度检测\n\n本项目利用基于透视变化的测速方法达到车辆测速目的\n\n问题：摄像头存在俯角\n\n将视频画面经过透视变换转换成俯视图，画面中所展示的视角和路面垂直，每像素所代表的实际物理距离保持固定不变，通过像素位移差和时间差计算目标速度。\n\n具体操作方法如下：首先，我们在原视频画面选取四个点，这四个点构成视频画面所记录的真实世界中的某个矩形顶点（如斑马线方格的四个顶点）。其次，我们在二维平面中选取构成同样像素大小的矩形的四个顶点。然后，根据前后各四个顶点的坐标，我们可以计算出从原图到俯视图的透视转换矩阵。在得到透视转换矩阵后，我们就可以将原视频画面的任意一个点坐标转换成俯视图中的点坐标。例如我们在原视频画面中选取目标在第**N**帧的坐标为(**Xn**、**Yn**)，目标第**M**帧的坐标为(**Xm**、**Ym**)，那么经过透视矩阵的转换，对应点在俯视图画面中的坐标分别为为(**Xn’**, **Yn’**)和(**Xm’**, **Ym’**)。然后，我们利用俯视图中两点的坐标计算车辆速度。由于俯视图中的每像素距离代表的实际物理距离是固定不变的，我们不妨假设为**W**，那么很容易得到目标车辆沿道路方向行驶的实际物理距离**s**。然后根据帧与帧的时间间隔得到第**N**帧到第**M**帧之间的时间**t**(**ms**)。最后，由于在较短时间内目标车辆的行驶可以看作匀速直线运动，那么我们可以利用速度公式（其中**fpst**代表一帧的时间间隔）：\n\n<center class=\"half\">    <img src=\"基于Yolov4和Deepsort的智能交通场景应用/51.png\" width=\"400\"/>    </center>\n\n\n\n<center class=\"half\">    <img src=\"基于Yolov4和Deepsort的智能交通场景应用/6.png\" width=\"400\"/>    </center>\n\n![7](基于Yolov4和Deepsort的智能交通场景应用/7.png)\n\n### 基于射线算法违章区域车辆检测\n\n我们基于Deep sort追踪的机动车违停技术：我们根据每个跟踪中心的位置，判断它是否停车和是否越线。在UI界面下手动圈选违章区域，然后通过判断跟踪中心的移动情况是否在违章停车区域，公交车道区域，来进行机动车和非机动车是否违章的判断。\n\n采用了射线法判断跟踪中心点是否在划定区域内，**射线法**就是以判断点开始，向右（或向左）的水平方向作一射线，计算该射线与多边形每条边的交点个数，如果交点个数为奇数，则点位于多边形内，偶数则在多边形外。该算法对于复合多边形也能正确判断。\n\n![8](基于Yolov4和Deepsort的智能交通场景应用/8.png)\n\n## 项目成果展示\n\n软件开发时间耗时6个月，算法模型历经了三次更新升级，最终在8月初完成最终模型。\n\n本项目于2020年5月收到计算机软件著作权登记证书，申请人为本次参赛的三位选手。目前已经开发出PC软件端。\n\n![9](基于Yolov4和Deepsort的智能交通场景应用/9.png)\n\n在PYQT封装后的整个文件夹大小为2.47GB，我们设计成了直接可以在windows电脑上运行的exe程序，我换了个图标大概长这样子。\n\n![10](基于Yolov4和Deepsort的智能交通场景应用/10.png)\n\n软件端的实测图片大概长这样：\n\n![11](基于Yolov4和Deepsort的智能交通场景应用/11.png)\n\n我放一个我们预先录制的答辩视频在这，可能会比较直观一点趴：\n\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\"          src=\"//player.bilibili.com/player.html?aid=971022307&bvid=BV1Qp4y1s7Xv&cid=279724597&page=1\"          scrolling=\"no\"          border=\"0\"          frameborder=\"no\"          framespacing=\"0\"          allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n\n## 后记\n\n关于中软杯的最后一场答辩已经过去了4个月了，还想得起来那是一个午后，中午饭我恰了一碗泡面。线上视频的这边是我和宇浩和涛哥三个人挤在宿舍里狭小的课桌前，对面是一群坐在敞亮大厅里的企业和高校的专家。放松心情，我们顺利地完成了比赛的答辩，没有正式的服装，甚至听不清评委问题的时候，我们三还做出奇怪的姿势，靠近笔记本电脑的音响。视频两头的气氛是完全不搭调，好在我们进了决赛第二轮，保底已经是二等奖，答辩的结果已经有底，整个过程还是极为放松。\n\n至于一等奖队伍确实也做了比我们更多的事，只是但从答辩过程来看，对他们的一些疑问依然存在于我们的脑海中。只是更好的结果对于我来说，也不是很重要了。这一段完整的比赛经历带给我的成长是毋庸置疑的，在收尾的时候感谢那段时间一起付出的队友们，大家都特别的给力，也感谢那段时间付出了心血的自己，没有那段熬夜的日子，应该也没有现在躺着度日的我。\n\n附奖状：\n\n![12](基于Yolov4和Deepsort的智能交通场景应用/12.png)","source":"_posts/基于Yolov4和Deepsort的智能交通场景应用.md","raw":"---\ntitle: 基于Yolov4和Deepsort的智能交通场景应用\ncatalog: true\ndate: 2021-01-27 11:58:51\nsubtitle: 中国软件杯参赛作品\ntop: 3\nheader-img: /img/header_img/vehicle.jpg\nmathjax: true\ntags:\n- Python\n- Pyqt5\ncategories:\n- 工程项目\n---\n\n> 在2019年的最后一个月开始尝试接触目标识别和跟踪的知识，那时候的我甚至连pycharm都没有用过，还不知道各个框架的概念。在盲目的代码复现和学习中，时间来到了2020年的三月份，了解到了中软杯的赛题，努力开始有了一个方向，也是我第一个负责和成功完成的项目。项目获得第九届中国软件杯大赛的全国二等奖，至于比赛的各种奇奇怪怪的事情我们暂且不用过多关注，最后能取得这么一个成绩，是我非常满意的。\n\n## 项目背景\n\n智慧交通建设是关系到我国国计民生的重要基础行业，我国政府对其发展极其重视。中共中央、国务院近两年先后颁布了《国家“物联网与智慧城市”研发计划2019年度项目申报指南》《关于进一步加快智慧城市建设的若干意见》等政策，明确提出推动大数据、信息共享和智慧社会的发展。\n\n基于对公共交通路口摄像头类似视角的影像数据进行处理，采用计算机视觉的算法对各种复杂的交通场景进行检测识别。项目使用计算机视觉技术打造了提供多功能智慧交通相关的软件。\n\n## 项目简介和功能描述\n\n本项目设计一种基于计算机视觉的智能摄像系统，运用了精确的单目标跟踪、多目标跟踪、实时目标识别、OCR技术、矩阵透视、射线法等多种技术，然后将技术整体展示，利用PYQT5开发出软件端，将数据可视化结果直接展示在用户眼前。\n\n中软杯官网赛题要求：\n\n* 程序实现基本的机动车检测、车牌识别和至少实现一种交通场景功能。\n* 该项目不仅实现了机动车检测、车牌识别，同时完成了如下交通场景功能。\n\n![1](基于Yolov4和Deepsort的智能交通场景应用/1.png)\n\n## 关键技术\n\n### 基于YOLO v4和Deep SORT的识别和跟踪\n\n![2](基于Yolov4和Deepsort的智能交通场景应用/2.png)\n\n* #### 车辆数据集单独训练\n\n本项目采用YOLOv4网络作为目标检测算法，采用Deep SORT网络作为多目标跟踪算法。我们使用KITTI训练集自己训练车辆数据集，该训练集可以识别80个不同的物体，能超实时地识别目标的类型。\n\n![3](基于Yolov4和Deepsort的智能交通场景应用/3.png)\n\n* #### 针对交通场景识别六类主流物体\n\n 应用在交通路口处理，可以识别人(person)、轿车(car)、货车(truck)、公交车(bus)、摩托车(motorbike)和红绿灯(traffic light)，并且将种类和置信度(CI)展示在视频处理结果中。\n\nYolov4基础模型和改进模型可以识别80类物体\n\n### 基于改进lPRnet和mtcnn的车牌识别\n\n这部分的操作是周哥主攻的哈，我们使用改进 MTCNN + SPL + LPRNet 结合的针对车牌识别的神经网络。可以到达实时的效果，并且车牌识别精度有所提高。\n\n经过自主改进的网络稳定性和识别能力大大增强，同时依旧维持了 LPRNet 的实时性。通过高效的动态规划对网络结果实时处理，是我们的算法兼顾可解释性和精度。在实践中，我们的车牌识别甚至可以实时对肉眼不可鉴别的目标作出准确识别。\n\n![4](基于Yolov4和Deepsort的智能交通场景应用/4.png)\n\n倾斜视角的车牌面积较小，将车牌变成正视图的视角后，车牌面积会增大，从而增加车牌的识别率。\n\n车牌校正\n\n设置resizing factor：\n\n![5](基于Yolov4和Deepsort的智能交通场景应用/5.png)\n\n### 基于透视变化的实时目标速度检测\n\n本项目利用基于透视变化的测速方法达到车辆测速目的\n\n问题：摄像头存在俯角\n\n将视频画面经过透视变换转换成俯视图，画面中所展示的视角和路面垂直，每像素所代表的实际物理距离保持固定不变，通过像素位移差和时间差计算目标速度。\n\n具体操作方法如下：首先，我们在原视频画面选取四个点，这四个点构成视频画面所记录的真实世界中的某个矩形顶点（如斑马线方格的四个顶点）。其次，我们在二维平面中选取构成同样像素大小的矩形的四个顶点。然后，根据前后各四个顶点的坐标，我们可以计算出从原图到俯视图的透视转换矩阵。在得到透视转换矩阵后，我们就可以将原视频画面的任意一个点坐标转换成俯视图中的点坐标。例如我们在原视频画面中选取目标在第**N**帧的坐标为(**Xn**、**Yn**)，目标第**M**帧的坐标为(**Xm**、**Ym**)，那么经过透视矩阵的转换，对应点在俯视图画面中的坐标分别为为(**Xn’**, **Yn’**)和(**Xm’**, **Ym’**)。然后，我们利用俯视图中两点的坐标计算车辆速度。由于俯视图中的每像素距离代表的实际物理距离是固定不变的，我们不妨假设为**W**，那么很容易得到目标车辆沿道路方向行驶的实际物理距离**s**。然后根据帧与帧的时间间隔得到第**N**帧到第**M**帧之间的时间**t**(**ms**)。最后，由于在较短时间内目标车辆的行驶可以看作匀速直线运动，那么我们可以利用速度公式（其中**fpst**代表一帧的时间间隔）：\n\n<center class=\"half\">    <img src=\"基于Yolov4和Deepsort的智能交通场景应用/51.png\" width=\"400\"/>    </center>\n\n\n\n<center class=\"half\">    <img src=\"基于Yolov4和Deepsort的智能交通场景应用/6.png\" width=\"400\"/>    </center>\n\n![7](基于Yolov4和Deepsort的智能交通场景应用/7.png)\n\n### 基于射线算法违章区域车辆检测\n\n我们基于Deep sort追踪的机动车违停技术：我们根据每个跟踪中心的位置，判断它是否停车和是否越线。在UI界面下手动圈选违章区域，然后通过判断跟踪中心的移动情况是否在违章停车区域，公交车道区域，来进行机动车和非机动车是否违章的判断。\n\n采用了射线法判断跟踪中心点是否在划定区域内，**射线法**就是以判断点开始，向右（或向左）的水平方向作一射线，计算该射线与多边形每条边的交点个数，如果交点个数为奇数，则点位于多边形内，偶数则在多边形外。该算法对于复合多边形也能正确判断。\n\n![8](基于Yolov4和Deepsort的智能交通场景应用/8.png)\n\n## 项目成果展示\n\n软件开发时间耗时6个月，算法模型历经了三次更新升级，最终在8月初完成最终模型。\n\n本项目于2020年5月收到计算机软件著作权登记证书，申请人为本次参赛的三位选手。目前已经开发出PC软件端。\n\n![9](基于Yolov4和Deepsort的智能交通场景应用/9.png)\n\n在PYQT封装后的整个文件夹大小为2.47GB，我们设计成了直接可以在windows电脑上运行的exe程序，我换了个图标大概长这样子。\n\n![10](基于Yolov4和Deepsort的智能交通场景应用/10.png)\n\n软件端的实测图片大概长这样：\n\n![11](基于Yolov4和Deepsort的智能交通场景应用/11.png)\n\n我放一个我们预先录制的答辩视频在这，可能会比较直观一点趴：\n\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\"          src=\"//player.bilibili.com/player.html?aid=971022307&bvid=BV1Qp4y1s7Xv&cid=279724597&page=1\"          scrolling=\"no\"          border=\"0\"          frameborder=\"no\"          framespacing=\"0\"          allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n\n## 后记\n\n关于中软杯的最后一场答辩已经过去了4个月了，还想得起来那是一个午后，中午饭我恰了一碗泡面。线上视频的这边是我和宇浩和涛哥三个人挤在宿舍里狭小的课桌前，对面是一群坐在敞亮大厅里的企业和高校的专家。放松心情，我们顺利地完成了比赛的答辩，没有正式的服装，甚至听不清评委问题的时候，我们三还做出奇怪的姿势，靠近笔记本电脑的音响。视频两头的气氛是完全不搭调，好在我们进了决赛第二轮，保底已经是二等奖，答辩的结果已经有底，整个过程还是极为放松。\n\n至于一等奖队伍确实也做了比我们更多的事，只是但从答辩过程来看，对他们的一些疑问依然存在于我们的脑海中。只是更好的结果对于我来说，也不是很重要了。这一段完整的比赛经历带给我的成长是毋庸置疑的，在收尾的时候感谢那段时间一起付出的队友们，大家都特别的给力，也感谢那段时间付出了心血的自己，没有那段熬夜的日子，应该也没有现在躺着度日的我。\n\n附奖状：\n\n![12](基于Yolov4和Deepsort的智能交通场景应用/12.png)","slug":"基于Yolov4和Deepsort的智能交通场景应用","published":1,"updated":"2022-01-13T09:01:16.414Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxwv000e3oueey4m5olg","content":"<blockquote>\n<p>在2019年的最后一个月开始尝试接触目标识别和跟踪的知识，那时候的我甚至连pycharm都没有用过，还不知道各个框架的概念。在盲目的代码复现和学习中，时间来到了2020年的三月份，了解到了中软杯的赛题，努力开始有了一个方向，也是我第一个负责和成功完成的项目。项目获得第九届中国软件杯大赛的全国二等奖，至于比赛的各种奇奇怪怪的事情我们暂且不用过多关注，最后能取得这么一个成绩，是我非常满意的。</p>\n</blockquote>\n<h2 id=\"项目背景\"><a href=\"#项目背景\" class=\"headerlink\" title=\"项目背景\"></a>项目背景</h2><p>智慧交通建设是关系到我国国计民生的重要基础行业，我国政府对其发展极其重视。中共中央、国务院近两年先后颁布了《国家“物联网与智慧城市”研发计划2019年度项目申报指南》《关于进一步加快智慧城市建设的若干意见》等政策，明确提出推动大数据、信息共享和智慧社会的发展。</p>\n<p>基于对公共交通路口摄像头类似视角的影像数据进行处理，采用计算机视觉的算法对各种复杂的交通场景进行检测识别。项目使用计算机视觉技术打造了提供多功能智慧交通相关的软件。</p>\n<h2 id=\"项目简介和功能描述\"><a href=\"#项目简介和功能描述\" class=\"headerlink\" title=\"项目简介和功能描述\"></a>项目简介和功能描述</h2><p>本项目设计一种基于计算机视觉的智能摄像系统，运用了精确的单目标跟踪、多目标跟踪、实时目标识别、OCR技术、矩阵透视、射线法等多种技术，然后将技术整体展示，利用PYQT5开发出软件端，将数据可视化结果直接展示在用户眼前。</p>\n<p>中软杯官网赛题要求：</p>\n<ul>\n<li>程序实现基本的机动车检测、车牌识别和至少实现一种交通场景功能。</li>\n<li>该项目不仅实现了机动车检测、车牌识别，同时完成了如下交通场景功能。</li>\n</ul>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/1.png\" alt=\"1\"></p>\n<h2 id=\"关键技术\"><a href=\"#关键技术\" class=\"headerlink\" title=\"关键技术\"></a>关键技术</h2><h3 id=\"基于YOLO-v4和Deep-SORT的识别和跟踪\"><a href=\"#基于YOLO-v4和Deep-SORT的识别和跟踪\" class=\"headerlink\" title=\"基于YOLO v4和Deep SORT的识别和跟踪\"></a>基于YOLO v4和Deep SORT的识别和跟踪</h3><p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/2.png\" alt=\"2\"></p>\n<ul>\n<li><h4 id=\"车辆数据集单独训练\"><a href=\"#车辆数据集单独训练\" class=\"headerlink\" title=\"车辆数据集单独训练\"></a>车辆数据集单独训练</h4></li>\n</ul>\n<p>本项目采用YOLOv4网络作为目标检测算法，采用Deep SORT网络作为多目标跟踪算法。我们使用KITTI训练集自己训练车辆数据集，该训练集可以识别80个不同的物体，能超实时地识别目标的类型。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/3.png\" alt=\"3\"></p>\n<ul>\n<li><h4 id=\"针对交通场景识别六类主流物体\"><a href=\"#针对交通场景识别六类主流物体\" class=\"headerlink\" title=\"针对交通场景识别六类主流物体\"></a>针对交通场景识别六类主流物体</h4><p>应用在交通路口处理，可以识别人(person)、轿车(car)、货车(truck)、公交车(bus)、摩托车(motorbike)和红绿灯(traffic light)，并且将种类和置信度(CI)展示在视频处理结果中。</p>\n</li>\n</ul>\n<p>Yolov4基础模型和改进模型可以识别80类物体</p>\n<h3 id=\"基于改进lPRnet和mtcnn的车牌识别\"><a href=\"#基于改进lPRnet和mtcnn的车牌识别\" class=\"headerlink\" title=\"基于改进lPRnet和mtcnn的车牌识别\"></a>基于改进lPRnet和mtcnn的车牌识别</h3><p>这部分的操作是周哥主攻的哈，我们使用改进 MTCNN + SPL + LPRNet 结合的针对车牌识别的神经网络。可以到达实时的效果，并且车牌识别精度有所提高。</p>\n<p>经过自主改进的网络稳定性和识别能力大大增强，同时依旧维持了 LPRNet 的实时性。通过高效的动态规划对网络结果实时处理，是我们的算法兼顾可解释性和精度。在实践中，我们的车牌识别甚至可以实时对肉眼不可鉴别的目标作出准确识别。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/4.png\" alt=\"4\"></p>\n<p>倾斜视角的车牌面积较小，将车牌变成正视图的视角后，车牌面积会增大，从而增加车牌的识别率。</p>\n<p>车牌校正</p>\n<p>设置resizing factor：</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/5.png\" alt=\"5\"></p>\n<h3 id=\"基于透视变化的实时目标速度检测\"><a href=\"#基于透视变化的实时目标速度检测\" class=\"headerlink\" title=\"基于透视变化的实时目标速度检测\"></a>基于透视变化的实时目标速度检测</h3><p>本项目利用基于透视变化的测速方法达到车辆测速目的</p>\n<p>问题：摄像头存在俯角</p>\n<p>将视频画面经过透视变换转换成俯视图，画面中所展示的视角和路面垂直，每像素所代表的实际物理距离保持固定不变，通过像素位移差和时间差计算目标速度。</p>\n<p>具体操作方法如下：首先，我们在原视频画面选取四个点，这四个点构成视频画面所记录的真实世界中的某个矩形顶点（如斑马线方格的四个顶点）。其次，我们在二维平面中选取构成同样像素大小的矩形的四个顶点。然后，根据前后各四个顶点的坐标，我们可以计算出从原图到俯视图的透视转换矩阵。在得到透视转换矩阵后，我们就可以将原视频画面的任意一个点坐标转换成俯视图中的点坐标。例如我们在原视频画面中选取目标在第<strong>N</strong>帧的坐标为(<strong>Xn</strong>、<strong>Yn</strong>)，目标第<strong>M</strong>帧的坐标为(<strong>Xm</strong>、<strong>Ym</strong>)，那么经过透视矩阵的转换，对应点在俯视图画面中的坐标分别为为(<strong>Xn’</strong>, <strong>Yn’</strong>)和(<strong>Xm’</strong>, <strong>Ym’</strong>)。然后，我们利用俯视图中两点的坐标计算车辆速度。由于俯视图中的每像素距离代表的实际物理距离是固定不变的，我们不妨假设为<strong>W</strong>，那么很容易得到目标车辆沿道路方向行驶的实际物理距离<strong>s</strong>。然后根据帧与帧的时间间隔得到第<strong>N</strong>帧到第<strong>M</strong>帧之间的时间<strong>t</strong>(<strong>ms</strong>)。最后，由于在较短时间内目标车辆的行驶可以看作匀速直线运动，那么我们可以利用速度公式（其中<strong>fpst</strong>代表一帧的时间间隔）：</p>\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/51.png\" width=\"400\">    </center>\n\n\n\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/6.png\" width=\"400\">    </center>\n\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/7.png\" alt=\"7\"></p>\n<h3 id=\"基于射线算法违章区域车辆检测\"><a href=\"#基于射线算法违章区域车辆检测\" class=\"headerlink\" title=\"基于射线算法违章区域车辆检测\"></a>基于射线算法违章区域车辆检测</h3><p>我们基于Deep sort追踪的机动车违停技术：我们根据每个跟踪中心的位置，判断它是否停车和是否越线。在UI界面下手动圈选违章区域，然后通过判断跟踪中心的移动情况是否在违章停车区域，公交车道区域，来进行机动车和非机动车是否违章的判断。</p>\n<p>采用了射线法判断跟踪中心点是否在划定区域内，<strong>射线法</strong>就是以判断点开始，向右（或向左）的水平方向作一射线，计算该射线与多边形每条边的交点个数，如果交点个数为奇数，则点位于多边形内，偶数则在多边形外。该算法对于复合多边形也能正确判断。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/8.png\" alt=\"8\"></p>\n<h2 id=\"项目成果展示\"><a href=\"#项目成果展示\" class=\"headerlink\" title=\"项目成果展示\"></a>项目成果展示</h2><p>软件开发时间耗时6个月，算法模型历经了三次更新升级，最终在8月初完成最终模型。</p>\n<p>本项目于2020年5月收到计算机软件著作权登记证书，申请人为本次参赛的三位选手。目前已经开发出PC软件端。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/9.png\" alt=\"9\"></p>\n<p>在PYQT封装后的整个文件夹大小为2.47GB，我们设计成了直接可以在windows电脑上运行的exe程序，我换了个图标大概长这样子。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/10.png\" alt=\"10\"></p>\n<p>软件端的实测图片大概长这样：</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/11.png\" alt=\"11\"></p>\n<p>我放一个我们预先录制的答辩视频在这，可能会比较直观一点趴：</p>\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\" src=\"//player.bilibili.com/player.html?aid=971022307&bvid=BV1Qp4y1s7Xv&cid=279724597&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>关于中软杯的最后一场答辩已经过去了4个月了，还想得起来那是一个午后，中午饭我恰了一碗泡面。线上视频的这边是我和宇浩和涛哥三个人挤在宿舍里狭小的课桌前，对面是一群坐在敞亮大厅里的企业和高校的专家。放松心情，我们顺利地完成了比赛的答辩，没有正式的服装，甚至听不清评委问题的时候，我们三还做出奇怪的姿势，靠近笔记本电脑的音响。视频两头的气氛是完全不搭调，好在我们进了决赛第二轮，保底已经是二等奖，答辩的结果已经有底，整个过程还是极为放松。</p>\n<p>至于一等奖队伍确实也做了比我们更多的事，只是但从答辩过程来看，对他们的一些疑问依然存在于我们的脑海中。只是更好的结果对于我来说，也不是很重要了。这一段完整的比赛经历带给我的成长是毋庸置疑的，在收尾的时候感谢那段时间一起付出的队友们，大家都特别的给力，也感谢那段时间付出了心血的自己，没有那段熬夜的日子，应该也没有现在躺着度日的我。</p>\n<p>附奖状：</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/12.png\" alt=\"12\"></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>在2019年的最后一个月开始尝试接触目标识别和跟踪的知识，那时候的我甚至连pycharm都没有用过，还不知道各个框架的概念。在盲目的代码复现和学习中，时间来到了2020年的三月份，了解到了中软杯的赛题，努力开始有了一个方向，也是我第一个负责和成功完成的项目。项目获得第九届中国软件杯大赛的全国二等奖，至于比赛的各种奇奇怪怪的事情我们暂且不用过多关注，最后能取得这么一个成绩，是我非常满意的。</p>\n</blockquote>\n<h2 id=\"项目背景\"><a href=\"#项目背景\" class=\"headerlink\" title=\"项目背景\"></a>项目背景</h2><p>智慧交通建设是关系到我国国计民生的重要基础行业，我国政府对其发展极其重视。中共中央、国务院近两年先后颁布了《国家“物联网与智慧城市”研发计划2019年度项目申报指南》《关于进一步加快智慧城市建设的若干意见》等政策，明确提出推动大数据、信息共享和智慧社会的发展。</p>\n<p>基于对公共交通路口摄像头类似视角的影像数据进行处理，采用计算机视觉的算法对各种复杂的交通场景进行检测识别。项目使用计算机视觉技术打造了提供多功能智慧交通相关的软件。</p>\n<h2 id=\"项目简介和功能描述\"><a href=\"#项目简介和功能描述\" class=\"headerlink\" title=\"项目简介和功能描述\"></a>项目简介和功能描述</h2><p>本项目设计一种基于计算机视觉的智能摄像系统，运用了精确的单目标跟踪、多目标跟踪、实时目标识别、OCR技术、矩阵透视、射线法等多种技术，然后将技术整体展示，利用PYQT5开发出软件端，将数据可视化结果直接展示在用户眼前。</p>\n<p>中软杯官网赛题要求：</p>\n<ul>\n<li>程序实现基本的机动车检测、车牌识别和至少实现一种交通场景功能。</li>\n<li>该项目不仅实现了机动车检测、车牌识别，同时完成了如下交通场景功能。</li>\n</ul>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/1.png\" alt=\"1\"></p>\n<h2 id=\"关键技术\"><a href=\"#关键技术\" class=\"headerlink\" title=\"关键技术\"></a>关键技术</h2><h3 id=\"基于YOLO-v4和Deep-SORT的识别和跟踪\"><a href=\"#基于YOLO-v4和Deep-SORT的识别和跟踪\" class=\"headerlink\" title=\"基于YOLO v4和Deep SORT的识别和跟踪\"></a>基于YOLO v4和Deep SORT的识别和跟踪</h3><p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/2.png\" alt=\"2\"></p>\n<ul>\n<li><h4 id=\"车辆数据集单独训练\"><a href=\"#车辆数据集单独训练\" class=\"headerlink\" title=\"车辆数据集单独训练\"></a>车辆数据集单独训练</h4></li>\n</ul>\n<p>本项目采用YOLOv4网络作为目标检测算法，采用Deep SORT网络作为多目标跟踪算法。我们使用KITTI训练集自己训练车辆数据集，该训练集可以识别80个不同的物体，能超实时地识别目标的类型。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/3.png\" alt=\"3\"></p>\n<ul>\n<li><h4 id=\"针对交通场景识别六类主流物体\"><a href=\"#针对交通场景识别六类主流物体\" class=\"headerlink\" title=\"针对交通场景识别六类主流物体\"></a>针对交通场景识别六类主流物体</h4><p>应用在交通路口处理，可以识别人(person)、轿车(car)、货车(truck)、公交车(bus)、摩托车(motorbike)和红绿灯(traffic light)，并且将种类和置信度(CI)展示在视频处理结果中。</p>\n</li>\n</ul>\n<p>Yolov4基础模型和改进模型可以识别80类物体</p>\n<h3 id=\"基于改进lPRnet和mtcnn的车牌识别\"><a href=\"#基于改进lPRnet和mtcnn的车牌识别\" class=\"headerlink\" title=\"基于改进lPRnet和mtcnn的车牌识别\"></a>基于改进lPRnet和mtcnn的车牌识别</h3><p>这部分的操作是周哥主攻的哈，我们使用改进 MTCNN + SPL + LPRNet 结合的针对车牌识别的神经网络。可以到达实时的效果，并且车牌识别精度有所提高。</p>\n<p>经过自主改进的网络稳定性和识别能力大大增强，同时依旧维持了 LPRNet 的实时性。通过高效的动态规划对网络结果实时处理，是我们的算法兼顾可解释性和精度。在实践中，我们的车牌识别甚至可以实时对肉眼不可鉴别的目标作出准确识别。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/4.png\" alt=\"4\"></p>\n<p>倾斜视角的车牌面积较小，将车牌变成正视图的视角后，车牌面积会增大，从而增加车牌的识别率。</p>\n<p>车牌校正</p>\n<p>设置resizing factor：</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/5.png\" alt=\"5\"></p>\n<h3 id=\"基于透视变化的实时目标速度检测\"><a href=\"#基于透视变化的实时目标速度检测\" class=\"headerlink\" title=\"基于透视变化的实时目标速度检测\"></a>基于透视变化的实时目标速度检测</h3><p>本项目利用基于透视变化的测速方法达到车辆测速目的</p>\n<p>问题：摄像头存在俯角</p>\n<p>将视频画面经过透视变换转换成俯视图，画面中所展示的视角和路面垂直，每像素所代表的实际物理距离保持固定不变，通过像素位移差和时间差计算目标速度。</p>\n<p>具体操作方法如下：首先，我们在原视频画面选取四个点，这四个点构成视频画面所记录的真实世界中的某个矩形顶点（如斑马线方格的四个顶点）。其次，我们在二维平面中选取构成同样像素大小的矩形的四个顶点。然后，根据前后各四个顶点的坐标，我们可以计算出从原图到俯视图的透视转换矩阵。在得到透视转换矩阵后，我们就可以将原视频画面的任意一个点坐标转换成俯视图中的点坐标。例如我们在原视频画面中选取目标在第<strong>N</strong>帧的坐标为(<strong>Xn</strong>、<strong>Yn</strong>)，目标第<strong>M</strong>帧的坐标为(<strong>Xm</strong>、<strong>Ym</strong>)，那么经过透视矩阵的转换，对应点在俯视图画面中的坐标分别为为(<strong>Xn’</strong>, <strong>Yn’</strong>)和(<strong>Xm’</strong>, <strong>Ym’</strong>)。然后，我们利用俯视图中两点的坐标计算车辆速度。由于俯视图中的每像素距离代表的实际物理距离是固定不变的，我们不妨假设为<strong>W</strong>，那么很容易得到目标车辆沿道路方向行驶的实际物理距离<strong>s</strong>。然后根据帧与帧的时间间隔得到第<strong>N</strong>帧到第<strong>M</strong>帧之间的时间<strong>t</strong>(<strong>ms</strong>)。最后，由于在较短时间内目标车辆的行驶可以看作匀速直线运动，那么我们可以利用速度公式（其中<strong>fpst</strong>代表一帧的时间间隔）：</p>\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/51.png\" width=\"400\">    </center>\n\n\n\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/6.png\" width=\"400\">    </center>\n\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/7.png\" alt=\"7\"></p>\n<h3 id=\"基于射线算法违章区域车辆检测\"><a href=\"#基于射线算法违章区域车辆检测\" class=\"headerlink\" title=\"基于射线算法违章区域车辆检测\"></a>基于射线算法违章区域车辆检测</h3><p>我们基于Deep sort追踪的机动车违停技术：我们根据每个跟踪中心的位置，判断它是否停车和是否越线。在UI界面下手动圈选违章区域，然后通过判断跟踪中心的移动情况是否在违章停车区域，公交车道区域，来进行机动车和非机动车是否违章的判断。</p>\n<p>采用了射线法判断跟踪中心点是否在划定区域内，<strong>射线法</strong>就是以判断点开始，向右（或向左）的水平方向作一射线，计算该射线与多边形每条边的交点个数，如果交点个数为奇数，则点位于多边形内，偶数则在多边形外。该算法对于复合多边形也能正确判断。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/8.png\" alt=\"8\"></p>\n<h2 id=\"项目成果展示\"><a href=\"#项目成果展示\" class=\"headerlink\" title=\"项目成果展示\"></a>项目成果展示</h2><p>软件开发时间耗时6个月，算法模型历经了三次更新升级，最终在8月初完成最终模型。</p>\n<p>本项目于2020年5月收到计算机软件著作权登记证书，申请人为本次参赛的三位选手。目前已经开发出PC软件端。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/9.png\" alt=\"9\"></p>\n<p>在PYQT封装后的整个文件夹大小为2.47GB，我们设计成了直接可以在windows电脑上运行的exe程序，我换了个图标大概长这样子。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/10.png\" alt=\"10\"></p>\n<p>软件端的实测图片大概长这样：</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/11.png\" alt=\"11\"></p>\n<p>我放一个我们预先录制的答辩视频在这，可能会比较直观一点趴：</p>\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\" src=\"//player.bilibili.com/player.html?aid=971022307&bvid=BV1Qp4y1s7Xv&cid=279724597&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\">     </iframe> \n</div>\n\n\n\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>关于中软杯的最后一场答辩已经过去了4个月了，还想得起来那是一个午后，中午饭我恰了一碗泡面。线上视频的这边是我和宇浩和涛哥三个人挤在宿舍里狭小的课桌前，对面是一群坐在敞亮大厅里的企业和高校的专家。放松心情，我们顺利地完成了比赛的答辩，没有正式的服装，甚至听不清评委问题的时候，我们三还做出奇怪的姿势，靠近笔记本电脑的音响。视频两头的气氛是完全不搭调，好在我们进了决赛第二轮，保底已经是二等奖，答辩的结果已经有底，整个过程还是极为放松。</p>\n<p>至于一等奖队伍确实也做了比我们更多的事，只是但从答辩过程来看，对他们的一些疑问依然存在于我们的脑海中。只是更好的结果对于我来说，也不是很重要了。这一段完整的比赛经历带给我的成长是毋庸置疑的，在收尾的时候感谢那段时间一起付出的队友们，大家都特别的给力，也感谢那段时间付出了心血的自己，没有那段熬夜的日子，应该也没有现在躺着度日的我。</p>\n<p>附奖状：</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8EYolov4%E5%92%8CDeepsort%E7%9A%84%E6%99%BA%E8%83%BD%E4%BA%A4%E9%80%9A%E5%9C%BA%E6%99%AF%E5%BA%94%E7%94%A8/12.png\" alt=\"12\"></p>\n"},{"title":"子空间学习(2)-LLE","catalog":true,"date":"2022-01-12T04:24:17.000Z","subtitle":"Subspace Learning-LLE","top":9,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Think Globally, Fit Locally- Unsupervised Learning of Low Dimensional Manifolds（2003 JMLR）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LLE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，Locally Linear Embedding（局部线性嵌入）是一种无监督学习算法，可计算高维输入的低维、邻域保留嵌入。 我们假设输入是从一个底层流形中采样的，并被映射到一个低维的单一全局坐标系中。 映射源自局部线性重建的对称性，嵌入的实际计算简化为稀疏特征值问题。 在本报告中，我们尝试以数学方式解释 LLE 的主要思想，并讨论 PCA 和 LLE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Question&Answer：\n\n## 假设\n\nLLE 假设数据是从平滑的底层流形中采样的，并且有足够的数据（使得流形采样良好）。具体来说，\n\n- 数据是从<u>光滑流形</u>中采样的，即数据是无限可微的。 光滑流形的一阶导数的连续性主要用于 LLE，即\n  $$\n  \\begin{aligned}\n          &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}=f_{\\left(x_{0}\\right)}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)} \\\\\n          &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}^{\\prime}=f_{\\left(x_{0}\\right)}^{\\prime}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)}^{\\prime}.\n      \\end{aligned}\n  $$\n\n- 数据采样良好意味着采样密度是每个数据点都具有 $2d$ 邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。\n\n## 解决的问题\n\nLLE 是一种降维算法，它计算高维数据的低维、邻域保留嵌入，即将从底层流形采样（带有噪声）的高维数据映射到低维的单个全局坐标系中。\n\n## 目标函数\n\nLLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：\n$$\n\\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \n    \\end{aligned}\\tag{1}\n$$\n\n$$\n\\text{ s.t. } \\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\\ \\sum_{j}W_{ij}=1\n$$\n\n\n\n## 逐字理解Locally Linear Embedding的含义\n\n### Locally\n\n\"Locally\"指的是**流形的局部不变性**。由流形的定义可知，流形中的每一点$X_{a}$都有一个邻域$X_{U(a)}$，这个邻域同胚于欧氏空间中的一个开集$W_{a}$，如下所示：\n$$\n\\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n})\n    \\end{gathered}\\tag{2}\n$$\n其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。更具体地说，LLE 中的“Locally”使用**KNN**为每个重建做出贡献。我们可以通过不同的测距方法获得数据点 $X_{i}$ 的 $k$ 最近邻居，例如由欧几里得距离测量，\n$$\n\\begin{gathered}\n        D_{i,j}\\!=\\!\\sqrt{(X_{i,1}\\!-\\!X_{j,1})^2\\!+\\!(X_{i,2}\\!-\\!X_{j,2})^2\\!+\\!\\cdots\\!+\\!(X_{i,D}\\!-\\!X_{j,D})^2}\\\\\n        sort(\\lbrace D_{i,j}|1\\leq i,j\\leq D\\rbrace),\n    \\end{gathered}\n$$\n其中 $D_{i,j}$ 表示 D 维向量 $X_{i}$ 和 $X_{j}$ 的距离。我们对$D_{i,j}$进行排序，得到$X_{i}$的$k$个最近邻，即选择$k$个最小的$D_{i,j}$。更进一步，我们将解释为什么可以使用欧几里得距离来确定不变场。\n\n公式（1）指我们可以用欧几里得空间中的坐标系$\\tau$来表示流形中$X_{a}$点的邻域。所以$\\tau$中点的欧几里德距离代表了点$X_{a}$与其在流形中的邻域之间的关系，即流形可以局部抽象为欧氏空间。然而，当邻域太大而不能被视为欧几里得空间时，局部不变性将失效。\n\n### Linear\n\n\"Linear\"指计算权重 $W_{ij}$ 最好从 $X_{i}$的邻居$X_{U(i)}$中线性重建数据点 $X_{i}$，即最小化约束的，线性的，目标函数，见等式：\n$$\n\\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\\tag{3}\n$$\n其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。 此外，我们解释了为什么我们需要约束 $\\sum_{j}W_{ij}=1$。约束是**平移不变性、旋转不变性和伸缩不变性**的必要条件，并且可以通过约束$\\sum_{j}W_{ij}=1$来使用<u>拉格朗日乘子法</u>来最小化重构误差。\n\n更进一步，我们给出了平移不变性、旋转不变性和伸缩不变性的证明。现在，我们证明平移不变性，看下面的推导，\n$$\n\\begin{aligned}\n        \\Phi(Y)&\\!=\\!\\sum_{i=1}^{N}\\left\\|Y_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} Y_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(Y_{i}\\!-\\!Y_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}((Y_{i}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2})\\!-\\!(Y_{ij}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2}))W_{ij}\\right\\|^{2}.\n    \\end{aligned}\\tag{4}\n$$\n其中 $\\frac{\\sum_{i}Y_{i}}{2}$ 是平移量。然后，我们根据方程证明旋转不变性和伸缩不变性，看下面的推导，\n$$\n\\begin{aligned}\n        \\Phi(AY)&=\\sum_{i}\\left\\|AY_{i}-\\sum_{j}W_{ij}AY_{ij}\\right\\|^2\\\\\n        &=\\sum_{i}\\left\\|\\sum_{j}W_{ij}(AY_{i}-AY_{ij})\\right\\|^2\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}A^{T}AY(I_{i}-W_{i})\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}Y(I_{i}-W_{i})=\\Phi(Y),\n    \\end{aligned}\\tag{5}\n$$\n其中 $A$ 是旋转（伸缩）和 $\\left|A\\right|=0$。因此，第二个约束通过将 $\\vec{Y}_{i}$ 约束为具有单位阵来消除旋转自由度。同时，第二个约束将比例固定为 d 维，即降维后的维度。\n\n### Embedding\n\nLLE 中的“Embedding”是指将高维数据点 $X_{i}$ 映射到低维嵌入坐标。 在这一步中，LLE 试图最小化重构损失，见等式，\n$$\n\\begin{gathered}\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text { s.t. } \\sum_{i=1}^{N} Y_{i}=0, \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\\tag{6}\n$$\n其中降维后的数据$Y$ 是由权重 $W$ 重建。 因此，输出 $Y_{i}$ 是高维输入 $X_{i}$ 的低维嵌入。 通过在不影响损失函数的情况下添加约束，目标函数具有唯一的全局最小值。 \n\n## 具体的推导过程\n\n在这一部分，我们展示了 LLE 解决方案的细节。我们可以转化(3)为具有两个变量和一个约束的优化问题，\n$$\n\\begin{aligned}\n        \\Phi(W)&\\!=\\!\\sum_{i=1}^{N}\\left\\|X_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} X_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(X_{i}\\!-\\!X_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right) W_{i}\\right\\|^{2}\\!\\! \\\\\n        &=\\!\\!\\sum_{i=1}^{N}W_{i}^{T}\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)^{T}\\!\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)W_{i}\\\\\n        &\\!=\\!\\sum_{i=1}^{N} W_{i}^{T} S_{i} w_{i},\\ S_{i}\\!=\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)^{T}\\!\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)\\\\\n        & \\text{ s.t. } W_{i}^{T}1_{k\\times 1}=1 ,\n    \\end{aligned}\\tag{7}\n$$\n其中 $X_{i\\times k}=\\underbrace{\\left[X_{i}, \\ldots, X_{i}\\right]}_{k}$ 和 $N_{i}=\\left[X_{i1 }, \\ldots, X_{ik}\\right]$。接下来，我们将<u>拉格朗日乘数法</u>应用于方程(7)，然后得到权重 $W=[W_{1}, W_{2}, \\cdots, W_{N}]$，见(8)，\n$$\n\\begin{aligned}\n        L(W_{i})&=\\sum_{i=1}^{N} W_{i}^{T} S_{i} W_{i}+\\lambda (W_{i}^{T}1_{k\\times 1}-1) \\\\\n        \\frac{\\partial L}{\\partial W_{i}}&=2S_{i}W_{i}+\\lambda 1_{k\\times 1}\\\\\n        W_{i}&=\\frac{S_{i}^{-1}1_{k\\times 1}}{1_{k\\times 1}^{T}S_{i}^{-1}1_{k\\times 1}}.\n    \\end{aligned}\\tag{8}\n$$\n此外，我们将使用重建权重 $W$ 来获得输出 $Y$。更进一步，我们转换优化公式(6)，\n$$\n\\begin{aligned}\n        \\Phi(Y)&= \\sum_{i}\\|Y_{i}-\\sum_{j}W_{ij}Y_{ij}\\|^2\\\\\n        &=\\sum_{i=1}^{N}\\|Y(I_{i}-W_{i})\\|^2\\\\\n        &=tr(Y(I-W)(I-W)^{T}Y^{T})\\\\\n        &=tr(YMY^{T}),\\ M=(I-W)(I-W)^{T}\n    \\end{aligned}\\tag{9}\n$$\n其中 $Y=[y_{1}, y_{2}, \\cdots, y_{N}]$, $\\mathbb{X}_{i}$ 是包含 $X_{i}$的$k$ 个最近邻居点的集合。然后利用公式（6）中的约束，我们可以通过拉格朗日乘子法和特征分解求解问题（9），见如下过程，\n$$\n \\begin{gathered}\n        L(Y)=YMY^{T}+\\lambda(YY^{T}-NI)\\\\\n        \\frac{\\partial L}{\\partial Y}=2MY^{T}+2\\lambda Y^{T}=0\\\\\n        MY^{T}=\\lambda^{-1}Y^{T}\\\\\n        sort(\\lambda^{-1}), \\ if\\ j<k,\\ then\\ \\lambda^{-1}_{j}<\\lambda^{-1}_{k}\\\\\n        Output=[Y_{1}, Y_{2}, \\cdots, Y_{d}].\n    \\end{gathered}\n$$\n\n## 讨论\n\n### PCA和LLE的区别\n\nPCA 和 LLE 都是降维方法。 但它们在动机、要解决的问题和目标函数上是不同的。 我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。 现在我们从 PCA 和 LLE 的不同动机开始解释。\n\nPCA 试图通过线性变换 $P$ 来降低数据的维度，即找到<u>正交基</u>来表示原始数据 $A$，目的是最大化降维后协方差矩阵的迹。目标函数如下：\n$$\n\\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}\n$$\n\n\nLLE 通过两个步骤来降低底层流形的维数：首先，计算高维数据的低维、邻域保留嵌入 $W$。其次，通过最小化损失函数方程得到输出 $Y$。目标函数在上面已经提过了。\n\n### LLE的优点\n\n- 保留高维空间中的局部线性关系。\n- 可以处理有非线性关系的数据。\n- 可以学习任何维度的局部线性低维流形。\n- 计算输出时可以进行稀疏矩阵特征分解，计算复杂度比较小。\n\n### LLE的缺点\n\n- LLE 只能用于非封闭流形，样本集需要密集均匀。\n- LLE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。\n\n## 实验效果(MNIST)\n\n由于Sklearn已经对LLE做了很多的优化，需要代码的朋友可以之间调库解决：\n\n```python\nfrom sklearn.manifold import LocallyLinearEmbedding\ndef LLE(test_data, train_data, component, neighbor):\n    solver=LocallyLinearEmbedding(n_components = component, n_neighbors = neighbor)\n    solver.fit(train_data)\n    return solver.transform(data)\n```\n展示一些实验结果，有可视化的降维结果。然后我们在MNIST数据集上，使用PCA和LLE把数据降到2维，展示了当**KNN**的$k=1$时，当LLE的参数$k$变化的时候，准确率的影响：\n\n<img src=\"子空间学习(2)-LLE\\LLE-Val.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Performance of LE on MNIST.</center>\n\n<img src=\"子空间学习(2)-LLE\\k.png\" alt=\"k\" style=\"zoom:72%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. PCA(Baseline)和LE在MNIST数据集上的效果对比。</center>\n\n# 总结\n\n很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。","source":"_posts/子空间学习(2)-LLE.md","raw":"---\ntitle: 子空间学习(2)-LLE\ncatalog: true\ndate: 2022-01-12 12:24:17\nsubtitle: Subspace Learning-LLE\ntop: 9\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Think Globally, Fit Locally- Unsupervised Learning of Low Dimensional Manifolds（2003 JMLR）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LLE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，Locally Linear Embedding（局部线性嵌入）是一种无监督学习算法，可计算高维输入的低维、邻域保留嵌入。 我们假设输入是从一个底层流形中采样的，并被映射到一个低维的单一全局坐标系中。 映射源自局部线性重建的对称性，嵌入的实际计算简化为稀疏特征值问题。 在本报告中，我们尝试以数学方式解释 LLE 的主要思想，并讨论 PCA 和 LLE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Question&Answer：\n\n## 假设\n\nLLE 假设数据是从平滑的底层流形中采样的，并且有足够的数据（使得流形采样良好）。具体来说，\n\n- 数据是从<u>光滑流形</u>中采样的，即数据是无限可微的。 光滑流形的一阶导数的连续性主要用于 LLE，即\n  $$\n  \\begin{aligned}\n          &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}=f_{\\left(x_{0}\\right)}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)} \\\\\n          &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}^{\\prime}=f_{\\left(x_{0}\\right)}^{\\prime}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)}^{\\prime}.\n      \\end{aligned}\n  $$\n\n- 数据采样良好意味着采样密度是每个数据点都具有 $2d$ 邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。\n\n## 解决的问题\n\nLLE 是一种降维算法，它计算高维数据的低维、邻域保留嵌入，即将从底层流形采样（带有噪声）的高维数据映射到低维的单个全局坐标系中。\n\n## 目标函数\n\nLLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：\n$$\n\\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \n    \\end{aligned}\\tag{1}\n$$\n\n$$\n\\text{ s.t. } \\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\\ \\sum_{j}W_{ij}=1\n$$\n\n\n\n## 逐字理解Locally Linear Embedding的含义\n\n### Locally\n\n\"Locally\"指的是**流形的局部不变性**。由流形的定义可知，流形中的每一点$X_{a}$都有一个邻域$X_{U(a)}$，这个邻域同胚于欧氏空间中的一个开集$W_{a}$，如下所示：\n$$\n\\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n})\n    \\end{gathered}\\tag{2}\n$$\n其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。更具体地说，LLE 中的“Locally”使用**KNN**为每个重建做出贡献。我们可以通过不同的测距方法获得数据点 $X_{i}$ 的 $k$ 最近邻居，例如由欧几里得距离测量，\n$$\n\\begin{gathered}\n        D_{i,j}\\!=\\!\\sqrt{(X_{i,1}\\!-\\!X_{j,1})^2\\!+\\!(X_{i,2}\\!-\\!X_{j,2})^2\\!+\\!\\cdots\\!+\\!(X_{i,D}\\!-\\!X_{j,D})^2}\\\\\n        sort(\\lbrace D_{i,j}|1\\leq i,j\\leq D\\rbrace),\n    \\end{gathered}\n$$\n其中 $D_{i,j}$ 表示 D 维向量 $X_{i}$ 和 $X_{j}$ 的距离。我们对$D_{i,j}$进行排序，得到$X_{i}$的$k$个最近邻，即选择$k$个最小的$D_{i,j}$。更进一步，我们将解释为什么可以使用欧几里得距离来确定不变场。\n\n公式（1）指我们可以用欧几里得空间中的坐标系$\\tau$来表示流形中$X_{a}$点的邻域。所以$\\tau$中点的欧几里德距离代表了点$X_{a}$与其在流形中的邻域之间的关系，即流形可以局部抽象为欧氏空间。然而，当邻域太大而不能被视为欧几里得空间时，局部不变性将失效。\n\n### Linear\n\n\"Linear\"指计算权重 $W_{ij}$ 最好从 $X_{i}$的邻居$X_{U(i)}$中线性重建数据点 $X_{i}$，即最小化约束的，线性的，目标函数，见等式：\n$$\n\\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\\tag{3}\n$$\n其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。 此外，我们解释了为什么我们需要约束 $\\sum_{j}W_{ij}=1$。约束是**平移不变性、旋转不变性和伸缩不变性**的必要条件，并且可以通过约束$\\sum_{j}W_{ij}=1$来使用<u>拉格朗日乘子法</u>来最小化重构误差。\n\n更进一步，我们给出了平移不变性、旋转不变性和伸缩不变性的证明。现在，我们证明平移不变性，看下面的推导，\n$$\n\\begin{aligned}\n        \\Phi(Y)&\\!=\\!\\sum_{i=1}^{N}\\left\\|Y_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} Y_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(Y_{i}\\!-\\!Y_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}((Y_{i}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2})\\!-\\!(Y_{ij}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2}))W_{ij}\\right\\|^{2}.\n    \\end{aligned}\\tag{4}\n$$\n其中 $\\frac{\\sum_{i}Y_{i}}{2}$ 是平移量。然后，我们根据方程证明旋转不变性和伸缩不变性，看下面的推导，\n$$\n\\begin{aligned}\n        \\Phi(AY)&=\\sum_{i}\\left\\|AY_{i}-\\sum_{j}W_{ij}AY_{ij}\\right\\|^2\\\\\n        &=\\sum_{i}\\left\\|\\sum_{j}W_{ij}(AY_{i}-AY_{ij})\\right\\|^2\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}A^{T}AY(I_{i}-W_{i})\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}Y(I_{i}-W_{i})=\\Phi(Y),\n    \\end{aligned}\\tag{5}\n$$\n其中 $A$ 是旋转（伸缩）和 $\\left|A\\right|=0$。因此，第二个约束通过将 $\\vec{Y}_{i}$ 约束为具有单位阵来消除旋转自由度。同时，第二个约束将比例固定为 d 维，即降维后的维度。\n\n### Embedding\n\nLLE 中的“Embedding”是指将高维数据点 $X_{i}$ 映射到低维嵌入坐标。 在这一步中，LLE 试图最小化重构损失，见等式，\n$$\n\\begin{gathered}\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text { s.t. } \\sum_{i=1}^{N} Y_{i}=0, \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\\tag{6}\n$$\n其中降维后的数据$Y$ 是由权重 $W$ 重建。 因此，输出 $Y_{i}$ 是高维输入 $X_{i}$ 的低维嵌入。 通过在不影响损失函数的情况下添加约束，目标函数具有唯一的全局最小值。 \n\n## 具体的推导过程\n\n在这一部分，我们展示了 LLE 解决方案的细节。我们可以转化(3)为具有两个变量和一个约束的优化问题，\n$$\n\\begin{aligned}\n        \\Phi(W)&\\!=\\!\\sum_{i=1}^{N}\\left\\|X_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} X_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(X_{i}\\!-\\!X_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right) W_{i}\\right\\|^{2}\\!\\! \\\\\n        &=\\!\\!\\sum_{i=1}^{N}W_{i}^{T}\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)^{T}\\!\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)W_{i}\\\\\n        &\\!=\\!\\sum_{i=1}^{N} W_{i}^{T} S_{i} w_{i},\\ S_{i}\\!=\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)^{T}\\!\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)\\\\\n        & \\text{ s.t. } W_{i}^{T}1_{k\\times 1}=1 ,\n    \\end{aligned}\\tag{7}\n$$\n其中 $X_{i\\times k}=\\underbrace{\\left[X_{i}, \\ldots, X_{i}\\right]}_{k}$ 和 $N_{i}=\\left[X_{i1 }, \\ldots, X_{ik}\\right]$。接下来，我们将<u>拉格朗日乘数法</u>应用于方程(7)，然后得到权重 $W=[W_{1}, W_{2}, \\cdots, W_{N}]$，见(8)，\n$$\n\\begin{aligned}\n        L(W_{i})&=\\sum_{i=1}^{N} W_{i}^{T} S_{i} W_{i}+\\lambda (W_{i}^{T}1_{k\\times 1}-1) \\\\\n        \\frac{\\partial L}{\\partial W_{i}}&=2S_{i}W_{i}+\\lambda 1_{k\\times 1}\\\\\n        W_{i}&=\\frac{S_{i}^{-1}1_{k\\times 1}}{1_{k\\times 1}^{T}S_{i}^{-1}1_{k\\times 1}}.\n    \\end{aligned}\\tag{8}\n$$\n此外，我们将使用重建权重 $W$ 来获得输出 $Y$。更进一步，我们转换优化公式(6)，\n$$\n\\begin{aligned}\n        \\Phi(Y)&= \\sum_{i}\\|Y_{i}-\\sum_{j}W_{ij}Y_{ij}\\|^2\\\\\n        &=\\sum_{i=1}^{N}\\|Y(I_{i}-W_{i})\\|^2\\\\\n        &=tr(Y(I-W)(I-W)^{T}Y^{T})\\\\\n        &=tr(YMY^{T}),\\ M=(I-W)(I-W)^{T}\n    \\end{aligned}\\tag{9}\n$$\n其中 $Y=[y_{1}, y_{2}, \\cdots, y_{N}]$, $\\mathbb{X}_{i}$ 是包含 $X_{i}$的$k$ 个最近邻居点的集合。然后利用公式（6）中的约束，我们可以通过拉格朗日乘子法和特征分解求解问题（9），见如下过程，\n$$\n \\begin{gathered}\n        L(Y)=YMY^{T}+\\lambda(YY^{T}-NI)\\\\\n        \\frac{\\partial L}{\\partial Y}=2MY^{T}+2\\lambda Y^{T}=0\\\\\n        MY^{T}=\\lambda^{-1}Y^{T}\\\\\n        sort(\\lambda^{-1}), \\ if\\ j<k,\\ then\\ \\lambda^{-1}_{j}<\\lambda^{-1}_{k}\\\\\n        Output=[Y_{1}, Y_{2}, \\cdots, Y_{d}].\n    \\end{gathered}\n$$\n\n## 讨论\n\n### PCA和LLE的区别\n\nPCA 和 LLE 都是降维方法。 但它们在动机、要解决的问题和目标函数上是不同的。 我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。 现在我们从 PCA 和 LLE 的不同动机开始解释。\n\nPCA 试图通过线性变换 $P$ 来降低数据的维度，即找到<u>正交基</u>来表示原始数据 $A$，目的是最大化降维后协方差矩阵的迹。目标函数如下：\n$$\n\\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}\n$$\n\n\nLLE 通过两个步骤来降低底层流形的维数：首先，计算高维数据的低维、邻域保留嵌入 $W$。其次，通过最小化损失函数方程得到输出 $Y$。目标函数在上面已经提过了。\n\n### LLE的优点\n\n- 保留高维空间中的局部线性关系。\n- 可以处理有非线性关系的数据。\n- 可以学习任何维度的局部线性低维流形。\n- 计算输出时可以进行稀疏矩阵特征分解，计算复杂度比较小。\n\n### LLE的缺点\n\n- LLE 只能用于非封闭流形，样本集需要密集均匀。\n- LLE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。\n\n## 实验效果(MNIST)\n\n由于Sklearn已经对LLE做了很多的优化，需要代码的朋友可以之间调库解决：\n\n```python\nfrom sklearn.manifold import LocallyLinearEmbedding\ndef LLE(test_data, train_data, component, neighbor):\n    solver=LocallyLinearEmbedding(n_components = component, n_neighbors = neighbor)\n    solver.fit(train_data)\n    return solver.transform(data)\n```\n展示一些实验结果，有可视化的降维结果。然后我们在MNIST数据集上，使用PCA和LLE把数据降到2维，展示了当**KNN**的$k=1$时，当LLE的参数$k$变化的时候，准确率的影响：\n\n<img src=\"子空间学习(2)-LLE\\LLE-Val.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Performance of LE on MNIST.</center>\n\n<img src=\"子空间学习(2)-LLE\\k.png\" alt=\"k\" style=\"zoom:72%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. PCA(Baseline)和LE在MNIST数据集上的效果对比。</center>\n\n# 总结\n\n很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。","slug":"子空间学习(2)-LLE","published":1,"updated":"2022-01-13T12:55:45.290Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxww000f3oueeq6b4ehi","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Think Globally, Fit Locally- Unsupervised Learning of Low Dimensional Manifolds（2003 JMLR）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LLE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，Locally Linear Embedding（局部线性嵌入）是一种无监督学习算法，可计算高维输入的低维、邻域保留嵌入。 我们假设输入是从一个底层流形中采样的，并被映射到一个低维的单一全局坐标系中。 映射源自局部线性重建的对称性，嵌入的实际计算简化为稀疏特征值问题。 在本报告中，我们尝试以数学方式解释 LLE 的主要思想，并讨论 PCA 和 LLE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Question-amp-Answer：\"><a href=\"#Question-amp-Answer：\" class=\"headerlink\" title=\"Question&amp;Answer：\"></a>Question&amp;Answer：</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><p>LLE 假设数据是从平滑的底层流形中采样的，并且有足够的数据（使得流形采样良好）。具体来说，</p>\n<ul>\n<li><p>数据是从<u>光滑流形</u>中采样的，即数据是无限可微的。 光滑流形的一阶导数的连续性主要用于 LLE，即</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}=f_{\\left(x_{0}\\right)}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)} \\\\\n        &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}^{\\prime}=f_{\\left(x_{0}\\right)}^{\\prime}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)}^{\\prime}.\n    \\end{aligned}</script></li>\n<li><p>数据采样良好意味着采样密度是每个数据点都具有 $2d$ 邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。</p>\n</li>\n</ul>\n<h2 id=\"解决的问题\"><a href=\"#解决的问题\" class=\"headerlink\" title=\"解决的问题\"></a>解决的问题</h2><p>LLE 是一种降维算法，它计算高维数据的低维、邻域保留嵌入，即将从底层流形采样（带有噪声）的高维数据映射到低维的单个全局坐标系中。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>LLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \n    \\end{aligned}\\tag{1}</script><script type=\"math/tex; mode=display\">\n\\text{ s.t. } \\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\\ \\sum_{j}W_{ij}=1</script><h2 id=\"逐字理解Locally-Linear-Embedding的含义\"><a href=\"#逐字理解Locally-Linear-Embedding的含义\" class=\"headerlink\" title=\"逐字理解Locally Linear Embedding的含义\"></a>逐字理解Locally Linear Embedding的含义</h2><h3 id=\"Locally\"><a href=\"#Locally\" class=\"headerlink\" title=\"Locally\"></a>Locally</h3><p>“Locally”指的是<strong>流形的局部不变性</strong>。由流形的定义可知，流形中的每一点$X_{a}$都有一个邻域$X_{U(a)}$，这个邻域同胚于欧氏空间中的一个开集$W_{a}$，如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n})\n    \\end{gathered}\\tag{2}</script><p>其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。更具体地说，LLE 中的“Locally”使用<strong>KNN</strong>为每个重建做出贡献。我们可以通过不同的测距方法获得数据点 $X_{i}$ 的 $k$ 最近邻居，例如由欧几里得距离测量，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        D_{i,j}\\!=\\!\\sqrt{(X_{i,1}\\!-\\!X_{j,1})^2\\!+\\!(X_{i,2}\\!-\\!X_{j,2})^2\\!+\\!\\cdots\\!+\\!(X_{i,D}\\!-\\!X_{j,D})^2}\\\\\n        sort(\\lbrace D_{i,j}|1\\leq i,j\\leq D\\rbrace),\n    \\end{gathered}</script><p>其中 $D_{i,j}$ 表示 D 维向量 $X_{i}$ 和 $X_{j}$ 的距离。我们对$D_{i,j}$进行排序，得到$X_{i}$的$k$个最近邻，即选择$k$个最小的$D_{i,j}$。更进一步，我们将解释为什么可以使用欧几里得距离来确定不变场。</p>\n<p>公式（1）指我们可以用欧几里得空间中的坐标系$\\tau$来表示流形中$X_{a}$点的邻域。所以$\\tau$中点的欧几里德距离代表了点$X_{a}$与其在流形中的邻域之间的关系，即流形可以局部抽象为欧氏空间。然而，当邻域太大而不能被视为欧几里得空间时，局部不变性将失效。</p>\n<h3 id=\"Linear\"><a href=\"#Linear\" class=\"headerlink\" title=\"Linear\"></a>Linear</h3><p>“Linear”指计算权重 $W_{ij}$ 最好从 $X_{i}$的邻居$X_{U(i)}$中线性重建数据点 $X_{i}$，即最小化约束的，线性的，目标函数，见等式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\\tag{3}</script><p>其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。 此外，我们解释了为什么我们需要约束 $\\sum_{j}W_{ij}=1$。约束是<strong>平移不变性、旋转不变性和伸缩不变性</strong>的必要条件，并且可以通过约束$\\sum_{j}W_{ij}=1$来使用<u>拉格朗日乘子法</u>来最小化重构误差。</p>\n<p>更进一步，我们给出了平移不变性、旋转不变性和伸缩不变性的证明。现在，我们证明平移不变性，看下面的推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(Y)&\\!=\\!\\sum_{i=1}^{N}\\left\\|Y_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} Y_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(Y_{i}\\!-\\!Y_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}((Y_{i}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2})\\!-\\!(Y_{ij}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2}))W_{ij}\\right\\|^{2}.\n    \\end{aligned}\\tag{4}</script><p>其中 $\\frac{\\sum_{i}Y_{i}}{2}$ 是平移量。然后，我们根据方程证明旋转不变性和伸缩不变性，看下面的推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(AY)&=\\sum_{i}\\left\\|AY_{i}-\\sum_{j}W_{ij}AY_{ij}\\right\\|^2\\\\\n        &=\\sum_{i}\\left\\|\\sum_{j}W_{ij}(AY_{i}-AY_{ij})\\right\\|^2\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}A^{T}AY(I_{i}-W_{i})\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}Y(I_{i}-W_{i})=\\Phi(Y),\n    \\end{aligned}\\tag{5}</script><p>其中 $A$ 是旋转（伸缩）和 $\\left|A\\right|=0$。因此，第二个约束通过将 $\\vec{Y}_{i}$ 约束为具有单位阵来消除旋转自由度。同时，第二个约束将比例固定为 d 维，即降维后的维度。</p>\n<h3 id=\"Embedding\"><a href=\"#Embedding\" class=\"headerlink\" title=\"Embedding\"></a>Embedding</h3><p>LLE 中的“Embedding”是指将高维数据点 $X_{i}$ 映射到低维嵌入坐标。 在这一步中，LLE 试图最小化重构损失，见等式，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text { s.t. } \\sum_{i=1}^{N} Y_{i}=0, \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\\tag{6}</script><p>其中降维后的数据$Y$ 是由权重 $W$ 重建。 因此，输出 $Y_{i}$ 是高维输入 $X_{i}$ 的低维嵌入。 通过在不影响损失函数的情况下添加约束，目标函数具有唯一的全局最小值。 </p>\n<h2 id=\"具体的推导过程\"><a href=\"#具体的推导过程\" class=\"headerlink\" title=\"具体的推导过程\"></a>具体的推导过程</h2><p>在这一部分，我们展示了 LLE 解决方案的细节。我们可以转化(3)为具有两个变量和一个约束的优化问题，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(W)&\\!=\\!\\sum_{i=1}^{N}\\left\\|X_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} X_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(X_{i}\\!-\\!X_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right) W_{i}\\right\\|^{2}\\!\\! \\\\\n        &=\\!\\!\\sum_{i=1}^{N}W_{i}^{T}\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)^{T}\\!\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)W_{i}\\\\\n        &\\!=\\!\\sum_{i=1}^{N} W_{i}^{T} S_{i} w_{i},\\ S_{i}\\!=\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)^{T}\\!\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)\\\\\n        & \\text{ s.t. } W_{i}^{T}1_{k\\times 1}=1 ,\n    \\end{aligned}\\tag{7}</script><p>其中 $X_{i\\times k}=\\underbrace{\\left[X_{i}, \\ldots, X_{i}\\right]}_{k}$ 和 $N_{i}=\\left[X_{i1 }, \\ldots, X_{ik}\\right]$。接下来，我们将<u>拉格朗日乘数法</u>应用于方程(7)，然后得到权重 $W=[W_{1}, W_{2}, \\cdots, W_{N}]$，见(8)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        L(W_{i})&=\\sum_{i=1}^{N} W_{i}^{T} S_{i} W_{i}+\\lambda (W_{i}^{T}1_{k\\times 1}-1) \\\\\n        \\frac{\\partial L}{\\partial W_{i}}&=2S_{i}W_{i}+\\lambda 1_{k\\times 1}\\\\\n        W_{i}&=\\frac{S_{i}^{-1}1_{k\\times 1}}{1_{k\\times 1}^{T}S_{i}^{-1}1_{k\\times 1}}.\n    \\end{aligned}\\tag{8}</script><p>此外，我们将使用重建权重 $W$ 来获得输出 $Y$。更进一步，我们转换优化公式(6)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(Y)&= \\sum_{i}\\|Y_{i}-\\sum_{j}W_{ij}Y_{ij}\\|^2\\\\\n        &=\\sum_{i=1}^{N}\\|Y(I_{i}-W_{i})\\|^2\\\\\n        &=tr(Y(I-W)(I-W)^{T}Y^{T})\\\\\n        &=tr(YMY^{T}),\\ M=(I-W)(I-W)^{T}\n    \\end{aligned}\\tag{9}</script><p>其中 $Y=[y_{1}, y_{2}, \\cdots, y_{N}]$, $\\mathbb{X}_{i}$ 是包含 $X_{i}$的$k$ 个最近邻居点的集合。然后利用公式（6）中的约束，我们可以通过拉格朗日乘子法和特征分解求解问题（9），见如下过程，</p>\n<script type=\"math/tex; mode=display\">\n \\begin{gathered}\n        L(Y)=YMY^{T}+\\lambda(YY^{T}-NI)\\\\\n        \\frac{\\partial L}{\\partial Y}=2MY^{T}+2\\lambda Y^{T}=0\\\\\n        MY^{T}=\\lambda^{-1}Y^{T}\\\\\n        sort(\\lambda^{-1}), \\ if\\ j<k,\\ then\\ \\lambda^{-1}_{j}<\\lambda^{-1}_{k}\\\\\n        Output=[Y_{1}, Y_{2}, \\cdots, Y_{d}].\n    \\end{gathered}</script><h2 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h2><h3 id=\"PCA和LLE的区别\"><a href=\"#PCA和LLE的区别\" class=\"headerlink\" title=\"PCA和LLE的区别\"></a>PCA和LLE的区别</h3><p>PCA 和 LLE 都是降维方法。 但它们在动机、要解决的问题和目标函数上是不同的。 我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。 现在我们从 PCA 和 LLE 的不同动机开始解释。</p>\n<p>PCA 试图通过线性变换 $P$ 来降低数据的维度，即找到<u>正交基</u>来表示原始数据 $A$，目的是最大化降维后协方差矩阵的迹。目标函数如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}</script><p>LLE 通过两个步骤来降低底层流形的维数：首先，计算高维数据的低维、邻域保留嵌入 $W$。其次，通过最小化损失函数方程得到输出 $Y$。目标函数在上面已经提过了。</p>\n<h3 id=\"LLE的优点\"><a href=\"#LLE的优点\" class=\"headerlink\" title=\"LLE的优点\"></a>LLE的优点</h3><ul>\n<li>保留高维空间中的局部线性关系。</li>\n<li>可以处理有非线性关系的数据。</li>\n<li>可以学习任何维度的局部线性低维流形。</li>\n<li>计算输出时可以进行稀疏矩阵特征分解，计算复杂度比较小。</li>\n</ul>\n<h3 id=\"LLE的缺点\"><a href=\"#LLE的缺点\" class=\"headerlink\" title=\"LLE的缺点\"></a>LLE的缺点</h3><ul>\n<li>LLE 只能用于非封闭流形，样本集需要密集均匀。</li>\n<li>LLE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。</li>\n</ul>\n<h2 id=\"实验效果-MNIST\"><a href=\"#实验效果-MNIST\" class=\"headerlink\" title=\"实验效果(MNIST)\"></a>实验效果(MNIST)</h2><p>由于Sklearn已经对LLE做了很多的优化，需要代码的朋友可以之间调库解决：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> LocallyLinearEmbedding</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LLE</span>(<span class=\"params\">test_data, train_data, component, neighbor</span>):</span></span><br><span class=\"line\">    solver=LocallyLinearEmbedding(n_components = component, n_neighbors = neighbor)</span><br><span class=\"line\">    solver.fit(train_data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> solver.transform(data)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，有可视化的降维结果。然后我们在MNIST数据集上，使用PCA和LLE把数据降到2维，展示了当<strong>KNN</strong>的$k=1$时，当LLE的参数$k$变化的时候，准确率的影响：</p>\n<p><img src=\"/2022/01/12/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(2)-LLE/LLE-Val.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Performance of LE on MNIST.</center>\n\n<p><img src=\"/2022/01/12/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(2)-LLE/k.png\" alt=\"k\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. PCA(Baseline)和LE在MNIST数据集上的效果对比。</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Think Globally, Fit Locally- Unsupervised Learning of Low Dimensional Manifolds（2003 JMLR）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LLE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，Locally Linear Embedding（局部线性嵌入）是一种无监督学习算法，可计算高维输入的低维、邻域保留嵌入。 我们假设输入是从一个底层流形中采样的，并被映射到一个低维的单一全局坐标系中。 映射源自局部线性重建的对称性，嵌入的实际计算简化为稀疏特征值问题。 在本报告中，我们尝试以数学方式解释 LLE 的主要思想，并讨论 PCA 和 LLE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Question-amp-Answer：\"><a href=\"#Question-amp-Answer：\" class=\"headerlink\" title=\"Question&amp;Answer：\"></a>Question&amp;Answer：</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><p>LLE 假设数据是从平滑的底层流形中采样的，并且有足够的数据（使得流形采样良好）。具体来说，</p>\n<ul>\n<li><p>数据是从<u>光滑流形</u>中采样的，即数据是无限可微的。 光滑流形的一阶导数的连续性主要用于 LLE，即</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}=f_{\\left(x_{0}\\right)}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)} \\\\\n        &\\lim _{x \\rightarrow x_{0}^{-}} f_{(x)}^{\\prime}=f_{\\left(x_{0}\\right)}^{\\prime}=\\lim _{x \\rightarrow x_{0}^{+}} f_{(x)}^{\\prime}.\n    \\end{aligned}</script></li>\n<li><p>数据采样良好意味着采样密度是每个数据点都具有 $2d$ 邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。</p>\n</li>\n</ul>\n<h2 id=\"解决的问题\"><a href=\"#解决的问题\" class=\"headerlink\" title=\"解决的问题\"></a>解决的问题</h2><p>LLE 是一种降维算法，它计算高维数据的低维、邻域保留嵌入，即将从底层流形采样（带有噪声）的高维数据映射到低维的单个全局坐标系中。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>LLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \n    \\end{aligned}\\tag{1}</script><script type=\"math/tex; mode=display\">\n\\text{ s.t. } \\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\\ \\sum_{j}W_{ij}=1</script><h2 id=\"逐字理解Locally-Linear-Embedding的含义\"><a href=\"#逐字理解Locally-Linear-Embedding的含义\" class=\"headerlink\" title=\"逐字理解Locally Linear Embedding的含义\"></a>逐字理解Locally Linear Embedding的含义</h2><h3 id=\"Locally\"><a href=\"#Locally\" class=\"headerlink\" title=\"Locally\"></a>Locally</h3><p>“Locally”指的是<strong>流形的局部不变性</strong>。由流形的定义可知，流形中的每一点$X_{a}$都有一个邻域$X_{U(a)}$，这个邻域同胚于欧氏空间中的一个开集$W_{a}$，如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n})\n    \\end{gathered}\\tag{2}</script><p>其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。更具体地说，LLE 中的“Locally”使用<strong>KNN</strong>为每个重建做出贡献。我们可以通过不同的测距方法获得数据点 $X_{i}$ 的 $k$ 最近邻居，例如由欧几里得距离测量，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        D_{i,j}\\!=\\!\\sqrt{(X_{i,1}\\!-\\!X_{j,1})^2\\!+\\!(X_{i,2}\\!-\\!X_{j,2})^2\\!+\\!\\cdots\\!+\\!(X_{i,D}\\!-\\!X_{j,D})^2}\\\\\n        sort(\\lbrace D_{i,j}|1\\leq i,j\\leq D\\rbrace),\n    \\end{gathered}</script><p>其中 $D_{i,j}$ 表示 D 维向量 $X_{i}$ 和 $X_{j}$ 的距离。我们对$D_{i,j}$进行排序，得到$X_{i}$的$k$个最近邻，即选择$k$个最小的$D_{i,j}$。更进一步，我们将解释为什么可以使用欧几里得距离来确定不变场。</p>\n<p>公式（1）指我们可以用欧几里得空间中的坐标系$\\tau$来表示流形中$X_{a}$点的邻域。所以$\\tau$中点的欧几里德距离代表了点$X_{a}$与其在流形中的邻域之间的关系，即流形可以局部抽象为欧氏空间。然而，当邻域太大而不能被视为欧几里得空间时，局部不变性将失效。</p>\n<h3 id=\"Linear\"><a href=\"#Linear\" class=\"headerlink\" title=\"Linear\"></a>Linear</h3><p>“Linear”指计算权重 $W_{ij}$ 最好从 $X_{i}$的邻居$X_{U(i)}$中线性重建数据点 $X_{i}$，即最小化约束的，线性的，目标函数，见等式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\\tag{3}</script><p>其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。 此外，我们解释了为什么我们需要约束 $\\sum_{j}W_{ij}=1$。约束是<strong>平移不变性、旋转不变性和伸缩不变性</strong>的必要条件，并且可以通过约束$\\sum_{j}W_{ij}=1$来使用<u>拉格朗日乘子法</u>来最小化重构误差。</p>\n<p>更进一步，我们给出了平移不变性、旋转不变性和伸缩不变性的证明。现在，我们证明平移不变性，看下面的推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(Y)&\\!=\\!\\sum_{i=1}^{N}\\left\\|Y_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} Y_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(Y_{i}\\!-\\!Y_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}((Y_{i}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2})\\!-\\!(Y_{ij}\\!-\\!\\frac{\\sum_{i}Y_{i}}{2}))W_{ij}\\right\\|^{2}.\n    \\end{aligned}\\tag{4}</script><p>其中 $\\frac{\\sum_{i}Y_{i}}{2}$ 是平移量。然后，我们根据方程证明旋转不变性和伸缩不变性，看下面的推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(AY)&=\\sum_{i}\\left\\|AY_{i}-\\sum_{j}W_{ij}AY_{ij}\\right\\|^2\\\\\n        &=\\sum_{i}\\left\\|\\sum_{j}W_{ij}(AY_{i}-AY_{ij})\\right\\|^2\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}A^{T}AY(I_{i}-W_{i})\\\\\n        &=\\sum_{i}(I_{i}-W_{i})^{T}Y^{T}Y(I_{i}-W_{i})=\\Phi(Y),\n    \\end{aligned}\\tag{5}</script><p>其中 $A$ 是旋转（伸缩）和 $\\left|A\\right|=0$。因此，第二个约束通过将 $\\vec{Y}_{i}$ 约束为具有单位阵来消除旋转自由度。同时，第二个约束将比例固定为 d 维，即降维后的维度。</p>\n<h3 id=\"Embedding\"><a href=\"#Embedding\" class=\"headerlink\" title=\"Embedding\"></a>Embedding</h3><p>LLE 中的“Embedding”是指将高维数据点 $X_{i}$ 映射到低维嵌入坐标。 在这一步中，LLE 试图最小化重构损失，见等式，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text { s.t. } \\sum_{i=1}^{N} Y_{i}=0, \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\\tag{6}</script><p>其中降维后的数据$Y$ 是由权重 $W$ 重建。 因此，输出 $Y_{i}$ 是高维输入 $X_{i}$ 的低维嵌入。 通过在不影响损失函数的情况下添加约束，目标函数具有唯一的全局最小值。 </p>\n<h2 id=\"具体的推导过程\"><a href=\"#具体的推导过程\" class=\"headerlink\" title=\"具体的推导过程\"></a>具体的推导过程</h2><p>在这一部分，我们展示了 LLE 解决方案的细节。我们可以转化(3)为具有两个变量和一个约束的优化问题，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(W)&\\!=\\!\\sum_{i=1}^{N}\\left\\|X_{i}\\!-\\!\\sum_{j=1}^{k} W_{ij} X_{ij}\\right\\|^{2}\\!=\\!\\sum_{i=1}^{N}\\left\\|\\sum_{j=1}^{k}\\left(X_{i}\\!-\\!X_{ij}\\right) W_{ij}\\right\\|^{2} \\\\\n        &\\!=\\!\\sum_{i=1}^{N}\\left\\|\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right) W_{i}\\right\\|^{2}\\!\\! \\\\\n        &=\\!\\!\\sum_{i=1}^{N}W_{i}^{T}\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)^{T}\\!\\!\\!\\left(X_{i\\times k}\\!\\!-\\!\\!N_{i}\\right)W_{i}\\\\\n        &\\!=\\!\\sum_{i=1}^{N} W_{i}^{T} S_{i} w_{i},\\ S_{i}\\!=\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)^{T}\\!\\!\\left(X_{i\\times k}\\!-\\!N_{i}\\right)\\\\\n        & \\text{ s.t. } W_{i}^{T}1_{k\\times 1}=1 ,\n    \\end{aligned}\\tag{7}</script><p>其中 $X_{i\\times k}=\\underbrace{\\left[X_{i}, \\ldots, X_{i}\\right]}_{k}$ 和 $N_{i}=\\left[X_{i1 }, \\ldots, X_{ik}\\right]$。接下来，我们将<u>拉格朗日乘数法</u>应用于方程(7)，然后得到权重 $W=[W_{1}, W_{2}, \\cdots, W_{N}]$，见(8)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        L(W_{i})&=\\sum_{i=1}^{N} W_{i}^{T} S_{i} W_{i}+\\lambda (W_{i}^{T}1_{k\\times 1}-1) \\\\\n        \\frac{\\partial L}{\\partial W_{i}}&=2S_{i}W_{i}+\\lambda 1_{k\\times 1}\\\\\n        W_{i}&=\\frac{S_{i}^{-1}1_{k\\times 1}}{1_{k\\times 1}^{T}S_{i}^{-1}1_{k\\times 1}}.\n    \\end{aligned}\\tag{8}</script><p>此外，我们将使用重建权重 $W$ 来获得输出 $Y$。更进一步，我们转换优化公式(6)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        \\Phi(Y)&= \\sum_{i}\\|Y_{i}-\\sum_{j}W_{ij}Y_{ij}\\|^2\\\\\n        &=\\sum_{i=1}^{N}\\|Y(I_{i}-W_{i})\\|^2\\\\\n        &=tr(Y(I-W)(I-W)^{T}Y^{T})\\\\\n        &=tr(YMY^{T}),\\ M=(I-W)(I-W)^{T}\n    \\end{aligned}\\tag{9}</script><p>其中 $Y=[y_{1}, y_{2}, \\cdots, y_{N}]$, $\\mathbb{X}_{i}$ 是包含 $X_{i}$的$k$ 个最近邻居点的集合。然后利用公式（6）中的约束，我们可以通过拉格朗日乘子法和特征分解求解问题（9），见如下过程，</p>\n<script type=\"math/tex; mode=display\">\n \\begin{gathered}\n        L(Y)=YMY^{T}+\\lambda(YY^{T}-NI)\\\\\n        \\frac{\\partial L}{\\partial Y}=2MY^{T}+2\\lambda Y^{T}=0\\\\\n        MY^{T}=\\lambda^{-1}Y^{T}\\\\\n        sort(\\lambda^{-1}), \\ if\\ j<k,\\ then\\ \\lambda^{-1}_{j}<\\lambda^{-1}_{k}\\\\\n        Output=[Y_{1}, Y_{2}, \\cdots, Y_{d}].\n    \\end{gathered}</script><h2 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h2><h3 id=\"PCA和LLE的区别\"><a href=\"#PCA和LLE的区别\" class=\"headerlink\" title=\"PCA和LLE的区别\"></a>PCA和LLE的区别</h3><p>PCA 和 LLE 都是降维方法。 但它们在动机、要解决的问题和目标函数上是不同的。 我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。 现在我们从 PCA 和 LLE 的不同动机开始解释。</p>\n<p>PCA 试图通过线性变换 $P$ 来降低数据的维度，即找到<u>正交基</u>来表示原始数据 $A$，目的是最大化降维后协方差矩阵的迹。目标函数如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}</script><p>LLE 通过两个步骤来降低底层流形的维数：首先，计算高维数据的低维、邻域保留嵌入 $W$。其次，通过最小化损失函数方程得到输出 $Y$。目标函数在上面已经提过了。</p>\n<h3 id=\"LLE的优点\"><a href=\"#LLE的优点\" class=\"headerlink\" title=\"LLE的优点\"></a>LLE的优点</h3><ul>\n<li>保留高维空间中的局部线性关系。</li>\n<li>可以处理有非线性关系的数据。</li>\n<li>可以学习任何维度的局部线性低维流形。</li>\n<li>计算输出时可以进行稀疏矩阵特征分解，计算复杂度比较小。</li>\n</ul>\n<h3 id=\"LLE的缺点\"><a href=\"#LLE的缺点\" class=\"headerlink\" title=\"LLE的缺点\"></a>LLE的缺点</h3><ul>\n<li>LLE 只能用于非封闭流形，样本集需要密集均匀。</li>\n<li>LLE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。</li>\n</ul>\n<h2 id=\"实验效果-MNIST\"><a href=\"#实验效果-MNIST\" class=\"headerlink\" title=\"实验效果(MNIST)\"></a>实验效果(MNIST)</h2><p>由于Sklearn已经对LLE做了很多的优化，需要代码的朋友可以之间调库解决：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> LocallyLinearEmbedding</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LLE</span>(<span class=\"params\">test_data, train_data, component, neighbor</span>):</span></span><br><span class=\"line\">    solver=LocallyLinearEmbedding(n_components = component, n_neighbors = neighbor)</span><br><span class=\"line\">    solver.fit(train_data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> solver.transform(data)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，有可视化的降维结果。然后我们在MNIST数据集上，使用PCA和LLE把数据降到2维，展示了当<strong>KNN</strong>的$k=1$时，当LLE的参数$k$变化的时候，准确率的影响：</p>\n<p><img src=\"/2022/01/12/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(2)-LLE/LLE-Val.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Performance of LE on MNIST.</center>\n\n<p><img src=\"/2022/01/12/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(2)-LLE/k.png\" alt=\"k\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. PCA(Baseline)和LE在MNIST数据集上的效果对比。</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。</p>\n"},{"title":"基于改进Mobilenetv2的东北虎识别平台","catalog":true,"date":"2021-01-27T14:53:27.000Z","subtitle":"人工智能创意赛参赛作品","top":5,"header-img":"/img/header_img/tiger.png","_content":"\n\n\n> \n>\n> 项目基于从ABS拿到的东北虎数据集而建立，改进基于PaddlePaddle 的Mobilenetv2 模型并使用Django 搭建实时的野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。和另外两位队友在短时间之内搭建的平台，最终在人工智能创意赛的全国决赛取得了三等奖的成绩，但是这个成绩好像并不重要哈哈。浙江三日游成为了在疫情笼罩下的2020年少有的精彩回忆之一，也是2020年的一个转折点吧。\n\n\n\n## 项目简介\n\n本项目应用方向是野生动物保护，我们团队基于百度飞桨平台开发野生东北虎的识别与监测系统。通过自主收集的东北虎数据集完成模型训练。在未来该平台将于与摄像系统结合，广泛应用于野生动物自然保护区，结合大数据、人工智能等进一步对东北虎个体及其他物种进行目标识别、数量统计、实时监测，位置记录，有效地进行东北虎的监测与保护工作。\n\n![2](基于改进Mobilenetv2的东北虎识别平台/2.png)\n\n## 项目技术内容\n\n### 数据集\n\n我们在学校实验室的支持下，结合互联网和实地考察，我们收集并创建了自主的东北虎数据集，一共有4621张图片，使用labelme标注东北虎框一共7321个。\n\n![3](基于改进Mobilenetv2的东北虎识别平台/3.png)\n\n### 项目实现思路\n\n考虑到我们是一个实时的监测平台，对预测速度有一定的要求，并且需要模型易于部署，我们选择了基于Mobilenet v2的改进模型。本项目可分为两部分组成，一是通过基于改进Mobilenet v2的目标识别模型，二是基于Django搭建起来的实时野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。\n\n![4](基于改进Mobilenetv2的东北虎识别平台/4.png)\n\n### 算法改进\n\n![5](基于改进Mobilenetv2的东北虎识别平台/5.png)\n\n\n\n传统的 SSD 网络在提取的特征图上直接进行回归和分类，易造成目标的分类定位错误而降低检测的准确率。SSD 算法用低层特征图检测小目标，高层特征图检测大目标，低层卷积层分辨率高但语义信息低、感受野较小，小目标特征提取不充分；高层卷积层语义信息充分、感受野较大，可提取更多特征信息。\n\n![6](基于改进Mobilenetv2的东北虎识别平台/6.png)\n\n针对这个问题，我们将 RPN 网络引入进 SSD 网络，使用传输转换模块将两个网络相连接，从而构建出一种新的SSD网络。同时继承一步式和两步式检测方法的优点，在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，传输给SSD网络。在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，集成大规模上下文信息，增大感受野，增加低层网络的语义信息，提高检测精度。\n\n这一步骤有效地删除一些负样本先验框，减小分类器的搜索范围，降低目标分类或定位的错误率，为 SSD网络的回归操作提供更好的前提条件。\n\n在特征融合上，在MobileNetv2模型的基础框架上，对 Conv3_3、Conv4_3、fc7、Conv6_1、Conv7_1、Conv9_2 特征层，用 padding=0 的 1×1 卷积核做卷积操作，保证了融合时的通道统一，然后使用双线性插值使特征图大小统一。最后采用连接融合的方式得到了不同大小的特征图，改进后的模型较MobileNetv2模型的特征层语义信息更丰富，能更好地表达目标特征。\n\n同时为了增强浅层网络对小目标的检测能力。我们将 Smin 和 Smax 的值调整为 0.15，0.95，预测框的IOU 设置为 0.45，NMS 设置为 0.4，这样能够有效避免由于目标过小导致在训练阶段，真实标签无法找到相应地先验框与之匹配的问题。\n\n### 算法对比\n\n![7](基于改进Mobilenetv2的东北虎识别平台/7.png)\n\n![8](基于改进Mobilenetv2的东北虎识别平台/8.png)\n\n在算法对比中可以看到，迭代 1 万次时，MobileNetv2网络的准确率只有78.62%，而改进后的网络准确率可达到 83.26%，迭代 6 万次逐渐趋于稳定，但是改进后的网络准确率始终高于原网络，最高可达90.86%。\n\n我们用同一数据集进行了横向对比，改进后的网络 mAP 为91.86%。相比于Faster R-CNN 模型，检测精度提升了 10.26%；相比于 YOLO V4模型，检测精度提高了2.97%，检测速度提高了7.3FPS；相比于MobileNetv2模型，检测精度提高了 5.12%。\n\n### 成果展示\n\n#### 园区监控终端\n\n基于我们训练得到的模型，我们搭建了适用于自然保护区的智能监测平台。我们将通过规划后在区域内设置一定数量的摄像头用于实时监测，摄像头将搭载我们训练的识别模型，进行实时的识别和跟踪，标记出被识别的目标，并将信息传输给后台，供工作人员查看数据。\n\n![9](基于改进Mobilenetv2的东北虎识别平台/9.png)\n\n<center class=\"half\">    <img src=\"基于改进Mobilenetv2的东北虎识别平台/10.png\" width=\"500\"/>   </center>\n\n\n\n同时，系统会对识别到的东北虎进行持续的标记跟踪，密切关注每一只东北虎个体，记录其基本情况。通过串联园区内各个位置的摄像头，系统会自动绘制园区内每只东北虎的行为轨迹图，并以地图可视化的方式展现出来。一旦摄像头监测到东北虎出现异常状况或行为轨迹图可疑，系统将自动上报给后台工作人员，以便及时处理。\n\n<center class=\"half\">    <img src=\"基于改进Mobilenetv2的东北虎识别平台/11.png\" width=\"500\"/>    <img src=\"基于改进Mobilenetv2的东北虎识别平台/12.png\" width=\"500\"/> </center>\n\n#### 一些展望\n\n完成该项目所需要的技术算是比较基础的，而在我们的前期调查中发现，相关的产品并没有广泛应用于自然保护区和动物园，不知道是出于成本的原因还是什么。我认为相关的产品或是项目可以广泛应用于各个自然保护区，基于不同的数据集，对不同种类的动物进行监测。如果可以争取与政府的动物保护部门达成合作，以进行进一步的推广，弥补现有的市场空缺，从而广泛应用国内各类自然保护区中。\n\n对于野生动物的纪录片拍摄以及各种野生动物科研，这样的系统依然有着非常显著的作用。我们可以利用相关系统更快地找到野生动物的栖息地和活动轨迹，以便于更好的拍摄和研究。同时大大减少了相关人员花在寻找东北虎的时间和精力上，大大加快了效率。\n\n想法是好的，希望在未来的日子里中可以有人能够实现这样的想法。\n\n## 关于人工智能创意赛\n\n### GEEK YOUTH集训营\n\n2020年参加了很多的比赛哈，人工智能创意赛是我个人认为主办方非常良心的比赛之一。在得知了我们进入全国决赛之后，百度公司举行了GEEK YOUTH线上集训营，三天的讲解可谓是收获满满，请到了非常多很厉害的教授，我们也可以直面Paddlepaddle的技术人员，深入了解这个平台。如果没有疫情，应该会飞去北京参加线下的集训营，又是一场三天的白嫖旅行，也算蛮可惜的。因为可能记笔记比较认真，在最后的时候也作为代表表达了自己对集训营的一些看法，照片吗，网上好像直接搜我名字能搜到就不贴了。\n\n最后也收到了来自组委会的两波良心大礼包，赞:slightly_smiling_face:\n\n![14](基于改进Mobilenetv2的东北虎识别平台/14.jpeg)\n\n![15](基于改进Mobilenetv2的东北虎识别平台/15.jpg)\n\n### 杭州决赛行\n\n在第一天下飞机之后，我们来到了决赛举办的酒店，感觉应该是个旅游度假村，面积和江安的宿舍区有得一比。组委会安排住的是1500一天的别墅啊啊啊啊啊啊，直接震惊到爆炸，来几张图表示敬意。中午去恰了杭帮菜还算不错，下午逛了逛酒店，整个度假村的风景还算蛮不错的，本来两人一间房，但是我的室友并没有来（一人一间房很爽），于是便有了后来的夜宵局哈哈。\n\n整个决赛显得非常的专业，来了很多专业的教授和院士，现在想来没有去问问保研信息还蛮后悔的。在经历了第二天一整天紧张刺激的答辩(吹牛)后(下午溜出去到西湖玩了)，本来想去体验一下杭州的夜生活，奈何晚上九点街上就已经空空荡荡，于是小酌两杯后回到了酒店。结果在阿杜的鼓吹下，氪了一手原神，本来是钟离的up池，没想到保底出了一发七七，孙宝的运气可不是人人都有，生活总会有点意外。\n\n第三天在杭州的机器人小镇举行了颁奖仪式，颁奖典礼后便是一个峰会，还是认真听了一部分，机器人小镇的很多东西也蛮好玩的。第三天晚上参加了晚宴，非常豪华，本来和uncle说的是想和班主任小姐姐合张影，后来又怂了。当天成都发生了五角星事件还一度担心能不能正常回学校，而第四天中午便乘飞机回了学校，过程也挺顺畅。\n\n杭州行并没有留下什么谈得上的遗憾，留下了一堆不成文的照片。\n\n![16](基于改进Mobilenetv2的东北虎识别平台/16.jpg)\n\n![17](基于改进Mobilenetv2的东北虎识别平台/17.jpg)\n\n![18](基于改进Mobilenetv2的东北虎识别平台/18.jpg)\n\n![19](基于改进Mobilenetv2的东北虎识别平台/19.jpg)\n\n![20](基于改进Mobilenetv2的东北虎识别平台/20.jpg)\n\n![21](基于改进Mobilenetv2的东北虎识别平台/21.jpg)\n\n![24](基于改进Mobilenetv2的东北虎识别平台/24.jpg)\n\n![25](基于改进Mobilenetv2的东北虎识别平台/25.jpg)\n\n![26](基于改进Mobilenetv2的东北虎识别平台/26.jpg)\n\n![27](基于改进Mobilenetv2的东北虎识别平台/27.jpg)\n\n![28](基于改进Mobilenetv2的东北虎识别平台/28.jpg)\n\n![29](基于改进Mobilenetv2的东北虎识别平台/29.jpg)\n\n## 后记\n\n感谢两位队友uncle悦和阿杜的付出，这个项目并没有花费我们太多的时间，所以最终能拿到这样的结果也算非常满意了。同时我们也明白了，在与其他学校的项目对比中，我们由于从来没有接触过硬件相关的知识，也没有硬件可以展示，在PK中会显得比较薄弱，这可能也是纯软件的一些弱势吧，希望在之后的学习中能够接触到有关硬件的一些知识，得到一些进步。\n\n最后附上参赛作品的三分钟链接，阿杜在寝室剪辑的，现在看上去确实还蛮憨憨的，纪念意义还是拉满：\n\n[SCUCS_01](https://www.bilibili.com/video/BV1PX4y1K7TC)：https://www.bilibili.com/video/BV1PX4y1K7TC\n\n\n\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\"          src=\"//player.bilibili.com/player.html?aid=713571339&bvid=BV1PX4y1K7TC&cid=279720799&page=1\"          scrolling=\"no\"          border=\"0\"          frameborder=\"no\"          framespacing=\"0\"          allowfullscreen=\"true\">     </iframe> \n</div>\n\n","source":"_posts/基于改进Mobilenetv2的东北虎识别平台.md","raw":"---\ntitle: 基于改进Mobilenetv2的东北虎识别平台\ncatalog: true\ndate: 2021-01-27 22:53:27\nsubtitle: 人工智能创意赛参赛作品\ntop: 5\nheader-img: /img/header_img/tiger.png\ntags:\n- Python\n- Django\ncategories:\n- 算法改进\n\n---\n\n\n\n> \n>\n> 项目基于从ABS拿到的东北虎数据集而建立，改进基于PaddlePaddle 的Mobilenetv2 模型并使用Django 搭建实时的野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。和另外两位队友在短时间之内搭建的平台，最终在人工智能创意赛的全国决赛取得了三等奖的成绩，但是这个成绩好像并不重要哈哈。浙江三日游成为了在疫情笼罩下的2020年少有的精彩回忆之一，也是2020年的一个转折点吧。\n\n\n\n## 项目简介\n\n本项目应用方向是野生动物保护，我们团队基于百度飞桨平台开发野生东北虎的识别与监测系统。通过自主收集的东北虎数据集完成模型训练。在未来该平台将于与摄像系统结合，广泛应用于野生动物自然保护区，结合大数据、人工智能等进一步对东北虎个体及其他物种进行目标识别、数量统计、实时监测，位置记录，有效地进行东北虎的监测与保护工作。\n\n![2](基于改进Mobilenetv2的东北虎识别平台/2.png)\n\n## 项目技术内容\n\n### 数据集\n\n我们在学校实验室的支持下，结合互联网和实地考察，我们收集并创建了自主的东北虎数据集，一共有4621张图片，使用labelme标注东北虎框一共7321个。\n\n![3](基于改进Mobilenetv2的东北虎识别平台/3.png)\n\n### 项目实现思路\n\n考虑到我们是一个实时的监测平台，对预测速度有一定的要求，并且需要模型易于部署，我们选择了基于Mobilenet v2的改进模型。本项目可分为两部分组成，一是通过基于改进Mobilenet v2的目标识别模型，二是基于Django搭建起来的实时野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。\n\n![4](基于改进Mobilenetv2的东北虎识别平台/4.png)\n\n### 算法改进\n\n![5](基于改进Mobilenetv2的东北虎识别平台/5.png)\n\n\n\n传统的 SSD 网络在提取的特征图上直接进行回归和分类，易造成目标的分类定位错误而降低检测的准确率。SSD 算法用低层特征图检测小目标，高层特征图检测大目标，低层卷积层分辨率高但语义信息低、感受野较小，小目标特征提取不充分；高层卷积层语义信息充分、感受野较大，可提取更多特征信息。\n\n![6](基于改进Mobilenetv2的东北虎识别平台/6.png)\n\n针对这个问题，我们将 RPN 网络引入进 SSD 网络，使用传输转换模块将两个网络相连接，从而构建出一种新的SSD网络。同时继承一步式和两步式检测方法的优点，在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，传输给SSD网络。在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，集成大规模上下文信息，增大感受野，增加低层网络的语义信息，提高检测精度。\n\n这一步骤有效地删除一些负样本先验框，减小分类器的搜索范围，降低目标分类或定位的错误率，为 SSD网络的回归操作提供更好的前提条件。\n\n在特征融合上，在MobileNetv2模型的基础框架上，对 Conv3_3、Conv4_3、fc7、Conv6_1、Conv7_1、Conv9_2 特征层，用 padding=0 的 1×1 卷积核做卷积操作，保证了融合时的通道统一，然后使用双线性插值使特征图大小统一。最后采用连接融合的方式得到了不同大小的特征图，改进后的模型较MobileNetv2模型的特征层语义信息更丰富，能更好地表达目标特征。\n\n同时为了增强浅层网络对小目标的检测能力。我们将 Smin 和 Smax 的值调整为 0.15，0.95，预测框的IOU 设置为 0.45，NMS 设置为 0.4，这样能够有效避免由于目标过小导致在训练阶段，真实标签无法找到相应地先验框与之匹配的问题。\n\n### 算法对比\n\n![7](基于改进Mobilenetv2的东北虎识别平台/7.png)\n\n![8](基于改进Mobilenetv2的东北虎识别平台/8.png)\n\n在算法对比中可以看到，迭代 1 万次时，MobileNetv2网络的准确率只有78.62%，而改进后的网络准确率可达到 83.26%，迭代 6 万次逐渐趋于稳定，但是改进后的网络准确率始终高于原网络，最高可达90.86%。\n\n我们用同一数据集进行了横向对比，改进后的网络 mAP 为91.86%。相比于Faster R-CNN 模型，检测精度提升了 10.26%；相比于 YOLO V4模型，检测精度提高了2.97%，检测速度提高了7.3FPS；相比于MobileNetv2模型，检测精度提高了 5.12%。\n\n### 成果展示\n\n#### 园区监控终端\n\n基于我们训练得到的模型，我们搭建了适用于自然保护区的智能监测平台。我们将通过规划后在区域内设置一定数量的摄像头用于实时监测，摄像头将搭载我们训练的识别模型，进行实时的识别和跟踪，标记出被识别的目标，并将信息传输给后台，供工作人员查看数据。\n\n![9](基于改进Mobilenetv2的东北虎识别平台/9.png)\n\n<center class=\"half\">    <img src=\"基于改进Mobilenetv2的东北虎识别平台/10.png\" width=\"500\"/>   </center>\n\n\n\n同时，系统会对识别到的东北虎进行持续的标记跟踪，密切关注每一只东北虎个体，记录其基本情况。通过串联园区内各个位置的摄像头，系统会自动绘制园区内每只东北虎的行为轨迹图，并以地图可视化的方式展现出来。一旦摄像头监测到东北虎出现异常状况或行为轨迹图可疑，系统将自动上报给后台工作人员，以便及时处理。\n\n<center class=\"half\">    <img src=\"基于改进Mobilenetv2的东北虎识别平台/11.png\" width=\"500\"/>    <img src=\"基于改进Mobilenetv2的东北虎识别平台/12.png\" width=\"500\"/> </center>\n\n#### 一些展望\n\n完成该项目所需要的技术算是比较基础的，而在我们的前期调查中发现，相关的产品并没有广泛应用于自然保护区和动物园，不知道是出于成本的原因还是什么。我认为相关的产品或是项目可以广泛应用于各个自然保护区，基于不同的数据集，对不同种类的动物进行监测。如果可以争取与政府的动物保护部门达成合作，以进行进一步的推广，弥补现有的市场空缺，从而广泛应用国内各类自然保护区中。\n\n对于野生动物的纪录片拍摄以及各种野生动物科研，这样的系统依然有着非常显著的作用。我们可以利用相关系统更快地找到野生动物的栖息地和活动轨迹，以便于更好的拍摄和研究。同时大大减少了相关人员花在寻找东北虎的时间和精力上，大大加快了效率。\n\n想法是好的，希望在未来的日子里中可以有人能够实现这样的想法。\n\n## 关于人工智能创意赛\n\n### GEEK YOUTH集训营\n\n2020年参加了很多的比赛哈，人工智能创意赛是我个人认为主办方非常良心的比赛之一。在得知了我们进入全国决赛之后，百度公司举行了GEEK YOUTH线上集训营，三天的讲解可谓是收获满满，请到了非常多很厉害的教授，我们也可以直面Paddlepaddle的技术人员，深入了解这个平台。如果没有疫情，应该会飞去北京参加线下的集训营，又是一场三天的白嫖旅行，也算蛮可惜的。因为可能记笔记比较认真，在最后的时候也作为代表表达了自己对集训营的一些看法，照片吗，网上好像直接搜我名字能搜到就不贴了。\n\n最后也收到了来自组委会的两波良心大礼包，赞:slightly_smiling_face:\n\n![14](基于改进Mobilenetv2的东北虎识别平台/14.jpeg)\n\n![15](基于改进Mobilenetv2的东北虎识别平台/15.jpg)\n\n### 杭州决赛行\n\n在第一天下飞机之后，我们来到了决赛举办的酒店，感觉应该是个旅游度假村，面积和江安的宿舍区有得一比。组委会安排住的是1500一天的别墅啊啊啊啊啊啊，直接震惊到爆炸，来几张图表示敬意。中午去恰了杭帮菜还算不错，下午逛了逛酒店，整个度假村的风景还算蛮不错的，本来两人一间房，但是我的室友并没有来（一人一间房很爽），于是便有了后来的夜宵局哈哈。\n\n整个决赛显得非常的专业，来了很多专业的教授和院士，现在想来没有去问问保研信息还蛮后悔的。在经历了第二天一整天紧张刺激的答辩(吹牛)后(下午溜出去到西湖玩了)，本来想去体验一下杭州的夜生活，奈何晚上九点街上就已经空空荡荡，于是小酌两杯后回到了酒店。结果在阿杜的鼓吹下，氪了一手原神，本来是钟离的up池，没想到保底出了一发七七，孙宝的运气可不是人人都有，生活总会有点意外。\n\n第三天在杭州的机器人小镇举行了颁奖仪式，颁奖典礼后便是一个峰会，还是认真听了一部分，机器人小镇的很多东西也蛮好玩的。第三天晚上参加了晚宴，非常豪华，本来和uncle说的是想和班主任小姐姐合张影，后来又怂了。当天成都发生了五角星事件还一度担心能不能正常回学校，而第四天中午便乘飞机回了学校，过程也挺顺畅。\n\n杭州行并没有留下什么谈得上的遗憾，留下了一堆不成文的照片。\n\n![16](基于改进Mobilenetv2的东北虎识别平台/16.jpg)\n\n![17](基于改进Mobilenetv2的东北虎识别平台/17.jpg)\n\n![18](基于改进Mobilenetv2的东北虎识别平台/18.jpg)\n\n![19](基于改进Mobilenetv2的东北虎识别平台/19.jpg)\n\n![20](基于改进Mobilenetv2的东北虎识别平台/20.jpg)\n\n![21](基于改进Mobilenetv2的东北虎识别平台/21.jpg)\n\n![24](基于改进Mobilenetv2的东北虎识别平台/24.jpg)\n\n![25](基于改进Mobilenetv2的东北虎识别平台/25.jpg)\n\n![26](基于改进Mobilenetv2的东北虎识别平台/26.jpg)\n\n![27](基于改进Mobilenetv2的东北虎识别平台/27.jpg)\n\n![28](基于改进Mobilenetv2的东北虎识别平台/28.jpg)\n\n![29](基于改进Mobilenetv2的东北虎识别平台/29.jpg)\n\n## 后记\n\n感谢两位队友uncle悦和阿杜的付出，这个项目并没有花费我们太多的时间，所以最终能拿到这样的结果也算非常满意了。同时我们也明白了，在与其他学校的项目对比中，我们由于从来没有接触过硬件相关的知识，也没有硬件可以展示，在PK中会显得比较薄弱，这可能也是纯软件的一些弱势吧，希望在之后的学习中能够接触到有关硬件的一些知识，得到一些进步。\n\n最后附上参赛作品的三分钟链接，阿杜在寝室剪辑的，现在看上去确实还蛮憨憨的，纪念意义还是拉满：\n\n[SCUCS_01](https://www.bilibili.com/video/BV1PX4y1K7TC)：https://www.bilibili.com/video/BV1PX4y1K7TC\n\n\n\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\"          src=\"//player.bilibili.com/player.html?aid=713571339&bvid=BV1PX4y1K7TC&cid=279720799&page=1\"          scrolling=\"no\"          border=\"0\"          frameborder=\"no\"          framespacing=\"0\"          allowfullscreen=\"true\">     </iframe> \n</div>\n\n","slug":"基于改进Mobilenetv2的东北虎识别平台","published":1,"updated":"2022-01-13T09:01:17.853Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxwz000j3ouegyh635hz","content":"<blockquote>\n<p>项目基于从ABS拿到的东北虎数据集而建立，改进基于PaddlePaddle 的Mobilenetv2 模型并使用Django 搭建实时的野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。和另外两位队友在短时间之内搭建的平台，最终在人工智能创意赛的全国决赛取得了三等奖的成绩，但是这个成绩好像并不重要哈哈。浙江三日游成为了在疫情笼罩下的2020年少有的精彩回忆之一，也是2020年的一个转折点吧。</p>\n</blockquote>\n<h2 id=\"项目简介\"><a href=\"#项目简介\" class=\"headerlink\" title=\"项目简介\"></a>项目简介</h2><p>本项目应用方向是野生动物保护，我们团队基于百度飞桨平台开发野生东北虎的识别与监测系统。通过自主收集的东北虎数据集完成模型训练。在未来该平台将于与摄像系统结合，广泛应用于野生动物自然保护区，结合大数据、人工智能等进一步对东北虎个体及其他物种进行目标识别、数量统计、实时监测，位置记录，有效地进行东北虎的监测与保护工作。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/2.png\" alt=\"2\"></p>\n<h2 id=\"项目技术内容\"><a href=\"#项目技术内容\" class=\"headerlink\" title=\"项目技术内容\"></a>项目技术内容</h2><h3 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h3><p>我们在学校实验室的支持下，结合互联网和实地考察，我们收集并创建了自主的东北虎数据集，一共有4621张图片，使用labelme标注东北虎框一共7321个。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/3.png\" alt=\"3\"></p>\n<h3 id=\"项目实现思路\"><a href=\"#项目实现思路\" class=\"headerlink\" title=\"项目实现思路\"></a>项目实现思路</h3><p>考虑到我们是一个实时的监测平台，对预测速度有一定的要求，并且需要模型易于部署，我们选择了基于Mobilenet v2的改进模型。本项目可分为两部分组成，一是通过基于改进Mobilenet v2的目标识别模型，二是基于Django搭建起来的实时野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/4.png\" alt=\"4\"></p>\n<h3 id=\"算法改进\"><a href=\"#算法改进\" class=\"headerlink\" title=\"算法改进\"></a>算法改进</h3><p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/5.png\" alt=\"5\"></p>\n<p>传统的 SSD 网络在提取的特征图上直接进行回归和分类，易造成目标的分类定位错误而降低检测的准确率。SSD 算法用低层特征图检测小目标，高层特征图检测大目标，低层卷积层分辨率高但语义信息低、感受野较小，小目标特征提取不充分；高层卷积层语义信息充分、感受野较大，可提取更多特征信息。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/6.png\" alt=\"6\"></p>\n<p>针对这个问题，我们将 RPN 网络引入进 SSD 网络，使用传输转换模块将两个网络相连接，从而构建出一种新的SSD网络。同时继承一步式和两步式检测方法的优点，在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，传输给SSD网络。在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，集成大规模上下文信息，增大感受野，增加低层网络的语义信息，提高检测精度。</p>\n<p>这一步骤有效地删除一些负样本先验框，减小分类器的搜索范围，降低目标分类或定位的错误率，为 SSD网络的回归操作提供更好的前提条件。</p>\n<p>在特征融合上，在MobileNetv2模型的基础框架上，对 Conv3_3、Conv4_3、fc7、Conv6_1、Conv7_1、Conv9_2 特征层，用 padding=0 的 1×1 卷积核做卷积操作，保证了融合时的通道统一，然后使用双线性插值使特征图大小统一。最后采用连接融合的方式得到了不同大小的特征图，改进后的模型较MobileNetv2模型的特征层语义信息更丰富，能更好地表达目标特征。</p>\n<p>同时为了增强浅层网络对小目标的检测能力。我们将 Smin 和 Smax 的值调整为 0.15，0.95，预测框的IOU 设置为 0.45，NMS 设置为 0.4，这样能够有效避免由于目标过小导致在训练阶段，真实标签无法找到相应地先验框与之匹配的问题。</p>\n<h3 id=\"算法对比\"><a href=\"#算法对比\" class=\"headerlink\" title=\"算法对比\"></a>算法对比</h3><p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/7.png\" alt=\"7\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/8.png\" alt=\"8\"></p>\n<p>在算法对比中可以看到，迭代 1 万次时，MobileNetv2网络的准确率只有78.62%，而改进后的网络准确率可达到 83.26%，迭代 6 万次逐渐趋于稳定，但是改进后的网络准确率始终高于原网络，最高可达90.86%。</p>\n<p>我们用同一数据集进行了横向对比，改进后的网络 mAP 为91.86%。相比于Faster R-CNN 模型，检测精度提升了 10.26%；相比于 YOLO V4模型，检测精度提高了2.97%，检测速度提高了7.3FPS；相比于MobileNetv2模型，检测精度提高了 5.12%。</p>\n<h3 id=\"成果展示\"><a href=\"#成果展示\" class=\"headerlink\" title=\"成果展示\"></a>成果展示</h3><h4 id=\"园区监控终端\"><a href=\"#园区监控终端\" class=\"headerlink\" title=\"园区监控终端\"></a>园区监控终端</h4><p>基于我们训练得到的模型，我们搭建了适用于自然保护区的智能监测平台。我们将通过规划后在区域内设置一定数量的摄像头用于实时监测，摄像头将搭载我们训练的识别模型，进行实时的识别和跟踪，标记出被识别的目标，并将信息传输给后台，供工作人员查看数据。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/9.png\" alt=\"9\"></p>\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/10.png\" width=\"500\">   </center>\n\n\n\n<p>同时，系统会对识别到的东北虎进行持续的标记跟踪，密切关注每一只东北虎个体，记录其基本情况。通过串联园区内各个位置的摄像头，系统会自动绘制园区内每只东北虎的行为轨迹图，并以地图可视化的方式展现出来。一旦摄像头监测到东北虎出现异常状况或行为轨迹图可疑，系统将自动上报给后台工作人员，以便及时处理。</p>\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/11.png\" width=\"500\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/12.png\" width=\"500\"> </center>\n\n<h4 id=\"一些展望\"><a href=\"#一些展望\" class=\"headerlink\" title=\"一些展望\"></a>一些展望</h4><p>完成该项目所需要的技术算是比较基础的，而在我们的前期调查中发现，相关的产品并没有广泛应用于自然保护区和动物园，不知道是出于成本的原因还是什么。我认为相关的产品或是项目可以广泛应用于各个自然保护区，基于不同的数据集，对不同种类的动物进行监测。如果可以争取与政府的动物保护部门达成合作，以进行进一步的推广，弥补现有的市场空缺，从而广泛应用国内各类自然保护区中。</p>\n<p>对于野生动物的纪录片拍摄以及各种野生动物科研，这样的系统依然有着非常显著的作用。我们可以利用相关系统更快地找到野生动物的栖息地和活动轨迹，以便于更好的拍摄和研究。同时大大减少了相关人员花在寻找东北虎的时间和精力上，大大加快了效率。</p>\n<p>想法是好的，希望在未来的日子里中可以有人能够实现这样的想法。</p>\n<h2 id=\"关于人工智能创意赛\"><a href=\"#关于人工智能创意赛\" class=\"headerlink\" title=\"关于人工智能创意赛\"></a>关于人工智能创意赛</h2><h3 id=\"GEEK-YOUTH集训营\"><a href=\"#GEEK-YOUTH集训营\" class=\"headerlink\" title=\"GEEK YOUTH集训营\"></a>GEEK YOUTH集训营</h3><p>2020年参加了很多的比赛哈，人工智能创意赛是我个人认为主办方非常良心的比赛之一。在得知了我们进入全国决赛之后，百度公司举行了GEEK YOUTH线上集训营，三天的讲解可谓是收获满满，请到了非常多很厉害的教授，我们也可以直面Paddlepaddle的技术人员，深入了解这个平台。如果没有疫情，应该会飞去北京参加线下的集训营，又是一场三天的白嫖旅行，也算蛮可惜的。因为可能记笔记比较认真，在最后的时候也作为代表表达了自己对集训营的一些看法，照片吗，网上好像直接搜我名字能搜到就不贴了。</p>\n<p>最后也收到了来自组委会的两波良心大礼包，赞:slightly_smiling_face:</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/14.jpeg\" alt=\"14\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/15.jpg\" alt=\"15\"></p>\n<h3 id=\"杭州决赛行\"><a href=\"#杭州决赛行\" class=\"headerlink\" title=\"杭州决赛行\"></a>杭州决赛行</h3><p>在第一天下飞机之后，我们来到了决赛举办的酒店，感觉应该是个旅游度假村，面积和江安的宿舍区有得一比。组委会安排住的是1500一天的别墅啊啊啊啊啊啊，直接震惊到爆炸，来几张图表示敬意。中午去恰了杭帮菜还算不错，下午逛了逛酒店，整个度假村的风景还算蛮不错的，本来两人一间房，但是我的室友并没有来（一人一间房很爽），于是便有了后来的夜宵局哈哈。</p>\n<p>整个决赛显得非常的专业，来了很多专业的教授和院士，现在想来没有去问问保研信息还蛮后悔的。在经历了第二天一整天紧张刺激的答辩(吹牛)后(下午溜出去到西湖玩了)，本来想去体验一下杭州的夜生活，奈何晚上九点街上就已经空空荡荡，于是小酌两杯后回到了酒店。结果在阿杜的鼓吹下，氪了一手原神，本来是钟离的up池，没想到保底出了一发七七，孙宝的运气可不是人人都有，生活总会有点意外。</p>\n<p>第三天在杭州的机器人小镇举行了颁奖仪式，颁奖典礼后便是一个峰会，还是认真听了一部分，机器人小镇的很多东西也蛮好玩的。第三天晚上参加了晚宴，非常豪华，本来和uncle说的是想和班主任小姐姐合张影，后来又怂了。当天成都发生了五角星事件还一度担心能不能正常回学校，而第四天中午便乘飞机回了学校，过程也挺顺畅。</p>\n<p>杭州行并没有留下什么谈得上的遗憾，留下了一堆不成文的照片。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/16.jpg\" alt=\"16\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/17.jpg\" alt=\"17\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/18.jpg\" alt=\"18\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/19.jpg\" alt=\"19\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/20.jpg\" alt=\"20\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/21.jpg\" alt=\"21\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/24.jpg\" alt=\"24\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/25.jpg\" alt=\"25\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/26.jpg\" alt=\"26\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/27.jpg\" alt=\"27\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/28.jpg\" alt=\"28\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/29.jpg\" alt=\"29\"></p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>感谢两位队友uncle悦和阿杜的付出，这个项目并没有花费我们太多的时间，所以最终能拿到这样的结果也算非常满意了。同时我们也明白了，在与其他学校的项目对比中，我们由于从来没有接触过硬件相关的知识，也没有硬件可以展示，在PK中会显得比较薄弱，这可能也是纯软件的一些弱势吧，希望在之后的学习中能够接触到有关硬件的一些知识，得到一些进步。</p>\n<p>最后附上参赛作品的三分钟链接，阿杜在寝室剪辑的，现在看上去确实还蛮憨憨的，纪念意义还是拉满：</p>\n<p><a href=\"https://www.bilibili.com/video/BV1PX4y1K7TC\">SCUCS_01</a>：<a href=\"https://www.bilibili.com/video/BV1PX4y1K7TC\">https://www.bilibili.com/video/BV1PX4y1K7TC</a></p>\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\" src=\"//player.bilibili.com/player.html?aid=713571339&bvid=BV1PX4y1K7TC&cid=279720799&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\">     </iframe> \n</div>\n\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>项目基于从ABS拿到的东北虎数据集而建立，改进基于PaddlePaddle 的Mobilenetv2 模型并使用Django 搭建实时的野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。和另外两位队友在短时间之内搭建的平台，最终在人工智能创意赛的全国决赛取得了三等奖的成绩，但是这个成绩好像并不重要哈哈。浙江三日游成为了在疫情笼罩下的2020年少有的精彩回忆之一，也是2020年的一个转折点吧。</p>\n</blockquote>\n<h2 id=\"项目简介\"><a href=\"#项目简介\" class=\"headerlink\" title=\"项目简介\"></a>项目简介</h2><p>本项目应用方向是野生动物保护，我们团队基于百度飞桨平台开发野生东北虎的识别与监测系统。通过自主收集的东北虎数据集完成模型训练。在未来该平台将于与摄像系统结合，广泛应用于野生动物自然保护区，结合大数据、人工智能等进一步对东北虎个体及其他物种进行目标识别、数量统计、实时监测，位置记录，有效地进行东北虎的监测与保护工作。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/2.png\" alt=\"2\"></p>\n<h2 id=\"项目技术内容\"><a href=\"#项目技术内容\" class=\"headerlink\" title=\"项目技术内容\"></a>项目技术内容</h2><h3 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h3><p>我们在学校实验室的支持下，结合互联网和实地考察，我们收集并创建了自主的东北虎数据集，一共有4621张图片，使用labelme标注东北虎框一共7321个。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/3.png\" alt=\"3\"></p>\n<h3 id=\"项目实现思路\"><a href=\"#项目实现思路\" class=\"headerlink\" title=\"项目实现思路\"></a>项目实现思路</h3><p>考虑到我们是一个实时的监测平台，对预测速度有一定的要求，并且需要模型易于部署，我们选择了基于Mobilenet v2的改进模型。本项目可分为两部分组成，一是通过基于改进Mobilenet v2的目标识别模型，二是基于Django搭建起来的实时野外东北虎监测平台，将摄像头传回的视频进行实时地处理后，返回给前端来实现可视化展示。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/4.png\" alt=\"4\"></p>\n<h3 id=\"算法改进\"><a href=\"#算法改进\" class=\"headerlink\" title=\"算法改进\"></a>算法改进</h3><p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/5.png\" alt=\"5\"></p>\n<p>传统的 SSD 网络在提取的特征图上直接进行回归和分类，易造成目标的分类定位错误而降低检测的准确率。SSD 算法用低层特征图检测小目标，高层特征图检测大目标，低层卷积层分辨率高但语义信息低、感受野较小，小目标特征提取不充分；高层卷积层语义信息充分、感受野较大，可提取更多特征信息。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/6.png\" alt=\"6\"></p>\n<p>针对这个问题，我们将 RPN 网络引入进 SSD 网络，使用传输转换模块将两个网络相连接，从而构建出一种新的SSD网络。同时继承一步式和两步式检测方法的优点，在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，传输给SSD网络。在RPN经过细化的先验框基础上进行回归反卷积，使特征相融合，集成大规模上下文信息，增大感受野，增加低层网络的语义信息，提高检测精度。</p>\n<p>这一步骤有效地删除一些负样本先验框，减小分类器的搜索范围，降低目标分类或定位的错误率，为 SSD网络的回归操作提供更好的前提条件。</p>\n<p>在特征融合上，在MobileNetv2模型的基础框架上，对 Conv3_3、Conv4_3、fc7、Conv6_1、Conv7_1、Conv9_2 特征层，用 padding=0 的 1×1 卷积核做卷积操作，保证了融合时的通道统一，然后使用双线性插值使特征图大小统一。最后采用连接融合的方式得到了不同大小的特征图，改进后的模型较MobileNetv2模型的特征层语义信息更丰富，能更好地表达目标特征。</p>\n<p>同时为了增强浅层网络对小目标的检测能力。我们将 Smin 和 Smax 的值调整为 0.15，0.95，预测框的IOU 设置为 0.45，NMS 设置为 0.4，这样能够有效避免由于目标过小导致在训练阶段，真实标签无法找到相应地先验框与之匹配的问题。</p>\n<h3 id=\"算法对比\"><a href=\"#算法对比\" class=\"headerlink\" title=\"算法对比\"></a>算法对比</h3><p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/7.png\" alt=\"7\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/8.png\" alt=\"8\"></p>\n<p>在算法对比中可以看到，迭代 1 万次时，MobileNetv2网络的准确率只有78.62%，而改进后的网络准确率可达到 83.26%，迭代 6 万次逐渐趋于稳定，但是改进后的网络准确率始终高于原网络，最高可达90.86%。</p>\n<p>我们用同一数据集进行了横向对比，改进后的网络 mAP 为91.86%。相比于Faster R-CNN 模型，检测精度提升了 10.26%；相比于 YOLO V4模型，检测精度提高了2.97%，检测速度提高了7.3FPS；相比于MobileNetv2模型，检测精度提高了 5.12%。</p>\n<h3 id=\"成果展示\"><a href=\"#成果展示\" class=\"headerlink\" title=\"成果展示\"></a>成果展示</h3><h4 id=\"园区监控终端\"><a href=\"#园区监控终端\" class=\"headerlink\" title=\"园区监控终端\"></a>园区监控终端</h4><p>基于我们训练得到的模型，我们搭建了适用于自然保护区的智能监测平台。我们将通过规划后在区域内设置一定数量的摄像头用于实时监测，摄像头将搭载我们训练的识别模型，进行实时的识别和跟踪，标记出被识别的目标，并将信息传输给后台，供工作人员查看数据。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/9.png\" alt=\"9\"></p>\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/10.png\" width=\"500\">   </center>\n\n\n\n<p>同时，系统会对识别到的东北虎进行持续的标记跟踪，密切关注每一只东北虎个体，记录其基本情况。通过串联园区内各个位置的摄像头，系统会自动绘制园区内每只东北虎的行为轨迹图，并以地图可视化的方式展现出来。一旦摄像头监测到东北虎出现异常状况或行为轨迹图可疑，系统将自动上报给后台工作人员，以便及时处理。</p>\n<center class=\"half\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/11.png\" width=\"500\">    <img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/12.png\" width=\"500\"> </center>\n\n<h4 id=\"一些展望\"><a href=\"#一些展望\" class=\"headerlink\" title=\"一些展望\"></a>一些展望</h4><p>完成该项目所需要的技术算是比较基础的，而在我们的前期调查中发现，相关的产品并没有广泛应用于自然保护区和动物园，不知道是出于成本的原因还是什么。我认为相关的产品或是项目可以广泛应用于各个自然保护区，基于不同的数据集，对不同种类的动物进行监测。如果可以争取与政府的动物保护部门达成合作，以进行进一步的推广，弥补现有的市场空缺，从而广泛应用国内各类自然保护区中。</p>\n<p>对于野生动物的纪录片拍摄以及各种野生动物科研，这样的系统依然有着非常显著的作用。我们可以利用相关系统更快地找到野生动物的栖息地和活动轨迹，以便于更好的拍摄和研究。同时大大减少了相关人员花在寻找东北虎的时间和精力上，大大加快了效率。</p>\n<p>想法是好的，希望在未来的日子里中可以有人能够实现这样的想法。</p>\n<h2 id=\"关于人工智能创意赛\"><a href=\"#关于人工智能创意赛\" class=\"headerlink\" title=\"关于人工智能创意赛\"></a>关于人工智能创意赛</h2><h3 id=\"GEEK-YOUTH集训营\"><a href=\"#GEEK-YOUTH集训营\" class=\"headerlink\" title=\"GEEK YOUTH集训营\"></a>GEEK YOUTH集训营</h3><p>2020年参加了很多的比赛哈，人工智能创意赛是我个人认为主办方非常良心的比赛之一。在得知了我们进入全国决赛之后，百度公司举行了GEEK YOUTH线上集训营，三天的讲解可谓是收获满满，请到了非常多很厉害的教授，我们也可以直面Paddlepaddle的技术人员，深入了解这个平台。如果没有疫情，应该会飞去北京参加线下的集训营，又是一场三天的白嫖旅行，也算蛮可惜的。因为可能记笔记比较认真，在最后的时候也作为代表表达了自己对集训营的一些看法，照片吗，网上好像直接搜我名字能搜到就不贴了。</p>\n<p>最后也收到了来自组委会的两波良心大礼包，赞:slightly_smiling_face:</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/14.jpeg\" alt=\"14\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/15.jpg\" alt=\"15\"></p>\n<h3 id=\"杭州决赛行\"><a href=\"#杭州决赛行\" class=\"headerlink\" title=\"杭州决赛行\"></a>杭州决赛行</h3><p>在第一天下飞机之后，我们来到了决赛举办的酒店，感觉应该是个旅游度假村，面积和江安的宿舍区有得一比。组委会安排住的是1500一天的别墅啊啊啊啊啊啊，直接震惊到爆炸，来几张图表示敬意。中午去恰了杭帮菜还算不错，下午逛了逛酒店，整个度假村的风景还算蛮不错的，本来两人一间房，但是我的室友并没有来（一人一间房很爽），于是便有了后来的夜宵局哈哈。</p>\n<p>整个决赛显得非常的专业，来了很多专业的教授和院士，现在想来没有去问问保研信息还蛮后悔的。在经历了第二天一整天紧张刺激的答辩(吹牛)后(下午溜出去到西湖玩了)，本来想去体验一下杭州的夜生活，奈何晚上九点街上就已经空空荡荡，于是小酌两杯后回到了酒店。结果在阿杜的鼓吹下，氪了一手原神，本来是钟离的up池，没想到保底出了一发七七，孙宝的运气可不是人人都有，生活总会有点意外。</p>\n<p>第三天在杭州的机器人小镇举行了颁奖仪式，颁奖典礼后便是一个峰会，还是认真听了一部分，机器人小镇的很多东西也蛮好玩的。第三天晚上参加了晚宴，非常豪华，本来和uncle说的是想和班主任小姐姐合张影，后来又怂了。当天成都发生了五角星事件还一度担心能不能正常回学校，而第四天中午便乘飞机回了学校，过程也挺顺畅。</p>\n<p>杭州行并没有留下什么谈得上的遗憾，留下了一堆不成文的照片。</p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/16.jpg\" alt=\"16\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/17.jpg\" alt=\"17\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/18.jpg\" alt=\"18\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/19.jpg\" alt=\"19\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/20.jpg\" alt=\"20\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/21.jpg\" alt=\"21\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/24.jpg\" alt=\"24\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/25.jpg\" alt=\"25\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/26.jpg\" alt=\"26\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/27.jpg\" alt=\"27\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/28.jpg\" alt=\"28\"></p>\n<p><img src=\"/2021/01/27/%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BMobilenetv2%E7%9A%84%E4%B8%9C%E5%8C%97%E8%99%8E%E8%AF%86%E5%88%AB%E5%B9%B3%E5%8F%B0/29.jpg\" alt=\"29\"></p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2><p>感谢两位队友uncle悦和阿杜的付出，这个项目并没有花费我们太多的时间，所以最终能拿到这样的结果也算非常满意了。同时我们也明白了，在与其他学校的项目对比中，我们由于从来没有接触过硬件相关的知识，也没有硬件可以展示，在PK中会显得比较薄弱，这可能也是纯软件的一些弱势吧，希望在之后的学习中能够接触到有关硬件的一些知识，得到一些进步。</p>\n<p>最后附上参赛作品的三分钟链接，阿杜在寝室剪辑的，现在看上去确实还蛮憨憨的，纪念意义还是拉满：</p>\n<p><a href=\"https://www.bilibili.com/video/BV1PX4y1K7TC\">SCUCS_01</a>：<a href=\"https://www.bilibili.com/video/BV1PX4y1K7TC\">https://www.bilibili.com/video/BV1PX4y1K7TC</a></p>\n<div style=\"position: relative; padding: 30% 45%;\">     \n    <iframe style=\"         position: absolute;          width: 100%;          height: 100%;          left: 0; top: 0;\" src=\"//player.bilibili.com/player.html?aid=713571339&bvid=BV1PX4y1K7TC&cid=279720799&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\">     </iframe> \n</div>\n\n"},{"title":"子空间学习(1)-PCA","catalog":true,"date":"2022-01-11T04:24:17.000Z","subtitle":"Subspace Learning-PCA","top":8,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**A Tutorial on Principal Component Analysis**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述PCA的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n主成分分析：Principal Component Analysis（PCA）是无监督的<u>降维</u>算法，相信各路博客上已经有了不少的理解和推导。所以本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Question&Answer：\n\n## 假设\n\n- Linearity：线性框架把降维问题定义在<u>基（basis）</u>的变化上。如下的<u>线性变换（Linearly transform）</u>$P$可以把原始基变化为另一个基，这个新的基是原始基的线性组合，通过是更好地表示原始数据集$X$。\n\n$$\nPX=Y \\tag{1}.\n$$\n\n- Large variances have important structure：这里的方差是指将数据投影到某个主成分后数据的方差。 这个假设还包含这样一种理念，即数据具有高<u>信噪比</u>：\n  $$\n  SNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}.\n  $$\n  因此，具有较大相关方差的主成分代表重要结构，而具有较低方差的主成分代表噪声。\n\n- The principal components are <u>orthogonal（正交）</u>：这个假设使得 PCA 可以用<u>特征值分解（eigendecomposition）</u>的方法解决。矩阵$A$中不同特征值对应的特征向量是相互正交的（即相互<u>点乘</u>为0），如下所示。为了不让公式混乱，这里的$A$表示原始数据集$X$，别误会，\n  $$\n  Ax_{i}=\\lambda_{i} x_{i}\\\\\n   x_{i} \\cdot x_{j}=\\delta_{i j}=\\left\\{\\begin{array}{l}\n      others, \\ i=j \\\\\n      0, i \\neq j\n  \\end{array}\\right..\n  $$\n\n## 目标函数\n\nPCA 的目标是最大化降维之后的<u>协方差矩阵</u>$D=YY^{T}$的<u>迹</u>，换种说法，最大化降维之后的数据在主成分（特征向量）上的方差。如下所示：\n$$\n\\begin{array}{ll}\n\\underset{\\mathbf{P}}{\\arg \\max} & tr(\\mathbf{P} \\mathbf{X} \\mathbf{X}^{T} \\mathbf{P}^{T}) =  tr(\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\mathbf{P} \\boldsymbol{x}_{i}\\right)^{2})\\\\\n\\text { s.t. } & PP^{T}=I_{d\\times d}.\n\\end{array}\\tag{2}\n$$\n其中，$P$ 是特征向量的集合，$x_{i}$ 是特征向量，$d$是降维后的维度。如果我们确定了$d$，在约束条件$PP^{T}=I_{d\\times d}$下，最终我们会得到唯一解$P$。<u>当然在这类降维算法中约束条件的设定其实值得讨论，我在之后的文章里面会解释不同算法下约束条件的作用。</u>由于$x_{i}$是<u>正交</u>基的限制，协方差矩阵$D$的非对角线元素都为0，而协方差矩阵的对角线元素则是特征值，表示如下：\n$$\nrerank \\ \\ x_{i} \\ \\ by \\ \\ sort(\\lambda_{i})\\\\\n\\lambda_{1}\\geq\\lambda_{2}\\geq\\cdots\\geq\\lambda_{d}\\\\\nX=[x_{1},\\cdots,x_{d}]\\\\\nD=\\left[\\begin{array}{lllll}\n\\lambda_{1} & 0 & \\cdots & 0 & 0\\\\\n0 & \\lambda_{2} & \\cdots & 0 & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_{d-1} & 0\\\\\n0 & 0 & \\cdots & 0 & \\lambda_{d}\n\\end{array}\\right].\n$$\n\n## 方差，协方差，冗余和信噪比的关系\n\n- 方差（Variance）：Variance is a way of measuring the degree of dispersion of a data set，如下所示：\n  $$\n  \\sigma_{A}^{2}=\\frac{1}{n} \\sum_{i} A_{i}^{2}.\n  $$\n\n- 协方差（Covariance）：Covariance measures the degree of the linear relationship between two variables. 协方差为正表示这两个数据正相关，协方差为负表示两个数据之间负相关。数学表达如下：\n  $$\n  \\operatorname{cov}(X, Y)=\\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)\\left(Y_{i}-\\bar{Y}\\right)}{(n-1)}\n  $$\n  其中 X 和 Y 是需要评估相关性的$n$维向量。当有多个数据点需要表示相互之间的相关性时，我们用协方差矩阵$C$来表示。\n\n- 冗余（Redundancy）：Redundancy refers to whether the data expressed in the current dimension is redundant. PCA通过最大化协方差矩阵的迹来消除冗余。值得注意的是，冗余度越高表示数据间相关性越大，用某些维度去表示。\n\n在本文的假设中，协方差（多数据则是协方差矩阵的迹），冗余和信噪比之间是正比关系，如下所示：\n$$\nconvarince \\propto redundancy \\propto SNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}\n$$\n冗余定义为当前维度是否是多余的，噪声代表那些多余的维度。 协方差反映了数据之间的相关性。 不同维度之间的相关性越大，当前维度就越冗余。\n\n## PCA和协方差矩阵的关系\n\nPCA首先是通过预处理之后的原始数据$X_{pre}$进行协方差矩阵的计算得到了$C_{X}$，通过线性变化之后得到降维之后数据的协方差矩阵$C_{Y}$。协方差矩阵由如下两个特点：\n\n- 在对角线元素中，根据假设，大的特征值代表重要的主成分。\n- 在非对角线元素中，大的协方差值对应于高冗余。\n\n具体的过程是找到正交矩阵$P$使得$\\mathbf{C}_{\\mathbf{Y}} \\equiv \\frac{1}{n} \\mathbf{Y} \\mathbf{Y} ^{T}$ 是对角矩阵，转换过程如下所示：\n$$\n\\begin{aligned}\nC_{Y} &=\\frac{1}{n} Y Y^{T} \\\\\n&=\\frac{1}{n}(P X)(P X)^{T} \\\\\n&=P\\left(\\frac{1}{n} X X^{T}\\right) P^{T} \\\\\n&=P C_{X} P^{T}.\n\\end{aligned}\n$$\n\n## PCA，特征分解(ED)和奇异值分解(SVD)之间的关系\n\nPCA可以通过特征分解和奇异值分解来求解。具体而言，在PCA这个算法中，ED只使用了SVD的右奇异矩阵。SVD是一个更普通的解决方案，因为狭义的特征值分解需要原数据$X$是一个方阵，而SVD并没有这个限制。接下来我们将推导，**为什么说ED只使用了SVD的右奇异矩阵**。\n\n在狭义的特征值分解中，我们求解特征向量和特征值需要把原数据集$A$（为了不让公式混乱，这里的$A$表示原数据集$X$，别误会）表示为$Ax_{i}=\\lambda_{i}x_{i}$。在ED中$A$是一个对称正定矩阵，$A$可以表示为：\n$$\nA=XX^{T}=EDE^{T},\n$$\n其中$D$是一个对角矩阵，其中对角元素为特征值，$E=\\{x_{1},x_{2}, \\cdots, x_{n}\\}$的每一列都是特征值对应的特征向量。 $E$ 是归一化的正交向量集。 我们可以得到 $E^{T}=E^{-1}$。然后进行如下推导：\n$$\n\\begin{aligned}\nAx_{i}&=\\lambda_{i}x_{i}\\\\\nAE &=ED \\\\\nXX^{T}E &=ED \\\\\nXX^{T}E &=EDE^{T}E \\\\\nXX^{T} &=EDE^{T}.\n\\end{aligned}\n$$\n以上的推导把特征分解推向了与SVD类似的表示，即类似于SVD的右奇异矩阵，接下来我们展示SVD的过程：\n$$\n\\begin{aligned}\n\\mathbf{M} &=\\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^{T}\\\\\nM^{T}M &= V\\sigma^{T} U^{T}U\\sigma V^{T}\\\\\nA &= V\\sigma^{2}V^{T},\n\\end{aligned}\n$$\n其中 $A=M^{T}M$ 是正定矩阵，U 和 V 是归一化正交向量集，所以我们有 $U^{T}U=I$。\n\n## 缺点\n\nPCA 不能处理线性不可分的数据，数据可能位于多个子空间中。我们可以从方程（1）中看出。降维后的数据$B$是由原始数据$A$通过线性变换$P$得到的。PCA 不是为处理非线性数据而设计的，所以在处理非线性数据时，效果可能不太行。\n\n## 实验效果(MNIST)\n\n由于Sklearn已经对PCA做了很多的优化，需要代码的朋友可以之间调库解决：\n\n```python\nfrom sklearn.decomposition import PCA\ndef Pca(test_data, train_data, component):\n    solver = PCA(n_components = component) #test_data为测试集, train_data为训练集, component为降维后的维度\n    solver.fit(train_data)\n    return solver.transform(test_data)\n```\n<div>\t\t\t\n    <center>\t\n    <img src=\"子空间学习(1)-PCA/train_pca.png\"\n        alt=\"train_pca\"\n        style=\"zoom:50%\"/>\n    <img src=\"子空间学习(1)-PCA/test_pca.png\" \n        alt=\"test_pca\" \n        style=\"zoom:50%;\" />\n    </center>\n</div>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Left: Train dataset, Right: Test dataset.</center>\n\n# 总结\n\n很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。\n\n","source":"_posts/子空间学习(1)-PCA.md","raw":"---\ntitle: 子空间学习(1)-PCA\ncatalog: true\ndate: 2022-01-11 12:24:17\nsubtitle: Subspace Learning-PCA\ntop: 8\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**A Tutorial on Principal Component Analysis**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述PCA的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n主成分分析：Principal Component Analysis（PCA）是无监督的<u>降维</u>算法，相信各路博客上已经有了不少的理解和推导。所以本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Question&Answer：\n\n## 假设\n\n- Linearity：线性框架把降维问题定义在<u>基（basis）</u>的变化上。如下的<u>线性变换（Linearly transform）</u>$P$可以把原始基变化为另一个基，这个新的基是原始基的线性组合，通过是更好地表示原始数据集$X$。\n\n$$\nPX=Y \\tag{1}.\n$$\n\n- Large variances have important structure：这里的方差是指将数据投影到某个主成分后数据的方差。 这个假设还包含这样一种理念，即数据具有高<u>信噪比</u>：\n  $$\n  SNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}.\n  $$\n  因此，具有较大相关方差的主成分代表重要结构，而具有较低方差的主成分代表噪声。\n\n- The principal components are <u>orthogonal（正交）</u>：这个假设使得 PCA 可以用<u>特征值分解（eigendecomposition）</u>的方法解决。矩阵$A$中不同特征值对应的特征向量是相互正交的（即相互<u>点乘</u>为0），如下所示。为了不让公式混乱，这里的$A$表示原始数据集$X$，别误会，\n  $$\n  Ax_{i}=\\lambda_{i} x_{i}\\\\\n   x_{i} \\cdot x_{j}=\\delta_{i j}=\\left\\{\\begin{array}{l}\n      others, \\ i=j \\\\\n      0, i \\neq j\n  \\end{array}\\right..\n  $$\n\n## 目标函数\n\nPCA 的目标是最大化降维之后的<u>协方差矩阵</u>$D=YY^{T}$的<u>迹</u>，换种说法，最大化降维之后的数据在主成分（特征向量）上的方差。如下所示：\n$$\n\\begin{array}{ll}\n\\underset{\\mathbf{P}}{\\arg \\max} & tr(\\mathbf{P} \\mathbf{X} \\mathbf{X}^{T} \\mathbf{P}^{T}) =  tr(\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\mathbf{P} \\boldsymbol{x}_{i}\\right)^{2})\\\\\n\\text { s.t. } & PP^{T}=I_{d\\times d}.\n\\end{array}\\tag{2}\n$$\n其中，$P$ 是特征向量的集合，$x_{i}$ 是特征向量，$d$是降维后的维度。如果我们确定了$d$，在约束条件$PP^{T}=I_{d\\times d}$下，最终我们会得到唯一解$P$。<u>当然在这类降维算法中约束条件的设定其实值得讨论，我在之后的文章里面会解释不同算法下约束条件的作用。</u>由于$x_{i}$是<u>正交</u>基的限制，协方差矩阵$D$的非对角线元素都为0，而协方差矩阵的对角线元素则是特征值，表示如下：\n$$\nrerank \\ \\ x_{i} \\ \\ by \\ \\ sort(\\lambda_{i})\\\\\n\\lambda_{1}\\geq\\lambda_{2}\\geq\\cdots\\geq\\lambda_{d}\\\\\nX=[x_{1},\\cdots,x_{d}]\\\\\nD=\\left[\\begin{array}{lllll}\n\\lambda_{1} & 0 & \\cdots & 0 & 0\\\\\n0 & \\lambda_{2} & \\cdots & 0 & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_{d-1} & 0\\\\\n0 & 0 & \\cdots & 0 & \\lambda_{d}\n\\end{array}\\right].\n$$\n\n## 方差，协方差，冗余和信噪比的关系\n\n- 方差（Variance）：Variance is a way of measuring the degree of dispersion of a data set，如下所示：\n  $$\n  \\sigma_{A}^{2}=\\frac{1}{n} \\sum_{i} A_{i}^{2}.\n  $$\n\n- 协方差（Covariance）：Covariance measures the degree of the linear relationship between two variables. 协方差为正表示这两个数据正相关，协方差为负表示两个数据之间负相关。数学表达如下：\n  $$\n  \\operatorname{cov}(X, Y)=\\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)\\left(Y_{i}-\\bar{Y}\\right)}{(n-1)}\n  $$\n  其中 X 和 Y 是需要评估相关性的$n$维向量。当有多个数据点需要表示相互之间的相关性时，我们用协方差矩阵$C$来表示。\n\n- 冗余（Redundancy）：Redundancy refers to whether the data expressed in the current dimension is redundant. PCA通过最大化协方差矩阵的迹来消除冗余。值得注意的是，冗余度越高表示数据间相关性越大，用某些维度去表示。\n\n在本文的假设中，协方差（多数据则是协方差矩阵的迹），冗余和信噪比之间是正比关系，如下所示：\n$$\nconvarince \\propto redundancy \\propto SNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}\n$$\n冗余定义为当前维度是否是多余的，噪声代表那些多余的维度。 协方差反映了数据之间的相关性。 不同维度之间的相关性越大，当前维度就越冗余。\n\n## PCA和协方差矩阵的关系\n\nPCA首先是通过预处理之后的原始数据$X_{pre}$进行协方差矩阵的计算得到了$C_{X}$，通过线性变化之后得到降维之后数据的协方差矩阵$C_{Y}$。协方差矩阵由如下两个特点：\n\n- 在对角线元素中，根据假设，大的特征值代表重要的主成分。\n- 在非对角线元素中，大的协方差值对应于高冗余。\n\n具体的过程是找到正交矩阵$P$使得$\\mathbf{C}_{\\mathbf{Y}} \\equiv \\frac{1}{n} \\mathbf{Y} \\mathbf{Y} ^{T}$ 是对角矩阵，转换过程如下所示：\n$$\n\\begin{aligned}\nC_{Y} &=\\frac{1}{n} Y Y^{T} \\\\\n&=\\frac{1}{n}(P X)(P X)^{T} \\\\\n&=P\\left(\\frac{1}{n} X X^{T}\\right) P^{T} \\\\\n&=P C_{X} P^{T}.\n\\end{aligned}\n$$\n\n## PCA，特征分解(ED)和奇异值分解(SVD)之间的关系\n\nPCA可以通过特征分解和奇异值分解来求解。具体而言，在PCA这个算法中，ED只使用了SVD的右奇异矩阵。SVD是一个更普通的解决方案，因为狭义的特征值分解需要原数据$X$是一个方阵，而SVD并没有这个限制。接下来我们将推导，**为什么说ED只使用了SVD的右奇异矩阵**。\n\n在狭义的特征值分解中，我们求解特征向量和特征值需要把原数据集$A$（为了不让公式混乱，这里的$A$表示原数据集$X$，别误会）表示为$Ax_{i}=\\lambda_{i}x_{i}$。在ED中$A$是一个对称正定矩阵，$A$可以表示为：\n$$\nA=XX^{T}=EDE^{T},\n$$\n其中$D$是一个对角矩阵，其中对角元素为特征值，$E=\\{x_{1},x_{2}, \\cdots, x_{n}\\}$的每一列都是特征值对应的特征向量。 $E$ 是归一化的正交向量集。 我们可以得到 $E^{T}=E^{-1}$。然后进行如下推导：\n$$\n\\begin{aligned}\nAx_{i}&=\\lambda_{i}x_{i}\\\\\nAE &=ED \\\\\nXX^{T}E &=ED \\\\\nXX^{T}E &=EDE^{T}E \\\\\nXX^{T} &=EDE^{T}.\n\\end{aligned}\n$$\n以上的推导把特征分解推向了与SVD类似的表示，即类似于SVD的右奇异矩阵，接下来我们展示SVD的过程：\n$$\n\\begin{aligned}\n\\mathbf{M} &=\\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^{T}\\\\\nM^{T}M &= V\\sigma^{T} U^{T}U\\sigma V^{T}\\\\\nA &= V\\sigma^{2}V^{T},\n\\end{aligned}\n$$\n其中 $A=M^{T}M$ 是正定矩阵，U 和 V 是归一化正交向量集，所以我们有 $U^{T}U=I$。\n\n## 缺点\n\nPCA 不能处理线性不可分的数据，数据可能位于多个子空间中。我们可以从方程（1）中看出。降维后的数据$B$是由原始数据$A$通过线性变换$P$得到的。PCA 不是为处理非线性数据而设计的，所以在处理非线性数据时，效果可能不太行。\n\n## 实验效果(MNIST)\n\n由于Sklearn已经对PCA做了很多的优化，需要代码的朋友可以之间调库解决：\n\n```python\nfrom sklearn.decomposition import PCA\ndef Pca(test_data, train_data, component):\n    solver = PCA(n_components = component) #test_data为测试集, train_data为训练集, component为降维后的维度\n    solver.fit(train_data)\n    return solver.transform(test_data)\n```\n<div>\t\t\t\n    <center>\t\n    <img src=\"子空间学习(1)-PCA/train_pca.png\"\n        alt=\"train_pca\"\n        style=\"zoom:50%\"/>\n    <img src=\"子空间学习(1)-PCA/test_pca.png\" \n        alt=\"test_pca\" \n        style=\"zoom:50%;\" />\n    </center>\n</div>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Left: Train dataset, Right: Test dataset.</center>\n\n# 总结\n\n很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。\n\n","slug":"子空间学习(1)-PCA","published":1,"updated":"2022-01-13T12:55:39.323Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxx1000k3oue9qpv8ycc","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>A Tutorial on Principal Component Analysis</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述PCA的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>主成分分析：Principal Component Analysis（PCA）是无监督的<u>降维</u>算法，相信各路博客上已经有了不少的理解和推导。所以本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Question-amp-Answer：\"><a href=\"#Question-amp-Answer：\" class=\"headerlink\" title=\"Question&amp;Answer：\"></a>Question&amp;Answer：</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><ul>\n<li>Linearity：线性框架把降维问题定义在<u>基（basis）</u>的变化上。如下的<u>线性变换（Linearly transform）</u>$P$可以把原始基变化为另一个基，这个新的基是原始基的线性组合，通过是更好地表示原始数据集$X$。</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nPX=Y \\tag{1}.</script><ul>\n<li><p>Large variances have important structure：这里的方差是指将数据投影到某个主成分后数据的方差。 这个假设还包含这样一种理念，即数据具有高<u>信噪比</u>：</p>\n<script type=\"math/tex; mode=display\">\nSNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}.</script><p>因此，具有较大相关方差的主成分代表重要结构，而具有较低方差的主成分代表噪声。</p>\n</li>\n<li><p>The principal components are <u>orthogonal（正交）</u>：这个假设使得 PCA 可以用<u>特征值分解（eigendecomposition）</u>的方法解决。矩阵$A$中不同特征值对应的特征向量是相互正交的（即相互<u>点乘</u>为0），如下所示。为了不让公式混乱，这里的$A$表示原始数据集$X$，别误会，</p>\n<script type=\"math/tex; mode=display\">\nAx_{i}=\\lambda_{i} x_{i}\\\\\n x_{i} \\cdot x_{j}=\\delta_{i j}=\\left\\{\\begin{array}{l}\n    others, \\ i=j \\\\\n    0, i \\neq j\n\\end{array}\\right..</script></li>\n</ul>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>PCA 的目标是最大化降维之后的<u>协方差矩阵</u>$D=YY^{T}$的<u>迹</u>，换种说法，最大化降维之后的数据在主成分（特征向量）上的方差。如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{array}{ll}\n\\underset{\\mathbf{P}}{\\arg \\max} & tr(\\mathbf{P} \\mathbf{X} \\mathbf{X}^{T} \\mathbf{P}^{T}) =  tr(\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\mathbf{P} \\boldsymbol{x}_{i}\\right)^{2})\\\\\n\\text { s.t. } & PP^{T}=I_{d\\times d}.\n\\end{array}\\tag{2}</script><p>其中，$P$ 是特征向量的集合，$x_{i}$ 是特征向量，$d$是降维后的维度。如果我们确定了$d$，在约束条件$PP^{T}=I_{d\\times d}$下，最终我们会得到唯一解$P$。<u>当然在这类降维算法中约束条件的设定其实值得讨论，我在之后的文章里面会解释不同算法下约束条件的作用。</u>由于$x_{i}$是<u>正交</u>基的限制，协方差矩阵$D$的非对角线元素都为0，而协方差矩阵的对角线元素则是特征值，表示如下：</p>\n<script type=\"math/tex; mode=display\">\nrerank \\ \\ x_{i} \\ \\ by \\ \\ sort(\\lambda_{i})\\\\\n\\lambda_{1}\\geq\\lambda_{2}\\geq\\cdots\\geq\\lambda_{d}\\\\\nX=[x_{1},\\cdots,x_{d}]\\\\\nD=\\left[\\begin{array}{lllll}\n\\lambda_{1} & 0 & \\cdots & 0 & 0\\\\\n0 & \\lambda_{2} & \\cdots & 0 & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_{d-1} & 0\\\\\n0 & 0 & \\cdots & 0 & \\lambda_{d}\n\\end{array}\\right].</script><h2 id=\"方差，协方差，冗余和信噪比的关系\"><a href=\"#方差，协方差，冗余和信噪比的关系\" class=\"headerlink\" title=\"方差，协方差，冗余和信噪比的关系\"></a>方差，协方差，冗余和信噪比的关系</h2><ul>\n<li><p>方差（Variance）：Variance is a way of measuring the degree of dispersion of a data set，如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\sigma_{A}^{2}=\\frac{1}{n} \\sum_{i} A_{i}^{2}.</script></li>\n<li><p>协方差（Covariance）：Covariance measures the degree of the linear relationship between two variables. 协方差为正表示这两个数据正相关，协方差为负表示两个数据之间负相关。数学表达如下：</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{cov}(X, Y)=\\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)\\left(Y_{i}-\\bar{Y}\\right)}{(n-1)}</script><p>其中 X 和 Y 是需要评估相关性的$n$维向量。当有多个数据点需要表示相互之间的相关性时，我们用协方差矩阵$C$来表示。</p>\n</li>\n<li><p>冗余（Redundancy）：Redundancy refers to whether the data expressed in the current dimension is redundant. PCA通过最大化协方差矩阵的迹来消除冗余。值得注意的是，冗余度越高表示数据间相关性越大，用某些维度去表示。</p>\n</li>\n</ul>\n<p>在本文的假设中，协方差（多数据则是协方差矩阵的迹），冗余和信噪比之间是正比关系，如下所示：</p>\n<script type=\"math/tex; mode=display\">\nconvarince \\propto redundancy \\propto SNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}</script><p>冗余定义为当前维度是否是多余的，噪声代表那些多余的维度。 协方差反映了数据之间的相关性。 不同维度之间的相关性越大，当前维度就越冗余。</p>\n<h2 id=\"PCA和协方差矩阵的关系\"><a href=\"#PCA和协方差矩阵的关系\" class=\"headerlink\" title=\"PCA和协方差矩阵的关系\"></a>PCA和协方差矩阵的关系</h2><p>PCA首先是通过预处理之后的原始数据$X_{pre}$进行协方差矩阵的计算得到了$C_{X}$，通过线性变化之后得到降维之后数据的协方差矩阵$C_{Y}$。协方差矩阵由如下两个特点：</p>\n<ul>\n<li>在对角线元素中，根据假设，大的特征值代表重要的主成分。</li>\n<li>在非对角线元素中，大的协方差值对应于高冗余。</li>\n</ul>\n<p>具体的过程是找到正交矩阵$P$使得$\\mathbf{C}_{\\mathbf{Y}} \\equiv \\frac{1}{n} \\mathbf{Y} \\mathbf{Y} ^{T}$ 是对角矩阵，转换过程如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\nC_{Y} &=\\frac{1}{n} Y Y^{T} \\\\\n&=\\frac{1}{n}(P X)(P X)^{T} \\\\\n&=P\\left(\\frac{1}{n} X X^{T}\\right) P^{T} \\\\\n&=P C_{X} P^{T}.\n\\end{aligned}</script><h2 id=\"PCA，特征分解-ED-和奇异值分解-SVD-之间的关系\"><a href=\"#PCA，特征分解-ED-和奇异值分解-SVD-之间的关系\" class=\"headerlink\" title=\"PCA，特征分解(ED)和奇异值分解(SVD)之间的关系\"></a>PCA，特征分解(ED)和奇异值分解(SVD)之间的关系</h2><p>PCA可以通过特征分解和奇异值分解来求解。具体而言，在PCA这个算法中，ED只使用了SVD的右奇异矩阵。SVD是一个更普通的解决方案，因为狭义的特征值分解需要原数据$X$是一个方阵，而SVD并没有这个限制。接下来我们将推导，<strong>为什么说ED只使用了SVD的右奇异矩阵</strong>。</p>\n<p>在狭义的特征值分解中，我们求解特征向量和特征值需要把原数据集$A$（为了不让公式混乱，这里的$A$表示原数据集$X$，别误会）表示为$Ax_{i}=\\lambda_{i}x_{i}$。在ED中$A$是一个对称正定矩阵，$A$可以表示为：</p>\n<script type=\"math/tex; mode=display\">\nA=XX^{T}=EDE^{T},</script><p>其中$D$是一个对角矩阵，其中对角元素为特征值，$E=\\{x_{1},x_{2}, \\cdots, x_{n}\\}$的每一列都是特征值对应的特征向量。 $E$ 是归一化的正交向量集。 我们可以得到 $E^{T}=E^{-1}$。然后进行如下推导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\nAx_{i}&=\\lambda_{i}x_{i}\\\\\nAE &=ED \\\\\nXX^{T}E &=ED \\\\\nXX^{T}E &=EDE^{T}E \\\\\nXX^{T} &=EDE^{T}.\n\\end{aligned}</script><p>以上的推导把特征分解推向了与SVD类似的表示，即类似于SVD的右奇异矩阵，接下来我们展示SVD的过程：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n\\mathbf{M} &=\\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^{T}\\\\\nM^{T}M &= V\\sigma^{T} U^{T}U\\sigma V^{T}\\\\\nA &= V\\sigma^{2}V^{T},\n\\end{aligned}</script><p>其中 $A=M^{T}M$ 是正定矩阵，U 和 V 是归一化正交向量集，所以我们有 $U^{T}U=I$。</p>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>PCA 不能处理线性不可分的数据，数据可能位于多个子空间中。我们可以从方程（1）中看出。降维后的数据$B$是由原始数据$A$通过线性变换$P$得到的。PCA 不是为处理非线性数据而设计的，所以在处理非线性数据时，效果可能不太行。</p>\n<h2 id=\"实验效果-MNIST\"><a href=\"#实验效果-MNIST\" class=\"headerlink\" title=\"实验效果(MNIST)\"></a>实验效果(MNIST)</h2><p>由于Sklearn已经对PCA做了很多的优化，需要代码的朋友可以之间调库解决：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Pca</span>(<span class=\"params\">test_data, train_data, component</span>):</span></span><br><span class=\"line\">    solver = PCA(n_components = component) <span class=\"comment\">#test_data为测试集, train_data为训练集, component为降维后的维度</span></span><br><span class=\"line\">    solver.fit(train_data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> solver.transform(test_data)</span><br></pre></td></tr></table></figure>\n<div>            \n    <center>    \n    <img src=\"/2022/01/11/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(1)-PCA/train_pca.png\" alt=\"train_pca\" style=\"zoom:50%\">\n    <img src=\"/2022/01/11/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(1)-PCA/test_pca.png\" alt=\"test_pca\" style=\"zoom:50%;\">\n    </center>\n</div>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Left: Train dataset, Right: Test dataset.</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>A Tutorial on Principal Component Analysis</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述PCA的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>主成分分析：Principal Component Analysis（PCA）是无监督的<u>降维</u>算法，相信各路博客上已经有了不少的理解和推导。所以本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Question-amp-Answer：\"><a href=\"#Question-amp-Answer：\" class=\"headerlink\" title=\"Question&amp;Answer：\"></a>Question&amp;Answer：</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><ul>\n<li>Linearity：线性框架把降维问题定义在<u>基（basis）</u>的变化上。如下的<u>线性变换（Linearly transform）</u>$P$可以把原始基变化为另一个基，这个新的基是原始基的线性组合，通过是更好地表示原始数据集$X$。</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nPX=Y \\tag{1}.</script><ul>\n<li><p>Large variances have important structure：这里的方差是指将数据投影到某个主成分后数据的方差。 这个假设还包含这样一种理念，即数据具有高<u>信噪比</u>：</p>\n<script type=\"math/tex; mode=display\">\nSNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}.</script><p>因此，具有较大相关方差的主成分代表重要结构，而具有较低方差的主成分代表噪声。</p>\n</li>\n<li><p>The principal components are <u>orthogonal（正交）</u>：这个假设使得 PCA 可以用<u>特征值分解（eigendecomposition）</u>的方法解决。矩阵$A$中不同特征值对应的特征向量是相互正交的（即相互<u>点乘</u>为0），如下所示。为了不让公式混乱，这里的$A$表示原始数据集$X$，别误会，</p>\n<script type=\"math/tex; mode=display\">\nAx_{i}=\\lambda_{i} x_{i}\\\\\n x_{i} \\cdot x_{j}=\\delta_{i j}=\\left\\{\\begin{array}{l}\n    others, \\ i=j \\\\\n    0, i \\neq j\n\\end{array}\\right..</script></li>\n</ul>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>PCA 的目标是最大化降维之后的<u>协方差矩阵</u>$D=YY^{T}$的<u>迹</u>，换种说法，最大化降维之后的数据在主成分（特征向量）上的方差。如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{array}{ll}\n\\underset{\\mathbf{P}}{\\arg \\max} & tr(\\mathbf{P} \\mathbf{X} \\mathbf{X}^{T} \\mathbf{P}^{T}) =  tr(\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\mathbf{P} \\boldsymbol{x}_{i}\\right)^{2})\\\\\n\\text { s.t. } & PP^{T}=I_{d\\times d}.\n\\end{array}\\tag{2}</script><p>其中，$P$ 是特征向量的集合，$x_{i}$ 是特征向量，$d$是降维后的维度。如果我们确定了$d$，在约束条件$PP^{T}=I_{d\\times d}$下，最终我们会得到唯一解$P$。<u>当然在这类降维算法中约束条件的设定其实值得讨论，我在之后的文章里面会解释不同算法下约束条件的作用。</u>由于$x_{i}$是<u>正交</u>基的限制，协方差矩阵$D$的非对角线元素都为0，而协方差矩阵的对角线元素则是特征值，表示如下：</p>\n<script type=\"math/tex; mode=display\">\nrerank \\ \\ x_{i} \\ \\ by \\ \\ sort(\\lambda_{i})\\\\\n\\lambda_{1}\\geq\\lambda_{2}\\geq\\cdots\\geq\\lambda_{d}\\\\\nX=[x_{1},\\cdots,x_{d}]\\\\\nD=\\left[\\begin{array}{lllll}\n\\lambda_{1} & 0 & \\cdots & 0 & 0\\\\\n0 & \\lambda_{2} & \\cdots & 0 & 0\\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n0 & 0 & \\cdots & \\lambda_{d-1} & 0\\\\\n0 & 0 & \\cdots & 0 & \\lambda_{d}\n\\end{array}\\right].</script><h2 id=\"方差，协方差，冗余和信噪比的关系\"><a href=\"#方差，协方差，冗余和信噪比的关系\" class=\"headerlink\" title=\"方差，协方差，冗余和信噪比的关系\"></a>方差，协方差，冗余和信噪比的关系</h2><ul>\n<li><p>方差（Variance）：Variance is a way of measuring the degree of dispersion of a data set，如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\sigma_{A}^{2}=\\frac{1}{n} \\sum_{i} A_{i}^{2}.</script></li>\n<li><p>协方差（Covariance）：Covariance measures the degree of the linear relationship between two variables. 协方差为正表示这两个数据正相关，协方差为负表示两个数据之间负相关。数学表达如下：</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{cov}(X, Y)=\\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)\\left(Y_{i}-\\bar{Y}\\right)}{(n-1)}</script><p>其中 X 和 Y 是需要评估相关性的$n$维向量。当有多个数据点需要表示相互之间的相关性时，我们用协方差矩阵$C$来表示。</p>\n</li>\n<li><p>冗余（Redundancy）：Redundancy refers to whether the data expressed in the current dimension is redundant. PCA通过最大化协方差矩阵的迹来消除冗余。值得注意的是，冗余度越高表示数据间相关性越大，用某些维度去表示。</p>\n</li>\n</ul>\n<p>在本文的假设中，协方差（多数据则是协方差矩阵的迹），冗余和信噪比之间是正比关系，如下所示：</p>\n<script type=\"math/tex; mode=display\">\nconvarince \\propto redundancy \\propto SNR=\\frac{\\sigma_{\\text {signal }}^{2}}{\\sigma_{\\text {noise }}^{2}}</script><p>冗余定义为当前维度是否是多余的，噪声代表那些多余的维度。 协方差反映了数据之间的相关性。 不同维度之间的相关性越大，当前维度就越冗余。</p>\n<h2 id=\"PCA和协方差矩阵的关系\"><a href=\"#PCA和协方差矩阵的关系\" class=\"headerlink\" title=\"PCA和协方差矩阵的关系\"></a>PCA和协方差矩阵的关系</h2><p>PCA首先是通过预处理之后的原始数据$X_{pre}$进行协方差矩阵的计算得到了$C_{X}$，通过线性变化之后得到降维之后数据的协方差矩阵$C_{Y}$。协方差矩阵由如下两个特点：</p>\n<ul>\n<li>在对角线元素中，根据假设，大的特征值代表重要的主成分。</li>\n<li>在非对角线元素中，大的协方差值对应于高冗余。</li>\n</ul>\n<p>具体的过程是找到正交矩阵$P$使得$\\mathbf{C}_{\\mathbf{Y}} \\equiv \\frac{1}{n} \\mathbf{Y} \\mathbf{Y} ^{T}$ 是对角矩阵，转换过程如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\nC_{Y} &=\\frac{1}{n} Y Y^{T} \\\\\n&=\\frac{1}{n}(P X)(P X)^{T} \\\\\n&=P\\left(\\frac{1}{n} X X^{T}\\right) P^{T} \\\\\n&=P C_{X} P^{T}.\n\\end{aligned}</script><h2 id=\"PCA，特征分解-ED-和奇异值分解-SVD-之间的关系\"><a href=\"#PCA，特征分解-ED-和奇异值分解-SVD-之间的关系\" class=\"headerlink\" title=\"PCA，特征分解(ED)和奇异值分解(SVD)之间的关系\"></a>PCA，特征分解(ED)和奇异值分解(SVD)之间的关系</h2><p>PCA可以通过特征分解和奇异值分解来求解。具体而言，在PCA这个算法中，ED只使用了SVD的右奇异矩阵。SVD是一个更普通的解决方案，因为狭义的特征值分解需要原数据$X$是一个方阵，而SVD并没有这个限制。接下来我们将推导，<strong>为什么说ED只使用了SVD的右奇异矩阵</strong>。</p>\n<p>在狭义的特征值分解中，我们求解特征向量和特征值需要把原数据集$A$（为了不让公式混乱，这里的$A$表示原数据集$X$，别误会）表示为$Ax_{i}=\\lambda_{i}x_{i}$。在ED中$A$是一个对称正定矩阵，$A$可以表示为：</p>\n<script type=\"math/tex; mode=display\">\nA=XX^{T}=EDE^{T},</script><p>其中$D$是一个对角矩阵，其中对角元素为特征值，$E=\\{x_{1},x_{2}, \\cdots, x_{n}\\}$的每一列都是特征值对应的特征向量。 $E$ 是归一化的正交向量集。 我们可以得到 $E^{T}=E^{-1}$。然后进行如下推导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\nAx_{i}&=\\lambda_{i}x_{i}\\\\\nAE &=ED \\\\\nXX^{T}E &=ED \\\\\nXX^{T}E &=EDE^{T}E \\\\\nXX^{T} &=EDE^{T}.\n\\end{aligned}</script><p>以上的推导把特征分解推向了与SVD类似的表示，即类似于SVD的右奇异矩阵，接下来我们展示SVD的过程：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n\\mathbf{M} &=\\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^{T}\\\\\nM^{T}M &= V\\sigma^{T} U^{T}U\\sigma V^{T}\\\\\nA &= V\\sigma^{2}V^{T},\n\\end{aligned}</script><p>其中 $A=M^{T}M$ 是正定矩阵，U 和 V 是归一化正交向量集，所以我们有 $U^{T}U=I$。</p>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>PCA 不能处理线性不可分的数据，数据可能位于多个子空间中。我们可以从方程（1）中看出。降维后的数据$B$是由原始数据$A$通过线性变换$P$得到的。PCA 不是为处理非线性数据而设计的，所以在处理非线性数据时，效果可能不太行。</p>\n<h2 id=\"实验效果-MNIST\"><a href=\"#实验效果-MNIST\" class=\"headerlink\" title=\"实验效果(MNIST)\"></a>实验效果(MNIST)</h2><p>由于Sklearn已经对PCA做了很多的优化，需要代码的朋友可以之间调库解决：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Pca</span>(<span class=\"params\">test_data, train_data, component</span>):</span></span><br><span class=\"line\">    solver = PCA(n_components = component) <span class=\"comment\">#test_data为测试集, train_data为训练集, component为降维后的维度</span></span><br><span class=\"line\">    solver.fit(train_data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> solver.transform(test_data)</span><br></pre></td></tr></table></figure>\n<div>            \n    <center>    \n    <img src=\"/2022/01/11/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(1)-PCA/train_pca.png\" alt=\"train_pca\" style=\"zoom:50%\">\n    <img src=\"/2022/01/11/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(1)-PCA/test_pca.png\" alt=\"test_pca\" style=\"zoom:50%;\">\n    </center>\n</div>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. Left: Train dataset, Right: Test dataset.</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>很多地方说的不是很细，本篇博客更重要的是去回答一些看论文中的问题。</p>\n"},{"title":"子空间学习(10)- t-SNE","catalog":true,"date":"2022-01-22T04:12:17.000Z","subtitle":"Subspace Learning- t-SNE","top":17,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Visualizing Data using t-SNE（2008 JMLR）**，**Learning a Parametric embedding by preserving local structure（2009 AISTATS）**和**Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion（2010 JMLR）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述数据可视化方法t-SNE。\n\n# 摘要：\n\n无监督降维算法在表示学习中起着重要作用。 其中，t-SNE 旨在更好地创建一个单一的地图，以揭示许多不同尺度的结构。 此外，parametric t-SNE 学习在潜在空间中尽可能好地保留数据的局部结构的参数映射。 在本报告中，我们尝试从数学的角度探索 t-SNE 和parametric t-SNE，并评估 t-SNE 和parametric t-SNE 在 MNIST 上的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# t-SNE\n\nt-SNE 中的 $t$ 是指 Student-t 分布，用于计算低维空间中两点之间的相似度。更具体地说，Student-t 分布在低维空间中采用重尾分布来缓解 SNE 的拥挤问题和优化问题。在 t-SNE 中，Student-t 分布是具有一个自由度的低维映射中的重尾分布，该分布中的联合概率 $q_{ij}$ 为公式(1)：\n$$\n\\begin{equation}\n    q_{ij}=\\frac{\\left(1+\\|y_{i}-y_{j}\\|^{2}\\right)^{-1}}{\\sum_{k \\neq l}\\left(1+\\|y_{k}-y_{l}\\|^{2}\\right)^{-1}}.\n\\end{equation}\\tag{1}\n$$\nt-SNE 中的 SNE 指的是 Stochastic Neighbor Embedding，旨在找到一种低维数据表示，以最小化 $p_{j|i}$ 和 $q_{j|i}$ 之间的不匹配。更具体地说，SNE 使用梯度下降法最小化所有数据点上的 Kullback-Leibler 散度的总和，见公式(2)：\n$$\n\\begin{equation}\n    C=\\sum_{i}\\operatorname{KL}(P_{i}||Q_{i})=\\sum_{i}\\sum_{j}p_{j|i}log\\frac{p_{j|i}}{q_{j|i}},\n\\end{equation}\\tag{2}\n$$\n其中 $P_{i}$ 表示给定数据点 $x_{i}$ 的所有其他数据点的条件概率分布，$Q_{i}$ 表示给定数据点 $y_{i}$ 的所有其他数据点的条件概率分布。数据点 $x_{j}$ 与数据点 $x_{i}$ 的相似性是条件概率 $p_{j|i}$（见公式(3)），而 $q_{j|i}$是低维空间中的类似定义，见公式(1)：\n$$\n\\begin{equation}\n    p_{i j}=\\frac{\\exp \\left(-\\left\\|x_{i}-x_{j}\\right\\|^{2} / 2 \\sigma^{2}\\right)}{\\sum_{k \\neq l} \\exp \\left(-\\left\\|x_{k}-x_{l}\\right\\|^{2} / 2 \\sigma^{2}\\right)}.\n\\end{equation}\\tag{3}\n$$\n\n# AutoEncoder\n\n自编码器是一种人工神经网络，用于学习未标记数据的有效编码。 通过尝试从编码重新生成输入来验证和改进编码。 自编码器通过训练网络忽略噪声来学习一组数据的表示（编码），通常用于降维。\n\n自动编码器有两个主要部分：将输入映射到代码的编码器，以及将代码映射到输入重构的解码器。 数学上，我们假设编码器是$\\phi$，解码器是$\\psi$，自动编码器的目标函数是公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\phi:\\ X\\rightarrow \\mathcal{F}\\\\\n        \\psi:\\ \\mathcal{F}\\rightarrow Y \\\\\n        \\phi,\\psi=\\underset{\\phi,\\psi}{\\arg \\min}\\|X-(\\psi \\circ \\phi) X \\|^{2},\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $h=\\sigma\\left(Wx+b\\right)\\in \\mathcal{R}^{p}=\\mathcal{F}$。\n\n# Parametric t-SNE\n\nParametric t-SNE 旨在保留潜在空间中数据的局部结构，而 t-SNE 也有类似的目标。但是，Parametric t-SNE 具有以下优点：\n\n- 参数映射的缺乏使得非参数降维技术不太适合用于例如分类或回归任务。\n\n- 为了解决反向传播容易陷入局部最小值的问题，t-SNE 使用了一种训练过程，其灵感来自基于受限玻尔兹曼机 (RBM) 的自动编码器训练。更具体地说，所有节点上的联合分布由能量函数 $E(v,h)$ 指定的玻尔兹曼分布给出：\n  $$\n  E(v,h)=-\\sum_{i,j}W_{ij}v_{i}h_{j}-\\sum_{i}b_{i}v_{i}-\\sum_{j}c_{j}h_{j}.\n  $$\n\nParametric t-SNE 中的参数是指参数映射 $f:X\\rightarrow Y$，它通过权重为 $W$ 的前馈神经网络进行参数化。数据空间为$X$，低维潜在空间为$Y$。更具体地说，参数 t-SNE 的参数是自由度的数量，用于计算低维潜在空间中的相似性 $Q$，参见公式(5)：\n$$\n\\begin{equation}\n    q_{i j}=\\frac{\\left(1+\\left\\|f\\left(x_{i} \\mid W\\right)-f\\left(x_{j} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}}{\\sum_{k \\neq l}\\left(1+\\left\\|f\\left(x_{k} \\mid W\\right)-f\\left(x_{l} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}},\n\\end{equation}\\tag{5}\n$$\n其中 $\\alpha$ 表示 Student-t 分布的自由度数。\n\n潜在空间中使用的Student-t分布可能包含分布下的大部分概率质量，因为潜在空间$Y$的体积随其维度呈指数增长。这导致的问题可以通过设置自由度 $\\alpha$ 以校正潜在空间体积的指数增长来解决，因为增加自由度 $\\alpha$ 会导致分布较轻的尾巴。\n\n# 实验结果\n\n为了更直观地了解 t-SNE 和parametric t-SNE，我们分析了它们在 MNIST 和其他数据集上的性能，分别在如下数据集进行了实验：\n\n- MNIST：前 2k 个训练图像和前 2k 个测试图像。\n- COIL-20：数据库包含 20 个对象。 每个物体水平旋转 360°，每 5° 拍摄一张照片。 因此，每个物体有72张像素大小为64X64的图像，总共有360张灰度图像。\n- Olivetti Faces：由40个人的400张图片组成，即每个人有10张人脸图片。 每张图片的灰度为8位，每个像素的灰度在0-255之间，每张图片的大小为$64\\times 64$。\n\n<img src=\"子空间学习(10)-t-SNE\\MNIST.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. t-SNE在三个数据集上的实验结果。</center>\n<img src=\"子空间学习(10)-t-SNE\\MNIST2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. Parametric 和AutoEncoder在MNIST上的实验结果。</center>\nt-SNE在sklearn上有库，然后AutoEncoder网上代码也很多，parametric t-SNE我直接复现但是效果太差，没有找出bug...最后直接参考别人的代码。这里简单放一下t-SNE的代码，另外两个算法的代码，后续github有机会更新。\n\n```python\nfrom sklearn.manifold import TSNE\n\ndata_tsne=TSNE(n_components=2,perplexity=5).fit_transform(data) #这里参数可自定义\n```\n\n\n\n# 总结\n\n简单写的，最后一篇子空间学习笔记了。\n\n\n\n ","source":"_posts/子空间学习(10)-t-SNE.md","raw":"---\ntitle: 子空间学习(10)- t-SNE\ncatalog: true\ndate: 2022-01-22 12:12:17\nsubtitle: Subspace Learning- t-SNE\ntop: 17\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Visualizing Data using t-SNE（2008 JMLR）**，**Learning a Parametric embedding by preserving local structure（2009 AISTATS）**和**Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion（2010 JMLR）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述数据可视化方法t-SNE。\n\n# 摘要：\n\n无监督降维算法在表示学习中起着重要作用。 其中，t-SNE 旨在更好地创建一个单一的地图，以揭示许多不同尺度的结构。 此外，parametric t-SNE 学习在潜在空间中尽可能好地保留数据的局部结构的参数映射。 在本报告中，我们尝试从数学的角度探索 t-SNE 和parametric t-SNE，并评估 t-SNE 和parametric t-SNE 在 MNIST 上的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# t-SNE\n\nt-SNE 中的 $t$ 是指 Student-t 分布，用于计算低维空间中两点之间的相似度。更具体地说，Student-t 分布在低维空间中采用重尾分布来缓解 SNE 的拥挤问题和优化问题。在 t-SNE 中，Student-t 分布是具有一个自由度的低维映射中的重尾分布，该分布中的联合概率 $q_{ij}$ 为公式(1)：\n$$\n\\begin{equation}\n    q_{ij}=\\frac{\\left(1+\\|y_{i}-y_{j}\\|^{2}\\right)^{-1}}{\\sum_{k \\neq l}\\left(1+\\|y_{k}-y_{l}\\|^{2}\\right)^{-1}}.\n\\end{equation}\\tag{1}\n$$\nt-SNE 中的 SNE 指的是 Stochastic Neighbor Embedding，旨在找到一种低维数据表示，以最小化 $p_{j|i}$ 和 $q_{j|i}$ 之间的不匹配。更具体地说，SNE 使用梯度下降法最小化所有数据点上的 Kullback-Leibler 散度的总和，见公式(2)：\n$$\n\\begin{equation}\n    C=\\sum_{i}\\operatorname{KL}(P_{i}||Q_{i})=\\sum_{i}\\sum_{j}p_{j|i}log\\frac{p_{j|i}}{q_{j|i}},\n\\end{equation}\\tag{2}\n$$\n其中 $P_{i}$ 表示给定数据点 $x_{i}$ 的所有其他数据点的条件概率分布，$Q_{i}$ 表示给定数据点 $y_{i}$ 的所有其他数据点的条件概率分布。数据点 $x_{j}$ 与数据点 $x_{i}$ 的相似性是条件概率 $p_{j|i}$（见公式(3)），而 $q_{j|i}$是低维空间中的类似定义，见公式(1)：\n$$\n\\begin{equation}\n    p_{i j}=\\frac{\\exp \\left(-\\left\\|x_{i}-x_{j}\\right\\|^{2} / 2 \\sigma^{2}\\right)}{\\sum_{k \\neq l} \\exp \\left(-\\left\\|x_{k}-x_{l}\\right\\|^{2} / 2 \\sigma^{2}\\right)}.\n\\end{equation}\\tag{3}\n$$\n\n# AutoEncoder\n\n自编码器是一种人工神经网络，用于学习未标记数据的有效编码。 通过尝试从编码重新生成输入来验证和改进编码。 自编码器通过训练网络忽略噪声来学习一组数据的表示（编码），通常用于降维。\n\n自动编码器有两个主要部分：将输入映射到代码的编码器，以及将代码映射到输入重构的解码器。 数学上，我们假设编码器是$\\phi$，解码器是$\\psi$，自动编码器的目标函数是公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\phi:\\ X\\rightarrow \\mathcal{F}\\\\\n        \\psi:\\ \\mathcal{F}\\rightarrow Y \\\\\n        \\phi,\\psi=\\underset{\\phi,\\psi}{\\arg \\min}\\|X-(\\psi \\circ \\phi) X \\|^{2},\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $h=\\sigma\\left(Wx+b\\right)\\in \\mathcal{R}^{p}=\\mathcal{F}$。\n\n# Parametric t-SNE\n\nParametric t-SNE 旨在保留潜在空间中数据的局部结构，而 t-SNE 也有类似的目标。但是，Parametric t-SNE 具有以下优点：\n\n- 参数映射的缺乏使得非参数降维技术不太适合用于例如分类或回归任务。\n\n- 为了解决反向传播容易陷入局部最小值的问题，t-SNE 使用了一种训练过程，其灵感来自基于受限玻尔兹曼机 (RBM) 的自动编码器训练。更具体地说，所有节点上的联合分布由能量函数 $E(v,h)$ 指定的玻尔兹曼分布给出：\n  $$\n  E(v,h)=-\\sum_{i,j}W_{ij}v_{i}h_{j}-\\sum_{i}b_{i}v_{i}-\\sum_{j}c_{j}h_{j}.\n  $$\n\nParametric t-SNE 中的参数是指参数映射 $f:X\\rightarrow Y$，它通过权重为 $W$ 的前馈神经网络进行参数化。数据空间为$X$，低维潜在空间为$Y$。更具体地说，参数 t-SNE 的参数是自由度的数量，用于计算低维潜在空间中的相似性 $Q$，参见公式(5)：\n$$\n\\begin{equation}\n    q_{i j}=\\frac{\\left(1+\\left\\|f\\left(x_{i} \\mid W\\right)-f\\left(x_{j} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}}{\\sum_{k \\neq l}\\left(1+\\left\\|f\\left(x_{k} \\mid W\\right)-f\\left(x_{l} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}},\n\\end{equation}\\tag{5}\n$$\n其中 $\\alpha$ 表示 Student-t 分布的自由度数。\n\n潜在空间中使用的Student-t分布可能包含分布下的大部分概率质量，因为潜在空间$Y$的体积随其维度呈指数增长。这导致的问题可以通过设置自由度 $\\alpha$ 以校正潜在空间体积的指数增长来解决，因为增加自由度 $\\alpha$ 会导致分布较轻的尾巴。\n\n# 实验结果\n\n为了更直观地了解 t-SNE 和parametric t-SNE，我们分析了它们在 MNIST 和其他数据集上的性能，分别在如下数据集进行了实验：\n\n- MNIST：前 2k 个训练图像和前 2k 个测试图像。\n- COIL-20：数据库包含 20 个对象。 每个物体水平旋转 360°，每 5° 拍摄一张照片。 因此，每个物体有72张像素大小为64X64的图像，总共有360张灰度图像。\n- Olivetti Faces：由40个人的400张图片组成，即每个人有10张人脸图片。 每张图片的灰度为8位，每个像素的灰度在0-255之间，每张图片的大小为$64\\times 64$。\n\n<img src=\"子空间学习(10)-t-SNE\\MNIST.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. t-SNE在三个数据集上的实验结果。</center>\n<img src=\"子空间学习(10)-t-SNE\\MNIST2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. Parametric 和AutoEncoder在MNIST上的实验结果。</center>\nt-SNE在sklearn上有库，然后AutoEncoder网上代码也很多，parametric t-SNE我直接复现但是效果太差，没有找出bug...最后直接参考别人的代码。这里简单放一下t-SNE的代码，另外两个算法的代码，后续github有机会更新。\n\n```python\nfrom sklearn.manifold import TSNE\n\ndata_tsne=TSNE(n_components=2,perplexity=5).fit_transform(data) #这里参数可自定义\n```\n\n\n\n# 总结\n\n简单写的，最后一篇子空间学习笔记了。\n\n\n\n ","slug":"子空间学习(10)-t-SNE","published":1,"updated":"2022-01-13T12:56:37.487Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxx2000o3oue4g8c2ic1","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Visualizing Data using t-SNE（2008 JMLR）</strong>，<strong>Learning a Parametric embedding by preserving local structure（2009 AISTATS）</strong>和<strong>Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion（2010 JMLR）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述数据可视化方法t-SNE。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>无监督降维算法在表示学习中起着重要作用。 其中，t-SNE 旨在更好地创建一个单一的地图，以揭示许多不同尺度的结构。 此外，parametric t-SNE 学习在潜在空间中尽可能好地保留数据的局部结构的参数映射。 在本报告中，我们尝试从数学的角度探索 t-SNE 和parametric t-SNE，并评估 t-SNE 和parametric t-SNE 在 MNIST 上的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"t-SNE\"><a href=\"#t-SNE\" class=\"headerlink\" title=\"t-SNE\"></a>t-SNE</h1><p>t-SNE 中的 $t$ 是指 Student-t 分布，用于计算低维空间中两点之间的相似度。更具体地说，Student-t 分布在低维空间中采用重尾分布来缓解 SNE 的拥挤问题和优化问题。在 t-SNE 中，Student-t 分布是具有一个自由度的低维映射中的重尾分布，该分布中的联合概率 $q_{ij}$ 为公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    q_{ij}=\\frac{\\left(1+\\|y_{i}-y_{j}\\|^{2}\\right)^{-1}}{\\sum_{k \\neq l}\\left(1+\\|y_{k}-y_{l}\\|^{2}\\right)^{-1}}.\n\\end{equation}\\tag{1}</script><p>t-SNE 中的 SNE 指的是 Stochastic Neighbor Embedding，旨在找到一种低维数据表示，以最小化 $p_{j|i}$ 和 $q_{j|i}$ 之间的不匹配。更具体地说，SNE 使用梯度下降法最小化所有数据点上的 Kullback-Leibler 散度的总和，见公式(2)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    C=\\sum_{i}\\operatorname{KL}(P_{i}||Q_{i})=\\sum_{i}\\sum_{j}p_{j|i}log\\frac{p_{j|i}}{q_{j|i}},\n\\end{equation}\\tag{2}</script><p>其中 $P_{i}$ 表示给定数据点 $x_{i}$ 的所有其他数据点的条件概率分布，$Q_{i}$ 表示给定数据点 $y_{i}$ 的所有其他数据点的条件概率分布。数据点 $x_{j}$ 与数据点 $x_{i}$ 的相似性是条件概率 $p_{j|i}$（见公式(3)），而 $q_{j|i}$是低维空间中的类似定义，见公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    p_{i j}=\\frac{\\exp \\left(-\\left\\|x_{i}-x_{j}\\right\\|^{2} / 2 \\sigma^{2}\\right)}{\\sum_{k \\neq l} \\exp \\left(-\\left\\|x_{k}-x_{l}\\right\\|^{2} / 2 \\sigma^{2}\\right)}.\n\\end{equation}\\tag{3}</script><h1 id=\"AutoEncoder\"><a href=\"#AutoEncoder\" class=\"headerlink\" title=\"AutoEncoder\"></a>AutoEncoder</h1><p>自编码器是一种人工神经网络，用于学习未标记数据的有效编码。 通过尝试从编码重新生成输入来验证和改进编码。 自编码器通过训练网络忽略噪声来学习一组数据的表示（编码），通常用于降维。</p>\n<p>自动编码器有两个主要部分：将输入映射到代码的编码器，以及将代码映射到输入重构的解码器。 数学上，我们假设编码器是$\\phi$，解码器是$\\psi$，自动编码器的目标函数是公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\phi:\\ X\\rightarrow \\mathcal{F}\\\\\n        \\psi:\\ \\mathcal{F}\\rightarrow Y \\\\\n        \\phi,\\psi=\\underset{\\phi,\\psi}{\\arg \\min}\\|X-(\\psi \\circ \\phi) X \\|^{2},\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $h=\\sigma\\left(Wx+b\\right)\\in \\mathcal{R}^{p}=\\mathcal{F}$。</p>\n<h1 id=\"Parametric-t-SNE\"><a href=\"#Parametric-t-SNE\" class=\"headerlink\" title=\"Parametric t-SNE\"></a>Parametric t-SNE</h1><p>Parametric t-SNE 旨在保留潜在空间中数据的局部结构，而 t-SNE 也有类似的目标。但是，Parametric t-SNE 具有以下优点：</p>\n<ul>\n<li><p>参数映射的缺乏使得非参数降维技术不太适合用于例如分类或回归任务。</p>\n</li>\n<li><p>为了解决反向传播容易陷入局部最小值的问题，t-SNE 使用了一种训练过程，其灵感来自基于受限玻尔兹曼机 (RBM) 的自动编码器训练。更具体地说，所有节点上的联合分布由能量函数 $E(v,h)$ 指定的玻尔兹曼分布给出：</p>\n<script type=\"math/tex; mode=display\">\nE(v,h)=-\\sum_{i,j}W_{ij}v_{i}h_{j}-\\sum_{i}b_{i}v_{i}-\\sum_{j}c_{j}h_{j}.</script></li>\n</ul>\n<p>Parametric t-SNE 中的参数是指参数映射 $f:X\\rightarrow Y$，它通过权重为 $W$ 的前馈神经网络进行参数化。数据空间为$X$，低维潜在空间为$Y$。更具体地说，参数 t-SNE 的参数是自由度的数量，用于计算低维潜在空间中的相似性 $Q$，参见公式(5)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    q_{i j}=\\frac{\\left(1+\\left\\|f\\left(x_{i} \\mid W\\right)-f\\left(x_{j} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}}{\\sum_{k \\neq l}\\left(1+\\left\\|f\\left(x_{k} \\mid W\\right)-f\\left(x_{l} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}},\n\\end{equation}\\tag{5}</script><p>其中 $\\alpha$ 表示 Student-t 分布的自由度数。</p>\n<p>潜在空间中使用的Student-t分布可能包含分布下的大部分概率质量，因为潜在空间$Y$的体积随其维度呈指数增长。这导致的问题可以通过设置自由度 $\\alpha$ 以校正潜在空间体积的指数增长来解决，因为增加自由度 $\\alpha$ 会导致分布较轻的尾巴。</p>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>为了更直观地了解 t-SNE 和parametric t-SNE，我们分析了它们在 MNIST 和其他数据集上的性能，分别在如下数据集进行了实验：</p>\n<ul>\n<li>MNIST：前 2k 个训练图像和前 2k 个测试图像。</li>\n<li>COIL-20：数据库包含 20 个对象。 每个物体水平旋转 360°，每 5° 拍摄一张照片。 因此，每个物体有72张像素大小为64X64的图像，总共有360张灰度图像。</li>\n<li>Olivetti Faces：由40个人的400张图片组成，即每个人有10张人脸图片。 每张图片的灰度为8位，每个像素的灰度在0-255之间，每张图片的大小为$64\\times 64$。</li>\n</ul>\n<p><img src=\"/2022/01/22/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(10)-t-SNE/MNIST.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图1. t-SNE在三个数据集上的实验结果。</center><br><img src=\"/2022/01/22/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(10)-t-SNE/MNIST2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图2. Parametric 和AutoEncoder在MNIST上的实验结果。</center><br>t-SNE在sklearn上有库，然后AutoEncoder网上代码也很多，parametric t-SNE我直接复现但是效果太差，没有找出bug…最后直接参考别人的代码。这里简单放一下t-SNE的代码，另外两个算法的代码，后续github有机会更新。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> TSNE</span><br><span class=\"line\"></span><br><span class=\"line\">data_tsne=TSNE(n_components=<span class=\"number\">2</span>,perplexity=<span class=\"number\">5</span>).fit_transform(data) <span class=\"comment\">#这里参数可自定义</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>简单写的，最后一篇子空间学习笔记了。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Visualizing Data using t-SNE（2008 JMLR）</strong>，<strong>Learning a Parametric embedding by preserving local structure（2009 AISTATS）</strong>和<strong>Stacked Denoising Autoencoders - Learning Useful Representations in a Deep Network with a Local Denoising Criterion（2010 JMLR）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述数据可视化方法t-SNE。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>无监督降维算法在表示学习中起着重要作用。 其中，t-SNE 旨在更好地创建一个单一的地图，以揭示许多不同尺度的结构。 此外，parametric t-SNE 学习在潜在空间中尽可能好地保留数据的局部结构的参数映射。 在本报告中，我们尝试从数学的角度探索 t-SNE 和parametric t-SNE，并评估 t-SNE 和parametric t-SNE 在 MNIST 上的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"t-SNE\"><a href=\"#t-SNE\" class=\"headerlink\" title=\"t-SNE\"></a>t-SNE</h1><p>t-SNE 中的 $t$ 是指 Student-t 分布，用于计算低维空间中两点之间的相似度。更具体地说，Student-t 分布在低维空间中采用重尾分布来缓解 SNE 的拥挤问题和优化问题。在 t-SNE 中，Student-t 分布是具有一个自由度的低维映射中的重尾分布，该分布中的联合概率 $q_{ij}$ 为公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    q_{ij}=\\frac{\\left(1+\\|y_{i}-y_{j}\\|^{2}\\right)^{-1}}{\\sum_{k \\neq l}\\left(1+\\|y_{k}-y_{l}\\|^{2}\\right)^{-1}}.\n\\end{equation}\\tag{1}</script><p>t-SNE 中的 SNE 指的是 Stochastic Neighbor Embedding，旨在找到一种低维数据表示，以最小化 $p_{j|i}$ 和 $q_{j|i}$ 之间的不匹配。更具体地说，SNE 使用梯度下降法最小化所有数据点上的 Kullback-Leibler 散度的总和，见公式(2)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    C=\\sum_{i}\\operatorname{KL}(P_{i}||Q_{i})=\\sum_{i}\\sum_{j}p_{j|i}log\\frac{p_{j|i}}{q_{j|i}},\n\\end{equation}\\tag{2}</script><p>其中 $P_{i}$ 表示给定数据点 $x_{i}$ 的所有其他数据点的条件概率分布，$Q_{i}$ 表示给定数据点 $y_{i}$ 的所有其他数据点的条件概率分布。数据点 $x_{j}$ 与数据点 $x_{i}$ 的相似性是条件概率 $p_{j|i}$（见公式(3)），而 $q_{j|i}$是低维空间中的类似定义，见公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    p_{i j}=\\frac{\\exp \\left(-\\left\\|x_{i}-x_{j}\\right\\|^{2} / 2 \\sigma^{2}\\right)}{\\sum_{k \\neq l} \\exp \\left(-\\left\\|x_{k}-x_{l}\\right\\|^{2} / 2 \\sigma^{2}\\right)}.\n\\end{equation}\\tag{3}</script><h1 id=\"AutoEncoder\"><a href=\"#AutoEncoder\" class=\"headerlink\" title=\"AutoEncoder\"></a>AutoEncoder</h1><p>自编码器是一种人工神经网络，用于学习未标记数据的有效编码。 通过尝试从编码重新生成输入来验证和改进编码。 自编码器通过训练网络忽略噪声来学习一组数据的表示（编码），通常用于降维。</p>\n<p>自动编码器有两个主要部分：将输入映射到代码的编码器，以及将代码映射到输入重构的解码器。 数学上，我们假设编码器是$\\phi$，解码器是$\\psi$，自动编码器的目标函数是公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\phi:\\ X\\rightarrow \\mathcal{F}\\\\\n        \\psi:\\ \\mathcal{F}\\rightarrow Y \\\\\n        \\phi,\\psi=\\underset{\\phi,\\psi}{\\arg \\min}\\|X-(\\psi \\circ \\phi) X \\|^{2},\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $h=\\sigma\\left(Wx+b\\right)\\in \\mathcal{R}^{p}=\\mathcal{F}$。</p>\n<h1 id=\"Parametric-t-SNE\"><a href=\"#Parametric-t-SNE\" class=\"headerlink\" title=\"Parametric t-SNE\"></a>Parametric t-SNE</h1><p>Parametric t-SNE 旨在保留潜在空间中数据的局部结构，而 t-SNE 也有类似的目标。但是，Parametric t-SNE 具有以下优点：</p>\n<ul>\n<li><p>参数映射的缺乏使得非参数降维技术不太适合用于例如分类或回归任务。</p>\n</li>\n<li><p>为了解决反向传播容易陷入局部最小值的问题，t-SNE 使用了一种训练过程，其灵感来自基于受限玻尔兹曼机 (RBM) 的自动编码器训练。更具体地说，所有节点上的联合分布由能量函数 $E(v,h)$ 指定的玻尔兹曼分布给出：</p>\n<script type=\"math/tex; mode=display\">\nE(v,h)=-\\sum_{i,j}W_{ij}v_{i}h_{j}-\\sum_{i}b_{i}v_{i}-\\sum_{j}c_{j}h_{j}.</script></li>\n</ul>\n<p>Parametric t-SNE 中的参数是指参数映射 $f:X\\rightarrow Y$，它通过权重为 $W$ 的前馈神经网络进行参数化。数据空间为$X$，低维潜在空间为$Y$。更具体地说，参数 t-SNE 的参数是自由度的数量，用于计算低维潜在空间中的相似性 $Q$，参见公式(5)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    q_{i j}=\\frac{\\left(1+\\left\\|f\\left(x_{i} \\mid W\\right)-f\\left(x_{j} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}}{\\sum_{k \\neq l}\\left(1+\\left\\|f\\left(x_{k} \\mid W\\right)-f\\left(x_{l} \\mid W\\right)\\right\\|^{2} / \\alpha\\right)^{-\\frac{\\alpha+1}{2}}},\n\\end{equation}\\tag{5}</script><p>其中 $\\alpha$ 表示 Student-t 分布的自由度数。</p>\n<p>潜在空间中使用的Student-t分布可能包含分布下的大部分概率质量，因为潜在空间$Y$的体积随其维度呈指数增长。这导致的问题可以通过设置自由度 $\\alpha$ 以校正潜在空间体积的指数增长来解决，因为增加自由度 $\\alpha$ 会导致分布较轻的尾巴。</p>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>为了更直观地了解 t-SNE 和parametric t-SNE，我们分析了它们在 MNIST 和其他数据集上的性能，分别在如下数据集进行了实验：</p>\n<ul>\n<li>MNIST：前 2k 个训练图像和前 2k 个测试图像。</li>\n<li>COIL-20：数据库包含 20 个对象。 每个物体水平旋转 360°，每 5° 拍摄一张照片。 因此，每个物体有72张像素大小为64X64的图像，总共有360张灰度图像。</li>\n<li>Olivetti Faces：由40个人的400张图片组成，即每个人有10张人脸图片。 每张图片的灰度为8位，每个像素的灰度在0-255之间，每张图片的大小为$64\\times 64$。</li>\n</ul>\n<p><img src=\"/2022/01/22/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(10)-t-SNE/MNIST.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图1. t-SNE在三个数据集上的实验结果。</center><br><img src=\"/2022/01/22/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(10)-t-SNE/MNIST2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图2. Parametric 和AutoEncoder在MNIST上的实验结果。</center><br>t-SNE在sklearn上有库，然后AutoEncoder网上代码也很多，parametric t-SNE我直接复现但是效果太差，没有找出bug…最后直接参考别人的代码。这里简单放一下t-SNE的代码，另外两个算法的代码，后续github有机会更新。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> TSNE</span><br><span class=\"line\"></span><br><span class=\"line\">data_tsne=TSNE(n_components=<span class=\"number\">2</span>,perplexity=<span class=\"number\">5</span>).fit_transform(data) <span class=\"comment\">#这里参数可自定义</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>简单写的，最后一篇子空间学习笔记了。</p>\n"},{"title":"子空间学习(3)-LE","catalog":true,"date":"2022-01-13T04:24:17.000Z","subtitle":"Subspace Learning-LE","top":10,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Laplacian Eigenmaps for Dimensionality Reduction and Data Representation（2003 NC）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，其中，Laplacian Eigenmaps (LE) 是一种用于表示高维数据的几何动机算法，它利用了图 Laplacian、流形上的 Laplace Beltrami 算子以及与热方程的联系之间的对应关系 。LE算法为非线性降维提供了一种计算效率高的方法，保留了局部特性和聚类的一种自然联系。 在本报告中，我们尝试以数学方式解释 LE 的主要思想，并讨论 PCA 、LLE 和 LE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Question&Answer：\n\n## 假设\n\nLE 假设数据是从平滑、紧凑的<u>黎曼流形</u>中采样的，并且流形上有均匀的概率分布。进一步来说，\n\n- 数据是从光滑、紧凑的<u>黎曼流形</u>中采样的<u>光滑流形</u>，即数据是无限可微的。更具体地说，从流形到低维空间的映射 $f:\\mathbb{M} \\rightarrow \\mathbb{R}$ 是两次可微的\n  $$\n  \\begin{gathered}\n              f^{\\prime \\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f^{\\prime}\\left(x_{0}+\\Delta x\\right)-f^{\\prime}\\left(x_{0}\\right)}{\\Delta x}.\n          \\end{gathered}\n  $$\n\n- 流形上有一个均匀的概率分布，即采样密度使得每个数据点具有 $2d$  邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。\n\n## 解决的问题\n\nLE 试图通过使用图拉普拉斯算子之间的对应关系来为位于嵌入高维空间的低维流形上的数据构建表示，从而降低平滑、紧凑的黎曼流形的维数。\n\n## 理解LE算法中的拉普拉斯映射\n\n### 拉普拉斯图\n\nLE 中的<u>拉普拉斯算子</u>是指 LE 计算数据集的低维表示，该表示通过使用拉普拉斯矩阵 $L$ 的概念在某种意义上最优地保留了局部邻域信息。拉普拉斯矩阵可以用两个矩阵之间的差来表示，\n$$\nL=D-W\n$$\n其中$W$是使用一些策略来连接的邻接矩阵（参见之后的具体步骤），$D$是一个对角矩阵，其对角元素为度数（$D_{ii}=\\ sum^{n}_{j=1}W_{ij}$)。此外，流形拉普拉斯算子有几种可能的近似方案，例如，我们可以计算具有以下权重的图拉普拉斯算子，\n$$\nW_{ij}=\\begin{cases}\n    H_{t}(x_{i}, x_{j})e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{4t}} & \\text{ if }\\|x_{i}-x_{j}\\|< \\epsilon \\\\\n    0 & otherwise\n    \\end{cases},\n$$\n其中 $t \\in \\mathbb{R}$, $\\epsilon \\in \\mathbb{R}$ ，$H_{t}$ 是热核函数。\n\n### 映射\n\n在解释特征映射之前，我们应该了解什么是<u>映射</u>和<u>特征分解</u>。LE 中的特征映射是指数据的嵌入映射近似于<u>Laplace Beltrami 算子</u>的特征映射，它们是在整个流形上本质上定义的映射。 从<u>流形</u>的定义，数据的特征映射$f$如下所示：\n$$\n \\forall x_{i} \\ \\exists x_{U(i)}: \\ \\Phi(x_{U(i)})\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)) \\ (f \\subseteq \\mathbb{R}^{n}),\n$$\n其中 $f=[f_{0}, f_{1}, \\cdots, f_{k-1}]$ 是拉普拉斯图的特征映射。\n\n## 目标函数\n\nLLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：\n$$\n\\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,\n    \\end{gathered}\\tag{1}\n$$\n\n其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的，$d$是降维之后数据集的维度，$Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$是降维后的数据集。\n\n## 算法流程\n\n给定 $k$ 个数据点 $x_{1}, x_{2}, \\cdots, x_{k}$ in $\\mathbb{R}^{l}$，我们构建一个有 $k$ 个节点的加权图，每一个节点代表一个数据点，加权图的边表示两个数据点之间的关系。 现在通过计算图拉普拉斯算子的特征向量来构造嵌入图。 算法过程的三个步骤如下所示：\n\n### 第 1 步：构建邻接图\n\n动机：LE 明确考虑了数据可能驻留在其上的流形的局部结构。 因此，LE 构建了一个包含数据邻域信息的邻接图。\n\n假设：原始数据的构造图是连通的。（当然你可以用一些其他方法让它联通）\n\n如果 $x_{i}$ 和 $x_{j}$ 满足以下策略的条件，我们将边放在节点 $i$ 和 $j$ 之间。 因此，提出了两种策略：\n\n- $\\epsilon$-neighborhoods（参数 $\\epsilon \\in \\mathbb{R}$）： 如果 $\\|x_{i}-x_{j}\\|<\\epsilon$ ，节点 $i$ 和 $j$ 将会被连接，其中范数通常是在 $\\mathbb{R}^{l}$上的欧几里得范数。\n- $n$ nearest neighbors：如果 $i$ 位于 $j$ 的 $n$ 个最近邻居中或 $j$ 位于 $i$ 的 $n$ 个最近邻居中，则节点 $i$ 和 $j$ 由一条边连接。 \n\n### 第 2 步：选择权重\n\n在我们构建了邻接图之后，我们需要计算相邻点之间边的权重来构建邻接矩阵$W$，有两种对边进行加权的方法：\n\n- 核函数：如果节点 $i$ 和 $j$ 相连，$W_{ij}=e^{-\\frac{\\|x_{i}-x_{j\\|}^2}{t}}$，否则，$W{ij}$ = 0。稍后将提供这种权重选择的理由。\n- Simple-minded：$W_{ij}=1$ 如果顶点 i 和 j 由边连接，$W_{ij}=0$ 如果顶点 $i$ 和 $j$ 没有边连接。 这种简化避免了选择 $t$ 的需要。\n\n###  第3步：特征映射\n\n  由 LE 生成的嵌入映射可以被视为对连续映射的离散近似，连续映射自然产生于流形的几何形状。接下来我们计算得到特征映射，我们需要解决如下<u>特征分解</u>问题，\n$$\nLf=\\lambda Df,\n$$\n其中 $D$ 是对角矩阵，其对角线元素的值是 W 的列元素之和（或行，因为 W 是对称的）：$D_{ii}=\\sum_{j}W_{ji}$。 $L=D-W$ 是拉普拉斯矩阵。拉普拉斯矩阵是一个对称的半正定矩阵，可以将其视为定义在 G 的顶点上的拉普拉斯算子。设 $f_{0}, f_{1}, \\cdots, f_{k-1}$ 是方程的解，根据它们的特征值排序：\n$$\n  Lf_{i}=\\lambda Df_{i},\\ (0\\leq i\\leq k-1) \\\\\n        0=\\lambda_{0}\\leq\\lambda_{1}\\leq\\cdots\\leq\\lambda_{k-1}.\n$$\n然后，我们去掉对应于特征值 0 的特征向量 $f_{0}$ 并使用接下来的 $m$ 个特征向量嵌入 m 维欧几里得空间：\n$$\nx_{i}\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)).\n$$\n\n## 具体的推导过程\n\n在这一部分，我们展示了 LE 解决方案的细节。给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。 为了讨论的目的，假设图是连通的。 设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。 然后，我们可以将目标函数转化为半正定二次型矩阵的迹，如下推导，\n$$\n\\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &\\!=\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sum_{j=1}^{n}\\!W_{i j}\\!\\right)\\!y_{i} y_{i}\\!+\\!\\sum_{j=1}^{n}\\!\\left(\\!\\sum_{i=1}^{n}\\!W_{i j}\\!\\right)\\! y_{j} y_{j}\\!-\\!2\\!\\sum_{i=1}^{n}\\!\\sum_{j=1}^{n}\\!y_{i}\\!y_{j}\\!W_{i j}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sqrt{D_{i i}}\\!y_{i}\\!\\right)^{2}\\!-\\!2 \\sum_{i=1}^{n} y_{i}\\!\\left(\\!\\sum_{j=1}^{n} y_{j} W_{ij}\\!\\right)\\! \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\sum_{i=1}^{n} y_{i}^{T}(Y W)_{i} \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\operatorname{tr}\\left(Y^{T} W Y\\right) \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right),\n    \\end{aligned}\\tag{2}\n$$\n其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的。 此外，我们可以向目标函数添加两个约束。 因此，目标函数的优化问题可以由（2）转化（3），\n$$\n \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,\n$$\n其中 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$。 然后，我们用拉格朗日乘子法求解目标函数，如下所示：\n$$\n\\begin{aligned}\n        f(Y)&=\\operatorname{tr}\\left(Y^{T} L Y\\right)+\\operatorname{tr}\\left[\\Lambda\\left(Y^{T} D Y-I\\right)\\right] \\\\\n        \\frac{\\partial f(Y)}{\\partial Y}&=L Y+L^{T} Y+D^{T} Y \\Lambda^{T}+D Y \\Lambda \\\\\n        &=2 L Y+2 D Y \\Lambda=0 \\\\\n        & \\ \\ \\ \\ LY=-DY\\Lambda,\n    \\end{aligned}\n$$\n其中 $\\lambda$ 是对角矩阵，$L$ 和 $D$ 是实对称矩阵。 对于单个$y_{i}$向量，上式可以写成：$Ly=\\lambda Dy$，这是一个广义特征值问题。 通过得到$m$个最小非零特征值对应的特征向量，可以达到降维的目的。\n\n## 关于约束条件\n\n我们解释了两个约束的作用：\n\n- 去除平移不变性：约束 $\\textbf{y}_{i}^{T}D1=0$ 去除平移不变性，以下是推导，\n  $$\n   \\begin{aligned}\n              \\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}&=0 \\\\\n              \\sum_{i}\\textbf{y}_{i1}D_{ii}&=0,\n          \\end{aligned}\n  $$\n  其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。此外，$D$ 是出入度矩阵，因为 $D$ 提供了对图节点的出入度。\n\n- 消除比例因子：目标函数方程具有伸缩不变性。约束 $Y^{T}DY=I_{d\\times d}$ 去除了伸缩不变性，如下推导，\n  $$\n  \\begin{aligned}\n              Y^{T}DY&=I_{d\\times d} \\\\\n              \\textbf{y}_{i}^{T}D\\textbf{y}_{i}&=1,\n          \\end{aligned}\n  $$\n  其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。\n\n- 防止特征图退化到低维空间：我们可以将优化目标函数转化为求解方程中的特征分解问题。为了使特征图不退化到低维空间，我们需要保证方程中不同的特征向量是正交的，见下面的表达式，\n  $$\n   \\textbf{y}_{i}D\\textbf{y}_{j}=0,\\ i\\neq j.\n  $$\n  因为如果特征向量不是正交的，我们可以找到更少的特征值和特征向量，这会导致特征图退化到低维空间。\n\n## 讨论\n\n### PCA，LLE和LE的区别\n\n#### 动机\n\nPCA 试图通过线性变换 $P$ 来降低数据的维度，即使用正交基的组合来表示原始数据 $A$。 PCA 的目标是最大化数据投影后的方差。\n\nLLE 正试图通过计算高维数据的低维、邻域保留嵌入 $W$ 来降低平滑流形的维数，然后最小化重构损失。通过局部线性嵌入的处理，LLE 可以处理非线性数据。\n\n而 LE 正试图通过使用图拉普拉斯算子之间的对应关系来构高维空间数据在低维流形上的数据的表示，目标是最小化重构损失，从而降低数据的维数。\n\n#### 目标函数\n\n我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。\n\nPCA 的目标函数是最大化主成分上的方差，即降维后协方差矩阵的对角元素，如下：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $E=[E_{1}, E_{2}, \\cdots, E_{n}]$ 是特征向量集，$D_{ii}$ 是第 i 个特征向量的特征值。\n\nLLE 的目标函数是最小化重构误差，如下：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text{ s.t. } \\sum_{j}W_{ij}=1,\\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $X=[X_{1}, X_{2}, \\cdots, X_{N}]$ 是原始数据，$Y=[Y_{1}, Y_{2}, \\cdots, Y_{N} ]$是降维后的数据。 $X_{ij}$ 和 $Y_{ij}$ 分别是 $X_{i}$ 和 $Y_{i}$ 的 $k$ 最近邻。 $W$ 是重构等式中高维输入 $X_{i}$ 的权重。\n\nLE 的目标函数是最小化重构误差，见公式（1）。\n\n### LE的缺点\n\n- LE 只能用于非封闭流形，样本集需要密集均匀。\n- LE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。\n- LE 对热核和权重矩阵的选择很敏感。\n\n## 实验效果\n\n由于Sklearn已经对LE做了很多的优化，需要代码的朋友可以之间调库解决。我展示两种写法，一种是照抄原文中对权重矩阵$W$的写法，一种是直接使用Sklearn调库：\n\n```python\nfrom sklearn.manifold import spectral_embedding\nfrom sklearn.neighbors import kneighbors_graph\nfrom sklearn.manifold import SpectralEmbedding\nimport numpy as np\n\ndef Norm_LE(data, component, neighbor, t):\n    W = kneighbors_graph(data, neighbor, mode='distance', include_self=False)\n    W.data[:] = np.exp(-(W.data ** 2 / (t)))\n    maps = spectral_embedding(W, component)\n    return maps\n\ndef LE(data, train_data, component):\n    solver = SpectralEmbedding(n_components=component, affinity='rbf')\n    solver.fit(train_data)\n    return solver.transform(data)\n```\n展示一些实验结果，有可视化的降维结果。我们在瑞士卷上，使用PCA，LLE和LE把数据降到2维。\n\n<img src=\"子空间学习(3)-LE\\swiss.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n<center class=\"half\">    <img src=\"子空间学习(3)-LE/pca_swiss.png\" width=\"400\"/>    <img src=\"子空间学习(3)-LE/isomap_swiss.png\" width=\"400\"/> </center>\n\n<center class=\"half\">    <img src=\"子空间学习(3)-LE/lle_swiss.png\" width=\"400\"/>    <img src=\"子空间学习(3)-LE/le_swiss.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. PCA（左上）, ISOMAP（右上）, LLE（左下）, LE（右下）在瑞士卷上的效果。</center>\n\n同时我们在MNIST数据集上探究了**LE**算法(**KNN**的$k=1$时)的参数（邻居$n$和参数$t$）变化对效果的影响：\n\n<img src=\"子空间学习(3)-LE\\parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LE算法效果的影响。</center>\n\n最后是PCA，LLE和LE在MNIST数据集上降到不同维度，然后进行KNN($k=1$)分类的效果对比：\n\n<img src=\"子空间学习(3)-LE\\com.png\" alt=\"LLE-Val\" style=\"zoom:110%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. 三种算法降维后进行分类的准确率。</center>\n\n# 总结\n\n其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。","source":"_posts/子空间学习(3)-LE.md","raw":"---\ntitle: 子空间学习(3)-LE\ncatalog: true\ndate: 2022-01-13 12:24:17\nsubtitle: Subspace Learning-LE\ntop: 10\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Laplacian Eigenmaps for Dimensionality Reduction and Data Representation（2003 NC）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，其中，Laplacian Eigenmaps (LE) 是一种用于表示高维数据的几何动机算法，它利用了图 Laplacian、流形上的 Laplace Beltrami 算子以及与热方程的联系之间的对应关系 。LE算法为非线性降维提供了一种计算效率高的方法，保留了局部特性和聚类的一种自然联系。 在本报告中，我们尝试以数学方式解释 LE 的主要思想，并讨论 PCA 、LLE 和 LE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Question&Answer：\n\n## 假设\n\nLE 假设数据是从平滑、紧凑的<u>黎曼流形</u>中采样的，并且流形上有均匀的概率分布。进一步来说，\n\n- 数据是从光滑、紧凑的<u>黎曼流形</u>中采样的<u>光滑流形</u>，即数据是无限可微的。更具体地说，从流形到低维空间的映射 $f:\\mathbb{M} \\rightarrow \\mathbb{R}$ 是两次可微的\n  $$\n  \\begin{gathered}\n              f^{\\prime \\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f^{\\prime}\\left(x_{0}+\\Delta x\\right)-f^{\\prime}\\left(x_{0}\\right)}{\\Delta x}.\n          \\end{gathered}\n  $$\n\n- 流形上有一个均匀的概率分布，即采样密度使得每个数据点具有 $2d$  邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。\n\n## 解决的问题\n\nLE 试图通过使用图拉普拉斯算子之间的对应关系来为位于嵌入高维空间的低维流形上的数据构建表示，从而降低平滑、紧凑的黎曼流形的维数。\n\n## 理解LE算法中的拉普拉斯映射\n\n### 拉普拉斯图\n\nLE 中的<u>拉普拉斯算子</u>是指 LE 计算数据集的低维表示，该表示通过使用拉普拉斯矩阵 $L$ 的概念在某种意义上最优地保留了局部邻域信息。拉普拉斯矩阵可以用两个矩阵之间的差来表示，\n$$\nL=D-W\n$$\n其中$W$是使用一些策略来连接的邻接矩阵（参见之后的具体步骤），$D$是一个对角矩阵，其对角元素为度数（$D_{ii}=\\ sum^{n}_{j=1}W_{ij}$)。此外，流形拉普拉斯算子有几种可能的近似方案，例如，我们可以计算具有以下权重的图拉普拉斯算子，\n$$\nW_{ij}=\\begin{cases}\n    H_{t}(x_{i}, x_{j})e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{4t}} & \\text{ if }\\|x_{i}-x_{j}\\|< \\epsilon \\\\\n    0 & otherwise\n    \\end{cases},\n$$\n其中 $t \\in \\mathbb{R}$, $\\epsilon \\in \\mathbb{R}$ ，$H_{t}$ 是热核函数。\n\n### 映射\n\n在解释特征映射之前，我们应该了解什么是<u>映射</u>和<u>特征分解</u>。LE 中的特征映射是指数据的嵌入映射近似于<u>Laplace Beltrami 算子</u>的特征映射，它们是在整个流形上本质上定义的映射。 从<u>流形</u>的定义，数据的特征映射$f$如下所示：\n$$\n \\forall x_{i} \\ \\exists x_{U(i)}: \\ \\Phi(x_{U(i)})\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)) \\ (f \\subseteq \\mathbb{R}^{n}),\n$$\n其中 $f=[f_{0}, f_{1}, \\cdots, f_{k-1}]$ 是拉普拉斯图的特征映射。\n\n## 目标函数\n\nLLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：\n$$\n\\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,\n    \\end{gathered}\\tag{1}\n$$\n\n其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的，$d$是降维之后数据集的维度，$Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$是降维后的数据集。\n\n## 算法流程\n\n给定 $k$ 个数据点 $x_{1}, x_{2}, \\cdots, x_{k}$ in $\\mathbb{R}^{l}$，我们构建一个有 $k$ 个节点的加权图，每一个节点代表一个数据点，加权图的边表示两个数据点之间的关系。 现在通过计算图拉普拉斯算子的特征向量来构造嵌入图。 算法过程的三个步骤如下所示：\n\n### 第 1 步：构建邻接图\n\n动机：LE 明确考虑了数据可能驻留在其上的流形的局部结构。 因此，LE 构建了一个包含数据邻域信息的邻接图。\n\n假设：原始数据的构造图是连通的。（当然你可以用一些其他方法让它联通）\n\n如果 $x_{i}$ 和 $x_{j}$ 满足以下策略的条件，我们将边放在节点 $i$ 和 $j$ 之间。 因此，提出了两种策略：\n\n- $\\epsilon$-neighborhoods（参数 $\\epsilon \\in \\mathbb{R}$）： 如果 $\\|x_{i}-x_{j}\\|<\\epsilon$ ，节点 $i$ 和 $j$ 将会被连接，其中范数通常是在 $\\mathbb{R}^{l}$上的欧几里得范数。\n- $n$ nearest neighbors：如果 $i$ 位于 $j$ 的 $n$ 个最近邻居中或 $j$ 位于 $i$ 的 $n$ 个最近邻居中，则节点 $i$ 和 $j$ 由一条边连接。 \n\n### 第 2 步：选择权重\n\n在我们构建了邻接图之后，我们需要计算相邻点之间边的权重来构建邻接矩阵$W$，有两种对边进行加权的方法：\n\n- 核函数：如果节点 $i$ 和 $j$ 相连，$W_{ij}=e^{-\\frac{\\|x_{i}-x_{j\\|}^2}{t}}$，否则，$W{ij}$ = 0。稍后将提供这种权重选择的理由。\n- Simple-minded：$W_{ij}=1$ 如果顶点 i 和 j 由边连接，$W_{ij}=0$ 如果顶点 $i$ 和 $j$ 没有边连接。 这种简化避免了选择 $t$ 的需要。\n\n###  第3步：特征映射\n\n  由 LE 生成的嵌入映射可以被视为对连续映射的离散近似，连续映射自然产生于流形的几何形状。接下来我们计算得到特征映射，我们需要解决如下<u>特征分解</u>问题，\n$$\nLf=\\lambda Df,\n$$\n其中 $D$ 是对角矩阵，其对角线元素的值是 W 的列元素之和（或行，因为 W 是对称的）：$D_{ii}=\\sum_{j}W_{ji}$。 $L=D-W$ 是拉普拉斯矩阵。拉普拉斯矩阵是一个对称的半正定矩阵，可以将其视为定义在 G 的顶点上的拉普拉斯算子。设 $f_{0}, f_{1}, \\cdots, f_{k-1}$ 是方程的解，根据它们的特征值排序：\n$$\n  Lf_{i}=\\lambda Df_{i},\\ (0\\leq i\\leq k-1) \\\\\n        0=\\lambda_{0}\\leq\\lambda_{1}\\leq\\cdots\\leq\\lambda_{k-1}.\n$$\n然后，我们去掉对应于特征值 0 的特征向量 $f_{0}$ 并使用接下来的 $m$ 个特征向量嵌入 m 维欧几里得空间：\n$$\nx_{i}\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)).\n$$\n\n## 具体的推导过程\n\n在这一部分，我们展示了 LE 解决方案的细节。给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。 为了讨论的目的，假设图是连通的。 设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。 然后，我们可以将目标函数转化为半正定二次型矩阵的迹，如下推导，\n$$\n\\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &\\!=\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sum_{j=1}^{n}\\!W_{i j}\\!\\right)\\!y_{i} y_{i}\\!+\\!\\sum_{j=1}^{n}\\!\\left(\\!\\sum_{i=1}^{n}\\!W_{i j}\\!\\right)\\! y_{j} y_{j}\\!-\\!2\\!\\sum_{i=1}^{n}\\!\\sum_{j=1}^{n}\\!y_{i}\\!y_{j}\\!W_{i j}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sqrt{D_{i i}}\\!y_{i}\\!\\right)^{2}\\!-\\!2 \\sum_{i=1}^{n} y_{i}\\!\\left(\\!\\sum_{j=1}^{n} y_{j} W_{ij}\\!\\right)\\! \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\sum_{i=1}^{n} y_{i}^{T}(Y W)_{i} \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\operatorname{tr}\\left(Y^{T} W Y\\right) \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right),\n    \\end{aligned}\\tag{2}\n$$\n其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的。 此外，我们可以向目标函数添加两个约束。 因此，目标函数的优化问题可以由（2）转化（3），\n$$\n \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,\n$$\n其中 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$。 然后，我们用拉格朗日乘子法求解目标函数，如下所示：\n$$\n\\begin{aligned}\n        f(Y)&=\\operatorname{tr}\\left(Y^{T} L Y\\right)+\\operatorname{tr}\\left[\\Lambda\\left(Y^{T} D Y-I\\right)\\right] \\\\\n        \\frac{\\partial f(Y)}{\\partial Y}&=L Y+L^{T} Y+D^{T} Y \\Lambda^{T}+D Y \\Lambda \\\\\n        &=2 L Y+2 D Y \\Lambda=0 \\\\\n        & \\ \\ \\ \\ LY=-DY\\Lambda,\n    \\end{aligned}\n$$\n其中 $\\lambda$ 是对角矩阵，$L$ 和 $D$ 是实对称矩阵。 对于单个$y_{i}$向量，上式可以写成：$Ly=\\lambda Dy$，这是一个广义特征值问题。 通过得到$m$个最小非零特征值对应的特征向量，可以达到降维的目的。\n\n## 关于约束条件\n\n我们解释了两个约束的作用：\n\n- 去除平移不变性：约束 $\\textbf{y}_{i}^{T}D1=0$ 去除平移不变性，以下是推导，\n  $$\n   \\begin{aligned}\n              \\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}&=0 \\\\\n              \\sum_{i}\\textbf{y}_{i1}D_{ii}&=0,\n          \\end{aligned}\n  $$\n  其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。此外，$D$ 是出入度矩阵，因为 $D$ 提供了对图节点的出入度。\n\n- 消除比例因子：目标函数方程具有伸缩不变性。约束 $Y^{T}DY=I_{d\\times d}$ 去除了伸缩不变性，如下推导，\n  $$\n  \\begin{aligned}\n              Y^{T}DY&=I_{d\\times d} \\\\\n              \\textbf{y}_{i}^{T}D\\textbf{y}_{i}&=1,\n          \\end{aligned}\n  $$\n  其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。\n\n- 防止特征图退化到低维空间：我们可以将优化目标函数转化为求解方程中的特征分解问题。为了使特征图不退化到低维空间，我们需要保证方程中不同的特征向量是正交的，见下面的表达式，\n  $$\n   \\textbf{y}_{i}D\\textbf{y}_{j}=0,\\ i\\neq j.\n  $$\n  因为如果特征向量不是正交的，我们可以找到更少的特征值和特征向量，这会导致特征图退化到低维空间。\n\n## 讨论\n\n### PCA，LLE和LE的区别\n\n#### 动机\n\nPCA 试图通过线性变换 $P$ 来降低数据的维度，即使用正交基的组合来表示原始数据 $A$。 PCA 的目标是最大化数据投影后的方差。\n\nLLE 正试图通过计算高维数据的低维、邻域保留嵌入 $W$ 来降低平滑流形的维数，然后最小化重构损失。通过局部线性嵌入的处理，LLE 可以处理非线性数据。\n\n而 LE 正试图通过使用图拉普拉斯算子之间的对应关系来构高维空间数据在低维流形上的数据的表示，目标是最小化重构损失，从而降低数据的维数。\n\n#### 目标函数\n\n我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。\n\nPCA 的目标函数是最大化主成分上的方差，即降维后协方差矩阵的对角元素，如下：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $E=[E_{1}, E_{2}, \\cdots, E_{n}]$ 是特征向量集，$D_{ii}$ 是第 i 个特征向量的特征值。\n\nLLE 的目标函数是最小化重构误差，如下：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text{ s.t. } \\sum_{j}W_{ij}=1,\\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $X=[X_{1}, X_{2}, \\cdots, X_{N}]$ 是原始数据，$Y=[Y_{1}, Y_{2}, \\cdots, Y_{N} ]$是降维后的数据。 $X_{ij}$ 和 $Y_{ij}$ 分别是 $X_{i}$ 和 $Y_{i}$ 的 $k$ 最近邻。 $W$ 是重构等式中高维输入 $X_{i}$ 的权重。\n\nLE 的目标函数是最小化重构误差，见公式（1）。\n\n### LE的缺点\n\n- LE 只能用于非封闭流形，样本集需要密集均匀。\n- LE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。\n- LE 对热核和权重矩阵的选择很敏感。\n\n## 实验效果\n\n由于Sklearn已经对LE做了很多的优化，需要代码的朋友可以之间调库解决。我展示两种写法，一种是照抄原文中对权重矩阵$W$的写法，一种是直接使用Sklearn调库：\n\n```python\nfrom sklearn.manifold import spectral_embedding\nfrom sklearn.neighbors import kneighbors_graph\nfrom sklearn.manifold import SpectralEmbedding\nimport numpy as np\n\ndef Norm_LE(data, component, neighbor, t):\n    W = kneighbors_graph(data, neighbor, mode='distance', include_self=False)\n    W.data[:] = np.exp(-(W.data ** 2 / (t)))\n    maps = spectral_embedding(W, component)\n    return maps\n\ndef LE(data, train_data, component):\n    solver = SpectralEmbedding(n_components=component, affinity='rbf')\n    solver.fit(train_data)\n    return solver.transform(data)\n```\n展示一些实验结果，有可视化的降维结果。我们在瑞士卷上，使用PCA，LLE和LE把数据降到2维。\n\n<img src=\"子空间学习(3)-LE\\swiss.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n<center class=\"half\">    <img src=\"子空间学习(3)-LE/pca_swiss.png\" width=\"400\"/>    <img src=\"子空间学习(3)-LE/isomap_swiss.png\" width=\"400\"/> </center>\n\n<center class=\"half\">    <img src=\"子空间学习(3)-LE/lle_swiss.png\" width=\"400\"/>    <img src=\"子空间学习(3)-LE/le_swiss.png\" width=\"400\"/> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. PCA（左上）, ISOMAP（右上）, LLE（左下）, LE（右下）在瑞士卷上的效果。</center>\n\n同时我们在MNIST数据集上探究了**LE**算法(**KNN**的$k=1$时)的参数（邻居$n$和参数$t$）变化对效果的影响：\n\n<img src=\"子空间学习(3)-LE\\parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LE算法效果的影响。</center>\n\n最后是PCA，LLE和LE在MNIST数据集上降到不同维度，然后进行KNN($k=1$)分类的效果对比：\n\n<img src=\"子空间学习(3)-LE\\com.png\" alt=\"LLE-Val\" style=\"zoom:110%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. 三种算法降维后进行分类的准确率。</center>\n\n# 总结\n\n其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。","slug":"子空间学习(3)-LE","published":1,"updated":"2022-01-14T05:29:24.372Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxx3000p3ouefgph2ojt","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Laplacian Eigenmaps for Dimensionality Reduction and Data Representation（2003 NC）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，其中，Laplacian Eigenmaps (LE) 是一种用于表示高维数据的几何动机算法，它利用了图 Laplacian、流形上的 Laplace Beltrami 算子以及与热方程的联系之间的对应关系 。LE算法为非线性降维提供了一种计算效率高的方法，保留了局部特性和聚类的一种自然联系。 在本报告中，我们尝试以数学方式解释 LE 的主要思想，并讨论 PCA 、LLE 和 LE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Question-amp-Answer：\"><a href=\"#Question-amp-Answer：\" class=\"headerlink\" title=\"Question&amp;Answer：\"></a>Question&amp;Answer：</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><p>LE 假设数据是从平滑、紧凑的<u>黎曼流形</u>中采样的，并且流形上有均匀的概率分布。进一步来说，</p>\n<ul>\n<li><p>数据是从光滑、紧凑的<u>黎曼流形</u>中采样的<u>光滑流形</u>，即数据是无限可微的。更具体地说，从流形到低维空间的映射 $f:\\mathbb{M} \\rightarrow \\mathbb{R}$ 是两次可微的</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n            f^{\\prime \\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f^{\\prime}\\left(x_{0}+\\Delta x\\right)-f^{\\prime}\\left(x_{0}\\right)}{\\Delta x}.\n        \\end{gathered}</script></li>\n<li><p>流形上有一个均匀的概率分布，即采样密度使得每个数据点具有 $2d$  邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。</p>\n</li>\n</ul>\n<h2 id=\"解决的问题\"><a href=\"#解决的问题\" class=\"headerlink\" title=\"解决的问题\"></a>解决的问题</h2><p>LE 试图通过使用图拉普拉斯算子之间的对应关系来为位于嵌入高维空间的低维流形上的数据构建表示，从而降低平滑、紧凑的黎曼流形的维数。</p>\n<h2 id=\"理解LE算法中的拉普拉斯映射\"><a href=\"#理解LE算法中的拉普拉斯映射\" class=\"headerlink\" title=\"理解LE算法中的拉普拉斯映射\"></a>理解LE算法中的拉普拉斯映射</h2><h3 id=\"拉普拉斯图\"><a href=\"#拉普拉斯图\" class=\"headerlink\" title=\"拉普拉斯图\"></a>拉普拉斯图</h3><p>LE 中的<u>拉普拉斯算子</u>是指 LE 计算数据集的低维表示，该表示通过使用拉普拉斯矩阵 $L$ 的概念在某种意义上最优地保留了局部邻域信息。拉普拉斯矩阵可以用两个矩阵之间的差来表示，</p>\n<script type=\"math/tex; mode=display\">\nL=D-W</script><p>其中$W$是使用一些策略来连接的邻接矩阵（参见之后的具体步骤），$D$是一个对角矩阵，其对角元素为度数（$D_{ii}=\\ sum^{n}_{j=1}W_{ij}$)。此外，流形拉普拉斯算子有几种可能的近似方案，例如，我们可以计算具有以下权重的图拉普拉斯算子，</p>\n<script type=\"math/tex; mode=display\">\nW_{ij}=\\begin{cases}\n    H_{t}(x_{i}, x_{j})e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{4t}} & \\text{ if }\\|x_{i}-x_{j}\\|< \\epsilon \\\\\n    0 & otherwise\n    \\end{cases},</script><p>其中 $t \\in \\mathbb{R}$, $\\epsilon \\in \\mathbb{R}$ ，$H_{t}$ 是热核函数。</p>\n<h3 id=\"映射\"><a href=\"#映射\" class=\"headerlink\" title=\"映射\"></a>映射</h3><p>在解释特征映射之前，我们应该了解什么是<u>映射</u>和<u>特征分解</u>。LE 中的特征映射是指数据的嵌入映射近似于<u>Laplace Beltrami 算子</u>的特征映射，它们是在整个流形上本质上定义的映射。 从<u>流形</u>的定义，数据的特征映射$f$如下所示：</p>\n<script type=\"math/tex; mode=display\">\n \\forall x_{i} \\ \\exists x_{U(i)}: \\ \\Phi(x_{U(i)})\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)) \\ (f \\subseteq \\mathbb{R}^{n}),</script><p>其中 $f=[f_{0}, f_{1}, \\cdots, f_{k-1}]$ 是拉普拉斯图的特征映射。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>LLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,\n    \\end{gathered}\\tag{1}</script><p>其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的，$d$是降维之后数据集的维度，$Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$是降维后的数据集。</p>\n<h2 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h2><p>给定 $k$ 个数据点 $x_{1}, x_{2}, \\cdots, x_{k}$ in $\\mathbb{R}^{l}$，我们构建一个有 $k$ 个节点的加权图，每一个节点代表一个数据点，加权图的边表示两个数据点之间的关系。 现在通过计算图拉普拉斯算子的特征向量来构造嵌入图。 算法过程的三个步骤如下所示：</p>\n<h3 id=\"第-1-步：构建邻接图\"><a href=\"#第-1-步：构建邻接图\" class=\"headerlink\" title=\"第 1 步：构建邻接图\"></a>第 1 步：构建邻接图</h3><p>动机：LE 明确考虑了数据可能驻留在其上的流形的局部结构。 因此，LE 构建了一个包含数据邻域信息的邻接图。</p>\n<p>假设：原始数据的构造图是连通的。（当然你可以用一些其他方法让它联通）</p>\n<p>如果 $x_{i}$ 和 $x_{j}$ 满足以下策略的条件，我们将边放在节点 $i$ 和 $j$ 之间。 因此，提出了两种策略：</p>\n<ul>\n<li>$\\epsilon$-neighborhoods（参数 $\\epsilon \\in \\mathbb{R}$）： 如果 $|x_{i}-x_{j}|&lt;\\epsilon$ ，节点 $i$ 和 $j$ 将会被连接，其中范数通常是在 $\\mathbb{R}^{l}$上的欧几里得范数。</li>\n<li>$n$ nearest neighbors：如果 $i$ 位于 $j$ 的 $n$ 个最近邻居中或 $j$ 位于 $i$ 的 $n$ 个最近邻居中，则节点 $i$ 和 $j$ 由一条边连接。 </li>\n</ul>\n<h3 id=\"第-2-步：选择权重\"><a href=\"#第-2-步：选择权重\" class=\"headerlink\" title=\"第 2 步：选择权重\"></a>第 2 步：选择权重</h3><p>在我们构建了邻接图之后，我们需要计算相邻点之间边的权重来构建邻接矩阵$W$，有两种对边进行加权的方法：</p>\n<ul>\n<li>核函数：如果节点 $i$ 和 $j$ 相连，$W_{ij}=e^{-\\frac{|x_{i}-x_{j|}^2}{t}}$，否则，$W{ij}$ = 0。稍后将提供这种权重选择的理由。</li>\n<li>Simple-minded：$W_{ij}=1$ 如果顶点 i 和 j 由边连接，$W_{ij}=0$ 如果顶点 $i$ 和 $j$ 没有边连接。 这种简化避免了选择 $t$ 的需要。</li>\n</ul>\n<h3 id=\"第3步：特征映射\"><a href=\"#第3步：特征映射\" class=\"headerlink\" title=\"第3步：特征映射\"></a>第3步：特征映射</h3><p>  由 LE 生成的嵌入映射可以被视为对连续映射的离散近似，连续映射自然产生于流形的几何形状。接下来我们计算得到特征映射，我们需要解决如下<u>特征分解</u>问题，</p>\n<script type=\"math/tex; mode=display\">\nLf=\\lambda Df,</script><p>其中 $D$ 是对角矩阵，其对角线元素的值是 W 的列元素之和（或行，因为 W 是对称的）：$D_{ii}=\\sum_{j}W_{ji}$。 $L=D-W$ 是拉普拉斯矩阵。拉普拉斯矩阵是一个对称的半正定矩阵，可以将其视为定义在 G 的顶点上的拉普拉斯算子。设 $f_{0}, f_{1}, \\cdots, f_{k-1}$ 是方程的解，根据它们的特征值排序：</p>\n<script type=\"math/tex; mode=display\">\n  Lf_{i}=\\lambda Df_{i},\\ (0\\leq i\\leq k-1) \\\\\n        0=\\lambda_{0}\\leq\\lambda_{1}\\leq\\cdots\\leq\\lambda_{k-1}.</script><p>然后，我们去掉对应于特征值 0 的特征向量 $f_{0}$ 并使用接下来的 $m$ 个特征向量嵌入 m 维欧几里得空间：</p>\n<script type=\"math/tex; mode=display\">\nx_{i}\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)).</script><h2 id=\"具体的推导过程\"><a href=\"#具体的推导过程\" class=\"headerlink\" title=\"具体的推导过程\"></a>具体的推导过程</h2><p>在这一部分，我们展示了 LE 解决方案的细节。给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。 为了讨论的目的，假设图是连通的。 设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。 然后，我们可以将目标函数转化为半正定二次型矩阵的迹，如下推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &\\!=\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sum_{j=1}^{n}\\!W_{i j}\\!\\right)\\!y_{i} y_{i}\\!+\\!\\sum_{j=1}^{n}\\!\\left(\\!\\sum_{i=1}^{n}\\!W_{i j}\\!\\right)\\! y_{j} y_{j}\\!-\\!2\\!\\sum_{i=1}^{n}\\!\\sum_{j=1}^{n}\\!y_{i}\\!y_{j}\\!W_{i j}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sqrt{D_{i i}}\\!y_{i}\\!\\right)^{2}\\!-\\!2 \\sum_{i=1}^{n} y_{i}\\!\\left(\\!\\sum_{j=1}^{n} y_{j} W_{ij}\\!\\right)\\! \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\sum_{i=1}^{n} y_{i}^{T}(Y W)_{i} \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\operatorname{tr}\\left(Y^{T} W Y\\right) \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right),\n    \\end{aligned}\\tag{2}</script><p>其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的。 此外，我们可以向目标函数添加两个约束。 因此，目标函数的优化问题可以由（2）转化（3），</p>\n<script type=\"math/tex; mode=display\">\n \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,</script><p>其中 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$。 然后，我们用拉格朗日乘子法求解目标函数，如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        f(Y)&=\\operatorname{tr}\\left(Y^{T} L Y\\right)+\\operatorname{tr}\\left[\\Lambda\\left(Y^{T} D Y-I\\right)\\right] \\\\\n        \\frac{\\partial f(Y)}{\\partial Y}&=L Y+L^{T} Y+D^{T} Y \\Lambda^{T}+D Y \\Lambda \\\\\n        &=2 L Y+2 D Y \\Lambda=0 \\\\\n        & \\ \\ \\ \\ LY=-DY\\Lambda,\n    \\end{aligned}</script><p>其中 $\\lambda$ 是对角矩阵，$L$ 和 $D$ 是实对称矩阵。 对于单个$y_{i}$向量，上式可以写成：$Ly=\\lambda Dy$，这是一个广义特征值问题。 通过得到$m$个最小非零特征值对应的特征向量，可以达到降维的目的。</p>\n<h2 id=\"关于约束条件\"><a href=\"#关于约束条件\" class=\"headerlink\" title=\"关于约束条件\"></a>关于约束条件</h2><p>我们解释了两个约束的作用：</p>\n<ul>\n<li><p>去除平移不变性：约束 $\\textbf{y}_{i}^{T}D1=0$ 去除平移不变性，以下是推导，</p>\n<script type=\"math/tex; mode=display\">\n \\begin{aligned}\n            \\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}&=0 \\\\\n            \\sum_{i}\\textbf{y}_{i1}D_{ii}&=0,\n        \\end{aligned}</script><p>其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。此外，$D$ 是出入度矩阵，因为 $D$ 提供了对图节点的出入度。</p>\n</li>\n<li><p>消除比例因子：目标函数方程具有伸缩不变性。约束 $Y^{T}DY=I_{d\\times d}$ 去除了伸缩不变性，如下推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n            Y^{T}DY&=I_{d\\times d} \\\\\n            \\textbf{y}_{i}^{T}D\\textbf{y}_{i}&=1,\n        \\end{aligned}</script><p>其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。</p>\n</li>\n<li><p>防止特征图退化到低维空间：我们可以将优化目标函数转化为求解方程中的特征分解问题。为了使特征图不退化到低维空间，我们需要保证方程中不同的特征向量是正交的，见下面的表达式，</p>\n<script type=\"math/tex; mode=display\">\n \\textbf{y}_{i}D\\textbf{y}_{j}=0,\\ i\\neq j.</script><p>因为如果特征向量不是正交的，我们可以找到更少的特征值和特征向量，这会导致特征图退化到低维空间。</p>\n</li>\n</ul>\n<h2 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h2><h3 id=\"PCA，LLE和LE的区别\"><a href=\"#PCA，LLE和LE的区别\" class=\"headerlink\" title=\"PCA，LLE和LE的区别\"></a>PCA，LLE和LE的区别</h3><h4 id=\"动机\"><a href=\"#动机\" class=\"headerlink\" title=\"动机\"></a>动机</h4><p>PCA 试图通过线性变换 $P$ 来降低数据的维度，即使用正交基的组合来表示原始数据 $A$。 PCA 的目标是最大化数据投影后的方差。</p>\n<p>LLE 正试图通过计算高维数据的低维、邻域保留嵌入 $W$ 来降低平滑流形的维数，然后最小化重构损失。通过局部线性嵌入的处理，LLE 可以处理非线性数据。</p>\n<p>而 LE 正试图通过使用图拉普拉斯算子之间的对应关系来构高维空间数据在低维流形上的数据的表示，目标是最小化重构损失，从而降低数据的维数。</p>\n<h4 id=\"目标函数-1\"><a href=\"#目标函数-1\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h4><p>我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。</p>\n<p>PCA 的目标函数是最大化主成分上的方差，即降维后协方差矩阵的对角元素，如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}\n\\end{equation}</script><p>其中 $E=[E_{1}, E_{2}, \\cdots, E_{n}]$ 是特征向量集，$D_{ii}$ 是第 i 个特征向量的特征值。</p>\n<p>LLE 的目标函数是最小化重构误差，如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text{ s.t. } \\sum_{j}W_{ij}=1,\\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\n\\end{equation}</script><p>其中 $X=[X_{1}, X_{2}, \\cdots, X_{N}]$ 是原始数据，$Y=[Y_{1}, Y_{2}, \\cdots, Y_{N} ]$是降维后的数据。 $X_{ij}$ 和 $Y_{ij}$ 分别是 $X_{i}$ 和 $Y_{i}$ 的 $k$ 最近邻。 $W$ 是重构等式中高维输入 $X_{i}$ 的权重。</p>\n<p>LE 的目标函数是最小化重构误差，见公式（1）。</p>\n<h3 id=\"LE的缺点\"><a href=\"#LE的缺点\" class=\"headerlink\" title=\"LE的缺点\"></a>LE的缺点</h3><ul>\n<li>LE 只能用于非封闭流形，样本集需要密集均匀。</li>\n<li>LE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。</li>\n<li>LE 对热核和权重矩阵的选择很敏感。</li>\n</ul>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p>由于Sklearn已经对LE做了很多的优化，需要代码的朋友可以之间调库解决。我展示两种写法，一种是照抄原文中对权重矩阵$W$的写法，一种是直接使用Sklearn调库：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> spectral_embedding</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> kneighbors_graph</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> SpectralEmbedding</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Norm_LE</span>(<span class=\"params\">data, component, neighbor, t</span>):</span></span><br><span class=\"line\">    W = kneighbors_graph(data, neighbor, mode=<span class=\"string\">&#x27;distance&#x27;</span>, include_self=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    W.data[:] = np.exp(-(W.data ** <span class=\"number\">2</span> / (t)))</span><br><span class=\"line\">    maps = spectral_embedding(W, component)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> maps</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LE</span>(<span class=\"params\">data, train_data, component</span>):</span></span><br><span class=\"line\">    solver = SpectralEmbedding(n_components=component, affinity=<span class=\"string\">&#x27;rbf&#x27;</span>)</span><br><span class=\"line\">    solver.fit(train_data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> solver.transform(data)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，有可视化的降维结果。我们在瑞士卷上，使用PCA，LLE和LE把数据降到2维。</p>\n<p><img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/swiss.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center class=\"half\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/pca_swiss.png\" width=\"400\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/isomap_swiss.png\" width=\"400\"> </center>\n\n<center class=\"half\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/lle_swiss.png\" width=\"400\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/le_swiss.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. PCA（左上）, ISOMAP（右上）, LLE（左下）, LE（右下）在瑞士卷上的效果。</center>\n\n<p>同时我们在MNIST数据集上探究了<strong>LE</strong>算法(<strong>KNN</strong>的$k=1$时)的参数（邻居$n$和参数$t$）变化对效果的影响：</p>\n<p><img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LE算法效果的影响。</center>\n\n<p>最后是PCA，LLE和LE在MNIST数据集上降到不同维度，然后进行KNN($k=1$)分类的效果对比：</p>\n<p><img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/com.png\" alt=\"LLE-Val\" style=\"zoom:110%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. 三种算法降维后进行分类的准确率。</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Laplacian Eigenmaps for Dimensionality Reduction and Data Representation（2003 NC）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>降维算法出现在信息处理的许多领域，包括机器学习、数据压缩、科学可视化、模式识别和神经计算。 其中，其中，Laplacian Eigenmaps (LE) 是一种用于表示高维数据的几何动机算法，它利用了图 Laplacian、流形上的 Laplace Beltrami 算子以及与热方程的联系之间的对应关系 。LE算法为非线性降维提供了一种计算效率高的方法，保留了局部特性和聚类的一种自然联系。 在本报告中，我们尝试以数学方式解释 LE 的主要思想，并讨论 PCA 、LLE 和 LE 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Question-amp-Answer：\"><a href=\"#Question-amp-Answer：\" class=\"headerlink\" title=\"Question&amp;Answer：\"></a>Question&amp;Answer：</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><p>LE 假设数据是从平滑、紧凑的<u>黎曼流形</u>中采样的，并且流形上有均匀的概率分布。进一步来说，</p>\n<ul>\n<li><p>数据是从光滑、紧凑的<u>黎曼流形</u>中采样的<u>光滑流形</u>，即数据是无限可微的。更具体地说，从流形到低维空间的映射 $f:\\mathbb{M} \\rightarrow \\mathbb{R}$ 是两次可微的</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n            f^{\\prime \\prime}(x)=\\lim _{\\Delta x \\rightarrow 0} \\frac{f^{\\prime}\\left(x_{0}+\\Delta x\\right)-f^{\\prime}\\left(x_{0}\\right)}{\\Delta x}.\n        \\end{gathered}</script></li>\n<li><p>流形上有一个均匀的概率分布，即采样密度使得每个数据点具有 $2d$  邻居的数量级，这些邻居在流形上相对于输入空间中的某个度量定义了一个大致线性的补丁。</p>\n</li>\n</ul>\n<h2 id=\"解决的问题\"><a href=\"#解决的问题\" class=\"headerlink\" title=\"解决的问题\"></a>解决的问题</h2><p>LE 试图通过使用图拉普拉斯算子之间的对应关系来为位于嵌入高维空间的低维流形上的数据构建表示，从而降低平滑、紧凑的黎曼流形的维数。</p>\n<h2 id=\"理解LE算法中的拉普拉斯映射\"><a href=\"#理解LE算法中的拉普拉斯映射\" class=\"headerlink\" title=\"理解LE算法中的拉普拉斯映射\"></a>理解LE算法中的拉普拉斯映射</h2><h3 id=\"拉普拉斯图\"><a href=\"#拉普拉斯图\" class=\"headerlink\" title=\"拉普拉斯图\"></a>拉普拉斯图</h3><p>LE 中的<u>拉普拉斯算子</u>是指 LE 计算数据集的低维表示，该表示通过使用拉普拉斯矩阵 $L$ 的概念在某种意义上最优地保留了局部邻域信息。拉普拉斯矩阵可以用两个矩阵之间的差来表示，</p>\n<script type=\"math/tex; mode=display\">\nL=D-W</script><p>其中$W$是使用一些策略来连接的邻接矩阵（参见之后的具体步骤），$D$是一个对角矩阵，其对角元素为度数（$D_{ii}=\\ sum^{n}_{j=1}W_{ij}$)。此外，流形拉普拉斯算子有几种可能的近似方案，例如，我们可以计算具有以下权重的图拉普拉斯算子，</p>\n<script type=\"math/tex; mode=display\">\nW_{ij}=\\begin{cases}\n    H_{t}(x_{i}, x_{j})e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{4t}} & \\text{ if }\\|x_{i}-x_{j}\\|< \\epsilon \\\\\n    0 & otherwise\n    \\end{cases},</script><p>其中 $t \\in \\mathbb{R}$, $\\epsilon \\in \\mathbb{R}$ ，$H_{t}$ 是热核函数。</p>\n<h3 id=\"映射\"><a href=\"#映射\" class=\"headerlink\" title=\"映射\"></a>映射</h3><p>在解释特征映射之前，我们应该了解什么是<u>映射</u>和<u>特征分解</u>。LE 中的特征映射是指数据的嵌入映射近似于<u>Laplace Beltrami 算子</u>的特征映射，它们是在整个流形上本质上定义的映射。 从<u>流形</u>的定义，数据的特征映射$f$如下所示：</p>\n<script type=\"math/tex; mode=display\">\n \\forall x_{i} \\ \\exists x_{U(i)}: \\ \\Phi(x_{U(i)})\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)) \\ (f \\subseteq \\mathbb{R}^{n}),</script><p>其中 $f=[f_{0}, f_{1}, \\cdots, f_{k-1}]$ 是拉普拉斯图的特征映射。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>LLE的目标函数是为了最小化重构损失，最大程度的保持数据之间的局部关系（为什么保持数据间的局部关系可以进行更好的降维？下一个回答将解释）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,\n    \\end{gathered}\\tag{1}</script><p>其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的，$d$是降维之后数据集的维度，$Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$是降维后的数据集。</p>\n<h2 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h2><p>给定 $k$ 个数据点 $x_{1}, x_{2}, \\cdots, x_{k}$ in $\\mathbb{R}^{l}$，我们构建一个有 $k$ 个节点的加权图，每一个节点代表一个数据点，加权图的边表示两个数据点之间的关系。 现在通过计算图拉普拉斯算子的特征向量来构造嵌入图。 算法过程的三个步骤如下所示：</p>\n<h3 id=\"第-1-步：构建邻接图\"><a href=\"#第-1-步：构建邻接图\" class=\"headerlink\" title=\"第 1 步：构建邻接图\"></a>第 1 步：构建邻接图</h3><p>动机：LE 明确考虑了数据可能驻留在其上的流形的局部结构。 因此，LE 构建了一个包含数据邻域信息的邻接图。</p>\n<p>假设：原始数据的构造图是连通的。（当然你可以用一些其他方法让它联通）</p>\n<p>如果 $x_{i}$ 和 $x_{j}$ 满足以下策略的条件，我们将边放在节点 $i$ 和 $j$ 之间。 因此，提出了两种策略：</p>\n<ul>\n<li>$\\epsilon$-neighborhoods（参数 $\\epsilon \\in \\mathbb{R}$）： 如果 $|x_{i}-x_{j}|&lt;\\epsilon$ ，节点 $i$ 和 $j$ 将会被连接，其中范数通常是在 $\\mathbb{R}^{l}$上的欧几里得范数。</li>\n<li>$n$ nearest neighbors：如果 $i$ 位于 $j$ 的 $n$ 个最近邻居中或 $j$ 位于 $i$ 的 $n$ 个最近邻居中，则节点 $i$ 和 $j$ 由一条边连接。 </li>\n</ul>\n<h3 id=\"第-2-步：选择权重\"><a href=\"#第-2-步：选择权重\" class=\"headerlink\" title=\"第 2 步：选择权重\"></a>第 2 步：选择权重</h3><p>在我们构建了邻接图之后，我们需要计算相邻点之间边的权重来构建邻接矩阵$W$，有两种对边进行加权的方法：</p>\n<ul>\n<li>核函数：如果节点 $i$ 和 $j$ 相连，$W_{ij}=e^{-\\frac{|x_{i}-x_{j|}^2}{t}}$，否则，$W{ij}$ = 0。稍后将提供这种权重选择的理由。</li>\n<li>Simple-minded：$W_{ij}=1$ 如果顶点 i 和 j 由边连接，$W_{ij}=0$ 如果顶点 $i$ 和 $j$ 没有边连接。 这种简化避免了选择 $t$ 的需要。</li>\n</ul>\n<h3 id=\"第3步：特征映射\"><a href=\"#第3步：特征映射\" class=\"headerlink\" title=\"第3步：特征映射\"></a>第3步：特征映射</h3><p>  由 LE 生成的嵌入映射可以被视为对连续映射的离散近似，连续映射自然产生于流形的几何形状。接下来我们计算得到特征映射，我们需要解决如下<u>特征分解</u>问题，</p>\n<script type=\"math/tex; mode=display\">\nLf=\\lambda Df,</script><p>其中 $D$ 是对角矩阵，其对角线元素的值是 W 的列元素之和（或行，因为 W 是对称的）：$D_{ii}=\\sum_{j}W_{ji}$。 $L=D-W$ 是拉普拉斯矩阵。拉普拉斯矩阵是一个对称的半正定矩阵，可以将其视为定义在 G 的顶点上的拉普拉斯算子。设 $f_{0}, f_{1}, \\cdots, f_{k-1}$ 是方程的解，根据它们的特征值排序：</p>\n<script type=\"math/tex; mode=display\">\n  Lf_{i}=\\lambda Df_{i},\\ (0\\leq i\\leq k-1) \\\\\n        0=\\lambda_{0}\\leq\\lambda_{1}\\leq\\cdots\\leq\\lambda_{k-1}.</script><p>然后，我们去掉对应于特征值 0 的特征向量 $f_{0}$ 并使用接下来的 $m$ 个特征向量嵌入 m 维欧几里得空间：</p>\n<script type=\"math/tex; mode=display\">\nx_{i}\\rightarrow (f_{1}(i), \\cdots, f_{m}(i)).</script><h2 id=\"具体的推导过程\"><a href=\"#具体的推导过程\" class=\"headerlink\" title=\"具体的推导过程\"></a>具体的推导过程</h2><p>在这一部分，我们展示了 LE 解决方案的细节。给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。 为了讨论的目的，假设图是连通的。 设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。 然后，我们可以将目标函数转化为半正定二次型矩阵的迹，如下推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &\\!=\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sum_{j=1}^{n}\\!W_{i j}\\!\\right)\\!y_{i} y_{i}\\!+\\!\\sum_{j=1}^{n}\\!\\left(\\!\\sum_{i=1}^{n}\\!W_{i j}\\!\\right)\\! y_{j} y_{j}\\!-\\!2\\!\\sum_{i=1}^{n}\\!\\sum_{j=1}^{n}\\!y_{i}\\!y_{j}\\!W_{i j}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2\\!\\sum_{i=1}^{n}\\!\\left(\\!\\sqrt{D_{i i}}\\!y_{i}\\!\\right)^{2}\\!-\\!2 \\sum_{i=1}^{n} y_{i}\\!\\left(\\!\\sum_{j=1}^{n} y_{j} W_{ij}\\!\\right)\\! \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\sum_{i=1}^{n} y_{i}^{T}(Y W)_{i} \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} D Y\\right)-2 \\operatorname{tr}\\left(Y^{T} W Y\\right) \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right),\n    \\end{aligned}\\tag{2}</script><p>其中 $L=D-W$, $D$ ($D_{ii}=\\sum_{j=1}^{n}W_{ij}$) 和 $w$ 是对称的。 此外，我们可以向目标函数添加两个约束。 因此，目标函数的优化问题可以由（2）转化（3），</p>\n<script type=\"math/tex; mode=display\">\n \\arg \\min_{Y^{T}}\\Phi(Y)=tr(Y^{T}LY) \\\\\n        \\text{ s.t. } Y^{T} D Y=I_{d\\times d},\\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}=0,</script><p>其中 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$。 然后，我们用拉格朗日乘子法求解目标函数，如下所示：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n        f(Y)&=\\operatorname{tr}\\left(Y^{T} L Y\\right)+\\operatorname{tr}\\left[\\Lambda\\left(Y^{T} D Y-I\\right)\\right] \\\\\n        \\frac{\\partial f(Y)}{\\partial Y}&=L Y+L^{T} Y+D^{T} Y \\Lambda^{T}+D Y \\Lambda \\\\\n        &=2 L Y+2 D Y \\Lambda=0 \\\\\n        & \\ \\ \\ \\ LY=-DY\\Lambda,\n    \\end{aligned}</script><p>其中 $\\lambda$ 是对角矩阵，$L$ 和 $D$ 是实对称矩阵。 对于单个$y_{i}$向量，上式可以写成：$Ly=\\lambda Dy$，这是一个广义特征值问题。 通过得到$m$个最小非零特征值对应的特征向量，可以达到降维的目的。</p>\n<h2 id=\"关于约束条件\"><a href=\"#关于约束条件\" class=\"headerlink\" title=\"关于约束条件\"></a>关于约束条件</h2><p>我们解释了两个约束的作用：</p>\n<ul>\n<li><p>去除平移不变性：约束 $\\textbf{y}_{i}^{T}D1=0$ 去除平移不变性，以下是推导，</p>\n<script type=\"math/tex; mode=display\">\n \\begin{aligned}\n            \\textbf{y}_{i}^{T}D\\textbf{1}_{1\\times d}&=0 \\\\\n            \\sum_{i}\\textbf{y}_{i1}D_{ii}&=0,\n        \\end{aligned}</script><p>其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。此外，$D$ 是出入度矩阵，因为 $D$ 提供了对图节点的出入度。</p>\n</li>\n<li><p>消除比例因子：目标函数方程具有伸缩不变性。约束 $Y^{T}DY=I_{d\\times d}$ 去除了伸缩不变性，如下推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n            Y^{T}DY&=I_{d\\times d} \\\\\n            \\textbf{y}_{i}^{T}D\\textbf{y}_{i}&=1,\n        \\end{aligned}</script><p>其中 $D$ 是确定的，所以 $y_{i}$ 是确定的。</p>\n</li>\n<li><p>防止特征图退化到低维空间：我们可以将优化目标函数转化为求解方程中的特征分解问题。为了使特征图不退化到低维空间，我们需要保证方程中不同的特征向量是正交的，见下面的表达式，</p>\n<script type=\"math/tex; mode=display\">\n \\textbf{y}_{i}D\\textbf{y}_{j}=0,\\ i\\neq j.</script><p>因为如果特征向量不是正交的，我们可以找到更少的特征值和特征向量，这会导致特征图退化到低维空间。</p>\n</li>\n</ul>\n<h2 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h2><h3 id=\"PCA，LLE和LE的区别\"><a href=\"#PCA，LLE和LE的区别\" class=\"headerlink\" title=\"PCA，LLE和LE的区别\"></a>PCA，LLE和LE的区别</h3><h4 id=\"动机\"><a href=\"#动机\" class=\"headerlink\" title=\"动机\"></a>动机</h4><p>PCA 试图通过线性变换 $P$ 来降低数据的维度，即使用正交基的组合来表示原始数据 $A$。 PCA 的目标是最大化数据投影后的方差。</p>\n<p>LLE 正试图通过计算高维数据的低维、邻域保留嵌入 $W$ 来降低平滑流形的维数，然后最小化重构损失。通过局部线性嵌入的处理，LLE 可以处理非线性数据。</p>\n<p>而 LE 正试图通过使用图拉普拉斯算子之间的对应关系来构高维空间数据在低维流形上的数据的表示，目标是最小化重构损失，从而降低数据的维数。</p>\n<h4 id=\"目标函数-1\"><a href=\"#目标函数-1\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h4><p>我们假设$A$是原始数据，$B$是降维后的数据。 同时，$D$ 是$A$ 的维度，$d$ 是$B$ 的维度。</p>\n<p>PCA 的目标函数是最大化主成分上的方差，即降维后协方差矩阵的对角元素，如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        B=PA,\\ AE=ED\\ (AE_{i}=D_{ii} E_{i})\\\\\n        sort(D_{ii}),\\ D_{ii}<=D_{jj}\\ when \\ i<j\\\\ \n        P=[E_{1}, E_{2}, \\cdots, E_{d}]^{T} \\\\\n        \\arg \\max_{P} tr(PAA^{T}P^{T}) = tr(\\frac{1}{n} \\sum_{i=1}^{n}(PA_{i})^{2})\\\\\n        \\text { s.t. } PP^{T}=I_{d\\times d}.\n    \\end{gathered}\n\\end{equation}</script><p>其中 $E=[E_{1}, E_{2}, \\cdots, E_{n}]$ 是特征向量集，$D_{ii}$ 是第 i 个特征向量的特征值。</p>\n<p>LLE 的目标函数是最小化重构误差，如下：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        \\text{ s.t. } \\sum_{j}W_{ij}=1,\\ \\sum_{i=1}^{N} Y_{i}=0,\\ \\sum_{i=1}^{N} Y_{i} Y_{i}^{T}=N I_{d \\times d},\n    \\end{gathered}\n\\end{equation}</script><p>其中 $X=[X_{1}, X_{2}, \\cdots, X_{N}]$ 是原始数据，$Y=[Y_{1}, Y_{2}, \\cdots, Y_{N} ]$是降维后的数据。 $X_{ij}$ 和 $Y_{ij}$ 分别是 $X_{i}$ 和 $Y_{i}$ 的 $k$ 最近邻。 $W$ 是重构等式中高维输入 $X_{i}$ 的权重。</p>\n<p>LE 的目标函数是最小化重构误差，见公式（1）。</p>\n<h3 id=\"LE的缺点\"><a href=\"#LE的缺点\" class=\"headerlink\" title=\"LE的缺点\"></a>LE的缺点</h3><ul>\n<li>LE 只能用于非封闭流形，样本集需要密集均匀。</li>\n<li>LE对最近邻样本个数的选择很敏感，不同的近邻个数对最终的降维结果影响较大。</li>\n<li>LE 对热核和权重矩阵的选择很敏感。</li>\n</ul>\n<h2 id=\"实验效果\"><a href=\"#实验效果\" class=\"headerlink\" title=\"实验效果\"></a>实验效果</h2><p>由于Sklearn已经对LE做了很多的优化，需要代码的朋友可以之间调库解决。我展示两种写法，一种是照抄原文中对权重矩阵$W$的写法，一种是直接使用Sklearn调库：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> spectral_embedding</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> kneighbors_graph</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.manifold <span class=\"keyword\">import</span> SpectralEmbedding</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Norm_LE</span>(<span class=\"params\">data, component, neighbor, t</span>):</span></span><br><span class=\"line\">    W = kneighbors_graph(data, neighbor, mode=<span class=\"string\">&#x27;distance&#x27;</span>, include_self=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    W.data[:] = np.exp(-(W.data ** <span class=\"number\">2</span> / (t)))</span><br><span class=\"line\">    maps = spectral_embedding(W, component)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> maps</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LE</span>(<span class=\"params\">data, train_data, component</span>):</span></span><br><span class=\"line\">    solver = SpectralEmbedding(n_components=component, affinity=<span class=\"string\">&#x27;rbf&#x27;</span>)</span><br><span class=\"line\">    solver.fit(train_data)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> solver.transform(data)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，有可视化的降维结果。我们在瑞士卷上，使用PCA，LLE和LE把数据降到2维。</p>\n<p><img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/swiss.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center class=\"half\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/pca_swiss.png\" width=\"400\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/isomap_swiss.png\" width=\"400\"> </center>\n\n<center class=\"half\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/lle_swiss.png\" width=\"400\">    <img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/le_swiss.png\" width=\"400\"> </center>\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. PCA（左上）, ISOMAP（右上）, LLE（左下）, LE（右下）在瑞士卷上的效果。</center>\n\n<p>同时我们在MNIST数据集上探究了<strong>LE</strong>算法(<strong>KNN</strong>的$k=1$时)的参数（邻居$n$和参数$t$）变化对效果的影响：</p>\n<p><img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LE算法效果的影响。</center>\n\n<p>最后是PCA，LLE和LE在MNIST数据集上降到不同维度，然后进行KNN($k=1$)分类的效果对比：</p>\n<p><img src=\"/2022/01/13/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(3)-LE/com.png\" alt=\"LLE-Val\" style=\"zoom:110%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. 三种算法降维后进行分类的准确率。</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。</p>\n"},{"title":"子空间学习(4)-LPP&NPE","catalog":true,"date":"2022-01-14T04:24:17.000Z","subtitle":"Subspace Learning-LPP&NPE","top":11,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Locality Preserving Projections（2004 NIPS）**和**Neighborhood Preserving Embedding（2005 ICCV）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LPP和NPE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n信息处理中的许多问题都涉及某种形式的降维。 因此，人们对降维算法很感兴趣。 与旨在保留全局欧几里德结构的主成分分析，我们将介绍两种旨在保留流形上的局部邻域结构的子空间学习算法：邻域保留嵌入（NPE）是局部线性嵌入（LLE）的线性近似，而LPP是拉普拉斯映射（LE）的线性近似。 在本报告中，我们尝试以数学方式解释 NPE 和 LPP 的主要思想，并讨论 PCA、LLE、LE、NPE 和 LPP 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n\n\n# Method\n\n## 假设\n\n数据点可能位于非线性子流形上，但假设每个局部邻域都是线性的。\n\n## 解决的问题\n\nNPE和LPP中每个词的含义可以分别看作三个算法步骤的，这两个算法的很多步骤都是相似的。 更具体地说，流形的“邻域”（Neighborhood，Locality）使我们能够构建邻接图，Perserving的处理是计算权重 $W$，而“嵌入”（Embedding和Projection）则计算投影。\n\n## LPP和NPE的算法理解\n\n### 构建邻域图\n\nNPE 和LPP中的“邻域”指的是只有邻域对重建有贡献。\n\n由流形的定义可知，流形中的每一点$X_{a}$在欧氏空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。 更具体地说，NPE 中的“Neighborhood”使用两种方式构建邻接图$G$：\n\n- $K$ 最近邻（KNN）：如果$x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那么在第$i$个节点和第$j$个节点连一条边。\n- 如果 $\\|x_{i}-x_{j}\\|< \\epsilon$，则在节点 $i$ 和 $j$ 之间放置一条边。\n\n### 计算邻域矩阵\n\n这一步中NPE和LPP的做法不同。\n\n#### NPE计算$W$\n\nNPE中的“保留”是指保留流形的局部不变性。 在这一步中，NPE算法尝试计算权重 $W_{ij}$，以每个点的邻域为基础，最好地线性重建每个数据点 $X_{i}$，即最小化线性的重构损失，见公式（1）：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{1}\n$$\n其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。\n\n此外，我们解释为什么我们需要约束 $\\sum_{j}W_{ij}=1$。 约束是平移不变性、旋转不变性和伸缩不变性的必要条件。 并且可以通过约束$\\sum_{j}W_{ij}=1$的拉格朗日乘子法来最小化重构误差。\n\n#### LPP计算$W$\n\nLPP 中的“保留”是指保留数据集的邻域结构。 更具体地说，数据集的邻域结构可以用线性变换$W$来表示。 在这一步中，我们有两种对边进行加权的方法，即计算权重 $W_{ij}$：\n\n- 核函数：如果节点 $i$ 和 $j$ 相连，则放置\n  $$\n       W_{ij}=e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{t}}。\n  $$\n\n- 简单连接：$W_{ij}=1$ 当且仅当顶点 $i$ 和 $j$ 由一条边连接。\n\n### 映射\n\n#### NPE计算嵌入\n\nNPE 中的“嵌入”是指将高维数据点 $X_{i}$ 线性映射到低维嵌入坐标，如公式（2）：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        x_{i}\\rightarrow y_{i}=A^{T}x_{i}\\\\\n        A=(a_{0}, a_{1}, \\cdots, a_{d-1}),\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $y_{i}$ 是一个 d 维向量，而 $A$ 是一个 $n\\times d$ 矩阵。 同时，列向量$a_{0}、a_{1}、\\cdots、a_{d-1}$是公式(3)中分解问题的解。 根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(3)：\n$$\n\\begin{equation}\n    XMX^{T}a=\\lambda XX^{T}a,\n\\end{equation}\\tag{3}\n$$\n其中 $X=(x_{1},\\cdots,x_{m}), M=\\left(IW\\right)^{T}\\left(IW\\right), I=diag(1,\\cdots,1 )$。\n\n#### LPP计算映射\n\nLPP 中的“投影”是指线性投影，它可以最佳地保留流形上高维数据的邻域结构。\n\n投影与公式(2)类似，但获得投影 $A$ 的方式不同。 列向量 $a_{0}, a_{1}, \\cdots, a_{d-1}$ 是公式(4)中特征分解问题的解。根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(4):\n$$\n\\begin{equation}\n        XLX^{T}\\mathbf{a}=\\lambda XDX^{T}\\mathbf{a}\n\\end{equation}\\tag{4}\n$$\n其中 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。 $L=D-W$ 是拉普拉斯矩阵。\n\n## 具体的推导过程\n\n在这一部分，我们展示NPE和LPP实现的数学细节。\n\n### NPE数学推导\n\n在 NPE 中，每个数据点都可以表示为其邻居的线性组合。边权可以通过最小化目标目标函数来计算，即最小化重构误差，见等式：\n$$\n\\begin{equation}\n    \\phi(W)=\\sum_{i}\\left\\|\\mathbf{x}_{i}-\\sum_{j} W_{i j} \\mathbf{x}_{j}\\right\\|^{2}.\n\\end{equation}\n$$\n设 $\\mathbf{y}=\\left(y_{1}, y_{2}, \\cdots, y_{m}\\right)^{T}$ 是这样的映射。选择一个好的映射的合理标准是最小化以下目标函数，见公式(5):\n$$\n\\begin{equation}\n    \\Phi(\\mathbf{y})=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2},\n\\end{equation}\\tag{5}\n$$\n在适当的约束下。该成本函数基于局部线性重构的误差，但在这里我们在优化坐标 $y_{i}$ 的同时固定权重 $W_{ij}$。假设变换是线性的，即$y^{T}=a^{T}X$，其中$X$的第i列向量为$x_{i}$。我们定义：\n$$\nz_{i}=y_{i}-\\sum_{j}W_{ij}y_{ij},\n$$\n同时$z_{i}$可以写成向量形式：\n$$\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\mathbf{z}&=\\mathbf{y}-w\\mathbf{y}\\\\\n        &=(I-W)\\mathbf{y}.\n    \\end{aligned}\n\\end{equation}\n$$\n由此目标函数公式(5)可以简化为：\n$$\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\Phi(\\mathbf{y}) &=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2} \\\\\n        &=\\sum_{i}\\left(z_{i}\\right)^{2} \\\\\n        &=\\mathbf{z}^{T} \\mathbf{z} \\\\\n        &=\\mathbf{y}^{T}(I-W)^{T}(I-W) \\mathbf{y} \\\\\n        &=\\mathbf{a}^{T} X(I-W)^{T}(I-W) X^{T} \\mathbf{a} \\\\\n        & \\doteq \\mathbf{a}^{T} X M X^{T} \\mathbf{a}\n    \\end{aligned}\n\\end{equation}\n$$\n其中矩阵 $XMX^{T}$ 是对称和半正定的。为了去除投影中的任意缩放因子，NPE 施加如下约束：\n$$\n\\mathbf{y}^{T} \\mathbf{y}=1 \\Longrightarrow \\mathbf{a}^{T} X X^{T} \\mathbf{a}=1.\n$$\n最后，最小化问题简化为求解如下问题，\n$$\n\\begin{equation}\n    \\underset{\\mathbf{a}^{T} X X^{T} \\mathbf{a}=1}{\\arg \\underset{\\mathbf{a}}{\\min}} \\mathbf{a}^{T} X M X^{T} \\mathbf{a}.\n\\end{equation}\n$$\n然后，我们用拉格朗日乘子法求解上述目标函数，见以下推导：\n$$\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)M(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XMX^{T}\\textbf{a}-2\\lambda XX^{T}\\textbf{a}=0 \\\\\n        & \\ \\ \\ \\ \\ \\ X M X^{T} \\mathbf{a}=\\lambda X X^{T} \\mathbf{a}.\n    \\end{aligned}\n\\end{equation}\n$$\n其中$\\textbf{a}$的求解可以用特征值分解或者SVD来求解。\n\n### LPP的数学推导\n\n给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。假设图是连通的。设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。然后，我们可以将目标函数转换为半正定二次型的迹作为以下推导，\n$$\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right)=2\\textbf{y}^{T}L\\textbf{y}.\n    \\end{aligned}\n\\end{equation}\n$$\n在投影中为消除任意缩放因子添加一个约束。因此，目标函数的优化问题可以转化为如下形式：\n$$\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=2\\textbf{y}^{T}L\\textbf{y} \\\\\n        \\text{ s.t. } \\textbf{y}^{T}D\\textbf{y}=1.\n    \\end{gathered}\n\\end{equation}\\tag{6}\n$$\n假设$\\textbf{a}$是线性拉普拉斯特征图的变换向量，即$\\textbf{y}^{T}=\\textbf{a}^{T}X$。公式(6)的最小化问题可以转化为公式：\n$$\n\\begin{equation}\n    \\underset{(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T}=1}{\\arg \\underset{\\textbf{a}}{\\min}}=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}.\n\\end{equation}\n$$\n然后，我们用拉格朗日乘子法求解目标函数，\n$$\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XLX^{T}\\textbf{a}-2\\lambda XDX^{T}\\textbf{a} \\\\\n        &=2(L^{\\prime} \\mathbf{a}-\\lambda D^{\\prime}\\mathbf{a})=0 \\\\\n        & \\ \\ \\ \\ \\ \\ L^{\\prime} \\mathbf{a}=\\lambda D^{\\prime}\\mathbf{a},\n    \\end{aligned}\n\\end{equation}\n$$\n其中 $L^{\\prime}=X L X^{T}，D^{\\prime}=X D X^{T}$。很容易证明矩阵 $D^{\\prime}$ 和 $L^{\\prime}$ 是对称的和半正定的。求解向量 $\\mathbf{a}_{i}(i=1,2, \\cdots, k)$ 可以使用特征值分解或SVD进行。\n\n## 讨论：PCA，LLE，LE，NPE和LPP的区别\n\n与旨在保留全局欧几里得结构的 PCA 不同，四种降维方法（LLE、LE、NPE 和 LPP）旨在保留局部流形结构。\n\nLLE 和 NPE 都试图通过计算高维数据的低维、邻域保留嵌入来降低平滑流形的维数。LLE 试图发现流形的非线性结构，而 NPE 是 LLE 的线性近似。 所以，NPE 与 LLE 相比有两个优势：\n\n- 与 LLE 相比，NPE 的定义无处不在，而不仅仅是在训练数据点上。 这意味着 NPE 可以在监督或非监督模式下执行。\n- NPE 是线性的。 这使其快速且适用于实际应用。 它可以在原始空间中进行，也可以在数据点映射到的再现核希尔伯特空间（RKHS）中进行，所以有核NPE。\n\nLE 和 LPP 都试图通过使用图拉普拉斯算子之间的对应关系来减少流形的维数，以构建高维空间上的数据在低维流形上的表示。然而，LE 试图发现流形的非线性结构，而 LPP 是非线性 LE 的线性近似。LPP相对于LE的优势类似于NPE相对于LLE的优势。\n\n同时NPE和LPP还是有一些区别的，他们的目标函数完全不同，分别见公式(7)和公式(8):\n$$\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        &=\\textbf{y}M\\textbf{y}=\\textbf{a}^{T}XMX^{T}\\textbf{a}\\\\\n    \\end{aligned}\n\\end{equation}\\tag{7}\n$$\n\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2\\textbf{y}^{T}L\\textbf{y}=2(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}=1,\\ \\textbf{y}^{T}=\\textbf{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{8}\n$$\n\n$L$ 提供了流形上拉普拉斯贝尔特拉米算子 $\\mathcal{L}$ 的离散近似。 因此，矩阵 $M$ 提供了对 $\\mathcal{L}^{2}$ 的离散近似。 这表明 NPE 本质上试图找到迭代拉普拉斯算子 $\\mathcal{L}^{2}$ 的特征函数的线性近似。 从这个意义上说，NPE 和 LPP 提供了两种不同的方法来线性逼近 Laplace Beltrami 算子的特征函数。\n\n## 实验效果(MNIST and ORL)\n\nNPE和LPP的代码我自己写的，由粗略实验效果来看，估计有一些问题，也可能是参数没调对。\n\n```python\nfrom sklearn.neighbors import kneighbors_graph\nimport scipy\nimport numpy as np\nimport math\n\ndef sparse_max(A, B):\n    Ag = (A > B).astype(int)\n    return Ag.multiply(A - B) + B\n\ndef NPE(data, train_data, component, neighboor):\n    W = kneighbors_graph(train_data, neighboor, mode='distance', include_self=False)\n    W = W.A\n    X = train_data.T\n    M = (np.eye(X.shape[1]) - W).dot((np.eye(X.shape[1]) - W).T)\n    T1 = X.dot(M).dot(X.T)\n    T2 = X.dot(X.T)\n    T2 = T2 + np.exp(-10) * np.eye(T2.shape[0])\n    T = scipy.linalg.inv(T2).dot(T1)\n    eigVals, eigVects = np.linalg.eigh(T)  # 求特征值，特征向量\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[0:component]\n    w = eigVects[:, eigValInd]\n    npe = data.dot(w)\n    return npe\n\ndef LPP(data, train_data, component, neighboor, t):\n    W = kneighbors_graph(train_data, neighboor, mode='distance', include_self=False)\n    W = sparse_max(W, W.T) #让W矩阵对称，不报warning\n    W.data[:] = np.exp(-(W.data ** 2 / (t)))\n    W = W.A\n    D = np.diag(np.sum(W, axis=0))\n    L = D - W\n    X = train_data.T\n    T1 = X.dot(L).dot(X.T)\n    T2 = X.dot(D).dot(X.T)\n    T2 = T2 + np.exp(-10) * np.eye(T2.shape[0])\n    T = scipy.linalg.pinv(T2).dot(T1)\n    eigVals, eigVects = np.linalg.eigh(T)  # 求特征值，特征向量\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[0:component]\n    w = eigVects[:, eigValInd]\n    lpp = data.dot(w)\n    return lpp\n```\n展示一些实验结果，有可视化的降维结果。然后我们在MNIST上，使用PCA，LLE和LE把数据降到2维。\n\n<img src=\"子空间学习(4)-LPP&NPE\\com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 六种降维算法在MNIST上的效果。</center>\n\n同时我们在MNIST数据集上探究了NPE和LPP算法(**KNN**的$k=1$时)的参数（NPE：邻居$n$，LPP：邻居$n$和参数$t$）变化对效果的影响：\n\n<img src=\"子空间学习(4)-LPP&NPE\\parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数对NPE和LPP算法的影响。</center>\n\n然后我们展示算法在ORL数据集上的实验效果。\n\n<img src=\"子空间学习(4)-LPP&NPE\\acc.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. ORL数据集上的准确率对比。</center>\n\n<img src=\"子空间学习(4)-LPP&NPE\\face.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4. ORL数据集上的可视化降维效果。</center>\n\n<img src=\"子空间学习(4)-LPP&NPE\\eig.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5. 算法提取的特征。</center>\n# 总结\n\n其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。\n\n\n\n\n\n","source":"_posts/子空间学习(4)-LPP&NPE.md","raw":"---\ntitle: 子空间学习(4)-LPP&NPE\ncatalog: true\ndate: 2022-01-14 12:24:17\nsubtitle: Subspace Learning-LPP&NPE\ntop: 11\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Locality Preserving Projections（2004 NIPS）**和**Neighborhood Preserving Embedding（2005 ICCV）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LPP和NPE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。\n\n# 摘要：\n\n信息处理中的许多问题都涉及某种形式的降维。 因此，人们对降维算法很感兴趣。 与旨在保留全局欧几里德结构的主成分分析，我们将介绍两种旨在保留流形上的局部邻域结构的子空间学习算法：邻域保留嵌入（NPE）是局部线性嵌入（LLE）的线性近似，而LPP是拉普拉斯映射（LE）的线性近似。 在本报告中，我们尝试以数学方式解释 NPE 和 LPP 的主要思想，并讨论 PCA、LLE、LE、NPE 和 LPP 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n\n\n# Method\n\n## 假设\n\n数据点可能位于非线性子流形上，但假设每个局部邻域都是线性的。\n\n## 解决的问题\n\nNPE和LPP中每个词的含义可以分别看作三个算法步骤的，这两个算法的很多步骤都是相似的。 更具体地说，流形的“邻域”（Neighborhood，Locality）使我们能够构建邻接图，Perserving的处理是计算权重 $W$，而“嵌入”（Embedding和Projection）则计算投影。\n\n## LPP和NPE的算法理解\n\n### 构建邻域图\n\nNPE 和LPP中的“邻域”指的是只有邻域对重建有贡献。\n\n由流形的定义可知，流形中的每一点$X_{a}$在欧氏空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。 更具体地说，NPE 中的“Neighborhood”使用两种方式构建邻接图$G$：\n\n- $K$ 最近邻（KNN）：如果$x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那么在第$i$个节点和第$j$个节点连一条边。\n- 如果 $\\|x_{i}-x_{j}\\|< \\epsilon$，则在节点 $i$ 和 $j$ 之间放置一条边。\n\n### 计算邻域矩阵\n\n这一步中NPE和LPP的做法不同。\n\n#### NPE计算$W$\n\nNPE中的“保留”是指保留流形的局部不变性。 在这一步中，NPE算法尝试计算权重 $W_{ij}$，以每个点的邻域为基础，最好地线性重建每个数据点 $X_{i}$，即最小化线性的重构损失，见公式（1）：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{1}\n$$\n其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。\n\n此外，我们解释为什么我们需要约束 $\\sum_{j}W_{ij}=1$。 约束是平移不变性、旋转不变性和伸缩不变性的必要条件。 并且可以通过约束$\\sum_{j}W_{ij}=1$的拉格朗日乘子法来最小化重构误差。\n\n#### LPP计算$W$\n\nLPP 中的“保留”是指保留数据集的邻域结构。 更具体地说，数据集的邻域结构可以用线性变换$W$来表示。 在这一步中，我们有两种对边进行加权的方法，即计算权重 $W_{ij}$：\n\n- 核函数：如果节点 $i$ 和 $j$ 相连，则放置\n  $$\n       W_{ij}=e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{t}}。\n  $$\n\n- 简单连接：$W_{ij}=1$ 当且仅当顶点 $i$ 和 $j$ 由一条边连接。\n\n### 映射\n\n#### NPE计算嵌入\n\nNPE 中的“嵌入”是指将高维数据点 $X_{i}$ 线性映射到低维嵌入坐标，如公式（2）：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        x_{i}\\rightarrow y_{i}=A^{T}x_{i}\\\\\n        A=(a_{0}, a_{1}, \\cdots, a_{d-1}),\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $y_{i}$ 是一个 d 维向量，而 $A$ 是一个 $n\\times d$ 矩阵。 同时，列向量$a_{0}、a_{1}、\\cdots、a_{d-1}$是公式(3)中分解问题的解。 根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(3)：\n$$\n\\begin{equation}\n    XMX^{T}a=\\lambda XX^{T}a,\n\\end{equation}\\tag{3}\n$$\n其中 $X=(x_{1},\\cdots,x_{m}), M=\\left(IW\\right)^{T}\\left(IW\\right), I=diag(1,\\cdots,1 )$。\n\n#### LPP计算映射\n\nLPP 中的“投影”是指线性投影，它可以最佳地保留流形上高维数据的邻域结构。\n\n投影与公式(2)类似，但获得投影 $A$ 的方式不同。 列向量 $a_{0}, a_{1}, \\cdots, a_{d-1}$ 是公式(4)中特征分解问题的解。根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(4):\n$$\n\\begin{equation}\n        XLX^{T}\\mathbf{a}=\\lambda XDX^{T}\\mathbf{a}\n\\end{equation}\\tag{4}\n$$\n其中 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。 $L=D-W$ 是拉普拉斯矩阵。\n\n## 具体的推导过程\n\n在这一部分，我们展示NPE和LPP实现的数学细节。\n\n### NPE数学推导\n\n在 NPE 中，每个数据点都可以表示为其邻居的线性组合。边权可以通过最小化目标目标函数来计算，即最小化重构误差，见等式：\n$$\n\\begin{equation}\n    \\phi(W)=\\sum_{i}\\left\\|\\mathbf{x}_{i}-\\sum_{j} W_{i j} \\mathbf{x}_{j}\\right\\|^{2}.\n\\end{equation}\n$$\n设 $\\mathbf{y}=\\left(y_{1}, y_{2}, \\cdots, y_{m}\\right)^{T}$ 是这样的映射。选择一个好的映射的合理标准是最小化以下目标函数，见公式(5):\n$$\n\\begin{equation}\n    \\Phi(\\mathbf{y})=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2},\n\\end{equation}\\tag{5}\n$$\n在适当的约束下。该成本函数基于局部线性重构的误差，但在这里我们在优化坐标 $y_{i}$ 的同时固定权重 $W_{ij}$。假设变换是线性的，即$y^{T}=a^{T}X$，其中$X$的第i列向量为$x_{i}$。我们定义：\n$$\nz_{i}=y_{i}-\\sum_{j}W_{ij}y_{ij},\n$$\n同时$z_{i}$可以写成向量形式：\n$$\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\mathbf{z}&=\\mathbf{y}-w\\mathbf{y}\\\\\n        &=(I-W)\\mathbf{y}.\n    \\end{aligned}\n\\end{equation}\n$$\n由此目标函数公式(5)可以简化为：\n$$\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\Phi(\\mathbf{y}) &=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2} \\\\\n        &=\\sum_{i}\\left(z_{i}\\right)^{2} \\\\\n        &=\\mathbf{z}^{T} \\mathbf{z} \\\\\n        &=\\mathbf{y}^{T}(I-W)^{T}(I-W) \\mathbf{y} \\\\\n        &=\\mathbf{a}^{T} X(I-W)^{T}(I-W) X^{T} \\mathbf{a} \\\\\n        & \\doteq \\mathbf{a}^{T} X M X^{T} \\mathbf{a}\n    \\end{aligned}\n\\end{equation}\n$$\n其中矩阵 $XMX^{T}$ 是对称和半正定的。为了去除投影中的任意缩放因子，NPE 施加如下约束：\n$$\n\\mathbf{y}^{T} \\mathbf{y}=1 \\Longrightarrow \\mathbf{a}^{T} X X^{T} \\mathbf{a}=1.\n$$\n最后，最小化问题简化为求解如下问题，\n$$\n\\begin{equation}\n    \\underset{\\mathbf{a}^{T} X X^{T} \\mathbf{a}=1}{\\arg \\underset{\\mathbf{a}}{\\min}} \\mathbf{a}^{T} X M X^{T} \\mathbf{a}.\n\\end{equation}\n$$\n然后，我们用拉格朗日乘子法求解上述目标函数，见以下推导：\n$$\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)M(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XMX^{T}\\textbf{a}-2\\lambda XX^{T}\\textbf{a}=0 \\\\\n        & \\ \\ \\ \\ \\ \\ X M X^{T} \\mathbf{a}=\\lambda X X^{T} \\mathbf{a}.\n    \\end{aligned}\n\\end{equation}\n$$\n其中$\\textbf{a}$的求解可以用特征值分解或者SVD来求解。\n\n### LPP的数学推导\n\n给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。假设图是连通的。设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。然后，我们可以将目标函数转换为半正定二次型的迹作为以下推导，\n$$\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right)=2\\textbf{y}^{T}L\\textbf{y}.\n    \\end{aligned}\n\\end{equation}\n$$\n在投影中为消除任意缩放因子添加一个约束。因此，目标函数的优化问题可以转化为如下形式：\n$$\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=2\\textbf{y}^{T}L\\textbf{y} \\\\\n        \\text{ s.t. } \\textbf{y}^{T}D\\textbf{y}=1.\n    \\end{gathered}\n\\end{equation}\\tag{6}\n$$\n假设$\\textbf{a}$是线性拉普拉斯特征图的变换向量，即$\\textbf{y}^{T}=\\textbf{a}^{T}X$。公式(6)的最小化问题可以转化为公式：\n$$\n\\begin{equation}\n    \\underset{(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T}=1}{\\arg \\underset{\\textbf{a}}{\\min}}=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}.\n\\end{equation}\n$$\n然后，我们用拉格朗日乘子法求解目标函数，\n$$\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XLX^{T}\\textbf{a}-2\\lambda XDX^{T}\\textbf{a} \\\\\n        &=2(L^{\\prime} \\mathbf{a}-\\lambda D^{\\prime}\\mathbf{a})=0 \\\\\n        & \\ \\ \\ \\ \\ \\ L^{\\prime} \\mathbf{a}=\\lambda D^{\\prime}\\mathbf{a},\n    \\end{aligned}\n\\end{equation}\n$$\n其中 $L^{\\prime}=X L X^{T}，D^{\\prime}=X D X^{T}$。很容易证明矩阵 $D^{\\prime}$ 和 $L^{\\prime}$ 是对称的和半正定的。求解向量 $\\mathbf{a}_{i}(i=1,2, \\cdots, k)$ 可以使用特征值分解或SVD进行。\n\n## 讨论：PCA，LLE，LE，NPE和LPP的区别\n\n与旨在保留全局欧几里得结构的 PCA 不同，四种降维方法（LLE、LE、NPE 和 LPP）旨在保留局部流形结构。\n\nLLE 和 NPE 都试图通过计算高维数据的低维、邻域保留嵌入来降低平滑流形的维数。LLE 试图发现流形的非线性结构，而 NPE 是 LLE 的线性近似。 所以，NPE 与 LLE 相比有两个优势：\n\n- 与 LLE 相比，NPE 的定义无处不在，而不仅仅是在训练数据点上。 这意味着 NPE 可以在监督或非监督模式下执行。\n- NPE 是线性的。 这使其快速且适用于实际应用。 它可以在原始空间中进行，也可以在数据点映射到的再现核希尔伯特空间（RKHS）中进行，所以有核NPE。\n\nLE 和 LPP 都试图通过使用图拉普拉斯算子之间的对应关系来减少流形的维数，以构建高维空间上的数据在低维流形上的表示。然而，LE 试图发现流形的非线性结构，而 LPP 是非线性 LE 的线性近似。LPP相对于LE的优势类似于NPE相对于LLE的优势。\n\n同时NPE和LPP还是有一些区别的，他们的目标函数完全不同，分别见公式(7)和公式(8):\n$$\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        &=\\textbf{y}M\\textbf{y}=\\textbf{a}^{T}XMX^{T}\\textbf{a}\\\\\n    \\end{aligned}\n\\end{equation}\\tag{7}\n$$\n\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2\\textbf{y}^{T}L\\textbf{y}=2(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}=1,\\ \\textbf{y}^{T}=\\textbf{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{8}\n$$\n\n$L$ 提供了流形上拉普拉斯贝尔特拉米算子 $\\mathcal{L}$ 的离散近似。 因此，矩阵 $M$ 提供了对 $\\mathcal{L}^{2}$ 的离散近似。 这表明 NPE 本质上试图找到迭代拉普拉斯算子 $\\mathcal{L}^{2}$ 的特征函数的线性近似。 从这个意义上说，NPE 和 LPP 提供了两种不同的方法来线性逼近 Laplace Beltrami 算子的特征函数。\n\n## 实验效果(MNIST and ORL)\n\nNPE和LPP的代码我自己写的，由粗略实验效果来看，估计有一些问题，也可能是参数没调对。\n\n```python\nfrom sklearn.neighbors import kneighbors_graph\nimport scipy\nimport numpy as np\nimport math\n\ndef sparse_max(A, B):\n    Ag = (A > B).astype(int)\n    return Ag.multiply(A - B) + B\n\ndef NPE(data, train_data, component, neighboor):\n    W = kneighbors_graph(train_data, neighboor, mode='distance', include_self=False)\n    W = W.A\n    X = train_data.T\n    M = (np.eye(X.shape[1]) - W).dot((np.eye(X.shape[1]) - W).T)\n    T1 = X.dot(M).dot(X.T)\n    T2 = X.dot(X.T)\n    T2 = T2 + np.exp(-10) * np.eye(T2.shape[0])\n    T = scipy.linalg.inv(T2).dot(T1)\n    eigVals, eigVects = np.linalg.eigh(T)  # 求特征值，特征向量\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[0:component]\n    w = eigVects[:, eigValInd]\n    npe = data.dot(w)\n    return npe\n\ndef LPP(data, train_data, component, neighboor, t):\n    W = kneighbors_graph(train_data, neighboor, mode='distance', include_self=False)\n    W = sparse_max(W, W.T) #让W矩阵对称，不报warning\n    W.data[:] = np.exp(-(W.data ** 2 / (t)))\n    W = W.A\n    D = np.diag(np.sum(W, axis=0))\n    L = D - W\n    X = train_data.T\n    T1 = X.dot(L).dot(X.T)\n    T2 = X.dot(D).dot(X.T)\n    T2 = T2 + np.exp(-10) * np.eye(T2.shape[0])\n    T = scipy.linalg.pinv(T2).dot(T1)\n    eigVals, eigVects = np.linalg.eigh(T)  # 求特征值，特征向量\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[0:component]\n    w = eigVects[:, eigValInd]\n    lpp = data.dot(w)\n    return lpp\n```\n展示一些实验结果，有可视化的降维结果。然后我们在MNIST上，使用PCA，LLE和LE把数据降到2维。\n\n<img src=\"子空间学习(4)-LPP&NPE\\com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 六种降维算法在MNIST上的效果。</center>\n\n同时我们在MNIST数据集上探究了NPE和LPP算法(**KNN**的$k=1$时)的参数（NPE：邻居$n$，LPP：邻居$n$和参数$t$）变化对效果的影响：\n\n<img src=\"子空间学习(4)-LPP&NPE\\parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数对NPE和LPP算法的影响。</center>\n\n然后我们展示算法在ORL数据集上的实验效果。\n\n<img src=\"子空间学习(4)-LPP&NPE\\acc.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. ORL数据集上的准确率对比。</center>\n\n<img src=\"子空间学习(4)-LPP&NPE\\face.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4. ORL数据集上的可视化降维效果。</center>\n\n<img src=\"子空间学习(4)-LPP&NPE\\eig.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图5. 算法提取的特征。</center>\n# 总结\n\n其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。\n\n\n\n\n\n","slug":"子空间学习(4)-LPP&NPE","published":1,"updated":"2022-01-14T05:21:49.708Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxx5000u3oue4oqogxnt","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Locality Preserving Projections（2004 NIPS）</strong>和<strong>Neighborhood Preserving Embedding（2005 ICCV）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LPP和NPE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>信息处理中的许多问题都涉及某种形式的降维。 因此，人们对降维算法很感兴趣。 与旨在保留全局欧几里德结构的主成分分析，我们将介绍两种旨在保留流形上的局部邻域结构的子空间学习算法：邻域保留嵌入（NPE）是局部线性嵌入（LLE）的线性近似，而LPP是拉普拉斯映射（LE）的线性近似。 在本报告中，我们尝试以数学方式解释 NPE 和 LPP 的主要思想，并讨论 PCA、LLE、LE、NPE 和 LPP 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><p>数据点可能位于非线性子流形上，但假设每个局部邻域都是线性的。</p>\n<h2 id=\"解决的问题\"><a href=\"#解决的问题\" class=\"headerlink\" title=\"解决的问题\"></a>解决的问题</h2><p>NPE和LPP中每个词的含义可以分别看作三个算法步骤的，这两个算法的很多步骤都是相似的。 更具体地说，流形的“邻域”（Neighborhood，Locality）使我们能够构建邻接图，Perserving的处理是计算权重 $W$，而“嵌入”（Embedding和Projection）则计算投影。</p>\n<h2 id=\"LPP和NPE的算法理解\"><a href=\"#LPP和NPE的算法理解\" class=\"headerlink\" title=\"LPP和NPE的算法理解\"></a>LPP和NPE的算法理解</h2><h3 id=\"构建邻域图\"><a href=\"#构建邻域图\" class=\"headerlink\" title=\"构建邻域图\"></a>构建邻域图</h3><p>NPE 和LPP中的“邻域”指的是只有邻域对重建有贡献。</p>\n<p>由流形的定义可知，流形中的每一点$X_{a}$在欧氏空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}</script><p>其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。 更具体地说，NPE 中的“Neighborhood”使用两种方式构建邻接图$G$：</p>\n<ul>\n<li>$K$ 最近邻（KNN）：如果$x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那么在第$i$个节点和第$j$个节点连一条边。</li>\n<li>如果 $|x_{i}-x_{j}|&lt; \\epsilon$，则在节点 $i$ 和 $j$ 之间放置一条边。</li>\n</ul>\n<h3 id=\"计算邻域矩阵\"><a href=\"#计算邻域矩阵\" class=\"headerlink\" title=\"计算邻域矩阵\"></a>计算邻域矩阵</h3><p>这一步中NPE和LPP的做法不同。</p>\n<h4 id=\"NPE计算-W\"><a href=\"#NPE计算-W\" class=\"headerlink\" title=\"NPE计算$W$\"></a>NPE计算$W$</h4><p>NPE中的“保留”是指保留流形的局部不变性。 在这一步中，NPE算法尝试计算权重 $W_{ij}$，以每个点的邻域为基础，最好地线性重建每个数据点 $X_{i}$，即最小化线性的重构损失，见公式（1）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{1}</script><p>其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。</p>\n<p>此外，我们解释为什么我们需要约束 $\\sum_{j}W_{ij}=1$。 约束是平移不变性、旋转不变性和伸缩不变性的必要条件。 并且可以通过约束$\\sum_{j}W_{ij}=1$的拉格朗日乘子法来最小化重构误差。</p>\n<h4 id=\"LPP计算-W\"><a href=\"#LPP计算-W\" class=\"headerlink\" title=\"LPP计算$W$\"></a>LPP计算$W$</h4><p>LPP 中的“保留”是指保留数据集的邻域结构。 更具体地说，数据集的邻域结构可以用线性变换$W$来表示。 在这一步中，我们有两种对边进行加权的方法，即计算权重 $W_{ij}$：</p>\n<ul>\n<li><p>核函数：如果节点 $i$ 和 $j$ 相连，则放置</p>\n<script type=\"math/tex; mode=display\">\n     W_{ij}=e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{t}}。</script></li>\n<li><p>简单连接：$W_{ij}=1$ 当且仅当顶点 $i$ 和 $j$ 由一条边连接。</p>\n</li>\n</ul>\n<h3 id=\"映射\"><a href=\"#映射\" class=\"headerlink\" title=\"映射\"></a>映射</h3><h4 id=\"NPE计算嵌入\"><a href=\"#NPE计算嵌入\" class=\"headerlink\" title=\"NPE计算嵌入\"></a>NPE计算嵌入</h4><p>NPE 中的“嵌入”是指将高维数据点 $X_{i}$ 线性映射到低维嵌入坐标，如公式（2）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        x_{i}\\rightarrow y_{i}=A^{T}x_{i}\\\\\n        A=(a_{0}, a_{1}, \\cdots, a_{d-1}),\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $y_{i}$ 是一个 d 维向量，而 $A$ 是一个 $n\\times d$ 矩阵。 同时，列向量$a_{0}、a_{1}、\\cdots、a_{d-1}$是公式(3)中分解问题的解。 根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    XMX^{T}a=\\lambda XX^{T}a,\n\\end{equation}\\tag{3}</script><p>其中 $X=(x_{1},\\cdots,x_{m}), M=\\left(IW\\right)^{T}\\left(IW\\right), I=diag(1,\\cdots,1 )$。</p>\n<h4 id=\"LPP计算映射\"><a href=\"#LPP计算映射\" class=\"headerlink\" title=\"LPP计算映射\"></a>LPP计算映射</h4><p>LPP 中的“投影”是指线性投影，它可以最佳地保留流形上高维数据的邻域结构。</p>\n<p>投影与公式(2)类似，但获得投影 $A$ 的方式不同。 列向量 $a_{0}, a_{1}, \\cdots, a_{d-1}$ 是公式(4)中特征分解问题的解。根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(4):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n        XLX^{T}\\mathbf{a}=\\lambda XDX^{T}\\mathbf{a}\n\\end{equation}\\tag{4}</script><p>其中 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。 $L=D-W$ 是拉普拉斯矩阵。</p>\n<h2 id=\"具体的推导过程\"><a href=\"#具体的推导过程\" class=\"headerlink\" title=\"具体的推导过程\"></a>具体的推导过程</h2><p>在这一部分，我们展示NPE和LPP实现的数学细节。</p>\n<h3 id=\"NPE数学推导\"><a href=\"#NPE数学推导\" class=\"headerlink\" title=\"NPE数学推导\"></a>NPE数学推导</h3><p>在 NPE 中，每个数据点都可以表示为其邻居的线性组合。边权可以通过最小化目标目标函数来计算，即最小化重构误差，见等式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\phi(W)=\\sum_{i}\\left\\|\\mathbf{x}_{i}-\\sum_{j} W_{i j} \\mathbf{x}_{j}\\right\\|^{2}.\n\\end{equation}</script><p>设 $\\mathbf{y}=\\left(y_{1}, y_{2}, \\cdots, y_{m}\\right)^{T}$ 是这样的映射。选择一个好的映射的合理标准是最小化以下目标函数，见公式(5):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\Phi(\\mathbf{y})=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2},\n\\end{equation}\\tag{5}</script><p>在适当的约束下。该成本函数基于局部线性重构的误差，但在这里我们在优化坐标 $y_{i}$ 的同时固定权重 $W_{ij}$。假设变换是线性的，即$y^{T}=a^{T}X$，其中$X$的第i列向量为$x_{i}$。我们定义：</p>\n<script type=\"math/tex; mode=display\">\nz_{i}=y_{i}-\\sum_{j}W_{ij}y_{ij},</script><p>同时$z_{i}$可以写成向量形式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\mathbf{z}&=\\mathbf{y}-w\\mathbf{y}\\\\\n        &=(I-W)\\mathbf{y}.\n    \\end{aligned}\n\\end{equation}</script><p>由此目标函数公式(5)可以简化为：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\Phi(\\mathbf{y}) &=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2} \\\\\n        &=\\sum_{i}\\left(z_{i}\\right)^{2} \\\\\n        &=\\mathbf{z}^{T} \\mathbf{z} \\\\\n        &=\\mathbf{y}^{T}(I-W)^{T}(I-W) \\mathbf{y} \\\\\n        &=\\mathbf{a}^{T} X(I-W)^{T}(I-W) X^{T} \\mathbf{a} \\\\\n        & \\doteq \\mathbf{a}^{T} X M X^{T} \\mathbf{a}\n    \\end{aligned}\n\\end{equation}</script><p>其中矩阵 $XMX^{T}$ 是对称和半正定的。为了去除投影中的任意缩放因子，NPE 施加如下约束：</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y}^{T} \\mathbf{y}=1 \\Longrightarrow \\mathbf{a}^{T} X X^{T} \\mathbf{a}=1.</script><p>最后，最小化问题简化为求解如下问题，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{\\mathbf{a}^{T} X X^{T} \\mathbf{a}=1}{\\arg \\underset{\\mathbf{a}}{\\min}} \\mathbf{a}^{T} X M X^{T} \\mathbf{a}.\n\\end{equation}</script><p>然后，我们用拉格朗日乘子法求解上述目标函数，见以下推导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)M(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XMX^{T}\\textbf{a}-2\\lambda XX^{T}\\textbf{a}=0 \\\\\n        & \\ \\ \\ \\ \\ \\ X M X^{T} \\mathbf{a}=\\lambda X X^{T} \\mathbf{a}.\n    \\end{aligned}\n\\end{equation}</script><p>其中$\\textbf{a}$的求解可以用特征值分解或者SVD来求解。</p>\n<h3 id=\"LPP的数学推导\"><a href=\"#LPP的数学推导\" class=\"headerlink\" title=\"LPP的数学推导\"></a>LPP的数学推导</h3><p>给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。假设图是连通的。设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。然后，我们可以将目标函数转换为半正定二次型的迹作为以下推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right)=2\\textbf{y}^{T}L\\textbf{y}.\n    \\end{aligned}\n\\end{equation}</script><p>在投影中为消除任意缩放因子添加一个约束。因此，目标函数的优化问题可以转化为如下形式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=2\\textbf{y}^{T}L\\textbf{y} \\\\\n        \\text{ s.t. } \\textbf{y}^{T}D\\textbf{y}=1.\n    \\end{gathered}\n\\end{equation}\\tag{6}</script><p>假设$\\textbf{a}$是线性拉普拉斯特征图的变换向量，即$\\textbf{y}^{T}=\\textbf{a}^{T}X$。公式(6)的最小化问题可以转化为公式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T}=1}{\\arg \\underset{\\textbf{a}}{\\min}}=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}.\n\\end{equation}</script><p>然后，我们用拉格朗日乘子法求解目标函数，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XLX^{T}\\textbf{a}-2\\lambda XDX^{T}\\textbf{a} \\\\\n        &=2(L^{\\prime} \\mathbf{a}-\\lambda D^{\\prime}\\mathbf{a})=0 \\\\\n        & \\ \\ \\ \\ \\ \\ L^{\\prime} \\mathbf{a}=\\lambda D^{\\prime}\\mathbf{a},\n    \\end{aligned}\n\\end{equation}</script><p>其中 $L^{\\prime}=X L X^{T}，D^{\\prime}=X D X^{T}$。很容易证明矩阵 $D^{\\prime}$ 和 $L^{\\prime}$ 是对称的和半正定的。求解向量 $\\mathbf{a}_{i}(i=1,2, \\cdots, k)$ 可以使用特征值分解或SVD进行。</p>\n<h2 id=\"讨论：PCA，LLE，LE，NPE和LPP的区别\"><a href=\"#讨论：PCA，LLE，LE，NPE和LPP的区别\" class=\"headerlink\" title=\"讨论：PCA，LLE，LE，NPE和LPP的区别\"></a>讨论：PCA，LLE，LE，NPE和LPP的区别</h2><p>与旨在保留全局欧几里得结构的 PCA 不同，四种降维方法（LLE、LE、NPE 和 LPP）旨在保留局部流形结构。</p>\n<p>LLE 和 NPE 都试图通过计算高维数据的低维、邻域保留嵌入来降低平滑流形的维数。LLE 试图发现流形的非线性结构，而 NPE 是 LLE 的线性近似。 所以，NPE 与 LLE 相比有两个优势：</p>\n<ul>\n<li>与 LLE 相比，NPE 的定义无处不在，而不仅仅是在训练数据点上。 这意味着 NPE 可以在监督或非监督模式下执行。</li>\n<li>NPE 是线性的。 这使其快速且适用于实际应用。 它可以在原始空间中进行，也可以在数据点映射到的再现核希尔伯特空间（RKHS）中进行，所以有核NPE。</li>\n</ul>\n<p>LE 和 LPP 都试图通过使用图拉普拉斯算子之间的对应关系来减少流形的维数，以构建高维空间上的数据在低维流形上的表示。然而，LE 试图发现流形的非线性结构，而 LPP 是非线性 LE 的线性近似。LPP相对于LE的优势类似于NPE相对于LLE的优势。</p>\n<p>同时NPE和LPP还是有一些区别的，他们的目标函数完全不同，分别见公式(7)和公式(8):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        &=\\textbf{y}M\\textbf{y}=\\textbf{a}^{T}XMX^{T}\\textbf{a}\\\\\n    \\end{aligned}\n\\end{equation}\\tag{7}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2\\textbf{y}^{T}L\\textbf{y}=2(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}=1,\\ \\textbf{y}^{T}=\\textbf{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{8}</script><p>$L$ 提供了流形上拉普拉斯贝尔特拉米算子 $\\mathcal{L}$ 的离散近似。 因此，矩阵 $M$ 提供了对 $\\mathcal{L}^{2}$ 的离散近似。 这表明 NPE 本质上试图找到迭代拉普拉斯算子 $\\mathcal{L}^{2}$ 的特征函数的线性近似。 从这个意义上说，NPE 和 LPP 提供了两种不同的方法来线性逼近 Laplace Beltrami 算子的特征函数。</p>\n<h2 id=\"实验效果-MNIST-and-ORL\"><a href=\"#实验效果-MNIST-and-ORL\" class=\"headerlink\" title=\"实验效果(MNIST and ORL)\"></a>实验效果(MNIST and ORL)</h2><p>NPE和LPP的代码我自己写的，由粗略实验效果来看，估计有一些问题，也可能是参数没调对。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> kneighbors_graph</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sparse_max</span>(<span class=\"params\">A, B</span>):</span></span><br><span class=\"line\">    Ag = (A &gt; B).astype(<span class=\"built_in\">int</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Ag.multiply(A - B) + B</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">NPE</span>(<span class=\"params\">data, train_data, component, neighboor</span>):</span></span><br><span class=\"line\">    W = kneighbors_graph(train_data, neighboor, mode=<span class=\"string\">&#x27;distance&#x27;</span>, include_self=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    W = W.A</span><br><span class=\"line\">    X = train_data.T</span><br><span class=\"line\">    M = (np.eye(X.shape[<span class=\"number\">1</span>]) - W).dot((np.eye(X.shape[<span class=\"number\">1</span>]) - W).T)</span><br><span class=\"line\">    T1 = X.dot(M).dot(X.T)</span><br><span class=\"line\">    T2 = X.dot(X.T)</span><br><span class=\"line\">    T2 = T2 + np.exp(-<span class=\"number\">10</span>) * np.eye(T2.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.inv(T2).dot(T1)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)  <span class=\"comment\"># 求特征值，特征向量</span></span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[<span class=\"number\">0</span>:component]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    npe = data.dot(w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> npe</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LPP</span>(<span class=\"params\">data, train_data, component, neighboor, t</span>):</span></span><br><span class=\"line\">    W = kneighbors_graph(train_data, neighboor, mode=<span class=\"string\">&#x27;distance&#x27;</span>, include_self=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    W = sparse_max(W, W.T) <span class=\"comment\">#让W矩阵对称，不报warning</span></span><br><span class=\"line\">    W.data[:] = np.exp(-(W.data ** <span class=\"number\">2</span> / (t)))</span><br><span class=\"line\">    W = W.A</span><br><span class=\"line\">    D = np.diag(np.<span class=\"built_in\">sum</span>(W, axis=<span class=\"number\">0</span>))</span><br><span class=\"line\">    L = D - W</span><br><span class=\"line\">    X = train_data.T</span><br><span class=\"line\">    T1 = X.dot(L).dot(X.T)</span><br><span class=\"line\">    T2 = X.dot(D).dot(X.T)</span><br><span class=\"line\">    T2 = T2 + np.exp(-<span class=\"number\">10</span>) * np.eye(T2.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.pinv(T2).dot(T1)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)  <span class=\"comment\"># 求特征值，特征向量</span></span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[<span class=\"number\">0</span>:component]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    lpp = data.dot(w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> lpp</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，有可视化的降维结果。然后我们在MNIST上，使用PCA，LLE和LE把数据降到2维。</p>\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 六种降维算法在MNIST上的效果。</center>\n\n<p>同时我们在MNIST数据集上探究了NPE和LPP算法(<strong>KNN</strong>的$k=1$时)的参数（NPE：邻居$n$，LPP：邻居$n$和参数$t$）变化对效果的影响：</p>\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数对NPE和LPP算法的影响。</center>\n\n<p>然后我们展示算法在ORL数据集上的实验效果。</p>\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/acc.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. ORL数据集上的准确率对比。</center>\n\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/face.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4. ORL数据集上的可视化降维效果。</center>\n\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/eig.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图5. 算法提取的特征。</center></p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Locality Preserving Projections（2004 NIPS）</strong>和<strong>Neighborhood Preserving Embedding（2005 ICCV）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LPP和NPE的动机，目标函数和限制等。额，然后本系列的解释应该是中英文混合，私以为用简略的句子生动地描述复杂抽象的概念，需要对算法有着极为深刻的理解和一定的勇气。显然我水平不够，如果强制翻译一些原文的描述和概念，难免不太妥当。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>信息处理中的许多问题都涉及某种形式的降维。 因此，人们对降维算法很感兴趣。 与旨在保留全局欧几里德结构的主成分分析，我们将介绍两种旨在保留流形上的局部邻域结构的子空间学习算法：邻域保留嵌入（NPE）是局部线性嵌入（LLE）的线性近似，而LPP是拉普拉斯映射（LE）的线性近似。 在本报告中，我们尝试以数学方式解释 NPE 和 LPP 的主要思想，并讨论 PCA、LLE、LE、NPE 和 LPP 之间的区别。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Method\"><a href=\"#Method\" class=\"headerlink\" title=\"Method\"></a>Method</h1><h2 id=\"假设\"><a href=\"#假设\" class=\"headerlink\" title=\"假设\"></a>假设</h2><p>数据点可能位于非线性子流形上，但假设每个局部邻域都是线性的。</p>\n<h2 id=\"解决的问题\"><a href=\"#解决的问题\" class=\"headerlink\" title=\"解决的问题\"></a>解决的问题</h2><p>NPE和LPP中每个词的含义可以分别看作三个算法步骤的，这两个算法的很多步骤都是相似的。 更具体地说，流形的“邻域”（Neighborhood，Locality）使我们能够构建邻接图，Perserving的处理是计算权重 $W$，而“嵌入”（Embedding和Projection）则计算投影。</p>\n<h2 id=\"LPP和NPE的算法理解\"><a href=\"#LPP和NPE的算法理解\" class=\"headerlink\" title=\"LPP和NPE的算法理解\"></a>LPP和NPE的算法理解</h2><h3 id=\"构建邻域图\"><a href=\"#构建邻域图\" class=\"headerlink\" title=\"构建邻域图\"></a>构建邻域图</h3><p>NPE 和LPP中的“邻域”指的是只有邻域对重建有贡献。</p>\n<p>由流形的定义可知，流形中的每一点$X_{a}$在欧氏空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}</script><p>其中 $W_{a}$ 是不变的，$X$ 是高维数据，$Y$ 是低维数据。 更具体地说，NPE 中的“Neighborhood”使用两种方式构建邻接图$G$：</p>\n<ul>\n<li>$K$ 最近邻（KNN）：如果$x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那么在第$i$个节点和第$j$个节点连一条边。</li>\n<li>如果 $|x_{i}-x_{j}|&lt; \\epsilon$，则在节点 $i$ 和 $j$ 之间放置一条边。</li>\n</ul>\n<h3 id=\"计算邻域矩阵\"><a href=\"#计算邻域矩阵\" class=\"headerlink\" title=\"计算邻域矩阵\"></a>计算邻域矩阵</h3><p>这一步中NPE和LPP的做法不同。</p>\n<h4 id=\"NPE计算-W\"><a href=\"#NPE计算-W\" class=\"headerlink\" title=\"NPE计算$W$\"></a>NPE计算$W$</h4><p>NPE中的“保留”是指保留流形的局部不变性。 在这一步中，NPE算法尝试计算权重 $W_{ij}$，以每个点的邻域为基础，最好地线性重建每个数据点 $X_{i}$，即最小化线性的重构损失，见公式（1）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W) = \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\text{ s.t. }\\sum_{j}W_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{1}</script><p>其中 $X_{ij}$ 是 $X_{i}$ 的邻居，$\\sum_{j}W_{ij}X_{ij}$ 是局部线性重建。</p>\n<p>此外，我们解释为什么我们需要约束 $\\sum_{j}W_{ij}=1$。 约束是平移不变性、旋转不变性和伸缩不变性的必要条件。 并且可以通过约束$\\sum_{j}W_{ij}=1$的拉格朗日乘子法来最小化重构误差。</p>\n<h4 id=\"LPP计算-W\"><a href=\"#LPP计算-W\" class=\"headerlink\" title=\"LPP计算$W$\"></a>LPP计算$W$</h4><p>LPP 中的“保留”是指保留数据集的邻域结构。 更具体地说，数据集的邻域结构可以用线性变换$W$来表示。 在这一步中，我们有两种对边进行加权的方法，即计算权重 $W_{ij}$：</p>\n<ul>\n<li><p>核函数：如果节点 $i$ 和 $j$ 相连，则放置</p>\n<script type=\"math/tex; mode=display\">\n     W_{ij}=e^{-\\frac{\\|x_{i}-x_{j}\\|^{2}}{t}}。</script></li>\n<li><p>简单连接：$W_{ij}=1$ 当且仅当顶点 $i$ 和 $j$ 由一条边连接。</p>\n</li>\n</ul>\n<h3 id=\"映射\"><a href=\"#映射\" class=\"headerlink\" title=\"映射\"></a>映射</h3><h4 id=\"NPE计算嵌入\"><a href=\"#NPE计算嵌入\" class=\"headerlink\" title=\"NPE计算嵌入\"></a>NPE计算嵌入</h4><p>NPE 中的“嵌入”是指将高维数据点 $X_{i}$ 线性映射到低维嵌入坐标，如公式（2）：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        x_{i}\\rightarrow y_{i}=A^{T}x_{i}\\\\\n        A=(a_{0}, a_{1}, \\cdots, a_{d-1}),\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $y_{i}$ 是一个 d 维向量，而 $A$ 是一个 $n\\times d$ 矩阵。 同时，列向量$a_{0}、a_{1}、\\cdots、a_{d-1}$是公式(3)中分解问题的解。 根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    XMX^{T}a=\\lambda XX^{T}a,\n\\end{equation}\\tag{3}</script><p>其中 $X=(x_{1},\\cdots,x_{m}), M=\\left(IW\\right)^{T}\\left(IW\\right), I=diag(1,\\cdots,1 )$。</p>\n<h4 id=\"LPP计算映射\"><a href=\"#LPP计算映射\" class=\"headerlink\" title=\"LPP计算映射\"></a>LPP计算映射</h4><p>LPP 中的“投影”是指线性投影，它可以最佳地保留流形上高维数据的邻域结构。</p>\n<p>投影与公式(2)类似，但获得投影 $A$ 的方式不同。 列向量 $a_{0}, a_{1}, \\cdots, a_{d-1}$ 是公式(4)中特征分解问题的解。根据它们的特征值排序，$\\lambda_{0}\\leq \\cdots \\leq \\lambda_{d-1}$，见公式(4):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n        XLX^{T}\\mathbf{a}=\\lambda XDX^{T}\\mathbf{a}\n\\end{equation}\\tag{4}</script><p>其中 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。 $L=D-W$ 是拉普拉斯矩阵。</p>\n<h2 id=\"具体的推导过程\"><a href=\"#具体的推导过程\" class=\"headerlink\" title=\"具体的推导过程\"></a>具体的推导过程</h2><p>在这一部分，我们展示NPE和LPP实现的数学细节。</p>\n<h3 id=\"NPE数学推导\"><a href=\"#NPE数学推导\" class=\"headerlink\" title=\"NPE数学推导\"></a>NPE数学推导</h3><p>在 NPE 中，每个数据点都可以表示为其邻居的线性组合。边权可以通过最小化目标目标函数来计算，即最小化重构误差，见等式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\phi(W)=\\sum_{i}\\left\\|\\mathbf{x}_{i}-\\sum_{j} W_{i j} \\mathbf{x}_{j}\\right\\|^{2}.\n\\end{equation}</script><p>设 $\\mathbf{y}=\\left(y_{1}, y_{2}, \\cdots, y_{m}\\right)^{T}$ 是这样的映射。选择一个好的映射的合理标准是最小化以下目标函数，见公式(5):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\Phi(\\mathbf{y})=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2},\n\\end{equation}\\tag{5}</script><p>在适当的约束下。该成本函数基于局部线性重构的误差，但在这里我们在优化坐标 $y_{i}$ 的同时固定权重 $W_{ij}$。假设变换是线性的，即$y^{T}=a^{T}X$，其中$X$的第i列向量为$x_{i}$。我们定义：</p>\n<script type=\"math/tex; mode=display\">\nz_{i}=y_{i}-\\sum_{j}W_{ij}y_{ij},</script><p>同时$z_{i}$可以写成向量形式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\mathbf{z}&=\\mathbf{y}-w\\mathbf{y}\\\\\n        &=(I-W)\\mathbf{y}.\n    \\end{aligned}\n\\end{equation}</script><p>由此目标函数公式(5)可以简化为：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        \\Phi(\\mathbf{y}) &=\\sum_{i}\\left(y_{i}-\\sum_{j} W_{i j} y_{j}\\right)^{2} \\\\\n        &=\\sum_{i}\\left(z_{i}\\right)^{2} \\\\\n        &=\\mathbf{z}^{T} \\mathbf{z} \\\\\n        &=\\mathbf{y}^{T}(I-W)^{T}(I-W) \\mathbf{y} \\\\\n        &=\\mathbf{a}^{T} X(I-W)^{T}(I-W) X^{T} \\mathbf{a} \\\\\n        & \\doteq \\mathbf{a}^{T} X M X^{T} \\mathbf{a}\n    \\end{aligned}\n\\end{equation}</script><p>其中矩阵 $XMX^{T}$ 是对称和半正定的。为了去除投影中的任意缩放因子，NPE 施加如下约束：</p>\n<script type=\"math/tex; mode=display\">\n\\mathbf{y}^{T} \\mathbf{y}=1 \\Longrightarrow \\mathbf{a}^{T} X X^{T} \\mathbf{a}=1.</script><p>最后，最小化问题简化为求解如下问题，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{\\mathbf{a}^{T} X X^{T} \\mathbf{a}=1}{\\arg \\underset{\\mathbf{a}}{\\min}} \\mathbf{a}^{T} X M X^{T} \\mathbf{a}.\n\\end{equation}</script><p>然后，我们用拉格朗日乘子法求解上述目标函数，见以下推导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)M(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XMX^{T}\\textbf{a}-2\\lambda XX^{T}\\textbf{a}=0 \\\\\n        & \\ \\ \\ \\ \\ \\ X M X^{T} \\mathbf{a}=\\lambda X X^{T} \\mathbf{a}.\n    \\end{aligned}\n\\end{equation}</script><p>其中$\\textbf{a}$的求解可以用特征值分解或者SVD来求解。</p>\n<h3 id=\"LPP的数学推导\"><a href=\"#LPP的数学推导\" class=\"headerlink\" title=\"LPP的数学推导\"></a>LPP的数学推导</h3><p>给定一个数据集，我们构建一个加权图 $G = (V, E)$，其中边将附近的点彼此连接起来。假设图是连通的。设 $Y=[\\textbf{y}_{1}, \\textbf{y}_{2}, \\cdots, \\textbf{y}_{n}]$ 是这样的映射，并且 $\\textbf{y }=(y_{1}, y_{2}, \\cdots, y_{n})^{T}$。然后，我们可以将目标函数转换为半正定二次型的迹作为以下推导，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{aligned}\n        &\\ \\ \\ \\ \\sum_{i,j}\\|y_{i}-y_{j}\\|^{2}W_{ij}=\\Phi(Y) \\\\\n        &=\\sum_{i=1}^{n}\\sum_{j=1}^{n}(y_{i}y_{i}-2y_{i}y_{j}+y_{j}y_{j})W_{ij}\\\\\n        &=2 \\sum_{i=1}^{n} D_{i i} y_{i}^{2}-2 \\sum_{i=1}^{n} \\sum_{j=1}^{n} y_{i} y_{j} W_{i j} \\\\\n        &=2 \\operatorname{tr}\\left[Y^{T}(D-W) Y\\right] \\\\\n        &=2 \\operatorname{tr}\\left(Y^{T} L Y\\right)=2\\textbf{y}^{T}L\\textbf{y}.\n    \\end{aligned}\n\\end{equation}</script><p>在投影中为消除任意缩放因子添加一个约束。因此，目标函数的优化问题可以转化为如下形式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\Phi(Y)=2\\textbf{y}^{T}L\\textbf{y} \\\\\n        \\text{ s.t. } \\textbf{y}^{T}D\\textbf{y}=1.\n    \\end{gathered}\n\\end{equation}\\tag{6}</script><p>假设$\\textbf{a}$是线性拉普拉斯特征图的变换向量，即$\\textbf{y}^{T}=\\textbf{a}^{T}X$。公式(6)的最小化问题可以转化为公式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T}=1}{\\arg \\underset{\\textbf{a}}{\\min}}=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}.\n\\end{equation}</script><p>然后，我们用拉格朗日乘子法求解目标函数，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        f(Y)&=(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} - \\lambda(\\textbf{a}^{T}X)D(\\textbf{a}^{T}X)^{T} \\\\\n        \\frac{\\partial f(Y)}{\\partial \\textbf{a}}&=2XLX^{T}\\textbf{a}-2\\lambda XDX^{T}\\textbf{a} \\\\\n        &=2(L^{\\prime} \\mathbf{a}-\\lambda D^{\\prime}\\mathbf{a})=0 \\\\\n        & \\ \\ \\ \\ \\ \\ L^{\\prime} \\mathbf{a}=\\lambda D^{\\prime}\\mathbf{a},\n    \\end{aligned}\n\\end{equation}</script><p>其中 $L^{\\prime}=X L X^{T}，D^{\\prime}=X D X^{T}$。很容易证明矩阵 $D^{\\prime}$ 和 $L^{\\prime}$ 是对称的和半正定的。求解向量 $\\mathbf{a}_{i}(i=1,2, \\cdots, k)$ 可以使用特征值分解或SVD进行。</p>\n<h2 id=\"讨论：PCA，LLE，LE，NPE和LPP的区别\"><a href=\"#讨论：PCA，LLE，LE，NPE和LPP的区别\" class=\"headerlink\" title=\"讨论：PCA，LLE，LE，NPE和LPP的区别\"></a>讨论：PCA，LLE，LE，NPE和LPP的区别</h2><p>与旨在保留全局欧几里得结构的 PCA 不同，四种降维方法（LLE、LE、NPE 和 LPP）旨在保留局部流形结构。</p>\n<p>LLE 和 NPE 都试图通过计算高维数据的低维、邻域保留嵌入来降低平滑流形的维数。LLE 试图发现流形的非线性结构，而 NPE 是 LLE 的线性近似。 所以，NPE 与 LLE 相比有两个优势：</p>\n<ul>\n<li>与 LLE 相比，NPE 的定义无处不在，而不仅仅是在训练数据点上。 这意味着 NPE 可以在监督或非监督模式下执行。</li>\n<li>NPE 是线性的。 这使其快速且适用于实际应用。 它可以在原始空间中进行，也可以在数据点映射到的再现核希尔伯特空间（RKHS）中进行，所以有核NPE。</li>\n</ul>\n<p>LE 和 LPP 都试图通过使用图拉普拉斯算子之间的对应关系来减少流形的维数，以构建高维空间上的数据在低维流形上的表示。然而，LE 试图发现流形的非线性结构，而 LPP 是非线性 LE 的线性近似。LPP相对于LE的优势类似于NPE相对于LLE的优势。</p>\n<p>同时NPE和LPP还是有一些区别的，他们的目标函数完全不同，分别见公式(7)和公式(8):</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}|X_{i}-\\sum_{j}W_{ij}X_{ij}|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}|Y_{i}-\\sum_{j}W_{ij}Y_{ij}|^2 \\\\\n        &=\\textbf{y}M\\textbf{y}=\\textbf{a}^{T}XMX^{T}\\textbf{a}\\\\\n    \\end{aligned}\n\\end{equation}\\tag{7}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2\\textbf{y}^{T}L\\textbf{y}=2(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\textbf{a}^{T}X)L(\\textbf{a}^{T}X)^{T}=1,\\ \\textbf{y}^{T}=\\textbf{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{8}</script><p>$L$ 提供了流形上拉普拉斯贝尔特拉米算子 $\\mathcal{L}$ 的离散近似。 因此，矩阵 $M$ 提供了对 $\\mathcal{L}^{2}$ 的离散近似。 这表明 NPE 本质上试图找到迭代拉普拉斯算子 $\\mathcal{L}^{2}$ 的特征函数的线性近似。 从这个意义上说，NPE 和 LPP 提供了两种不同的方法来线性逼近 Laplace Beltrami 算子的特征函数。</p>\n<h2 id=\"实验效果-MNIST-and-ORL\"><a href=\"#实验效果-MNIST-and-ORL\" class=\"headerlink\" title=\"实验效果(MNIST and ORL)\"></a>实验效果(MNIST and ORL)</h2><p>NPE和LPP的代码我自己写的，由粗略实验效果来看，估计有一些问题，也可能是参数没调对。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> kneighbors_graph</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sparse_max</span>(<span class=\"params\">A, B</span>):</span></span><br><span class=\"line\">    Ag = (A &gt; B).astype(<span class=\"built_in\">int</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Ag.multiply(A - B) + B</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">NPE</span>(<span class=\"params\">data, train_data, component, neighboor</span>):</span></span><br><span class=\"line\">    W = kneighbors_graph(train_data, neighboor, mode=<span class=\"string\">&#x27;distance&#x27;</span>, include_self=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    W = W.A</span><br><span class=\"line\">    X = train_data.T</span><br><span class=\"line\">    M = (np.eye(X.shape[<span class=\"number\">1</span>]) - W).dot((np.eye(X.shape[<span class=\"number\">1</span>]) - W).T)</span><br><span class=\"line\">    T1 = X.dot(M).dot(X.T)</span><br><span class=\"line\">    T2 = X.dot(X.T)</span><br><span class=\"line\">    T2 = T2 + np.exp(-<span class=\"number\">10</span>) * np.eye(T2.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.inv(T2).dot(T1)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)  <span class=\"comment\"># 求特征值，特征向量</span></span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[<span class=\"number\">0</span>:component]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    npe = data.dot(w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> npe</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LPP</span>(<span class=\"params\">data, train_data, component, neighboor, t</span>):</span></span><br><span class=\"line\">    W = kneighbors_graph(train_data, neighboor, mode=<span class=\"string\">&#x27;distance&#x27;</span>, include_self=<span class=\"literal\">False</span>)</span><br><span class=\"line\">    W = sparse_max(W, W.T) <span class=\"comment\">#让W矩阵对称，不报warning</span></span><br><span class=\"line\">    W.data[:] = np.exp(-(W.data ** <span class=\"number\">2</span> / (t)))</span><br><span class=\"line\">    W = W.A</span><br><span class=\"line\">    D = np.diag(np.<span class=\"built_in\">sum</span>(W, axis=<span class=\"number\">0</span>))</span><br><span class=\"line\">    L = D - W</span><br><span class=\"line\">    X = train_data.T</span><br><span class=\"line\">    T1 = X.dot(L).dot(X.T)</span><br><span class=\"line\">    T2 = X.dot(D).dot(X.T)</span><br><span class=\"line\">    T2 = T2 + np.exp(-<span class=\"number\">10</span>) * np.eye(T2.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.pinv(T2).dot(T1)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)  <span class=\"comment\"># 求特征值，特征向量</span></span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[<span class=\"number\">0</span>:component]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    lpp = data.dot(w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> lpp</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，有可视化的降维结果。然后我们在MNIST上，使用PCA，LLE和LE把数据降到2维。</p>\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 六种降维算法在MNIST上的效果。</center>\n\n<p>同时我们在MNIST数据集上探究了NPE和LPP算法(<strong>KNN</strong>的$k=1$时)的参数（NPE：邻居$n$，LPP：邻居$n$和参数$t$）变化对效果的影响：</p>\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/parameter.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数对NPE和LPP算法的影响。</center>\n\n<p>然后我们展示算法在ORL数据集上的实验效果。</p>\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/acc.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. ORL数据集上的准确率对比。</center>\n\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/face.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4. ORL数据集上的可视化降维效果。</center>\n\n<p><img src=\"/2022/01/14/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(4)-LPP&NPE/eig.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图5. 算法提取的特征。</center></p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>其实在复现过程中，并没有达到论文中的效果，我怀疑是降维算法和分类算法参数的选择并没有使效果达到最优。</p>\n"},{"title":"子空间学习(5)-GE","catalog":true,"date":"2022-01-15T04:24:17.000Z","subtitle":"Subspace Learning-GE","top":12,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Graph Embedding and Extensions-A General Framework for Dimensionality Reduction（2007 TPAMI）**，Semi-supervised Discriminant Analysis（2005 CVPR），Kernel eigenfaces vs. kernel fisherfaces- Face recognition using kernel methods（2002）。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Eigenfaces，Fisherfaces，Kernel Trick和SDA。\n\n# 摘要：\n\n在过去的几十年里，出现了一大类算法，有监督的或无监督的，源于统计学或几何理论——旨在为降维问题提供不同的解决方案。 尽管子空间学习算法的动机不同，但我们可以引入了一种称为图嵌入的通用公式，以将它们统一在一个通用框架内。 在图嵌入中，每个算法都可以被认为是直接图嵌入或其线性/核/张量扩展的特定内在图，该图描述了数据集的某些所需统计或几何属性，具有来自尺度归一化或惩罚项的约束。 在本报告中，我们将在数学上分析**Graph Embedding**，并在通用框架下比较先前学习的流形学习算法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Graph Embedding理解\n\n在本节中，降维算法以统一框架表示。 对于一般分类问题，模型训练的样本集表示为矩阵 $X=[x_{1},x_{2},\\cdots,x_{N}]$, $x_{i}\\in \\mathcal {R}^{m}$，其中 $N$ 是样本数，$m$ 是特征维度。 进一步，样本集的低维表示为 $\\textbf{y}=[y_{1},y_{2},\\cdots,y_{N}]^{T}$，其中 $y_{i} $ 是顶点 $x_{i}$ 的低维表示。\n\n对于监督学习问题，假设样本$x_{i}$的类标签为$c_{i}=\\{1,2,\\cdots,N_{c}\\}$，其中$N_{c} $ 是类的数量。 我们还让 $\\phi_{c}$ 和 $n_{c}$ 分别表示属于 $c_{th}$ 类的索引集和样本数量。\n\n## Graph\n\n令 $G=\\{X,W\\}$ 是一个无向加权图，其顶点集为 $X$，相似矩阵为 $W\\in \\mathcal{R}^{N\\times N}$。 对于一对顶点，实对称矩阵 $W$ 的每个元素测量其相似度，该相似度可能为负。\n\n在这项工作中，图$G$ 的图嵌入被定义为一种算法，以找到$G$ 顶点之间所需的低维向量关系，同时这种低维向量关系最能表征$G$ 中顶点对之间相似关系。\n\n## Embedding\n\n降维的基本任务是找到一个称为“嵌入”的映射函数 $\\phi$，\n$$\n\\begin{equation}\n    \\Phi:\\mathcal{R}^{m}\\rightarrow F,\\ X \\mapsto \\textbf{y},\n\\end{equation}\n$$\n它将 $x\\in \\mathcal{R}^{m}$ 转换为所需的低维表示 $\\textbf{y}\\in R^{\\prime}$，通常为 $m\\gg m^{\\prime }$。 $F$ 指的是特征空间，嵌入$\\Phi$ 在不同情况下可以是显式或隐式、线性或非线性的。\n\n## 框架下的目标函数\n\nGraph-preserving criterion的目标函数是公式(1)：\n$$\n\\begin{equation}\n    y^{*}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\sum_{i \\neq j}\\left\\|y_{i}-y_{j}\\right\\|^{2} W_{i j}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\textbf{y}^{T} L \\textbf{y}\n\\end{equation}\\tag{1}\n$$\n其中 $d$ 是一个常数，$B$ 是为避免目标函数的平凡解而定义的约束矩阵。 $B$ 通常是用于尺度归一化的对角矩阵，也可能是惩罚图的拉普拉斯矩阵。 即$B=L=D-W$，其中$D$为对角矩阵定义为$D_{ii}=\\sum_{j}W_{ij}, {\\forall} i$。 此外，约束 $\\textbf{y}^{T} B \\textbf{y}=d$ 用于尺度归一化。\n\n## 为什么LLE，LE，NPE和LPP属于GE框架\n\n流形具有局部结构和局部不变性，局部结构可以用图嵌入来表示（LLE，LE，NPE和LPP都利用了局部不变性）。 更具体地说，根据流形的定义，我们可以知道流形中的每一个点$X_{a}$在欧几里得空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$ ，见公式：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $W_{a}$ 是不变的。\n\n## 框架下的分类和总结\n\n| Group           | Algorithm                           |\n| --------------- | ----------------------------------- |\n| Full supervised | LDA, KLDA, NPE                      |\n| Semi-supervised | SDA                                 |\n| Un-supervised   | PCA, LLE, LE, LPP, NPE, Isomap, MDS |\n\n<img src=\"子空间学习(5)-GE\\com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n# Kernel Eigenfaces and Kernel Fisherfaces\n\nEigenfaces和Fisherfaces算法见一下篇博客：子空间学习(6)-LDE。\n\n## 动机\n\nKernel Eigenfaces 旨在找到在非线性映射 $\\Phi$ 之后最大化特征空间方差的投影方向，而 Kernel Fisherfaces 通过最小化类内数据点距离和类间数据点距离之间的比率来搜索最有效的区分方向。即Kernel Eigenfaces是在<u>PCA</u>的基础上使用了核函数，Kernel Fisherfaces是在<u>LDA和PCA</u>的基础上使用了核函数。\n\n## 目标函数\n\nKernel Eigenfaces 和 Kernel Fisherfaces 的目标函数根据它们的动机不同，我们假设每个数据点 $x_{i}$ 从输入空间 $\\mathcal{R}^{m}$ 投影到特征空间 $\\mathcal {R}^{m^{\\prime}}$ ，其中非线性映射函数是：$\\Phi: \\mathcal{R}^{m}\\rightarrow \\mathcal{R}^{m^{\\prime}}$， $m<m^{\\prime}$。Eigenfaces 和 Fisherfaces中的一些计算矩阵将由：$w^{\\Phi}$、$C^{\\Phi}$、$S^{\\Phi}$ 和 $W^{\\Phi}$ 表示，它们都与 $\\Phi(x_{1} ),\\Phi(x_{2}),\\cdots,\\Phi(x_{m})$相关的。\n\nKernel Eigenfaces的目标函数是：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    W^{\\Phi}=\\underset{(w^{\\Phi})^{T}w^{\\Phi}=1}{\\arg \\min} (w^{\\Phi})^{T}C^{\\Phi}w^{\\Phi} \\ \\ with\\\\\n    C^{\\Phi}=\\frac{1}{N}\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x}))(\\Phi(x_{i})-\\Phi(\\bar{x})^{T}.\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $C^{\\Phi}$ 是协方差矩阵，$\\Phi(\\bar{x})$ 是特征空间中所有样本的均值。\n\nKernel Fisherfaces的目标函数是最大化特征空间中类间方差$S_{B}$和类内方差$S_{W}$的比率：\n$$\n\\begin{equation}\n    \\begin{aligned}\n    W^{\\Phi} &=\\arg \\max _{W^{\\Phi}} \\frac{\\left|\\left(W^{\\Phi}\\right)^{T} S_{B}^{\\Phi} W^{\\Phi}\\right|}{\\left|\\left(W^{\\Phi}\\right)^{T} S_{W}^{\\Phi} W^{\\Phi}\\right|}=[w_{1}^{\\Phi},\\cdots,w_{m}^{\\Phi}]\\\\\n    S_{W}&=\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})^{T}\\\\\n    S_{B}&=\\sum_{c=1}^{N_{c}}n_{c}(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))^{T}.\n    \\end{aligned}\n\\end{equation}\\tag{3}\n$$\n其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}^{c_{i}}$ 是 $c_{th}$ 类第$i_{th}$个样本。\n\n## 监督方式\n\nKernel Eigenfaces 是一种无监督的降维算法，而 Kernel Fisherfaces 是有监督的。 Kernel Fisherfaces最多只能将维数降到类别数减1。但是Kernel Fisherfaces也可以用于分类，而Kernel Eigenfaces不能。\n\n# 核函数（Kernel Trick）\n\n通过使用核函数，Kernel Eigenfaces是Eigenfaces的非线性推广。 Eigenfaces的基本思想是将数据沿最大方差的方向进行线性投影。 将线性投影方法扩展到非线性情况的一种技术是直接利用核技巧。\n\n## 核函数的优势\n\n- 内核技巧使算法不需要显式计算高维空间中的表示，而只需要在投影到的子空间中计算它。\n- 通过使用不同内核的可能性，它包含了可以使用的相当普遍的非线性类别。\n- 与Eigenfaces相比，非线性主成分比相应数量的线性主成分提供了更好的识别率，并且可以通过使用比线性情况下更多的成分来提高非线性成分的性能。\n- 与其他非线性特征提取技术相比，核方法不需要非线性优化，只需要求解一个特征值问题。\n\n## 核函数的限制\n\n- 与神经方法相比，如果我们需要处理大量的观察，内核技巧可能是不利的，因为这会导致一个大矩阵 $K$。\n- 与Eigenfaces相比，内核技巧在输入空间中更难解释。 然而，至少对于多项式核，它在高阶特征方面有非常清晰的解释。\n\n## SDA\n\nSDA 是 LDA 的半监督形式，它额外包含graphical perspective（图嵌入化），linearization（线性化）和kernel trick（核函数）。 这里主要谈一下SDA相对LDA的一些不同。核函数之前在Kernel Fisherfaces已经解释过了，就不提了。\n\n## 监督方式\n\nLDA是一种全监督降维方法，而SDA是一种半监督方法，有标签的数据用于最大化不同类别之间的可分离性，没有标签的数据点用于估计数据的内在几何结构。\n\n## 图嵌入形式\n\n假设映射方向 $w=\\sum_{i}\\alpha_{i}\\Phi(x_{i})$ 和 $K$ 是核 Gram 矩阵，其中 $K_{ij}=\\Phi(x_{i} )\\Phi(x_{j})$，LDA 的目标函数可以转换为graphical perspective，其中类内和类间方差可以通过矩阵的线性变换来表示，见公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\textbf{a}_{opt}=\\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}S_{b}\\textbf{a}}{\\textbf{a}^{T}S_{t}\\textbf{a}}=  \\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}XW_{l\\times l}X^{T}\\textbf{a}}{\\textbf{a}^{T}XX^{T}\\textbf{a}} \\\\\n    S_{b}=\\sum^{c}_{k=1}X^{(k)}W^{k}(X^{k})^{T}=XW_{l\\times l}X^{T} \\\\\n    S_{t}=\\sum_{i=1}^{l}(x_{i}-\\mu)(x_{i}-\\mu)^{T}=XX^{T}\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $W^{(k)}$ 是一个 $l_{k}\\times l_{k}$ 矩阵，其中所有元素都等于 $1/l_{k}$ ，并且 $X^{(k)}=[x_ {1}^{(k)},\\cdots,x_{lk}^{(k)}]$表示$k_{th}$类的数据矩阵。 和数据矩阵 $X=[X^{(1)},\\cdots,X^{(c)}]$ 并定义 $l\\times l$ 矩阵 $W_{l\\times l}$ 为：\n$$\nW_{l \\times l}=\\left[\\begin{array}{cccc}\nW^{(1)} & 0 & \\cdots & 0 \\\\\n0 & W^{(2)} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & W^{(c)}\n\\end{array}\\right].\n$$\n\n## 线性化\n\n假设顶点的低维向量表示可以从线性投影中获得，如 $y=\\textbf{a}^{T}x$，其中$\\textbf{a}$是投影向量，目标函数修改为公式(5)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\mathbf{a}_{o p t}=\\arg \\max _{\\mathbf{a}} \\frac{\\mathbf{a}^{T} S_{b} \\mathbf{a}}{\\mathbf{a}^{T} S_{w} \\mathbf{a}}, \\\\\n        S_{b}=\\sum_{k=1}^{c} l_{k}\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)^{T}, \\\\\n        S_{w}=\\sum_{k=1}^{c}\\left(\\sum_{i=1}^{l_{k}}\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)^{T}\\right),\n    \\end{gathered}\n\\end{equation}\\tag{5}\n$$\n\n# 代码\n\n贴一下Fisherfaces的代码，Eigenfaces是PCA的具体实现也就不贴了，同时呢，Sklearn也有自己的库可以直接使用LDA：\n\n```python\nfrom sklearn.decomposition import PCA\nimport numpy as np\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis #sklearn的库，这里未使用\n\ndef LDA(data, train_data, train_target, n_dim):\n    clusters = np.unique(train_target)\n    # within_class scatter matrix\n    Sw = np.zeros((train_data.shape[1], train_data.shape[1]))\n    for i in clusters:\n        train_datai = train_data[train_target[:] == i]\n        train_datai = train_datai - train_datai.mean(0)\n        Swi = np.mat(train_datai).T * np.mat(train_datai)\n        Sw += Swi\n    # between_class scatter matrix\n    SB = np.zeros((train_data.shape[1], train_data.shape[1]))\n    u = train_data.mean(0)  # 所有样本的平均值\n    for i in clusters:\n        Ni = train_data[train_target[:] == i].shape[0]\n        ui = train_data[train_target[:] == i].mean(0)  # 某个类别的平均值\n        SBi = Ni * np.mat(ui - u).T * np.mat(ui - u)\n        SB += SBi\n    Sw = Sw + np.exp(-1) * np.eye(Sw.shape[0])\n    S = np.linalg.pinv(Sw).dot(SB)\n    eigVals, eigVects = np.linalg.eig(S)  # 求特征值，特征向量\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[:(-n_dim - 1):-1]\n    w = eigVects[:, eigValInd]\n    data_ndim = np.dot(data, w)\n    return data_ndim.real\n\n\ndef Fisherfaces(data, train_data, train_label, component):\n    n = train_data.shape[0]\n    c = len(np.unique(train_label))\n    pca = PCA(n_components=n - c)\n    pca.fit(train_data)\n    data_train_pca = pca.transform(train_data)\n    data_pca = pca.transform(data)\n    data_fld = LDA(data, train_data, train_label, component)\n    return data_fld\n```\n\n# 总结\n\nTPAMI的那篇文章对2007年及之前的降维算法进行了总结，还是比较到位。\n\n","source":"_posts/子空间学习(5)-GE.md","raw":"---\ntitle: 子空间学习(5)-GE\ncatalog: true\ndate: 2022-01-15 12:24:17\nsubtitle: Subspace Learning-GE\ntop: 12\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Graph Embedding and Extensions-A General Framework for Dimensionality Reduction（2007 TPAMI）**，Semi-supervised Discriminant Analysis（2005 CVPR），Kernel eigenfaces vs. kernel fisherfaces- Face recognition using kernel methods（2002）。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Eigenfaces，Fisherfaces，Kernel Trick和SDA。\n\n# 摘要：\n\n在过去的几十年里，出现了一大类算法，有监督的或无监督的，源于统计学或几何理论——旨在为降维问题提供不同的解决方案。 尽管子空间学习算法的动机不同，但我们可以引入了一种称为图嵌入的通用公式，以将它们统一在一个通用框架内。 在图嵌入中，每个算法都可以被认为是直接图嵌入或其线性/核/张量扩展的特定内在图，该图描述了数据集的某些所需统计或几何属性，具有来自尺度归一化或惩罚项的约束。 在本报告中，我们将在数学上分析**Graph Embedding**，并在通用框架下比较先前学习的流形学习算法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Graph Embedding理解\n\n在本节中，降维算法以统一框架表示。 对于一般分类问题，模型训练的样本集表示为矩阵 $X=[x_{1},x_{2},\\cdots,x_{N}]$, $x_{i}\\in \\mathcal {R}^{m}$，其中 $N$ 是样本数，$m$ 是特征维度。 进一步，样本集的低维表示为 $\\textbf{y}=[y_{1},y_{2},\\cdots,y_{N}]^{T}$，其中 $y_{i} $ 是顶点 $x_{i}$ 的低维表示。\n\n对于监督学习问题，假设样本$x_{i}$的类标签为$c_{i}=\\{1,2,\\cdots,N_{c}\\}$，其中$N_{c} $ 是类的数量。 我们还让 $\\phi_{c}$ 和 $n_{c}$ 分别表示属于 $c_{th}$ 类的索引集和样本数量。\n\n## Graph\n\n令 $G=\\{X,W\\}$ 是一个无向加权图，其顶点集为 $X$，相似矩阵为 $W\\in \\mathcal{R}^{N\\times N}$。 对于一对顶点，实对称矩阵 $W$ 的每个元素测量其相似度，该相似度可能为负。\n\n在这项工作中，图$G$ 的图嵌入被定义为一种算法，以找到$G$ 顶点之间所需的低维向量关系，同时这种低维向量关系最能表征$G$ 中顶点对之间相似关系。\n\n## Embedding\n\n降维的基本任务是找到一个称为“嵌入”的映射函数 $\\phi$，\n$$\n\\begin{equation}\n    \\Phi:\\mathcal{R}^{m}\\rightarrow F,\\ X \\mapsto \\textbf{y},\n\\end{equation}\n$$\n它将 $x\\in \\mathcal{R}^{m}$ 转换为所需的低维表示 $\\textbf{y}\\in R^{\\prime}$，通常为 $m\\gg m^{\\prime }$。 $F$ 指的是特征空间，嵌入$\\Phi$ 在不同情况下可以是显式或隐式、线性或非线性的。\n\n## 框架下的目标函数\n\nGraph-preserving criterion的目标函数是公式(1)：\n$$\n\\begin{equation}\n    y^{*}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\sum_{i \\neq j}\\left\\|y_{i}-y_{j}\\right\\|^{2} W_{i j}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\textbf{y}^{T} L \\textbf{y}\n\\end{equation}\\tag{1}\n$$\n其中 $d$ 是一个常数，$B$ 是为避免目标函数的平凡解而定义的约束矩阵。 $B$ 通常是用于尺度归一化的对角矩阵，也可能是惩罚图的拉普拉斯矩阵。 即$B=L=D-W$，其中$D$为对角矩阵定义为$D_{ii}=\\sum_{j}W_{ij}, {\\forall} i$。 此外，约束 $\\textbf{y}^{T} B \\textbf{y}=d$ 用于尺度归一化。\n\n## 为什么LLE，LE，NPE和LPP属于GE框架\n\n流形具有局部结构和局部不变性，局部结构可以用图嵌入来表示（LLE，LE，NPE和LPP都利用了局部不变性）。 更具体地说，根据流形的定义，我们可以知道流形中的每一个点$X_{a}$在欧几里得空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$ ，见公式：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}\n$$\n其中 $W_{a}$ 是不变的。\n\n## 框架下的分类和总结\n\n| Group           | Algorithm                           |\n| --------------- | ----------------------------------- |\n| Full supervised | LDA, KLDA, NPE                      |\n| Semi-supervised | SDA                                 |\n| Un-supervised   | PCA, LLE, LE, LPP, NPE, Isomap, MDS |\n\n<img src=\"子空间学习(5)-GE\\com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\" />\n\n# Kernel Eigenfaces and Kernel Fisherfaces\n\nEigenfaces和Fisherfaces算法见一下篇博客：子空间学习(6)-LDE。\n\n## 动机\n\nKernel Eigenfaces 旨在找到在非线性映射 $\\Phi$ 之后最大化特征空间方差的投影方向，而 Kernel Fisherfaces 通过最小化类内数据点距离和类间数据点距离之间的比率来搜索最有效的区分方向。即Kernel Eigenfaces是在<u>PCA</u>的基础上使用了核函数，Kernel Fisherfaces是在<u>LDA和PCA</u>的基础上使用了核函数。\n\n## 目标函数\n\nKernel Eigenfaces 和 Kernel Fisherfaces 的目标函数根据它们的动机不同，我们假设每个数据点 $x_{i}$ 从输入空间 $\\mathcal{R}^{m}$ 投影到特征空间 $\\mathcal {R}^{m^{\\prime}}$ ，其中非线性映射函数是：$\\Phi: \\mathcal{R}^{m}\\rightarrow \\mathcal{R}^{m^{\\prime}}$， $m<m^{\\prime}$。Eigenfaces 和 Fisherfaces中的一些计算矩阵将由：$w^{\\Phi}$、$C^{\\Phi}$、$S^{\\Phi}$ 和 $W^{\\Phi}$ 表示，它们都与 $\\Phi(x_{1} ),\\Phi(x_{2}),\\cdots,\\Phi(x_{m})$相关的。\n\nKernel Eigenfaces的目标函数是：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    W^{\\Phi}=\\underset{(w^{\\Phi})^{T}w^{\\Phi}=1}{\\arg \\min} (w^{\\Phi})^{T}C^{\\Phi}w^{\\Phi} \\ \\ with\\\\\n    C^{\\Phi}=\\frac{1}{N}\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x}))(\\Phi(x_{i})-\\Phi(\\bar{x})^{T}.\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $C^{\\Phi}$ 是协方差矩阵，$\\Phi(\\bar{x})$ 是特征空间中所有样本的均值。\n\nKernel Fisherfaces的目标函数是最大化特征空间中类间方差$S_{B}$和类内方差$S_{W}$的比率：\n$$\n\\begin{equation}\n    \\begin{aligned}\n    W^{\\Phi} &=\\arg \\max _{W^{\\Phi}} \\frac{\\left|\\left(W^{\\Phi}\\right)^{T} S_{B}^{\\Phi} W^{\\Phi}\\right|}{\\left|\\left(W^{\\Phi}\\right)^{T} S_{W}^{\\Phi} W^{\\Phi}\\right|}=[w_{1}^{\\Phi},\\cdots,w_{m}^{\\Phi}]\\\\\n    S_{W}&=\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})^{T}\\\\\n    S_{B}&=\\sum_{c=1}^{N_{c}}n_{c}(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))^{T}.\n    \\end{aligned}\n\\end{equation}\\tag{3}\n$$\n其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}^{c_{i}}$ 是 $c_{th}$ 类第$i_{th}$个样本。\n\n## 监督方式\n\nKernel Eigenfaces 是一种无监督的降维算法，而 Kernel Fisherfaces 是有监督的。 Kernel Fisherfaces最多只能将维数降到类别数减1。但是Kernel Fisherfaces也可以用于分类，而Kernel Eigenfaces不能。\n\n# 核函数（Kernel Trick）\n\n通过使用核函数，Kernel Eigenfaces是Eigenfaces的非线性推广。 Eigenfaces的基本思想是将数据沿最大方差的方向进行线性投影。 将线性投影方法扩展到非线性情况的一种技术是直接利用核技巧。\n\n## 核函数的优势\n\n- 内核技巧使算法不需要显式计算高维空间中的表示，而只需要在投影到的子空间中计算它。\n- 通过使用不同内核的可能性，它包含了可以使用的相当普遍的非线性类别。\n- 与Eigenfaces相比，非线性主成分比相应数量的线性主成分提供了更好的识别率，并且可以通过使用比线性情况下更多的成分来提高非线性成分的性能。\n- 与其他非线性特征提取技术相比，核方法不需要非线性优化，只需要求解一个特征值问题。\n\n## 核函数的限制\n\n- 与神经方法相比，如果我们需要处理大量的观察，内核技巧可能是不利的，因为这会导致一个大矩阵 $K$。\n- 与Eigenfaces相比，内核技巧在输入空间中更难解释。 然而，至少对于多项式核，它在高阶特征方面有非常清晰的解释。\n\n## SDA\n\nSDA 是 LDA 的半监督形式，它额外包含graphical perspective（图嵌入化），linearization（线性化）和kernel trick（核函数）。 这里主要谈一下SDA相对LDA的一些不同。核函数之前在Kernel Fisherfaces已经解释过了，就不提了。\n\n## 监督方式\n\nLDA是一种全监督降维方法，而SDA是一种半监督方法，有标签的数据用于最大化不同类别之间的可分离性，没有标签的数据点用于估计数据的内在几何结构。\n\n## 图嵌入形式\n\n假设映射方向 $w=\\sum_{i}\\alpha_{i}\\Phi(x_{i})$ 和 $K$ 是核 Gram 矩阵，其中 $K_{ij}=\\Phi(x_{i} )\\Phi(x_{j})$，LDA 的目标函数可以转换为graphical perspective，其中类内和类间方差可以通过矩阵的线性变换来表示，见公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\textbf{a}_{opt}=\\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}S_{b}\\textbf{a}}{\\textbf{a}^{T}S_{t}\\textbf{a}}=  \\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}XW_{l\\times l}X^{T}\\textbf{a}}{\\textbf{a}^{T}XX^{T}\\textbf{a}} \\\\\n    S_{b}=\\sum^{c}_{k=1}X^{(k)}W^{k}(X^{k})^{T}=XW_{l\\times l}X^{T} \\\\\n    S_{t}=\\sum_{i=1}^{l}(x_{i}-\\mu)(x_{i}-\\mu)^{T}=XX^{T}\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $W^{(k)}$ 是一个 $l_{k}\\times l_{k}$ 矩阵，其中所有元素都等于 $1/l_{k}$ ，并且 $X^{(k)}=[x_ {1}^{(k)},\\cdots,x_{lk}^{(k)}]$表示$k_{th}$类的数据矩阵。 和数据矩阵 $X=[X^{(1)},\\cdots,X^{(c)}]$ 并定义 $l\\times l$ 矩阵 $W_{l\\times l}$ 为：\n$$\nW_{l \\times l}=\\left[\\begin{array}{cccc}\nW^{(1)} & 0 & \\cdots & 0 \\\\\n0 & W^{(2)} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & W^{(c)}\n\\end{array}\\right].\n$$\n\n## 线性化\n\n假设顶点的低维向量表示可以从线性投影中获得，如 $y=\\textbf{a}^{T}x$，其中$\\textbf{a}$是投影向量，目标函数修改为公式(5)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\mathbf{a}_{o p t}=\\arg \\max _{\\mathbf{a}} \\frac{\\mathbf{a}^{T} S_{b} \\mathbf{a}}{\\mathbf{a}^{T} S_{w} \\mathbf{a}}, \\\\\n        S_{b}=\\sum_{k=1}^{c} l_{k}\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)^{T}, \\\\\n        S_{w}=\\sum_{k=1}^{c}\\left(\\sum_{i=1}^{l_{k}}\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)^{T}\\right),\n    \\end{gathered}\n\\end{equation}\\tag{5}\n$$\n\n# 代码\n\n贴一下Fisherfaces的代码，Eigenfaces是PCA的具体实现也就不贴了，同时呢，Sklearn也有自己的库可以直接使用LDA：\n\n```python\nfrom sklearn.decomposition import PCA\nimport numpy as np\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis #sklearn的库，这里未使用\n\ndef LDA(data, train_data, train_target, n_dim):\n    clusters = np.unique(train_target)\n    # within_class scatter matrix\n    Sw = np.zeros((train_data.shape[1], train_data.shape[1]))\n    for i in clusters:\n        train_datai = train_data[train_target[:] == i]\n        train_datai = train_datai - train_datai.mean(0)\n        Swi = np.mat(train_datai).T * np.mat(train_datai)\n        Sw += Swi\n    # between_class scatter matrix\n    SB = np.zeros((train_data.shape[1], train_data.shape[1]))\n    u = train_data.mean(0)  # 所有样本的平均值\n    for i in clusters:\n        Ni = train_data[train_target[:] == i].shape[0]\n        ui = train_data[train_target[:] == i].mean(0)  # 某个类别的平均值\n        SBi = Ni * np.mat(ui - u).T * np.mat(ui - u)\n        SB += SBi\n    Sw = Sw + np.exp(-1) * np.eye(Sw.shape[0])\n    S = np.linalg.pinv(Sw).dot(SB)\n    eigVals, eigVects = np.linalg.eig(S)  # 求特征值，特征向量\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[:(-n_dim - 1):-1]\n    w = eigVects[:, eigValInd]\n    data_ndim = np.dot(data, w)\n    return data_ndim.real\n\n\ndef Fisherfaces(data, train_data, train_label, component):\n    n = train_data.shape[0]\n    c = len(np.unique(train_label))\n    pca = PCA(n_components=n - c)\n    pca.fit(train_data)\n    data_train_pca = pca.transform(train_data)\n    data_pca = pca.transform(data)\n    data_fld = LDA(data, train_data, train_label, component)\n    return data_fld\n```\n\n# 总结\n\nTPAMI的那篇文章对2007年及之前的降维算法进行了总结，还是比较到位。\n\n","slug":"子空间学习(5)-GE","published":1,"updated":"2022-01-14T07:29:50.242Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxx6000w3oue4jfqhf3z","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Graph Embedding and Extensions-A General Framework for Dimensionality Reduction（2007 TPAMI）</strong>，Semi-supervised Discriminant Analysis（2005 CVPR），Kernel eigenfaces vs. kernel fisherfaces- Face recognition using kernel methods（2002）。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Eigenfaces，Fisherfaces，Kernel Trick和SDA。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>在过去的几十年里，出现了一大类算法，有监督的或无监督的，源于统计学或几何理论——旨在为降维问题提供不同的解决方案。 尽管子空间学习算法的动机不同，但我们可以引入了一种称为图嵌入的通用公式，以将它们统一在一个通用框架内。 在图嵌入中，每个算法都可以被认为是直接图嵌入或其线性/核/张量扩展的特定内在图，该图描述了数据集的某些所需统计或几何属性，具有来自尺度归一化或惩罚项的约束。 在本报告中，我们将在数学上分析<strong>Graph Embedding</strong>，并在通用框架下比较先前学习的流形学习算法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Graph-Embedding理解\"><a href=\"#Graph-Embedding理解\" class=\"headerlink\" title=\"Graph Embedding理解\"></a>Graph Embedding理解</h1><p>在本节中，降维算法以统一框架表示。 对于一般分类问题，模型训练的样本集表示为矩阵 $X=[x_{1},x_{2},\\cdots,x_{N}]$, $x_{i}\\in \\mathcal {R}^{m}$，其中 $N$ 是样本数，$m$ 是特征维度。 进一步，样本集的低维表示为 $\\textbf{y}=[y_{1},y_{2},\\cdots,y_{N}]^{T}$，其中 $y_{i} $ 是顶点 $x_{i}$ 的低维表示。</p>\n<p>对于监督学习问题，假设样本$x_{i}$的类标签为$c_{i}=\\{1,2,\\cdots,N_{c}\\}$，其中$N_{c} $ 是类的数量。 我们还让 $\\phi_{c}$ 和 $n_{c}$ 分别表示属于 $c_{th}$ 类的索引集和样本数量。</p>\n<h2 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h2><p>令 $G=\\{X,W\\}$ 是一个无向加权图，其顶点集为 $X$，相似矩阵为 $W\\in \\mathcal{R}^{N\\times N}$。 对于一对顶点，实对称矩阵 $W$ 的每个元素测量其相似度，该相似度可能为负。</p>\n<p>在这项工作中，图$G$ 的图嵌入被定义为一种算法，以找到$G$ 顶点之间所需的低维向量关系，同时这种低维向量关系最能表征$G$ 中顶点对之间相似关系。</p>\n<h2 id=\"Embedding\"><a href=\"#Embedding\" class=\"headerlink\" title=\"Embedding\"></a>Embedding</h2><p>降维的基本任务是找到一个称为“嵌入”的映射函数 $\\phi$，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\Phi:\\mathcal{R}^{m}\\rightarrow F,\\ X \\mapsto \\textbf{y},\n\\end{equation}</script><p>它将 $x\\in \\mathcal{R}^{m}$ 转换为所需的低维表示 $\\textbf{y}\\in R^{\\prime}$，通常为 $m\\gg m^{\\prime }$。 $F$ 指的是特征空间，嵌入$\\Phi$ 在不同情况下可以是显式或隐式、线性或非线性的。</p>\n<h2 id=\"框架下的目标函数\"><a href=\"#框架下的目标函数\" class=\"headerlink\" title=\"框架下的目标函数\"></a>框架下的目标函数</h2><p>Graph-preserving criterion的目标函数是公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    y^{*}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\sum_{i \\neq j}\\left\\|y_{i}-y_{j}\\right\\|^{2} W_{i j}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\textbf{y}^{T} L \\textbf{y}\n\\end{equation}\\tag{1}</script><p>其中 $d$ 是一个常数，$B$ 是为避免目标函数的平凡解而定义的约束矩阵。 $B$ 通常是用于尺度归一化的对角矩阵，也可能是惩罚图的拉普拉斯矩阵。 即$B=L=D-W$，其中$D$为对角矩阵定义为$D_{ii}=\\sum_{j}W_{ij}, {\\forall} i$。 此外，约束 $\\textbf{y}^{T} B \\textbf{y}=d$ 用于尺度归一化。</p>\n<h2 id=\"为什么LLE，LE，NPE和LPP属于GE框架\"><a href=\"#为什么LLE，LE，NPE和LPP属于GE框架\" class=\"headerlink\" title=\"为什么LLE，LE，NPE和LPP属于GE框架\"></a>为什么LLE，LE，NPE和LPP属于GE框架</h2><p>流形具有局部结构和局部不变性，局部结构可以用图嵌入来表示（LLE，LE，NPE和LPP都利用了局部不变性）。 更具体地说，根据流形的定义，我们可以知道流形中的每一个点$X_{a}$在欧几里得空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$ ，见公式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}</script><p>其中 $W_{a}$ 是不变的。</p>\n<h2 id=\"框架下的分类和总结\"><a href=\"#框架下的分类和总结\" class=\"headerlink\" title=\"框架下的分类和总结\"></a>框架下的分类和总结</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Group</th>\n<th>Algorithm</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Full supervised</td>\n<td>LDA, KLDA, NPE</td>\n</tr>\n<tr>\n<td>Semi-supervised</td>\n<td>SDA</td>\n</tr>\n<tr>\n<td>Un-supervised</td>\n<td>PCA, LLE, LE, LPP, NPE, Isomap, MDS</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><img src=\"/2022/01/15/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(5)-GE/com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<h1 id=\"Kernel-Eigenfaces-and-Kernel-Fisherfaces\"><a href=\"#Kernel-Eigenfaces-and-Kernel-Fisherfaces\" class=\"headerlink\" title=\"Kernel Eigenfaces and Kernel Fisherfaces\"></a>Kernel Eigenfaces and Kernel Fisherfaces</h1><p>Eigenfaces和Fisherfaces算法见一下篇博客：子空间学习(6)-LDE。</p>\n<h2 id=\"动机\"><a href=\"#动机\" class=\"headerlink\" title=\"动机\"></a>动机</h2><p>Kernel Eigenfaces 旨在找到在非线性映射 $\\Phi$ 之后最大化特征空间方差的投影方向，而 Kernel Fisherfaces 通过最小化类内数据点距离和类间数据点距离之间的比率来搜索最有效的区分方向。即Kernel Eigenfaces是在<u>PCA</u>的基础上使用了核函数，Kernel Fisherfaces是在<u>LDA和PCA</u>的基础上使用了核函数。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>Kernel Eigenfaces 和 Kernel Fisherfaces 的目标函数根据它们的动机不同，我们假设每个数据点 $x_{i}$ 从输入空间 $\\mathcal{R}^{m}$ 投影到特征空间 $\\mathcal {R}^{m^{\\prime}}$ ，其中非线性映射函数是：$\\Phi: \\mathcal{R}^{m}\\rightarrow \\mathcal{R}^{m^{\\prime}}$， $m&lt;m^{\\prime}$。Eigenfaces 和 Fisherfaces中的一些计算矩阵将由：$w^{\\Phi}$、$C^{\\Phi}$、$S^{\\Phi}$ 和 $W^{\\Phi}$ 表示，它们都与 $\\Phi(x_{1} ),\\Phi(x_{2}),\\cdots,\\Phi(x_{m})$相关的。</p>\n<p>Kernel Eigenfaces的目标函数是：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    W^{\\Phi}=\\underset{(w^{\\Phi})^{T}w^{\\Phi}=1}{\\arg \\min} (w^{\\Phi})^{T}C^{\\Phi}w^{\\Phi} \\ \\ with\\\\\n    C^{\\Phi}=\\frac{1}{N}\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x}))(\\Phi(x_{i})-\\Phi(\\bar{x})^{T}.\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $C^{\\Phi}$ 是协方差矩阵，$\\Phi(\\bar{x})$ 是特征空间中所有样本的均值。</p>\n<p>Kernel Fisherfaces的目标函数是最大化特征空间中类间方差$S_{B}$和类内方差$S_{W}$的比率：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n    W^{\\Phi} &=\\arg \\max _{W^{\\Phi}} \\frac{\\left|\\left(W^{\\Phi}\\right)^{T} S_{B}^{\\Phi} W^{\\Phi}\\right|}{\\left|\\left(W^{\\Phi}\\right)^{T} S_{W}^{\\Phi} W^{\\Phi}\\right|}=[w_{1}^{\\Phi},\\cdots,w_{m}^{\\Phi}]\\\\\n    S_{W}&=\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})^{T}\\\\\n    S_{B}&=\\sum_{c=1}^{N_{c}}n_{c}(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))^{T}.\n    \\end{aligned}\n\\end{equation}\\tag{3}</script><p>其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}^{c_{i}}$ 是 $c_{th}$ 类第$i_{th}$个样本。</p>\n<h2 id=\"监督方式\"><a href=\"#监督方式\" class=\"headerlink\" title=\"监督方式\"></a>监督方式</h2><p>Kernel Eigenfaces 是一种无监督的降维算法，而 Kernel Fisherfaces 是有监督的。 Kernel Fisherfaces最多只能将维数降到类别数减1。但是Kernel Fisherfaces也可以用于分类，而Kernel Eigenfaces不能。</p>\n<h1 id=\"核函数（Kernel-Trick）\"><a href=\"#核函数（Kernel-Trick）\" class=\"headerlink\" title=\"核函数（Kernel Trick）\"></a>核函数（Kernel Trick）</h1><p>通过使用核函数，Kernel Eigenfaces是Eigenfaces的非线性推广。 Eigenfaces的基本思想是将数据沿最大方差的方向进行线性投影。 将线性投影方法扩展到非线性情况的一种技术是直接利用核技巧。</p>\n<h2 id=\"核函数的优势\"><a href=\"#核函数的优势\" class=\"headerlink\" title=\"核函数的优势\"></a>核函数的优势</h2><ul>\n<li>内核技巧使算法不需要显式计算高维空间中的表示，而只需要在投影到的子空间中计算它。</li>\n<li>通过使用不同内核的可能性，它包含了可以使用的相当普遍的非线性类别。</li>\n<li>与Eigenfaces相比，非线性主成分比相应数量的线性主成分提供了更好的识别率，并且可以通过使用比线性情况下更多的成分来提高非线性成分的性能。</li>\n<li>与其他非线性特征提取技术相比，核方法不需要非线性优化，只需要求解一个特征值问题。</li>\n</ul>\n<h2 id=\"核函数的限制\"><a href=\"#核函数的限制\" class=\"headerlink\" title=\"核函数的限制\"></a>核函数的限制</h2><ul>\n<li>与神经方法相比，如果我们需要处理大量的观察，内核技巧可能是不利的，因为这会导致一个大矩阵 $K$。</li>\n<li>与Eigenfaces相比，内核技巧在输入空间中更难解释。 然而，至少对于多项式核，它在高阶特征方面有非常清晰的解释。</li>\n</ul>\n<h2 id=\"SDA\"><a href=\"#SDA\" class=\"headerlink\" title=\"SDA\"></a>SDA</h2><p>SDA 是 LDA 的半监督形式，它额外包含graphical perspective（图嵌入化），linearization（线性化）和kernel trick（核函数）。 这里主要谈一下SDA相对LDA的一些不同。核函数之前在Kernel Fisherfaces已经解释过了，就不提了。</p>\n<h2 id=\"监督方式-1\"><a href=\"#监督方式-1\" class=\"headerlink\" title=\"监督方式\"></a>监督方式</h2><p>LDA是一种全监督降维方法，而SDA是一种半监督方法，有标签的数据用于最大化不同类别之间的可分离性，没有标签的数据点用于估计数据的内在几何结构。</p>\n<h2 id=\"图嵌入形式\"><a href=\"#图嵌入形式\" class=\"headerlink\" title=\"图嵌入形式\"></a>图嵌入形式</h2><p>假设映射方向 $w=\\sum_{i}\\alpha_{i}\\Phi(x_{i})$ 和 $K$ 是核 Gram 矩阵，其中 $K_{ij}=\\Phi(x_{i} )\\Phi(x_{j})$，LDA 的目标函数可以转换为graphical perspective，其中类内和类间方差可以通过矩阵的线性变换来表示，见公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\textbf{a}_{opt}=\\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}S_{b}\\textbf{a}}{\\textbf{a}^{T}S_{t}\\textbf{a}}=  \\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}XW_{l\\times l}X^{T}\\textbf{a}}{\\textbf{a}^{T}XX^{T}\\textbf{a}} \\\\\n    S_{b}=\\sum^{c}_{k=1}X^{(k)}W^{k}(X^{k})^{T}=XW_{l\\times l}X^{T} \\\\\n    S_{t}=\\sum_{i=1}^{l}(x_{i}-\\mu)(x_{i}-\\mu)^{T}=XX^{T}\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $W^{(k)}$ 是一个 $l_{k}\\times l_{k}$ 矩阵，其中所有元素都等于 $1/l_{k}$ ，并且 $X^{(k)}=[x_ {1}^{(k)},\\cdots,x_{lk}^{(k)}]$表示$k_{th}$类的数据矩阵。 和数据矩阵 $X=[X^{(1)},\\cdots,X^{(c)}]$ 并定义 $l\\times l$ 矩阵 $W_{l\\times l}$ 为：</p>\n<script type=\"math/tex; mode=display\">\nW_{l \\times l}=\\left[\\begin{array}{cccc}\nW^{(1)} & 0 & \\cdots & 0 \\\\\n0 & W^{(2)} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & W^{(c)}\n\\end{array}\\right].</script><h2 id=\"线性化\"><a href=\"#线性化\" class=\"headerlink\" title=\"线性化\"></a>线性化</h2><p>假设顶点的低维向量表示可以从线性投影中获得，如 $y=\\textbf{a}^{T}x$，其中$\\textbf{a}$是投影向量，目标函数修改为公式(5)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\mathbf{a}_{o p t}=\\arg \\max _{\\mathbf{a}} \\frac{\\mathbf{a}^{T} S_{b} \\mathbf{a}}{\\mathbf{a}^{T} S_{w} \\mathbf{a}}, \\\\\n        S_{b}=\\sum_{k=1}^{c} l_{k}\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)^{T}, \\\\\n        S_{w}=\\sum_{k=1}^{c}\\left(\\sum_{i=1}^{l_{k}}\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)^{T}\\right),\n    \\end{gathered}\n\\end{equation}\\tag{5}</script><h1 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h1><p>贴一下Fisherfaces的代码，Eigenfaces是PCA的具体实现也就不贴了，同时呢，Sklearn也有自己的库可以直接使用LDA：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.discriminant_analysis <span class=\"keyword\">import</span> LinearDiscriminantAnalysis <span class=\"comment\">#sklearn的库，这里未使用</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LDA</span>(<span class=\"params\">data, train_data, train_target, n_dim</span>):</span></span><br><span class=\"line\">    clusters = np.unique(train_target)</span><br><span class=\"line\">    <span class=\"comment\"># within_class scatter matrix</span></span><br><span class=\"line\">    Sw = np.zeros((train_data.shape[<span class=\"number\">1</span>], train_data.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        train_datai = train_data[train_target[:] == i]</span><br><span class=\"line\">        train_datai = train_datai - train_datai.mean(<span class=\"number\">0</span>)</span><br><span class=\"line\">        Swi = np.mat(train_datai).T * np.mat(train_datai)</span><br><span class=\"line\">        Sw += Swi</span><br><span class=\"line\">    <span class=\"comment\"># between_class scatter matrix</span></span><br><span class=\"line\">    SB = np.zeros((train_data.shape[<span class=\"number\">1</span>], train_data.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    u = train_data.mean(<span class=\"number\">0</span>)  <span class=\"comment\"># 所有样本的平均值</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        Ni = train_data[train_target[:] == i].shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">        ui = train_data[train_target[:] == i].mean(<span class=\"number\">0</span>)  <span class=\"comment\"># 某个类别的平均值</span></span><br><span class=\"line\">        SBi = Ni * np.mat(ui - u).T * np.mat(ui - u)</span><br><span class=\"line\">        SB += SBi</span><br><span class=\"line\">    Sw = Sw + np.exp(-<span class=\"number\">1</span>) * np.eye(Sw.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    S = np.linalg.pinv(Sw).dot(SB)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eig(S)  <span class=\"comment\"># 求特征值，特征向量</span></span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[:(-n_dim - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    data_ndim = np.dot(data, w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_ndim.real</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Fisherfaces</span>(<span class=\"params\">data, train_data, train_label, component</span>):</span></span><br><span class=\"line\">    n = train_data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    c = <span class=\"built_in\">len</span>(np.unique(train_label))</span><br><span class=\"line\">    pca = PCA(n_components=n - c)</span><br><span class=\"line\">    pca.fit(train_data)</span><br><span class=\"line\">    data_train_pca = pca.transform(train_data)</span><br><span class=\"line\">    data_pca = pca.transform(data)</span><br><span class=\"line\">    data_fld = LDA(data, train_data, train_label, component)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_fld</span><br></pre></td></tr></table></figure>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>TPAMI的那篇文章对2007年及之前的降维算法进行了总结，还是比较到位。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Graph Embedding and Extensions-A General Framework for Dimensionality Reduction（2007 TPAMI）</strong>，Semi-supervised Discriminant Analysis（2005 CVPR），Kernel eigenfaces vs. kernel fisherfaces- Face recognition using kernel methods（2002）。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Eigenfaces，Fisherfaces，Kernel Trick和SDA。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>在过去的几十年里，出现了一大类算法，有监督的或无监督的，源于统计学或几何理论——旨在为降维问题提供不同的解决方案。 尽管子空间学习算法的动机不同，但我们可以引入了一种称为图嵌入的通用公式，以将它们统一在一个通用框架内。 在图嵌入中，每个算法都可以被认为是直接图嵌入或其线性/核/张量扩展的特定内在图，该图描述了数据集的某些所需统计或几何属性，具有来自尺度归一化或惩罚项的约束。 在本报告中，我们将在数学上分析<strong>Graph Embedding</strong>，并在通用框架下比较先前学习的流形学习算法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Graph-Embedding理解\"><a href=\"#Graph-Embedding理解\" class=\"headerlink\" title=\"Graph Embedding理解\"></a>Graph Embedding理解</h1><p>在本节中，降维算法以统一框架表示。 对于一般分类问题，模型训练的样本集表示为矩阵 $X=[x_{1},x_{2},\\cdots,x_{N}]$, $x_{i}\\in \\mathcal {R}^{m}$，其中 $N$ 是样本数，$m$ 是特征维度。 进一步，样本集的低维表示为 $\\textbf{y}=[y_{1},y_{2},\\cdots,y_{N}]^{T}$，其中 $y_{i} $ 是顶点 $x_{i}$ 的低维表示。</p>\n<p>对于监督学习问题，假设样本$x_{i}$的类标签为$c_{i}=\\{1,2,\\cdots,N_{c}\\}$，其中$N_{c} $ 是类的数量。 我们还让 $\\phi_{c}$ 和 $n_{c}$ 分别表示属于 $c_{th}$ 类的索引集和样本数量。</p>\n<h2 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h2><p>令 $G=\\{X,W\\}$ 是一个无向加权图，其顶点集为 $X$，相似矩阵为 $W\\in \\mathcal{R}^{N\\times N}$。 对于一对顶点，实对称矩阵 $W$ 的每个元素测量其相似度，该相似度可能为负。</p>\n<p>在这项工作中，图$G$ 的图嵌入被定义为一种算法，以找到$G$ 顶点之间所需的低维向量关系，同时这种低维向量关系最能表征$G$ 中顶点对之间相似关系。</p>\n<h2 id=\"Embedding\"><a href=\"#Embedding\" class=\"headerlink\" title=\"Embedding\"></a>Embedding</h2><p>降维的基本任务是找到一个称为“嵌入”的映射函数 $\\phi$，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\Phi:\\mathcal{R}^{m}\\rightarrow F,\\ X \\mapsto \\textbf{y},\n\\end{equation}</script><p>它将 $x\\in \\mathcal{R}^{m}$ 转换为所需的低维表示 $\\textbf{y}\\in R^{\\prime}$，通常为 $m\\gg m^{\\prime }$。 $F$ 指的是特征空间，嵌入$\\Phi$ 在不同情况下可以是显式或隐式、线性或非线性的。</p>\n<h2 id=\"框架下的目标函数\"><a href=\"#框架下的目标函数\" class=\"headerlink\" title=\"框架下的目标函数\"></a>框架下的目标函数</h2><p>Graph-preserving criterion的目标函数是公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    y^{*}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\sum_{i \\neq j}\\left\\|y_{i}-y_{j}\\right\\|^{2} W_{i j}=\\arg \\min _{\\textbf{y}^{T} B \\textbf{y}=d} \\textbf{y}^{T} L \\textbf{y}\n\\end{equation}\\tag{1}</script><p>其中 $d$ 是一个常数，$B$ 是为避免目标函数的平凡解而定义的约束矩阵。 $B$ 通常是用于尺度归一化的对角矩阵，也可能是惩罚图的拉普拉斯矩阵。 即$B=L=D-W$，其中$D$为对角矩阵定义为$D_{ii}=\\sum_{j}W_{ij}, {\\forall} i$。 此外，约束 $\\textbf{y}^{T} B \\textbf{y}=d$ 用于尺度归一化。</p>\n<h2 id=\"为什么LLE，LE，NPE和LPP属于GE框架\"><a href=\"#为什么LLE，LE，NPE和LPP属于GE框架\" class=\"headerlink\" title=\"为什么LLE，LE，NPE和LPP属于GE框架\"></a>为什么LLE，LE，NPE和LPP属于GE框架</h2><p>流形具有局部结构和局部不变性，局部结构可以用图嵌入来表示（LLE，LE，NPE和LPP都利用了局部不变性）。 更具体地说，根据流形的定义，我们可以知道流形中的每一个点$X_{a}$在欧几里得空间中都有一个邻域$X_{U(a)}$同胚的开集$W_{a}$ ，见公式：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\forall X_{a} \\ \\exists X_{U(a)} : \\ f(X_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}) \\\\\n        \\forall Y_{a} \\ \\exists Y_{U(a)} : \\ f(Y_{U(a)})\\rightarrow W_{a} \\ (W_{a} \\subseteq \\mathbb{R}^{n}),\n    \\end{gathered}\n\\end{equation}</script><p>其中 $W_{a}$ 是不变的。</p>\n<h2 id=\"框架下的分类和总结\"><a href=\"#框架下的分类和总结\" class=\"headerlink\" title=\"框架下的分类和总结\"></a>框架下的分类和总结</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Group</th>\n<th>Algorithm</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Full supervised</td>\n<td>LDA, KLDA, NPE</td>\n</tr>\n<tr>\n<td>Semi-supervised</td>\n<td>SDA</td>\n</tr>\n<tr>\n<td>Un-supervised</td>\n<td>PCA, LLE, LE, LPP, NPE, Isomap, MDS</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><img src=\"/2022/01/15/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(5)-GE/com.png\" alt=\"LLE-Val\" style=\"zoom:72%;\"></p>\n<h1 id=\"Kernel-Eigenfaces-and-Kernel-Fisherfaces\"><a href=\"#Kernel-Eigenfaces-and-Kernel-Fisherfaces\" class=\"headerlink\" title=\"Kernel Eigenfaces and Kernel Fisherfaces\"></a>Kernel Eigenfaces and Kernel Fisherfaces</h1><p>Eigenfaces和Fisherfaces算法见一下篇博客：子空间学习(6)-LDE。</p>\n<h2 id=\"动机\"><a href=\"#动机\" class=\"headerlink\" title=\"动机\"></a>动机</h2><p>Kernel Eigenfaces 旨在找到在非线性映射 $\\Phi$ 之后最大化特征空间方差的投影方向，而 Kernel Fisherfaces 通过最小化类内数据点距离和类间数据点距离之间的比率来搜索最有效的区分方向。即Kernel Eigenfaces是在<u>PCA</u>的基础上使用了核函数，Kernel Fisherfaces是在<u>LDA和PCA</u>的基础上使用了核函数。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>Kernel Eigenfaces 和 Kernel Fisherfaces 的目标函数根据它们的动机不同，我们假设每个数据点 $x_{i}$ 从输入空间 $\\mathcal{R}^{m}$ 投影到特征空间 $\\mathcal {R}^{m^{\\prime}}$ ，其中非线性映射函数是：$\\Phi: \\mathcal{R}^{m}\\rightarrow \\mathcal{R}^{m^{\\prime}}$， $m&lt;m^{\\prime}$。Eigenfaces 和 Fisherfaces中的一些计算矩阵将由：$w^{\\Phi}$、$C^{\\Phi}$、$S^{\\Phi}$ 和 $W^{\\Phi}$ 表示，它们都与 $\\Phi(x_{1} ),\\Phi(x_{2}),\\cdots,\\Phi(x_{m})$相关的。</p>\n<p>Kernel Eigenfaces的目标函数是：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    W^{\\Phi}=\\underset{(w^{\\Phi})^{T}w^{\\Phi}=1}{\\arg \\min} (w^{\\Phi})^{T}C^{\\Phi}w^{\\Phi} \\ \\ with\\\\\n    C^{\\Phi}=\\frac{1}{N}\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x}))(\\Phi(x_{i})-\\Phi(\\bar{x})^{T}.\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $C^{\\Phi}$ 是协方差矩阵，$\\Phi(\\bar{x})$ 是特征空间中所有样本的均值。</p>\n<p>Kernel Fisherfaces的目标函数是最大化特征空间中类间方差$S_{B}$和类内方差$S_{W}$的比率：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n    W^{\\Phi} &=\\arg \\max _{W^{\\Phi}} \\frac{\\left|\\left(W^{\\Phi}\\right)^{T} S_{B}^{\\Phi} W^{\\Phi}\\right|}{\\left|\\left(W^{\\Phi}\\right)^{T} S_{W}^{\\Phi} W^{\\Phi}\\right|}=[w_{1}^{\\Phi},\\cdots,w_{m}^{\\Phi}]\\\\\n    S_{W}&=\\sum_{i=1}^{N}(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})(\\Phi(x_{i})-\\Phi(\\bar{x})^{c_{i}})^{T}\\\\\n    S_{B}&=\\sum_{c=1}^{N_{c}}n_{c}(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))(\\Phi(\\bar{x}^{c})-\\Phi(\\bar{x}))^{T}.\n    \\end{aligned}\n\\end{equation}\\tag{3}</script><p>其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}^{c_{i}}$ 是 $c_{th}$ 类第$i_{th}$个样本。</p>\n<h2 id=\"监督方式\"><a href=\"#监督方式\" class=\"headerlink\" title=\"监督方式\"></a>监督方式</h2><p>Kernel Eigenfaces 是一种无监督的降维算法，而 Kernel Fisherfaces 是有监督的。 Kernel Fisherfaces最多只能将维数降到类别数减1。但是Kernel Fisherfaces也可以用于分类，而Kernel Eigenfaces不能。</p>\n<h1 id=\"核函数（Kernel-Trick）\"><a href=\"#核函数（Kernel-Trick）\" class=\"headerlink\" title=\"核函数（Kernel Trick）\"></a>核函数（Kernel Trick）</h1><p>通过使用核函数，Kernel Eigenfaces是Eigenfaces的非线性推广。 Eigenfaces的基本思想是将数据沿最大方差的方向进行线性投影。 将线性投影方法扩展到非线性情况的一种技术是直接利用核技巧。</p>\n<h2 id=\"核函数的优势\"><a href=\"#核函数的优势\" class=\"headerlink\" title=\"核函数的优势\"></a>核函数的优势</h2><ul>\n<li>内核技巧使算法不需要显式计算高维空间中的表示，而只需要在投影到的子空间中计算它。</li>\n<li>通过使用不同内核的可能性，它包含了可以使用的相当普遍的非线性类别。</li>\n<li>与Eigenfaces相比，非线性主成分比相应数量的线性主成分提供了更好的识别率，并且可以通过使用比线性情况下更多的成分来提高非线性成分的性能。</li>\n<li>与其他非线性特征提取技术相比，核方法不需要非线性优化，只需要求解一个特征值问题。</li>\n</ul>\n<h2 id=\"核函数的限制\"><a href=\"#核函数的限制\" class=\"headerlink\" title=\"核函数的限制\"></a>核函数的限制</h2><ul>\n<li>与神经方法相比，如果我们需要处理大量的观察，内核技巧可能是不利的，因为这会导致一个大矩阵 $K$。</li>\n<li>与Eigenfaces相比，内核技巧在输入空间中更难解释。 然而，至少对于多项式核，它在高阶特征方面有非常清晰的解释。</li>\n</ul>\n<h2 id=\"SDA\"><a href=\"#SDA\" class=\"headerlink\" title=\"SDA\"></a>SDA</h2><p>SDA 是 LDA 的半监督形式，它额外包含graphical perspective（图嵌入化），linearization（线性化）和kernel trick（核函数）。 这里主要谈一下SDA相对LDA的一些不同。核函数之前在Kernel Fisherfaces已经解释过了，就不提了。</p>\n<h2 id=\"监督方式-1\"><a href=\"#监督方式-1\" class=\"headerlink\" title=\"监督方式\"></a>监督方式</h2><p>LDA是一种全监督降维方法，而SDA是一种半监督方法，有标签的数据用于最大化不同类别之间的可分离性，没有标签的数据点用于估计数据的内在几何结构。</p>\n<h2 id=\"图嵌入形式\"><a href=\"#图嵌入形式\" class=\"headerlink\" title=\"图嵌入形式\"></a>图嵌入形式</h2><p>假设映射方向 $w=\\sum_{i}\\alpha_{i}\\Phi(x_{i})$ 和 $K$ 是核 Gram 矩阵，其中 $K_{ij}=\\Phi(x_{i} )\\Phi(x_{j})$，LDA 的目标函数可以转换为graphical perspective，其中类内和类间方差可以通过矩阵的线性变换来表示，见公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\textbf{a}_{opt}=\\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}S_{b}\\textbf{a}}{\\textbf{a}^{T}S_{t}\\textbf{a}}=  \\underset{\\textbf{a}}{\\arg \\max}\\frac{\\textbf{a}^{T}XW_{l\\times l}X^{T}\\textbf{a}}{\\textbf{a}^{T}XX^{T}\\textbf{a}} \\\\\n    S_{b}=\\sum^{c}_{k=1}X^{(k)}W^{k}(X^{k})^{T}=XW_{l\\times l}X^{T} \\\\\n    S_{t}=\\sum_{i=1}^{l}(x_{i}-\\mu)(x_{i}-\\mu)^{T}=XX^{T}\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $W^{(k)}$ 是一个 $l_{k}\\times l_{k}$ 矩阵，其中所有元素都等于 $1/l_{k}$ ，并且 $X^{(k)}=[x_ {1}^{(k)},\\cdots,x_{lk}^{(k)}]$表示$k_{th}$类的数据矩阵。 和数据矩阵 $X=[X^{(1)},\\cdots,X^{(c)}]$ 并定义 $l\\times l$ 矩阵 $W_{l\\times l}$ 为：</p>\n<script type=\"math/tex; mode=display\">\nW_{l \\times l}=\\left[\\begin{array}{cccc}\nW^{(1)} & 0 & \\cdots & 0 \\\\\n0 & W^{(2)} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & W^{(c)}\n\\end{array}\\right].</script><h2 id=\"线性化\"><a href=\"#线性化\" class=\"headerlink\" title=\"线性化\"></a>线性化</h2><p>假设顶点的低维向量表示可以从线性投影中获得，如 $y=\\textbf{a}^{T}x$，其中$\\textbf{a}$是投影向量，目标函数修改为公式(5)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\mathbf{a}_{o p t}=\\arg \\max _{\\mathbf{a}} \\frac{\\mathbf{a}^{T} S_{b} \\mathbf{a}}{\\mathbf{a}^{T} S_{w} \\mathbf{a}}, \\\\\n        S_{b}=\\sum_{k=1}^{c} l_{k}\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)\\left(\\boldsymbol{\\mu}^{(k)}-\\boldsymbol{\\mu}\\right)^{T}, \\\\\n        S_{w}=\\sum_{k=1}^{c}\\left(\\sum_{i=1}^{l_{k}}\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)\\left(\\mathbf{x}_{i}^{(k)}-\\boldsymbol{\\mu}^{(k)}\\right)^{T}\\right),\n    \\end{gathered}\n\\end{equation}\\tag{5}</script><h1 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h1><p>贴一下Fisherfaces的代码，Eigenfaces是PCA的具体实现也就不贴了，同时呢，Sklearn也有自己的库可以直接使用LDA：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.decomposition <span class=\"keyword\">import</span> PCA</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.discriminant_analysis <span class=\"keyword\">import</span> LinearDiscriminantAnalysis <span class=\"comment\">#sklearn的库，这里未使用</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LDA</span>(<span class=\"params\">data, train_data, train_target, n_dim</span>):</span></span><br><span class=\"line\">    clusters = np.unique(train_target)</span><br><span class=\"line\">    <span class=\"comment\"># within_class scatter matrix</span></span><br><span class=\"line\">    Sw = np.zeros((train_data.shape[<span class=\"number\">1</span>], train_data.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        train_datai = train_data[train_target[:] == i]</span><br><span class=\"line\">        train_datai = train_datai - train_datai.mean(<span class=\"number\">0</span>)</span><br><span class=\"line\">        Swi = np.mat(train_datai).T * np.mat(train_datai)</span><br><span class=\"line\">        Sw += Swi</span><br><span class=\"line\">    <span class=\"comment\"># between_class scatter matrix</span></span><br><span class=\"line\">    SB = np.zeros((train_data.shape[<span class=\"number\">1</span>], train_data.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    u = train_data.mean(<span class=\"number\">0</span>)  <span class=\"comment\"># 所有样本的平均值</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        Ni = train_data[train_target[:] == i].shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">        ui = train_data[train_target[:] == i].mean(<span class=\"number\">0</span>)  <span class=\"comment\"># 某个类别的平均值</span></span><br><span class=\"line\">        SBi = Ni * np.mat(ui - u).T * np.mat(ui - u)</span><br><span class=\"line\">        SB += SBi</span><br><span class=\"line\">    Sw = Sw + np.exp(-<span class=\"number\">1</span>) * np.eye(Sw.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    S = np.linalg.pinv(Sw).dot(SB)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eig(S)  <span class=\"comment\"># 求特征值，特征向量</span></span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[:(-n_dim - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    data_ndim = np.dot(data, w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_ndim.real</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Fisherfaces</span>(<span class=\"params\">data, train_data, train_label, component</span>):</span></span><br><span class=\"line\">    n = train_data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    c = <span class=\"built_in\">len</span>(np.unique(train_label))</span><br><span class=\"line\">    pca = PCA(n_components=n - c)</span><br><span class=\"line\">    pca.fit(train_data)</span><br><span class=\"line\">    data_train_pca = pca.transform(train_data)</span><br><span class=\"line\">    data_pca = pca.transform(data)</span><br><span class=\"line\">    data_fld = LDA(data, train_data, train_label, component)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_fld</span><br></pre></td></tr></table></figure>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>TPAMI的那篇文章对2007年及之前的降维算法进行了总结，还是比较到位。</p>\n"},{"title":"子空间学习(6)-LDE","catalog":true,"date":"2022-01-16T04:24:17.000Z","subtitle":"Subspace Learning-LDE","top":13,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Local Discriminant Embedding and Its Variants（2005 CVPR）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LDE，除此之外简要介绍Eigenfaces和Fisherfaces，然后会对LPP和NPE（见-子空间学习(4)-LPP&NPE）进行一些拓展。\n\n# 摘要：\n\n信息处理中的许多问题都涉及某种形式的降维。因此，人们对降维算法很感兴趣。不同于 Eigenface旨在选择最大化所有类的总散射的投影，我们将介绍两种旨在最大化类间距离和类内距离的比率的子空间学习算法：Fisherfaces更关注数据的全局结构，而Local Discriminant Embedding (LDE) 更关注数据的局部关系和类的关系。然而，不关注局部关系使Fisherface从先验上有一定局限性。此外，LDE 通过保留同一类数据点的内在相邻关系来解决该问题，同时使不同类的相邻点不再相互粘连。在本报告中，我们尝试以数学方式解释 Fisherface 和 LDE 的主要思想，并像 LDE 一样扩展邻域保留嵌入 (NPE) 和局部保留投影 (LPP) 。此外，还包括对人脸识别的全面比较和广泛的实验，以探索 Fisherface 和 LDE 的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Fisherfaces\n\n## Fisher criterion\n\nFisher criterion是一个判别准则函数，由类间散点距离与类内散点距离的比率定义。 通过最大化这一标准，可以获得最优的判别投影轴。 在样本被投影到这个投影轴上之后，类内散布被最小化，类间散布被最大化。\n\n## Motivation\n\nEigenfaces 旨在选择一种降维线性投影，使所有投影样本的分散度最大化。 因此，Eigenfaces 不能很好地处理非线性数据，并且没有考虑类间和类内散点之间的关系。Fisherfaces则考虑了类间和类内散点之间的关系。类间$S_{B}$和类内$S_{W}$散布矩阵是类间散布和类内散布的表示，它们的数学形式如公式(1)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n     S_{W}=\\sum_{i=1}^{N}(x^{c_{i}}-\\bar{x}^{c})(x^{c_{i}}-\\bar{x}^{c})^{T}\\\\\n    S_{B}=\\sum_{c=1}^{N_{c}}n_{c}(\\bar{x}^{c}-\\bar{x})(\\bar{x}^{c}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{1}\n$$\n\n其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}$ 是所有样本的平均值，$x^{c_{i}}$ 是 $c_{th}$ 类中的 $i_{th}$ 样本。\n\n## Fisherface vs Eigenface\n\nEigenface 和 Fisherface 在动机、目标函数、监督方法上是不同的，见下文讨论。\n\nEigenface 旨在寻找线性投影后数据方差最大的投影方向，而 Fisherface 则通过最大化类间和类内分散之间的比率来寻找一条线，来有效区分不同类。\n\nEigenface 和 Fisherface 的目标函数根据不同的动机，也有所不同。 Eigenface 的目标函数是公式(2)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{W^{T}W=1}{\\arg \\min}\\ \\  (W)^{T}CW \\ \\ with\\\\\n    C=\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\bar{x})(x_{i}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $C$ 是协方差矩阵，$\\bar{x}$ 是所有样本的平均值。\n\nFisherface 的目标函数是最大化类间方差 $S_{B}$ 和类内方差 $S_{W}$ 的比率，见公式(3)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    W =\\arg \\max _{W}\\ \\frac{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{B}W_{pca} W\\right|}{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{W}W_{pca}W\\right|}=[w_{1},\\cdots,w_{m}]\\\\\n    \\text{s.t. }(W)^{T} S_{W} W=1.\n    \\end{gathered}\n\\end{equation}\\tag{3\n\n}\n$$\nEigenface 是一种无监督的维数算法，而 Fisherface 是有监督的。 Fisherface 与 Eigenface 相比具有以下优势：\n\n- 虽然 Eigenface 实现了更大的总散射，但 FLD 实现了更大的类间散射，因此简化了分类。\n- Fisherface 可用于分类，而 Eigenface 不能。\n\n然而，Fisherface 只能将维度减少到类别数减 1，而 Eigenface 则没有这个限制。\n\n## Mathematical Details\n\n拉格朗日方法用于解决方程中的优化问题公式(3)，请参见以下推导：\n$$\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\mathcal{L}=W^{T}W_{pca}^{T}S_{B}W_{pca}W-\\lambda W^{T}W_{pca}^{T}S_{W}W_{pca}W\\\\\n        \\frac{\\partial \\mathcal{L}}{\\partial W}=2\\left(W_{pca}^{T}S_{B}W_{pca}W-\\lambda W_{pca}^{T}S_{W}W_{pca}W\\right)=0\\\\\n        S_{W}^{-1}S_{B}W_{pca}W=\\lambda W_{pca}W.\n    \\end{gathered}\n\\end{equation}\n$$\n此外，可以应用 SVD 或特征分解来解决上述问题。 选取$m$个最大特征值对应的特征向量形成$W$：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        S_{W}^{-1}S_{B}W_{pca}W_{i}=\\lambda_{i} W_{pca}W_{i}\\\\\n        sort(\\lambda_{1},\\cdots,\\lambda_{n})\\\\\n        W=[W_{n-m+1},\\cdots,W_{n}].\n    \\end{gathered}\n\\end{equation}\n$$\n\n# Local Discriminant Embedding\n\n在这里介绍三种LDE，最开始的LDE，2DLDE和Kernel LDE。\n\n## LDE\n\n与 Eigenface 不同，LDE 中使用数据的局部关系和类关系来构建嵌入。 此外，LDE 没有 Eigenface 的限制。 在本节中，我们将详细介绍 LDE。\nLDE 旨在保持内在的相邻关系，而不同类别的相邻点不再相互粘连。\n在低维嵌入子空间中，如果相邻点具有相同的标签，LDE 希望保持相邻点靠近，而防止其他类的点进入邻域。 考虑到这两个方面，LDE 的目标函数为公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{V}{\\arg \\max}\\ \\ J(V)=\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}W_{ij}^{\\prime}\\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}w_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $V$ 是一个 $n\\times l$ 矩阵，$V$ 是线性投影 $\\textbf{z}=V^{T}x$。\n\n## 2DLDE\n\n受到少量训练数据的限制，无法准确近似底层流形。 2DLDE 尝试将图像（数据）视为矩阵，并根据矩阵形式解决子空间学习问题。 此外，当已知图像的变化是由translation, pitch或yaw引起时，2DLDE 比基于矢量的公式具有显着的优势。\n\n令 $\\{A_{i}|A_{i}\\in\\mathcal{R}^{n_{1}\\times n_{2}}\\}$ 为训练数据。 然后，我们修改了矩阵的 LDE，矩阵-向量乘法 $\\textbf{z}_{i}=V^{T}x_{i}$ 应改为双边形式 $B_{i}= L^{T}A_{i}R$，其中 $L\\in \\mathcal{R}^{n_{1}\\times l_{1}}$ 和 $R\\in \\mathcal{R}^{n_{ 2}\\times l_{2}}$ 将$A_{i}$ 转换成一个更小的矩阵$B_{i}\\in\\mathcal{R}^{l_{1}\\times l_{2}}$。 因此，目标函数公式(4)可以重写为公式(5)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{L,R}{\\arg \\max}\\ \\ Q(L, R)=\\sum_{i, j}\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} w_{i j}^{\\prime} \\\\\n    \\text {s.t. } \\sum\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} W_{i j}=1,\n    \\end{gathered}\n\\end{equation}\\tag{5}\n$$\n其中 Frobenius 矩阵范数为 $\\|A\\|_{F}=(\\sum_{j,k}a_{j,k}^{2})^{\\frac{1}{2}}=tr( AA^{T})$。 通过使用拉格朗日乘子法和特征分解，通过迭代直到收敛得到$L$和$R$。 然后，我们通过测试点$\\bar{A}$计算$\\bar{B}=L^{T}\\bar{A}R$，找到它的最近邻$B_{i}$，使得$\\ |B_{i}=\\bar{B}\\|_{F}$，并将标签指定为 $\\bar{y}=y_{i}$。\n\n## Kernel LDE\n\n受到线性学习算法有限分类能力的启发。 Kernel LDE 试图通过非线性映射将输入数据转换到更高维空间来提升分类性能。 因此，Kernel LDE 在处理非线性降维问题方面优于 LDE。\n\n假设非线性映射为$\\Phi:\\mathcal{R}^{n}\\rightarrow \\mathcal{F}$，$\\mathcal{F}$为特征空间。 因此，局部判别嵌入在 $\\mathcal{F}$ 中的投影方向 $v$ 是 $v=\\sum_{i}^{m}\\alpha_{i}\\Phi(x_{i})=\\sum_{ i}^{m}\\alpha_{i}k(x_{i},\\bar{x})$, $\\boldsymbol{\\alpha}_{i}$ 是膨胀系数。 目标函数(5)可以重写为公式(6)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n         \\underset{\\boldsymbol{\\alpha}}{\\arg \\max}\\ \\ U(\\boldsymbol{\\alpha})=\\boldsymbol{\\alpha}^{T} K\\left(D^{\\prime}-W^{\\prime}\\right) K \\boldsymbol{\\alpha} \\\\\n         \\text{s.t. }\\boldsymbol{\\alpha}^{T} K(D-W) K \\boldsymbol{\\alpha}=1,\n    \\end{gathered}\n\\end{equation}\\tag{6}\n$$\n其中 $K$ 是一个核矩阵，$K_{i,j}=k(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots, \\alpha_{n}]^{T}$ 由膨胀系数组成。 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。\n\n# 拓展LPP和NPE\n\n我们探讨了 LPP 是否可以扩展到2D和核函数方法。 此外，NPE 是对 Laplace Beltrami 算子的特征函数的另一种线性逼近。 因此，我们探索如何扩展 NPE，就像 LDE 对 LPP 所做的那样。\n\n## 2DLPP\n\nLPP 的目标函数是最小化重建误差，见公式(7)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}X)L(\\boldsymbol{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}X)D(\\boldsymbol{a}^{T}X)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{7}\n$$\n根据公式(5)，我们可以把LPP的目标函数公式(7)变成公式(8)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{L,R}\\ \\ \\sum_{i,j}\\|L^{T}A_{i}R-L^{T}A_{j}R\\|^{2}W_{ij} \\\\\n        \\text{ s.t. } (L^{T}A_{i}R)D(L^{T}A_{i}R)^{T}=1.\n    \\end{gathered}\n\\end{equation}\\tag{8}\n$$\n\n## Kernel LPP\n\n假设$\\mathcal{F}$中的点积可以通过核函数$k(x_{1},x_{2})=\\Phi(x_{1})^{T}\\Phi(x_{ 2})$。 与公式(6)中的假设，我们可以重写 LPP 的目标函数公式(7)为公式(9)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X,\n    \\end{gathered}\n\\end{equation}\\tag{9}\n$$\n其中 $K$ 是一个核矩阵，$K_{ij}=\\Phi(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots,\\ alpha_{n}]$ 由膨胀系数组成。\n\n## 拓展NPE\n\nLPP 线性逼近 Laplace Beltrami 算子 $\\mathcal{L}$ 的特征函数，而 NPE 中的矩阵 $M$ 提供了 $\\mathcal{L}^{2}$ 的离散逼近。 NPE 的目标函数是最小化重构误差，见公式(10)：\n$$\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}\\|x_{i}-\\sum_{j}W_{ij}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}\\|y_{i}-\\sum_{j}W_{ij}y_{ij}\\|^2 \\\\\n        &=\\boldsymbol{y}^{T}M\\boldsymbol{y}=\\boldsymbol{a}^{T}XMX^{T}\\boldsymbol{a}\n    \\end{aligned}\n\\end{equation}\\tag{10}\n$$\n\n$$\n\\text{ s.t. }  \\sum_{j}W_{ij}=1,\\ \\boldsymbol{a}^{T}XX^{T}\\boldsymbol{a}=1,\\ \\boldsymbol{y}=\\boldsymbol{a}^{T}X,\n$$\n\n其中 $I=diag(1,\\cdots,1)$。 此外，我们探讨了 LDE 对 LPP 的作用并扩展了 NPE。 $\\mathcal{R}^{n}$中的数据点$\\{x_{1}\\}_{i=1}^{m}$可以改写为数据矩阵$X=[x_{1}， \\cdots,x_{m}]\\in\\mathcal{R}^{n\\times m}$. 然后，我们通过以下步骤扩展 NPE。\n\n- 构建邻域图：对于无向图 $G$ 和 $G^{\\prime}$，考虑同一类的每一对点 $x_{i}$ 和 $x_{j}$ ($y_{i}=y_{j}$ ) 和不同的类 ($y_{i}\\neq y_{j}$)，如果 $x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那就在$x_{i}$和$x_{j}$之间加一条边。\n\n- 计算权重矩阵：对 $G$ 的矩阵 $W$ 加权\n  $$\n       w_{ij}=e^{\\frac{-\\|x_{i}-x_{j}\\|^{2}}{t}}。\n  $$\n  默认情况下，如果 $x_{i}$ 和 $x_{j}$ 没有连接，则 $w_{ij}=0$。 很明显，如此定义的 $W$ 是一个 $m \\times m$，稀疏对称矩阵。\n\n- 找到对应于 $l$ 最大特征值的广义特征向量 $v_{1}, v_{2},\\cdots, v_{l}$，\n  $$\n  \\begin{equation}\n          XM^{\\prime}X^{T}v=\\lambda XMX^{T}v,\n  \\end{equation}\n  $$\n  其中 $M=(I-W)^{T}(I-W)$ 和 $M^{\\prime}=(I-W^{\\prime})^{T}(I-W^{\\prime})$ 是对称矩阵。 $x_{i}$ 的嵌入由 $z_{i}=V^{T}x_{i}$ 完成，其中 $V=[v_{1},\\cdots,v_{l}]$。\n\n更进一步，上面的特征分解问题旨在保持相同标签的相邻点靠近，同时防止其他类的点进入邻域。 此外，NPE的目标函数可以变为公式(11)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W^{\\prime}) = \\sum_{i,j}\\|x_{i}-W_{ij}^{\\prime}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i,j}\\|V^{T}x_{i}-W_{ij}^{\\prime}V^{T}x_{ij}\\|^2 \\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-W_{ij}V^{T}x_{ij}\\|^2=1.\n    \\end{gathered}\n\\end{equation}\n$$\n\n# 讨论\n\n这里主要讨论一下LDE与之前的算法的区别：\n\nEigenface 旨在通过将数据在最大方差的方向投影来保持全局欧几里得结构，而 NPE 和 LPP 旨在通过最小化重构误差来保持局部流形结构。 此外，Eigenface、LPP 和 NPE 是无监督方法。 然而，Fisherface 和 LDE 是有监督的方法。 Fisherface 旨在通过最小化类内距离和类间距离之间的比率来寻找最有效的辨别方向。 此外，LDE 受到 Fisherface 的启发，并在 LPP 的基础上进行了改进。 因此，LDE 旨在通过最小化邻域中类内距离和类间距离之间的比率来保持内在的邻域关系。\n\n# 实验结果\n\n主要是本节相关算法的代码，这里只贴LDE有关的，因为太多了。至于拓展LPP和NPE的，我之后应该会上传到github上：\n\n```python\nimport numpy as np\nimport scipy\nfrom SubspaceLearning.Kernel import kernel\nimport math\n\n#构造最经典的权重矩阵\ndef construct_graph(data, label, k, t):\n    clusters = np.unique(label)\n    class_i = []\n    for i in clusters:\n        class_i.append(label[:] == i)\n    class_i = np.asarray(class_i)\n    n = data.shape[0]\n    W_full = np.zeros((n, n))\n    SW = np.zeros((n, n))\n    SB = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i, n):\n            dist = np.linalg.norm(data[i] - data[j])\n            W_full[i][j] = math.exp(-(dist ** 2 / (t)))\n            W_full[j][i] = W_full[i][j]\n    for i in range(n):\n        # G within\n        cl = label[i]\n        sl = class_i[cl][:]  # same label :true or false\n        slindex = np.array(np.where(sl == True))[0, :]  # within\n        nslindex = np.array(np.where(sl == False))[0, :]  # between class\n        W_sl = W_full[i][sl]\n        W_nsl = W_full[i][~sl]\n        index = np.argsort(W_sl)[1:k + 1]\n        nindex = np.argsort(W_nsl)[0:k]\n        SW[i][slindex[index]] = W_full[i][slindex[index]]\n        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]\n    return SW, SB\n\n#构造01的权重矩阵\ndef construct_graph_01(data, label, k):\n    clusters = np.unique(label)\n    class_i = []\n    for i in clusters:\n        class_i.append(label[:] == i)\n    class_i = np.asarray(class_i)\n    n = data.shape[0]\n    W_full = np.ones((n, n))\n    SW = np.zeros((n, n))\n    SB = np.zeros((n, n))\n    for i in range(n):\n        # G within\n        cl = label[i]\n        sl = class_i[cl][:]  # same label :true or false\n        slindex = np.array(np.where(sl == True))[0, :]  # within\n        nslindex = np.array(np.where(sl == False))[0, :]  # between class\n        W_sl = W_full[i][sl]\n        W_nsl = W_full[i][~sl]\n        index = np.argsort(W_sl)[1:k + 1]\n        nindex = np.argsort(W_nsl)[0:k]\n        SW[i][slindex[index]] = W_full[i][slindex[index]]\n        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]\n    return SW, SB\n\n#计算拉普拉斯矩阵\ndef Lap(W):\n    D = np.diag(np.sum(W, axis=0))\n    return D - W\n\n\ndef LDE(data, train_data, train_label, component, k, t):\n    SW, SB = construct_graph(train_data, train_label, k, t)\n    SW = np.array((SW, SW.T)).max(axis=0)\n    LW = Lap(SW)\n    SB = np.array((SB, SB.T)).max(axis=0)\n    LB = Lap(SB)\n    X = train_data.T\n    XLWXT = X.dot(LW).dot(X.T)\n    XLBXT = X.dot(LB).dot(X.T)\n    XLWXT = XLWXT + np.exp(-5) * np.eye(XLWXT.shape[0])\n    T = scipy.linalg.inv(XLWXT).dot(XLBXT)\n    eigVals, eigVects = np.linalg.eigh(T)\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[:(-component - 1):-1]\n    w = eigVects[:, eigValInd]\n    data_ndim = np.dot(data, w)\n    return data_ndim\n\n\ndef ddLDE(data, train_data, train_label, component1, component2, k, t):\n    n = train_data.shape[0]\n    n1 = n2 = int(math.sqrt(train_data.shape[1]))\n    L = np.ones((n1, component1))\n    R = np.ones((n2, component2))\n    SW, SB = construct_graph(train_data, train_label, k, t)\n    # solve for R\n    Rleft = np.zeros((n2, n2))\n    Rright = np.zeros((n2, n2))\n    Lleft = np.zeros((n2, n2))\n    Lright = np.zeros((n2, n2))\n    A = np.zeros((n, n, n1, n2))\n    for i in range(n):\n        for j in range(n):\n            A[i][j] = (train_data[i] - train_data[j]).reshape(n1, n2)\n    # offset=10\n    # while offset>0.1:\n    for z in range(2):\n        last_R = R.copy()\n        last_L = L.copy()\n        for i in range(n):\n            for j in range(n):\n                ATLLTA = ((A[i][j]).T) @ (L) @ (L.T) @ (A[i][j])\n                Rleft += SB[i][j] * (ATLLTA)\n                Rright += SW[i][j] * (ATLLTA)\n        eigVals, eigVects = scipy.linalg.eig(Rleft, Rright)\n        eigValInd = np.argsort(eigVals)\n        eigValInd = eigValInd[:(-component2 - 1):-1]\n        R = eigVects[:, eigValInd]\n\n        for i in range(n):\n            for j in range(n):\n                ATRRTA = (A[i][j]) @ (R) @ (R.T) @ (A[i][j].T)\n                Lleft += SB[i][j] * (ATRRTA)\n                Lright += SW[i][j] * (ATRRTA)\n        eigVals, eigVects = scipy.linalg.eig(Lleft, Lright)\n        eigValInd = np.argsort(eigVals)\n        eigValInd = eigValInd[:(-component1 - 1):-1]\n        L = eigVects[:, eigValInd]\n        offset = np.linalg.norm(np.squeeze(abs(last_R) - abs(R))) + np.linalg.norm(np.squeeze(np.abs(last_L) - abs(L)))\n        # print(offset)\n    B = L.T @ data.reshape(-1, n1, n2) @ R\n    return B.reshape(data.shape[0], -1)\n\n\ndef KernelLDE(data, train_data, train_label, ker, component, k,t):\n    SW, SB = construct_graph_01(train_data, train_label, k)\n    SW = np.array((SW, SW.T)).max(axis=0)\n    LW = Lap(SW)\n    SB = np.array((SB, SB.T)).max(axis=0)\n    LB = Lap(SB)\n    K = kernel(ker)(train_data, train_data,t)\n    KLWKT = K.T.dot(LW).dot(K)\n    KLBKT = K.T.dot(LB).dot(K)\n    KLWKT = KLWKT + np.exp(-5) * np.eye(KLWKT.shape[0])\n    T = scipy.linalg.inv(KLWKT).dot(KLBKT)\n    eigVals, eigVects = np.linalg.eigh(T)\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[:(-component - 1):-1]\n    w = eigVects[:, eigValInd]\n    data_ndim = (kernel(ker)(data, train_data,t)) @ w\n    return data_ndim\n```\n\n然后Kernel LDE可以有如下的：\n\n```python\nimport numpy as np\nimport math\n\nclass kernel:\n    def __init__(self, ker):\n        self.ker = ker\n\n    # 线性核函数\n    def linear(self, x1, x2):\n        return x1 @ x2.T\n\n    # 多项式核\n    def poly(self, x1, x2):\n        return (x1 @ x2.T) ** 2\n\n    # 高斯核\n    def RBF(self, x1, x2, t):\n        return math.exp(-(np.linalg.norm(x1 - x2)) / (t))\n\n    def ori(self, x1, x2):\n        return x1\n\n    def __call__(self, *args, **kwargs):\n        if self.ker == 'linear':\n            return self.linear(*args, **kwargs)\n        if self.ker == 'poly':\n            return self.poly(*args, **kwargs)\n        if self.ker == 'RBF':\n            return self.RBF(*args, **kwargs)\n        if self.ker == '':\n            return self.ori(*args, **kwargs)\n```\n\n展示一些实验结果，主要是使用的数据集还是ORL人脸数据集，它由总共 400 张人脸图像组成，总共 40 人（每人 10 个样本）。\n\n使用九种方法用于对ORL进行降维。 降维后，我们对特征进行KNN（$k=3$）来计算分类精度。 LPP（LPP、2DLPP 和 Kernel LPP）和 LDE（LDE、2DLDE、Kernel LDE）的用户指定参数是分量 $d$、邻居 $k$ 和参数 $t$。\n\n更进一步，我们讨论了降维后维度对准确性的影响，参见图1：\n\n<img src=\"子空间学习(6)-LDE\\com.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 九种算法在ORL数据集上的实验结果。</center>\n此外，我们将讨论当 $Component$ 为 $20$ 时参数邻居 $k$ 和 参数 $t$ 的影响。 我们可视化这两个参数对准确性的影响，参见图2。\n<img src=\"子空间学习(6)-LDE\\parameter.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LDE和LPP算法的影响。</center>\n\n# 总结\n\n当然实验结果不太对劲，估计还是参数有问题或者写丑了？由于那个年代的代码基本都是matlab的，我这里复现都是使用Python，有些优化应该不太到位，也没有去参考源码。\n\n","source":"_posts/子空间学习(6)-LDE.md","raw":"---\ntitle: 子空间学习(6)-LDE\ncatalog: true\ndate: 2022-01-16 12:24:17\nsubtitle: Subspace Learning-LDE\ntop: 13\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Local Discriminant Embedding and Its Variants（2005 CVPR）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LDE，除此之外简要介绍Eigenfaces和Fisherfaces，然后会对LPP和NPE（见-子空间学习(4)-LPP&NPE）进行一些拓展。\n\n# 摘要：\n\n信息处理中的许多问题都涉及某种形式的降维。因此，人们对降维算法很感兴趣。不同于 Eigenface旨在选择最大化所有类的总散射的投影，我们将介绍两种旨在最大化类间距离和类内距离的比率的子空间学习算法：Fisherfaces更关注数据的全局结构，而Local Discriminant Embedding (LDE) 更关注数据的局部关系和类的关系。然而，不关注局部关系使Fisherface从先验上有一定局限性。此外，LDE 通过保留同一类数据点的内在相邻关系来解决该问题，同时使不同类的相邻点不再相互粘连。在本报告中，我们尝试以数学方式解释 Fisherface 和 LDE 的主要思想，并像 LDE 一样扩展邻域保留嵌入 (NPE) 和局部保留投影 (LPP) 。此外，还包括对人脸识别的全面比较和广泛的实验，以探索 Fisherface 和 LDE 的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# Fisherfaces\n\n## Fisher criterion\n\nFisher criterion是一个判别准则函数，由类间散点距离与类内散点距离的比率定义。 通过最大化这一标准，可以获得最优的判别投影轴。 在样本被投影到这个投影轴上之后，类内散布被最小化，类间散布被最大化。\n\n## Motivation\n\nEigenfaces 旨在选择一种降维线性投影，使所有投影样本的分散度最大化。 因此，Eigenfaces 不能很好地处理非线性数据，并且没有考虑类间和类内散点之间的关系。Fisherfaces则考虑了类间和类内散点之间的关系。类间$S_{B}$和类内$S_{W}$散布矩阵是类间散布和类内散布的表示，它们的数学形式如公式(1)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n     S_{W}=\\sum_{i=1}^{N}(x^{c_{i}}-\\bar{x}^{c})(x^{c_{i}}-\\bar{x}^{c})^{T}\\\\\n    S_{B}=\\sum_{c=1}^{N_{c}}n_{c}(\\bar{x}^{c}-\\bar{x})(\\bar{x}^{c}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{1}\n$$\n\n其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}$ 是所有样本的平均值，$x^{c_{i}}$ 是 $c_{th}$ 类中的 $i_{th}$ 样本。\n\n## Fisherface vs Eigenface\n\nEigenface 和 Fisherface 在动机、目标函数、监督方法上是不同的，见下文讨论。\n\nEigenface 旨在寻找线性投影后数据方差最大的投影方向，而 Fisherface 则通过最大化类间和类内分散之间的比率来寻找一条线，来有效区分不同类。\n\nEigenface 和 Fisherface 的目标函数根据不同的动机，也有所不同。 Eigenface 的目标函数是公式(2)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{W^{T}W=1}{\\arg \\min}\\ \\  (W)^{T}CW \\ \\ with\\\\\n    C=\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\bar{x})(x_{i}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $C$ 是协方差矩阵，$\\bar{x}$ 是所有样本的平均值。\n\nFisherface 的目标函数是最大化类间方差 $S_{B}$ 和类内方差 $S_{W}$ 的比率，见公式(3)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    W =\\arg \\max _{W}\\ \\frac{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{B}W_{pca} W\\right|}{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{W}W_{pca}W\\right|}=[w_{1},\\cdots,w_{m}]\\\\\n    \\text{s.t. }(W)^{T} S_{W} W=1.\n    \\end{gathered}\n\\end{equation}\\tag{3\n\n}\n$$\nEigenface 是一种无监督的维数算法，而 Fisherface 是有监督的。 Fisherface 与 Eigenface 相比具有以下优势：\n\n- 虽然 Eigenface 实现了更大的总散射，但 FLD 实现了更大的类间散射，因此简化了分类。\n- Fisherface 可用于分类，而 Eigenface 不能。\n\n然而，Fisherface 只能将维度减少到类别数减 1，而 Eigenface 则没有这个限制。\n\n## Mathematical Details\n\n拉格朗日方法用于解决方程中的优化问题公式(3)，请参见以下推导：\n$$\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\mathcal{L}=W^{T}W_{pca}^{T}S_{B}W_{pca}W-\\lambda W^{T}W_{pca}^{T}S_{W}W_{pca}W\\\\\n        \\frac{\\partial \\mathcal{L}}{\\partial W}=2\\left(W_{pca}^{T}S_{B}W_{pca}W-\\lambda W_{pca}^{T}S_{W}W_{pca}W\\right)=0\\\\\n        S_{W}^{-1}S_{B}W_{pca}W=\\lambda W_{pca}W.\n    \\end{gathered}\n\\end{equation}\n$$\n此外，可以应用 SVD 或特征分解来解决上述问题。 选取$m$个最大特征值对应的特征向量形成$W$：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        S_{W}^{-1}S_{B}W_{pca}W_{i}=\\lambda_{i} W_{pca}W_{i}\\\\\n        sort(\\lambda_{1},\\cdots,\\lambda_{n})\\\\\n        W=[W_{n-m+1},\\cdots,W_{n}].\n    \\end{gathered}\n\\end{equation}\n$$\n\n# Local Discriminant Embedding\n\n在这里介绍三种LDE，最开始的LDE，2DLDE和Kernel LDE。\n\n## LDE\n\n与 Eigenface 不同，LDE 中使用数据的局部关系和类关系来构建嵌入。 此外，LDE 没有 Eigenface 的限制。 在本节中，我们将详细介绍 LDE。\nLDE 旨在保持内在的相邻关系，而不同类别的相邻点不再相互粘连。\n在低维嵌入子空间中，如果相邻点具有相同的标签，LDE 希望保持相邻点靠近，而防止其他类的点进入邻域。 考虑到这两个方面，LDE 的目标函数为公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{V}{\\arg \\max}\\ \\ J(V)=\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}W_{ij}^{\\prime}\\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}w_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $V$ 是一个 $n\\times l$ 矩阵，$V$ 是线性投影 $\\textbf{z}=V^{T}x$。\n\n## 2DLDE\n\n受到少量训练数据的限制，无法准确近似底层流形。 2DLDE 尝试将图像（数据）视为矩阵，并根据矩阵形式解决子空间学习问题。 此外，当已知图像的变化是由translation, pitch或yaw引起时，2DLDE 比基于矢量的公式具有显着的优势。\n\n令 $\\{A_{i}|A_{i}\\in\\mathcal{R}^{n_{1}\\times n_{2}}\\}$ 为训练数据。 然后，我们修改了矩阵的 LDE，矩阵-向量乘法 $\\textbf{z}_{i}=V^{T}x_{i}$ 应改为双边形式 $B_{i}= L^{T}A_{i}R$，其中 $L\\in \\mathcal{R}^{n_{1}\\times l_{1}}$ 和 $R\\in \\mathcal{R}^{n_{ 2}\\times l_{2}}$ 将$A_{i}$ 转换成一个更小的矩阵$B_{i}\\in\\mathcal{R}^{l_{1}\\times l_{2}}$。 因此，目标函数公式(4)可以重写为公式(5)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{L,R}{\\arg \\max}\\ \\ Q(L, R)=\\sum_{i, j}\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} w_{i j}^{\\prime} \\\\\n    \\text {s.t. } \\sum\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} W_{i j}=1,\n    \\end{gathered}\n\\end{equation}\\tag{5}\n$$\n其中 Frobenius 矩阵范数为 $\\|A\\|_{F}=(\\sum_{j,k}a_{j,k}^{2})^{\\frac{1}{2}}=tr( AA^{T})$。 通过使用拉格朗日乘子法和特征分解，通过迭代直到收敛得到$L$和$R$。 然后，我们通过测试点$\\bar{A}$计算$\\bar{B}=L^{T}\\bar{A}R$，找到它的最近邻$B_{i}$，使得$\\ |B_{i}=\\bar{B}\\|_{F}$，并将标签指定为 $\\bar{y}=y_{i}$。\n\n## Kernel LDE\n\n受到线性学习算法有限分类能力的启发。 Kernel LDE 试图通过非线性映射将输入数据转换到更高维空间来提升分类性能。 因此，Kernel LDE 在处理非线性降维问题方面优于 LDE。\n\n假设非线性映射为$\\Phi:\\mathcal{R}^{n}\\rightarrow \\mathcal{F}$，$\\mathcal{F}$为特征空间。 因此，局部判别嵌入在 $\\mathcal{F}$ 中的投影方向 $v$ 是 $v=\\sum_{i}^{m}\\alpha_{i}\\Phi(x_{i})=\\sum_{ i}^{m}\\alpha_{i}k(x_{i},\\bar{x})$, $\\boldsymbol{\\alpha}_{i}$ 是膨胀系数。 目标函数(5)可以重写为公式(6)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n         \\underset{\\boldsymbol{\\alpha}}{\\arg \\max}\\ \\ U(\\boldsymbol{\\alpha})=\\boldsymbol{\\alpha}^{T} K\\left(D^{\\prime}-W^{\\prime}\\right) K \\boldsymbol{\\alpha} \\\\\n         \\text{s.t. }\\boldsymbol{\\alpha}^{T} K(D-W) K \\boldsymbol{\\alpha}=1,\n    \\end{gathered}\n\\end{equation}\\tag{6}\n$$\n其中 $K$ 是一个核矩阵，$K_{i,j}=k(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots, \\alpha_{n}]^{T}$ 由膨胀系数组成。 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。\n\n# 拓展LPP和NPE\n\n我们探讨了 LPP 是否可以扩展到2D和核函数方法。 此外，NPE 是对 Laplace Beltrami 算子的特征函数的另一种线性逼近。 因此，我们探索如何扩展 NPE，就像 LDE 对 LPP 所做的那样。\n\n## 2DLPP\n\nLPP 的目标函数是最小化重建误差，见公式(7)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}X)L(\\boldsymbol{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}X)D(\\boldsymbol{a}^{T}X)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{7}\n$$\n根据公式(5)，我们可以把LPP的目标函数公式(7)变成公式(8)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{L,R}\\ \\ \\sum_{i,j}\\|L^{T}A_{i}R-L^{T}A_{j}R\\|^{2}W_{ij} \\\\\n        \\text{ s.t. } (L^{T}A_{i}R)D(L^{T}A_{i}R)^{T}=1.\n    \\end{gathered}\n\\end{equation}\\tag{8}\n$$\n\n## Kernel LPP\n\n假设$\\mathcal{F}$中的点积可以通过核函数$k(x_{1},x_{2})=\\Phi(x_{1})^{T}\\Phi(x_{ 2})$。 与公式(6)中的假设，我们可以重写 LPP 的目标函数公式(7)为公式(9)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X,\n    \\end{gathered}\n\\end{equation}\\tag{9}\n$$\n其中 $K$ 是一个核矩阵，$K_{ij}=\\Phi(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots,\\ alpha_{n}]$ 由膨胀系数组成。\n\n## 拓展NPE\n\nLPP 线性逼近 Laplace Beltrami 算子 $\\mathcal{L}$ 的特征函数，而 NPE 中的矩阵 $M$ 提供了 $\\mathcal{L}^{2}$ 的离散逼近。 NPE 的目标函数是最小化重构误差，见公式(10)：\n$$\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}\\|x_{i}-\\sum_{j}W_{ij}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}\\|y_{i}-\\sum_{j}W_{ij}y_{ij}\\|^2 \\\\\n        &=\\boldsymbol{y}^{T}M\\boldsymbol{y}=\\boldsymbol{a}^{T}XMX^{T}\\boldsymbol{a}\n    \\end{aligned}\n\\end{equation}\\tag{10}\n$$\n\n$$\n\\text{ s.t. }  \\sum_{j}W_{ij}=1,\\ \\boldsymbol{a}^{T}XX^{T}\\boldsymbol{a}=1,\\ \\boldsymbol{y}=\\boldsymbol{a}^{T}X,\n$$\n\n其中 $I=diag(1,\\cdots,1)$。 此外，我们探讨了 LDE 对 LPP 的作用并扩展了 NPE。 $\\mathcal{R}^{n}$中的数据点$\\{x_{1}\\}_{i=1}^{m}$可以改写为数据矩阵$X=[x_{1}， \\cdots,x_{m}]\\in\\mathcal{R}^{n\\times m}$. 然后，我们通过以下步骤扩展 NPE。\n\n- 构建邻域图：对于无向图 $G$ 和 $G^{\\prime}$，考虑同一类的每一对点 $x_{i}$ 和 $x_{j}$ ($y_{i}=y_{j}$ ) 和不同的类 ($y_{i}\\neq y_{j}$)，如果 $x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那就在$x_{i}$和$x_{j}$之间加一条边。\n\n- 计算权重矩阵：对 $G$ 的矩阵 $W$ 加权\n  $$\n       w_{ij}=e^{\\frac{-\\|x_{i}-x_{j}\\|^{2}}{t}}。\n  $$\n  默认情况下，如果 $x_{i}$ 和 $x_{j}$ 没有连接，则 $w_{ij}=0$。 很明显，如此定义的 $W$ 是一个 $m \\times m$，稀疏对称矩阵。\n\n- 找到对应于 $l$ 最大特征值的广义特征向量 $v_{1}, v_{2},\\cdots, v_{l}$，\n  $$\n  \\begin{equation}\n          XM^{\\prime}X^{T}v=\\lambda XMX^{T}v,\n  \\end{equation}\n  $$\n  其中 $M=(I-W)^{T}(I-W)$ 和 $M^{\\prime}=(I-W^{\\prime})^{T}(I-W^{\\prime})$ 是对称矩阵。 $x_{i}$ 的嵌入由 $z_{i}=V^{T}x_{i}$ 完成，其中 $V=[v_{1},\\cdots,v_{l}]$。\n\n更进一步，上面的特征分解问题旨在保持相同标签的相邻点靠近，同时防止其他类的点进入邻域。 此外，NPE的目标函数可以变为公式(11)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W^{\\prime}) = \\sum_{i,j}\\|x_{i}-W_{ij}^{\\prime}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i,j}\\|V^{T}x_{i}-W_{ij}^{\\prime}V^{T}x_{ij}\\|^2 \\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-W_{ij}V^{T}x_{ij}\\|^2=1.\n    \\end{gathered}\n\\end{equation}\n$$\n\n# 讨论\n\n这里主要讨论一下LDE与之前的算法的区别：\n\nEigenface 旨在通过将数据在最大方差的方向投影来保持全局欧几里得结构，而 NPE 和 LPP 旨在通过最小化重构误差来保持局部流形结构。 此外，Eigenface、LPP 和 NPE 是无监督方法。 然而，Fisherface 和 LDE 是有监督的方法。 Fisherface 旨在通过最小化类内距离和类间距离之间的比率来寻找最有效的辨别方向。 此外，LDE 受到 Fisherface 的启发，并在 LPP 的基础上进行了改进。 因此，LDE 旨在通过最小化邻域中类内距离和类间距离之间的比率来保持内在的邻域关系。\n\n# 实验结果\n\n主要是本节相关算法的代码，这里只贴LDE有关的，因为太多了。至于拓展LPP和NPE的，我之后应该会上传到github上：\n\n```python\nimport numpy as np\nimport scipy\nfrom SubspaceLearning.Kernel import kernel\nimport math\n\n#构造最经典的权重矩阵\ndef construct_graph(data, label, k, t):\n    clusters = np.unique(label)\n    class_i = []\n    for i in clusters:\n        class_i.append(label[:] == i)\n    class_i = np.asarray(class_i)\n    n = data.shape[0]\n    W_full = np.zeros((n, n))\n    SW = np.zeros((n, n))\n    SB = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i, n):\n            dist = np.linalg.norm(data[i] - data[j])\n            W_full[i][j] = math.exp(-(dist ** 2 / (t)))\n            W_full[j][i] = W_full[i][j]\n    for i in range(n):\n        # G within\n        cl = label[i]\n        sl = class_i[cl][:]  # same label :true or false\n        slindex = np.array(np.where(sl == True))[0, :]  # within\n        nslindex = np.array(np.where(sl == False))[0, :]  # between class\n        W_sl = W_full[i][sl]\n        W_nsl = W_full[i][~sl]\n        index = np.argsort(W_sl)[1:k + 1]\n        nindex = np.argsort(W_nsl)[0:k]\n        SW[i][slindex[index]] = W_full[i][slindex[index]]\n        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]\n    return SW, SB\n\n#构造01的权重矩阵\ndef construct_graph_01(data, label, k):\n    clusters = np.unique(label)\n    class_i = []\n    for i in clusters:\n        class_i.append(label[:] == i)\n    class_i = np.asarray(class_i)\n    n = data.shape[0]\n    W_full = np.ones((n, n))\n    SW = np.zeros((n, n))\n    SB = np.zeros((n, n))\n    for i in range(n):\n        # G within\n        cl = label[i]\n        sl = class_i[cl][:]  # same label :true or false\n        slindex = np.array(np.where(sl == True))[0, :]  # within\n        nslindex = np.array(np.where(sl == False))[0, :]  # between class\n        W_sl = W_full[i][sl]\n        W_nsl = W_full[i][~sl]\n        index = np.argsort(W_sl)[1:k + 1]\n        nindex = np.argsort(W_nsl)[0:k]\n        SW[i][slindex[index]] = W_full[i][slindex[index]]\n        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]\n    return SW, SB\n\n#计算拉普拉斯矩阵\ndef Lap(W):\n    D = np.diag(np.sum(W, axis=0))\n    return D - W\n\n\ndef LDE(data, train_data, train_label, component, k, t):\n    SW, SB = construct_graph(train_data, train_label, k, t)\n    SW = np.array((SW, SW.T)).max(axis=0)\n    LW = Lap(SW)\n    SB = np.array((SB, SB.T)).max(axis=0)\n    LB = Lap(SB)\n    X = train_data.T\n    XLWXT = X.dot(LW).dot(X.T)\n    XLBXT = X.dot(LB).dot(X.T)\n    XLWXT = XLWXT + np.exp(-5) * np.eye(XLWXT.shape[0])\n    T = scipy.linalg.inv(XLWXT).dot(XLBXT)\n    eigVals, eigVects = np.linalg.eigh(T)\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[:(-component - 1):-1]\n    w = eigVects[:, eigValInd]\n    data_ndim = np.dot(data, w)\n    return data_ndim\n\n\ndef ddLDE(data, train_data, train_label, component1, component2, k, t):\n    n = train_data.shape[0]\n    n1 = n2 = int(math.sqrt(train_data.shape[1]))\n    L = np.ones((n1, component1))\n    R = np.ones((n2, component2))\n    SW, SB = construct_graph(train_data, train_label, k, t)\n    # solve for R\n    Rleft = np.zeros((n2, n2))\n    Rright = np.zeros((n2, n2))\n    Lleft = np.zeros((n2, n2))\n    Lright = np.zeros((n2, n2))\n    A = np.zeros((n, n, n1, n2))\n    for i in range(n):\n        for j in range(n):\n            A[i][j] = (train_data[i] - train_data[j]).reshape(n1, n2)\n    # offset=10\n    # while offset>0.1:\n    for z in range(2):\n        last_R = R.copy()\n        last_L = L.copy()\n        for i in range(n):\n            for j in range(n):\n                ATLLTA = ((A[i][j]).T) @ (L) @ (L.T) @ (A[i][j])\n                Rleft += SB[i][j] * (ATLLTA)\n                Rright += SW[i][j] * (ATLLTA)\n        eigVals, eigVects = scipy.linalg.eig(Rleft, Rright)\n        eigValInd = np.argsort(eigVals)\n        eigValInd = eigValInd[:(-component2 - 1):-1]\n        R = eigVects[:, eigValInd]\n\n        for i in range(n):\n            for j in range(n):\n                ATRRTA = (A[i][j]) @ (R) @ (R.T) @ (A[i][j].T)\n                Lleft += SB[i][j] * (ATRRTA)\n                Lright += SW[i][j] * (ATRRTA)\n        eigVals, eigVects = scipy.linalg.eig(Lleft, Lright)\n        eigValInd = np.argsort(eigVals)\n        eigValInd = eigValInd[:(-component1 - 1):-1]\n        L = eigVects[:, eigValInd]\n        offset = np.linalg.norm(np.squeeze(abs(last_R) - abs(R))) + np.linalg.norm(np.squeeze(np.abs(last_L) - abs(L)))\n        # print(offset)\n    B = L.T @ data.reshape(-1, n1, n2) @ R\n    return B.reshape(data.shape[0], -1)\n\n\ndef KernelLDE(data, train_data, train_label, ker, component, k,t):\n    SW, SB = construct_graph_01(train_data, train_label, k)\n    SW = np.array((SW, SW.T)).max(axis=0)\n    LW = Lap(SW)\n    SB = np.array((SB, SB.T)).max(axis=0)\n    LB = Lap(SB)\n    K = kernel(ker)(train_data, train_data,t)\n    KLWKT = K.T.dot(LW).dot(K)\n    KLBKT = K.T.dot(LB).dot(K)\n    KLWKT = KLWKT + np.exp(-5) * np.eye(KLWKT.shape[0])\n    T = scipy.linalg.inv(KLWKT).dot(KLBKT)\n    eigVals, eigVects = np.linalg.eigh(T)\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[:(-component - 1):-1]\n    w = eigVects[:, eigValInd]\n    data_ndim = (kernel(ker)(data, train_data,t)) @ w\n    return data_ndim\n```\n\n然后Kernel LDE可以有如下的：\n\n```python\nimport numpy as np\nimport math\n\nclass kernel:\n    def __init__(self, ker):\n        self.ker = ker\n\n    # 线性核函数\n    def linear(self, x1, x2):\n        return x1 @ x2.T\n\n    # 多项式核\n    def poly(self, x1, x2):\n        return (x1 @ x2.T) ** 2\n\n    # 高斯核\n    def RBF(self, x1, x2, t):\n        return math.exp(-(np.linalg.norm(x1 - x2)) / (t))\n\n    def ori(self, x1, x2):\n        return x1\n\n    def __call__(self, *args, **kwargs):\n        if self.ker == 'linear':\n            return self.linear(*args, **kwargs)\n        if self.ker == 'poly':\n            return self.poly(*args, **kwargs)\n        if self.ker == 'RBF':\n            return self.RBF(*args, **kwargs)\n        if self.ker == '':\n            return self.ori(*args, **kwargs)\n```\n\n展示一些实验结果，主要是使用的数据集还是ORL人脸数据集，它由总共 400 张人脸图像组成，总共 40 人（每人 10 个样本）。\n\n使用九种方法用于对ORL进行降维。 降维后，我们对特征进行KNN（$k=3$）来计算分类精度。 LPP（LPP、2DLPP 和 Kernel LPP）和 LDE（LDE、2DLDE、Kernel LDE）的用户指定参数是分量 $d$、邻居 $k$ 和参数 $t$。\n\n更进一步，我们讨论了降维后维度对准确性的影响，参见图1：\n\n<img src=\"子空间学习(6)-LDE\\com.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 九种算法在ORL数据集上的实验结果。</center>\n此外，我们将讨论当 $Component$ 为 $20$ 时参数邻居 $k$ 和 参数 $t$ 的影响。 我们可视化这两个参数对准确性的影响，参见图2。\n<img src=\"子空间学习(6)-LDE\\parameter.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LDE和LPP算法的影响。</center>\n\n# 总结\n\n当然实验结果不太对劲，估计还是参数有问题或者写丑了？由于那个年代的代码基本都是matlab的，我这里复现都是使用Python，有些优化应该不太到位，也没有去参考源码。\n\n","slug":"子空间学习(6)-LDE","published":1,"updated":"2022-01-13T12:56:07.715Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxx600103ouegpyz9e9p","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Local Discriminant Embedding and Its Variants（2005 CVPR）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LDE，除此之外简要介绍Eigenfaces和Fisherfaces，然后会对LPP和NPE（见-子空间学习(4)-LPP&amp;NPE）进行一些拓展。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>信息处理中的许多问题都涉及某种形式的降维。因此，人们对降维算法很感兴趣。不同于 Eigenface旨在选择最大化所有类的总散射的投影，我们将介绍两种旨在最大化类间距离和类内距离的比率的子空间学习算法：Fisherfaces更关注数据的全局结构，而Local Discriminant Embedding (LDE) 更关注数据的局部关系和类的关系。然而，不关注局部关系使Fisherface从先验上有一定局限性。此外，LDE 通过保留同一类数据点的内在相邻关系来解决该问题，同时使不同类的相邻点不再相互粘连。在本报告中，我们尝试以数学方式解释 Fisherface 和 LDE 的主要思想，并像 LDE 一样扩展邻域保留嵌入 (NPE) 和局部保留投影 (LPP) 。此外，还包括对人脸识别的全面比较和广泛的实验，以探索 Fisherface 和 LDE 的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Fisherfaces\"><a href=\"#Fisherfaces\" class=\"headerlink\" title=\"Fisherfaces\"></a>Fisherfaces</h1><h2 id=\"Fisher-criterion\"><a href=\"#Fisher-criterion\" class=\"headerlink\" title=\"Fisher criterion\"></a>Fisher criterion</h2><p>Fisher criterion是一个判别准则函数，由类间散点距离与类内散点距离的比率定义。 通过最大化这一标准，可以获得最优的判别投影轴。 在样本被投影到这个投影轴上之后，类内散布被最小化，类间散布被最大化。</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>Eigenfaces 旨在选择一种降维线性投影，使所有投影样本的分散度最大化。 因此，Eigenfaces 不能很好地处理非线性数据，并且没有考虑类间和类内散点之间的关系。Fisherfaces则考虑了类间和类内散点之间的关系。类间$S_{B}$和类内$S_{W}$散布矩阵是类间散布和类内散布的表示，它们的数学形式如公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n     S_{W}=\\sum_{i=1}^{N}(x^{c_{i}}-\\bar{x}^{c})(x^{c_{i}}-\\bar{x}^{c})^{T}\\\\\n    S_{B}=\\sum_{c=1}^{N_{c}}n_{c}(\\bar{x}^{c}-\\bar{x})(\\bar{x}^{c}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{1}</script><p>其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}$ 是所有样本的平均值，$x^{c_{i}}$ 是 $c_{th}$ 类中的 $i_{th}$ 样本。</p>\n<h2 id=\"Fisherface-vs-Eigenface\"><a href=\"#Fisherface-vs-Eigenface\" class=\"headerlink\" title=\"Fisherface vs Eigenface\"></a>Fisherface vs Eigenface</h2><p>Eigenface 和 Fisherface 在动机、目标函数、监督方法上是不同的，见下文讨论。</p>\n<p>Eigenface 旨在寻找线性投影后数据方差最大的投影方向，而 Fisherface 则通过最大化类间和类内分散之间的比率来寻找一条线，来有效区分不同类。</p>\n<p>Eigenface 和 Fisherface 的目标函数根据不同的动机，也有所不同。 Eigenface 的目标函数是公式(2)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{W^{T}W=1}{\\arg \\min}\\ \\  (W)^{T}CW \\ \\ with\\\\\n    C=\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\bar{x})(x_{i}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $C$ 是协方差矩阵，$\\bar{x}$ 是所有样本的平均值。</p>\n<p>Fisherface 的目标函数是最大化类间方差 $S_{B}$ 和类内方差 $S_{W}$ 的比率，见公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    W =\\arg \\max _{W}\\ \\frac{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{B}W_{pca} W\\right|}{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{W}W_{pca}W\\right|}=[w_{1},\\cdots,w_{m}]\\\\\n    \\text{s.t. }(W)^{T} S_{W} W=1.\n    \\end{gathered}\n\\end{equation}\\tag{3\n\n}</script><p>Eigenface 是一种无监督的维数算法，而 Fisherface 是有监督的。 Fisherface 与 Eigenface 相比具有以下优势：</p>\n<ul>\n<li>虽然 Eigenface 实现了更大的总散射，但 FLD 实现了更大的类间散射，因此简化了分类。</li>\n<li>Fisherface 可用于分类，而 Eigenface 不能。</li>\n</ul>\n<p>然而，Fisherface 只能将维度减少到类别数减 1，而 Eigenface 则没有这个限制。</p>\n<h2 id=\"Mathematical-Details\"><a href=\"#Mathematical-Details\" class=\"headerlink\" title=\"Mathematical Details\"></a>Mathematical Details</h2><p>拉格朗日方法用于解决方程中的优化问题公式(3)，请参见以下推导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\mathcal{L}=W^{T}W_{pca}^{T}S_{B}W_{pca}W-\\lambda W^{T}W_{pca}^{T}S_{W}W_{pca}W\\\\\n        \\frac{\\partial \\mathcal{L}}{\\partial W}=2\\left(W_{pca}^{T}S_{B}W_{pca}W-\\lambda W_{pca}^{T}S_{W}W_{pca}W\\right)=0\\\\\n        S_{W}^{-1}S_{B}W_{pca}W=\\lambda W_{pca}W.\n    \\end{gathered}\n\\end{equation}</script><p>此外，可以应用 SVD 或特征分解来解决上述问题。 选取$m$个最大特征值对应的特征向量形成$W$：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        S_{W}^{-1}S_{B}W_{pca}W_{i}=\\lambda_{i} W_{pca}W_{i}\\\\\n        sort(\\lambda_{1},\\cdots,\\lambda_{n})\\\\\n        W=[W_{n-m+1},\\cdots,W_{n}].\n    \\end{gathered}\n\\end{equation}</script><h1 id=\"Local-Discriminant-Embedding\"><a href=\"#Local-Discriminant-Embedding\" class=\"headerlink\" title=\"Local Discriminant Embedding\"></a>Local Discriminant Embedding</h1><p>在这里介绍三种LDE，最开始的LDE，2DLDE和Kernel LDE。</p>\n<h2 id=\"LDE\"><a href=\"#LDE\" class=\"headerlink\" title=\"LDE\"></a>LDE</h2><p>与 Eigenface 不同，LDE 中使用数据的局部关系和类关系来构建嵌入。 此外，LDE 没有 Eigenface 的限制。 在本节中，我们将详细介绍 LDE。<br>LDE 旨在保持内在的相邻关系，而不同类别的相邻点不再相互粘连。<br>在低维嵌入子空间中，如果相邻点具有相同的标签，LDE 希望保持相邻点靠近，而防止其他类的点进入邻域。 考虑到这两个方面，LDE 的目标函数为公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{V}{\\arg \\max}\\ \\ J(V)=\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}W_{ij}^{\\prime}\\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}w_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $V$ 是一个 $n\\times l$ 矩阵，$V$ 是线性投影 $\\textbf{z}=V^{T}x$。</p>\n<h2 id=\"2DLDE\"><a href=\"#2DLDE\" class=\"headerlink\" title=\"2DLDE\"></a>2DLDE</h2><p>受到少量训练数据的限制，无法准确近似底层流形。 2DLDE 尝试将图像（数据）视为矩阵，并根据矩阵形式解决子空间学习问题。 此外，当已知图像的变化是由translation, pitch或yaw引起时，2DLDE 比基于矢量的公式具有显着的优势。</p>\n<p>令 $\\{A_{i}|A_{i}\\in\\mathcal{R}^{n_{1}\\times n_{2}}\\}$ 为训练数据。 然后，我们修改了矩阵的 LDE，矩阵-向量乘法 $\\textbf{z}_{i}=V^{T}x_{i}$ 应改为双边形式 $B_{i}= L^{T}A_{i}R$，其中 $L\\in \\mathcal{R}^{n_{1}\\times l_{1}}$ 和 $R\\in \\mathcal{R}^{n_{ 2}\\times l_{2}}$ 将$A_{i}$ 转换成一个更小的矩阵$B_{i}\\in\\mathcal{R}^{l_{1}\\times l_{2}}$。 因此，目标函数公式(4)可以重写为公式(5)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{L,R}{\\arg \\max}\\ \\ Q(L, R)=\\sum_{i, j}\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} w_{i j}^{\\prime} \\\\\n    \\text {s.t. } \\sum\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} W_{i j}=1,\n    \\end{gathered}\n\\end{equation}\\tag{5}</script><p>其中 Frobenius 矩阵范数为 $|A|_{F}=(\\sum_{j,k}a_{j,k}^{2})^{\\frac{1}{2}}=tr( AA^{T})$。 通过使用拉格朗日乘子法和特征分解，通过迭代直到收敛得到$L$和$R$。 然后，我们通过测试点$\\bar{A}$计算$\\bar{B}=L^{T}\\bar{A}R$，找到它的最近邻$B_{i}$，使得$\\ |B_{i}=\\bar{B}|_{F}$，并将标签指定为 $\\bar{y}=y_{i}$。</p>\n<h2 id=\"Kernel-LDE\"><a href=\"#Kernel-LDE\" class=\"headerlink\" title=\"Kernel LDE\"></a>Kernel LDE</h2><p>受到线性学习算法有限分类能力的启发。 Kernel LDE 试图通过非线性映射将输入数据转换到更高维空间来提升分类性能。 因此，Kernel LDE 在处理非线性降维问题方面优于 LDE。</p>\n<p>假设非线性映射为$\\Phi:\\mathcal{R}^{n}\\rightarrow \\mathcal{F}$，$\\mathcal{F}$为特征空间。 因此，局部判别嵌入在 $\\mathcal{F}$ 中的投影方向 $v$ 是 $v=\\sum_{i}^{m}\\alpha_{i}\\Phi(x_{i})=\\sum_{ i}^{m}\\alpha_{i}k(x_{i},\\bar{x})$, $\\boldsymbol{\\alpha}_{i}$ 是膨胀系数。 目标函数(5)可以重写为公式(6)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n         \\underset{\\boldsymbol{\\alpha}}{\\arg \\max}\\ \\ U(\\boldsymbol{\\alpha})=\\boldsymbol{\\alpha}^{T} K\\left(D^{\\prime}-W^{\\prime}\\right) K \\boldsymbol{\\alpha} \\\\\n         \\text{s.t. }\\boldsymbol{\\alpha}^{T} K(D-W) K \\boldsymbol{\\alpha}=1,\n    \\end{gathered}\n\\end{equation}\\tag{6}</script><p>其中 $K$ 是一个核矩阵，$K_{i,j}=k(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots, \\alpha_{n}]^{T}$ 由膨胀系数组成。 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。</p>\n<h1 id=\"拓展LPP和NPE\"><a href=\"#拓展LPP和NPE\" class=\"headerlink\" title=\"拓展LPP和NPE\"></a>拓展LPP和NPE</h1><p>我们探讨了 LPP 是否可以扩展到2D和核函数方法。 此外，NPE 是对 Laplace Beltrami 算子的特征函数的另一种线性逼近。 因此，我们探索如何扩展 NPE，就像 LDE 对 LPP 所做的那样。</p>\n<h2 id=\"2DLPP\"><a href=\"#2DLPP\" class=\"headerlink\" title=\"2DLPP\"></a>2DLPP</h2><p>LPP 的目标函数是最小化重建误差，见公式(7)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}X)L(\\boldsymbol{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}X)D(\\boldsymbol{a}^{T}X)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{7}</script><p>根据公式(5)，我们可以把LPP的目标函数公式(7)变成公式(8)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{L,R}\\ \\ \\sum_{i,j}\\|L^{T}A_{i}R-L^{T}A_{j}R\\|^{2}W_{ij} \\\\\n        \\text{ s.t. } (L^{T}A_{i}R)D(L^{T}A_{i}R)^{T}=1.\n    \\end{gathered}\n\\end{equation}\\tag{8}</script><h2 id=\"Kernel-LPP\"><a href=\"#Kernel-LPP\" class=\"headerlink\" title=\"Kernel LPP\"></a>Kernel LPP</h2><p>假设$\\mathcal{F}$中的点积可以通过核函数$k(x_{1},x_{2})=\\Phi(x_{1})^{T}\\Phi(x_{ 2})$。 与公式(6)中的假设，我们可以重写 LPP 的目标函数公式(7)为公式(9)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X,\n    \\end{gathered}\n\\end{equation}\\tag{9}</script><p>其中 $K$ 是一个核矩阵，$K_{ij}=\\Phi(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots,\\ alpha_{n}]$ 由膨胀系数组成。</p>\n<h2 id=\"拓展NPE\"><a href=\"#拓展NPE\" class=\"headerlink\" title=\"拓展NPE\"></a>拓展NPE</h2><p>LPP 线性逼近 Laplace Beltrami 算子 $\\mathcal{L}$ 的特征函数，而 NPE 中的矩阵 $M$ 提供了 $\\mathcal{L}^{2}$ 的离散逼近。 NPE 的目标函数是最小化重构误差，见公式(10)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}\\|x_{i}-\\sum_{j}W_{ij}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}\\|y_{i}-\\sum_{j}W_{ij}y_{ij}\\|^2 \\\\\n        &=\\boldsymbol{y}^{T}M\\boldsymbol{y}=\\boldsymbol{a}^{T}XMX^{T}\\boldsymbol{a}\n    \\end{aligned}\n\\end{equation}\\tag{10}</script><script type=\"math/tex; mode=display\">\n\\text{ s.t. }  \\sum_{j}W_{ij}=1,\\ \\boldsymbol{a}^{T}XX^{T}\\boldsymbol{a}=1,\\ \\boldsymbol{y}=\\boldsymbol{a}^{T}X,</script><p>其中 $I=diag(1,\\cdots,1)$。 此外，我们探讨了 LDE 对 LPP 的作用并扩展了 NPE。 $\\mathcal{R}^{n}$中的数据点$\\{x_{1}\\}_{i=1}^{m}$可以改写为数据矩阵$X=[x_{1}， \\cdots,x_{m}]\\in\\mathcal{R}^{n\\times m}$. 然后，我们通过以下步骤扩展 NPE。</p>\n<ul>\n<li><p>构建邻域图：对于无向图 $G$ 和 $G^{\\prime}$，考虑同一类的每一对点 $x_{i}$ 和 $x_{j}$ ($y_{i}=y_{j}$ ) 和不同的类 ($y_{i}\\neq y_{j}$)，如果 $x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那就在$x_{i}$和$x_{j}$之间加一条边。</p>\n</li>\n<li><p>计算权重矩阵：对 $G$ 的矩阵 $W$ 加权</p>\n<script type=\"math/tex; mode=display\">\n     w_{ij}=e^{\\frac{-\\|x_{i}-x_{j}\\|^{2}}{t}}。</script><p>默认情况下，如果 $x_{i}$ 和 $x_{j}$ 没有连接，则 $w_{ij}=0$。 很明显，如此定义的 $W$ 是一个 $m \\times m$，稀疏对称矩阵。</p>\n</li>\n<li><p>找到对应于 $l$ 最大特征值的广义特征向量 $v_{1}, v_{2},\\cdots, v_{l}$，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n        XM^{\\prime}X^{T}v=\\lambda XMX^{T}v,\n\\end{equation}</script><p>其中 $M=(I-W)^{T}(I-W)$ 和 $M^{\\prime}=(I-W^{\\prime})^{T}(I-W^{\\prime})$ 是对称矩阵。 $x_{i}$ 的嵌入由 $z_{i}=V^{T}x_{i}$ 完成，其中 $V=[v_{1},\\cdots,v_{l}]$。</p>\n</li>\n</ul>\n<p>更进一步，上面的特征分解问题旨在保持相同标签的相邻点靠近，同时防止其他类的点进入邻域。 此外，NPE的目标函数可以变为公式(11)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W^{\\prime}) = \\sum_{i,j}\\|x_{i}-W_{ij}^{\\prime}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i,j}\\|V^{T}x_{i}-W_{ij}^{\\prime}V^{T}x_{ij}\\|^2 \\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-W_{ij}V^{T}x_{ij}\\|^2=1.\n    \\end{gathered}\n\\end{equation}</script><h1 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h1><p>这里主要讨论一下LDE与之前的算法的区别：</p>\n<p>Eigenface 旨在通过将数据在最大方差的方向投影来保持全局欧几里得结构，而 NPE 和 LPP 旨在通过最小化重构误差来保持局部流形结构。 此外，Eigenface、LPP 和 NPE 是无监督方法。 然而，Fisherface 和 LDE 是有监督的方法。 Fisherface 旨在通过最小化类内距离和类间距离之间的比率来寻找最有效的辨别方向。 此外，LDE 受到 Fisherface 的启发，并在 LPP 的基础上进行了改进。 因此，LDE 旨在通过最小化邻域中类内距离和类间距离之间的比率来保持内在的邻域关系。</p>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>主要是本节相关算法的代码，这里只贴LDE有关的，因为太多了。至于拓展LPP和NPE的，我之后应该会上传到github上：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy</span><br><span class=\"line\"><span class=\"keyword\">from</span> SubspaceLearning.Kernel <span class=\"keyword\">import</span> kernel</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造最经典的权重矩阵</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">construct_graph</span>(<span class=\"params\">data, label, k, t</span>):</span></span><br><span class=\"line\">    clusters = np.unique(label)</span><br><span class=\"line\">    class_i = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        class_i.append(label[:] == i)</span><br><span class=\"line\">    class_i = np.asarray(class_i)</span><br><span class=\"line\">    n = data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    W_full = np.zeros((n, n))</span><br><span class=\"line\">    SW = np.zeros((n, n))</span><br><span class=\"line\">    SB = np.zeros((n, n))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(i, n):</span><br><span class=\"line\">            dist = np.linalg.norm(data[i] - data[j])</span><br><span class=\"line\">            W_full[i][j] = math.exp(-(dist ** <span class=\"number\">2</span> / (t)))</span><br><span class=\"line\">            W_full[j][i] = W_full[i][j]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"comment\"># G within</span></span><br><span class=\"line\">        cl = label[i]</span><br><span class=\"line\">        sl = class_i[cl][:]  <span class=\"comment\"># same label :true or false</span></span><br><span class=\"line\">        slindex = np.array(np.where(sl == <span class=\"literal\">True</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># within</span></span><br><span class=\"line\">        nslindex = np.array(np.where(sl == <span class=\"literal\">False</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># between class</span></span><br><span class=\"line\">        W_sl = W_full[i][sl]</span><br><span class=\"line\">        W_nsl = W_full[i][~sl]</span><br><span class=\"line\">        index = np.argsort(W_sl)[<span class=\"number\">1</span>:k + <span class=\"number\">1</span>]</span><br><span class=\"line\">        nindex = np.argsort(W_nsl)[<span class=\"number\">0</span>:k]</span><br><span class=\"line\">        SW[i][slindex[index]] = W_full[i][slindex[index]]</span><br><span class=\"line\">        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> SW, SB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造01的权重矩阵</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">construct_graph_01</span>(<span class=\"params\">data, label, k</span>):</span></span><br><span class=\"line\">    clusters = np.unique(label)</span><br><span class=\"line\">    class_i = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        class_i.append(label[:] == i)</span><br><span class=\"line\">    class_i = np.asarray(class_i)</span><br><span class=\"line\">    n = data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    W_full = np.ones((n, n))</span><br><span class=\"line\">    SW = np.zeros((n, n))</span><br><span class=\"line\">    SB = np.zeros((n, n))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"comment\"># G within</span></span><br><span class=\"line\">        cl = label[i]</span><br><span class=\"line\">        sl = class_i[cl][:]  <span class=\"comment\"># same label :true or false</span></span><br><span class=\"line\">        slindex = np.array(np.where(sl == <span class=\"literal\">True</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># within</span></span><br><span class=\"line\">        nslindex = np.array(np.where(sl == <span class=\"literal\">False</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># between class</span></span><br><span class=\"line\">        W_sl = W_full[i][sl]</span><br><span class=\"line\">        W_nsl = W_full[i][~sl]</span><br><span class=\"line\">        index = np.argsort(W_sl)[<span class=\"number\">1</span>:k + <span class=\"number\">1</span>]</span><br><span class=\"line\">        nindex = np.argsort(W_nsl)[<span class=\"number\">0</span>:k]</span><br><span class=\"line\">        SW[i][slindex[index]] = W_full[i][slindex[index]]</span><br><span class=\"line\">        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> SW, SB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#计算拉普拉斯矩阵</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Lap</span>(<span class=\"params\">W</span>):</span></span><br><span class=\"line\">    D = np.diag(np.<span class=\"built_in\">sum</span>(W, axis=<span class=\"number\">0</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> D - W</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LDE</span>(<span class=\"params\">data, train_data, train_label, component, k, t</span>):</span></span><br><span class=\"line\">    SW, SB = construct_graph(train_data, train_label, k, t)</span><br><span class=\"line\">    SW = np.array((SW, SW.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LW = Lap(SW)</span><br><span class=\"line\">    SB = np.array((SB, SB.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LB = Lap(SB)</span><br><span class=\"line\">    X = train_data.T</span><br><span class=\"line\">    XLWXT = X.dot(LW).dot(X.T)</span><br><span class=\"line\">    XLBXT = X.dot(LB).dot(X.T)</span><br><span class=\"line\">    XLWXT = XLWXT + np.exp(-<span class=\"number\">5</span>) * np.eye(XLWXT.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.inv(XLWXT).dot(XLBXT)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)</span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[:(-component - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    data_ndim = np.dot(data, w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_ndim</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ddLDE</span>(<span class=\"params\">data, train_data, train_label, component1, component2, k, t</span>):</span></span><br><span class=\"line\">    n = train_data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    n1 = n2 = <span class=\"built_in\">int</span>(math.sqrt(train_data.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    L = np.ones((n1, component1))</span><br><span class=\"line\">    R = np.ones((n2, component2))</span><br><span class=\"line\">    SW, SB = construct_graph(train_data, train_label, k, t)</span><br><span class=\"line\">    <span class=\"comment\"># solve for R</span></span><br><span class=\"line\">    Rleft = np.zeros((n2, n2))</span><br><span class=\"line\">    Rright = np.zeros((n2, n2))</span><br><span class=\"line\">    Lleft = np.zeros((n2, n2))</span><br><span class=\"line\">    Lright = np.zeros((n2, n2))</span><br><span class=\"line\">    A = np.zeros((n, n, n1, n2))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">            A[i][j] = (train_data[i] - train_data[j]).reshape(n1, n2)</span><br><span class=\"line\">    <span class=\"comment\"># offset=10</span></span><br><span class=\"line\">    <span class=\"comment\"># while offset&gt;0.1:</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> z <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">2</span>):</span><br><span class=\"line\">        last_R = R.copy()</span><br><span class=\"line\">        last_L = L.copy()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">                ATLLTA = ((A[i][j]).T) @ (L) @ (L.T) @ (A[i][j])</span><br><span class=\"line\">                Rleft += SB[i][j] * (ATLLTA)</span><br><span class=\"line\">                Rright += SW[i][j] * (ATLLTA)</span><br><span class=\"line\">        eigVals, eigVects = scipy.linalg.eig(Rleft, Rright)</span><br><span class=\"line\">        eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">        eigValInd = eigValInd[:(-component2 - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">        R = eigVects[:, eigValInd]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">                ATRRTA = (A[i][j]) @ (R) @ (R.T) @ (A[i][j].T)</span><br><span class=\"line\">                Lleft += SB[i][j] * (ATRRTA)</span><br><span class=\"line\">                Lright += SW[i][j] * (ATRRTA)</span><br><span class=\"line\">        eigVals, eigVects = scipy.linalg.eig(Lleft, Lright)</span><br><span class=\"line\">        eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">        eigValInd = eigValInd[:(-component1 - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">        L = eigVects[:, eigValInd]</span><br><span class=\"line\">        offset = np.linalg.norm(np.squeeze(<span class=\"built_in\">abs</span>(last_R) - <span class=\"built_in\">abs</span>(R))) + np.linalg.norm(np.squeeze(np.<span class=\"built_in\">abs</span>(last_L) - <span class=\"built_in\">abs</span>(L)))</span><br><span class=\"line\">        <span class=\"comment\"># print(offset)</span></span><br><span class=\"line\">    B = L.T @ data.reshape(-<span class=\"number\">1</span>, n1, n2) @ R</span><br><span class=\"line\">    <span class=\"keyword\">return</span> B.reshape(data.shape[<span class=\"number\">0</span>], -<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">KernelLDE</span>(<span class=\"params\">data, train_data, train_label, ker, component, k,t</span>):</span></span><br><span class=\"line\">    SW, SB = construct_graph_01(train_data, train_label, k)</span><br><span class=\"line\">    SW = np.array((SW, SW.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LW = Lap(SW)</span><br><span class=\"line\">    SB = np.array((SB, SB.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LB = Lap(SB)</span><br><span class=\"line\">    K = kernel(ker)(train_data, train_data,t)</span><br><span class=\"line\">    KLWKT = K.T.dot(LW).dot(K)</span><br><span class=\"line\">    KLBKT = K.T.dot(LB).dot(K)</span><br><span class=\"line\">    KLWKT = KLWKT + np.exp(-<span class=\"number\">5</span>) * np.eye(KLWKT.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.inv(KLWKT).dot(KLBKT)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)</span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[:(-component - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    data_ndim = (kernel(ker)(data, train_data,t)) @ w</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_ndim</span><br></pre></td></tr></table></figure>\n<p>然后Kernel LDE可以有如下的：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">kernel</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, ker</span>):</span></span><br><span class=\"line\">        self.ker = ker</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 线性核函数</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear</span>(<span class=\"params\">self, x1, x2</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x1 @ x2.T</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 多项式核</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">poly</span>(<span class=\"params\">self, x1, x2</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (x1 @ x2.T) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 高斯核</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">RBF</span>(<span class=\"params\">self, x1, x2, t</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> math.exp(-(np.linalg.norm(x1 - x2)) / (t))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ori</span>(<span class=\"params\">self, x1, x2</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x1</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__call__</span>(<span class=\"params\">self, *args, **kwargs</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;linear&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.linear(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;poly&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.poly(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;RBF&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.RBF(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.ori(*args, **kwargs)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，主要是使用的数据集还是ORL人脸数据集，它由总共 400 张人脸图像组成，总共 40 人（每人 10 个样本）。</p>\n<p>使用九种方法用于对ORL进行降维。 降维后，我们对特征进行KNN（$k=3$）来计算分类精度。 LPP（LPP、2DLPP 和 Kernel LPP）和 LDE（LDE、2DLDE、Kernel LDE）的用户指定参数是分量 $d$、邻居 $k$ 和参数 $t$。</p>\n<p>更进一步，我们讨论了降维后维度对准确性的影响，参见图1：</p>\n<p><img src=\"/2022/01/16/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(6)-LDE/com.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 九种算法在ORL数据集上的实验结果。</center>\n此外，我们将讨论当 $Component$ 为 $20$ 时参数邻居 $k$ 和 参数 $t$ 的影响。 我们可视化这两个参数对准确性的影响，参见图2。\n<img src=\"/2022/01/16/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(6)-LDE/parameter.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LDE和LPP算法的影响。</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>当然实验结果不太对劲，估计还是参数有问题或者写丑了？由于那个年代的代码基本都是matlab的，我这里复现都是使用Python，有些优化应该不太到位，也没有去参考源码。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Local Discriminant Embedding and Its Variants（2005 CVPR）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述LDE，除此之外简要介绍Eigenfaces和Fisherfaces，然后会对LPP和NPE（见-子空间学习(4)-LPP&amp;NPE）进行一些拓展。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>信息处理中的许多问题都涉及某种形式的降维。因此，人们对降维算法很感兴趣。不同于 Eigenface旨在选择最大化所有类的总散射的投影，我们将介绍两种旨在最大化类间距离和类内距离的比率的子空间学习算法：Fisherfaces更关注数据的全局结构，而Local Discriminant Embedding (LDE) 更关注数据的局部关系和类的关系。然而，不关注局部关系使Fisherface从先验上有一定局限性。此外，LDE 通过保留同一类数据点的内在相邻关系来解决该问题，同时使不同类的相邻点不再相互粘连。在本报告中，我们尝试以数学方式解释 Fisherface 和 LDE 的主要思想，并像 LDE 一样扩展邻域保留嵌入 (NPE) 和局部保留投影 (LPP) 。此外，还包括对人脸识别的全面比较和广泛的实验，以探索 Fisherface 和 LDE 的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"Fisherfaces\"><a href=\"#Fisherfaces\" class=\"headerlink\" title=\"Fisherfaces\"></a>Fisherfaces</h1><h2 id=\"Fisher-criterion\"><a href=\"#Fisher-criterion\" class=\"headerlink\" title=\"Fisher criterion\"></a>Fisher criterion</h2><p>Fisher criterion是一个判别准则函数，由类间散点距离与类内散点距离的比率定义。 通过最大化这一标准，可以获得最优的判别投影轴。 在样本被投影到这个投影轴上之后，类内散布被最小化，类间散布被最大化。</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>Eigenfaces 旨在选择一种降维线性投影，使所有投影样本的分散度最大化。 因此，Eigenfaces 不能很好地处理非线性数据，并且没有考虑类间和类内散点之间的关系。Fisherfaces则考虑了类间和类内散点之间的关系。类间$S_{B}$和类内$S_{W}$散布矩阵是类间散布和类内散布的表示，它们的数学形式如公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n     S_{W}=\\sum_{i=1}^{N}(x^{c_{i}}-\\bar{x}^{c})(x^{c_{i}}-\\bar{x}^{c})^{T}\\\\\n    S_{B}=\\sum_{c=1}^{N_{c}}n_{c}(\\bar{x}^{c}-\\bar{x})(\\bar{x}^{c}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{1}</script><p>其中 $\\bar{x}^{c}$ 是 $c_{th}$ 类的平均值，$\\bar{x}$ 是所有样本的平均值，$x^{c_{i}}$ 是 $c_{th}$ 类中的 $i_{th}$ 样本。</p>\n<h2 id=\"Fisherface-vs-Eigenface\"><a href=\"#Fisherface-vs-Eigenface\" class=\"headerlink\" title=\"Fisherface vs Eigenface\"></a>Fisherface vs Eigenface</h2><p>Eigenface 和 Fisherface 在动机、目标函数、监督方法上是不同的，见下文讨论。</p>\n<p>Eigenface 旨在寻找线性投影后数据方差最大的投影方向，而 Fisherface 则通过最大化类间和类内分散之间的比率来寻找一条线，来有效区分不同类。</p>\n<p>Eigenface 和 Fisherface 的目标函数根据不同的动机，也有所不同。 Eigenface 的目标函数是公式(2)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{W^{T}W=1}{\\arg \\min}\\ \\  (W)^{T}CW \\ \\ with\\\\\n    C=\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\bar{x})(x_{i}-\\bar{x})^{T},\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $C$ 是协方差矩阵，$\\bar{x}$ 是所有样本的平均值。</p>\n<p>Fisherface 的目标函数是最大化类间方差 $S_{B}$ 和类内方差 $S_{W}$ 的比率，见公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    W =\\arg \\max _{W}\\ \\frac{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{B}W_{pca} W\\right|}{\\left|\\left(W\\right)^{T}W_{pca}^{T}S_{W}W_{pca}W\\right|}=[w_{1},\\cdots,w_{m}]\\\\\n    \\text{s.t. }(W)^{T} S_{W} W=1.\n    \\end{gathered}\n\\end{equation}\\tag{3\n\n}</script><p>Eigenface 是一种无监督的维数算法，而 Fisherface 是有监督的。 Fisherface 与 Eigenface 相比具有以下优势：</p>\n<ul>\n<li>虽然 Eigenface 实现了更大的总散射，但 FLD 实现了更大的类间散射，因此简化了分类。</li>\n<li>Fisherface 可用于分类，而 Eigenface 不能。</li>\n</ul>\n<p>然而，Fisherface 只能将维度减少到类别数减 1，而 Eigenface 则没有这个限制。</p>\n<h2 id=\"Mathematical-Details\"><a href=\"#Mathematical-Details\" class=\"headerlink\" title=\"Mathematical Details\"></a>Mathematical Details</h2><p>拉格朗日方法用于解决方程中的优化问题公式(3)，请参见以下推导：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\\nonumber\n    \\begin{gathered}\n        \\mathcal{L}=W^{T}W_{pca}^{T}S_{B}W_{pca}W-\\lambda W^{T}W_{pca}^{T}S_{W}W_{pca}W\\\\\n        \\frac{\\partial \\mathcal{L}}{\\partial W}=2\\left(W_{pca}^{T}S_{B}W_{pca}W-\\lambda W_{pca}^{T}S_{W}W_{pca}W\\right)=0\\\\\n        S_{W}^{-1}S_{B}W_{pca}W=\\lambda W_{pca}W.\n    \\end{gathered}\n\\end{equation}</script><p>此外，可以应用 SVD 或特征分解来解决上述问题。 选取$m$个最大特征值对应的特征向量形成$W$：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        S_{W}^{-1}S_{B}W_{pca}W_{i}=\\lambda_{i} W_{pca}W_{i}\\\\\n        sort(\\lambda_{1},\\cdots,\\lambda_{n})\\\\\n        W=[W_{n-m+1},\\cdots,W_{n}].\n    \\end{gathered}\n\\end{equation}</script><h1 id=\"Local-Discriminant-Embedding\"><a href=\"#Local-Discriminant-Embedding\" class=\"headerlink\" title=\"Local Discriminant Embedding\"></a>Local Discriminant Embedding</h1><p>在这里介绍三种LDE，最开始的LDE，2DLDE和Kernel LDE。</p>\n<h2 id=\"LDE\"><a href=\"#LDE\" class=\"headerlink\" title=\"LDE\"></a>LDE</h2><p>与 Eigenface 不同，LDE 中使用数据的局部关系和类关系来构建嵌入。 此外，LDE 没有 Eigenface 的限制。 在本节中，我们将详细介绍 LDE。<br>LDE 旨在保持内在的相邻关系，而不同类别的相邻点不再相互粘连。<br>在低维嵌入子空间中，如果相邻点具有相同的标签，LDE 希望保持相邻点靠近，而防止其他类的点进入邻域。 考虑到这两个方面，LDE 的目标函数为公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{V}{\\arg \\max}\\ \\ J(V)=\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}W_{ij}^{\\prime}\\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-V^{T}x_{j}\\|^{2}w_{ij}=1,\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $V$ 是一个 $n\\times l$ 矩阵，$V$ 是线性投影 $\\textbf{z}=V^{T}x$。</p>\n<h2 id=\"2DLDE\"><a href=\"#2DLDE\" class=\"headerlink\" title=\"2DLDE\"></a>2DLDE</h2><p>受到少量训练数据的限制，无法准确近似底层流形。 2DLDE 尝试将图像（数据）视为矩阵，并根据矩阵形式解决子空间学习问题。 此外，当已知图像的变化是由translation, pitch或yaw引起时，2DLDE 比基于矢量的公式具有显着的优势。</p>\n<p>令 $\\{A_{i}|A_{i}\\in\\mathcal{R}^{n_{1}\\times n_{2}}\\}$ 为训练数据。 然后，我们修改了矩阵的 LDE，矩阵-向量乘法 $\\textbf{z}_{i}=V^{T}x_{i}$ 应改为双边形式 $B_{i}= L^{T}A_{i}R$，其中 $L\\in \\mathcal{R}^{n_{1}\\times l_{1}}$ 和 $R\\in \\mathcal{R}^{n_{ 2}\\times l_{2}}$ 将$A_{i}$ 转换成一个更小的矩阵$B_{i}\\in\\mathcal{R}^{l_{1}\\times l_{2}}$。 因此，目标函数公式(4)可以重写为公式(5)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\underset{L,R}{\\arg \\max}\\ \\ Q(L, R)=\\sum_{i, j}\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} w_{i j}^{\\prime} \\\\\n    \\text {s.t. } \\sum\\left\\|L^{T} A_{i} R-L^{T} A_{j} R\\right\\|_{F}^{2} W_{i j}=1,\n    \\end{gathered}\n\\end{equation}\\tag{5}</script><p>其中 Frobenius 矩阵范数为 $|A|_{F}=(\\sum_{j,k}a_{j,k}^{2})^{\\frac{1}{2}}=tr( AA^{T})$。 通过使用拉格朗日乘子法和特征分解，通过迭代直到收敛得到$L$和$R$。 然后，我们通过测试点$\\bar{A}$计算$\\bar{B}=L^{T}\\bar{A}R$，找到它的最近邻$B_{i}$，使得$\\ |B_{i}=\\bar{B}|_{F}$，并将标签指定为 $\\bar{y}=y_{i}$。</p>\n<h2 id=\"Kernel-LDE\"><a href=\"#Kernel-LDE\" class=\"headerlink\" title=\"Kernel LDE\"></a>Kernel LDE</h2><p>受到线性学习算法有限分类能力的启发。 Kernel LDE 试图通过非线性映射将输入数据转换到更高维空间来提升分类性能。 因此，Kernel LDE 在处理非线性降维问题方面优于 LDE。</p>\n<p>假设非线性映射为$\\Phi:\\mathcal{R}^{n}\\rightarrow \\mathcal{F}$，$\\mathcal{F}$为特征空间。 因此，局部判别嵌入在 $\\mathcal{F}$ 中的投影方向 $v$ 是 $v=\\sum_{i}^{m}\\alpha_{i}\\Phi(x_{i})=\\sum_{ i}^{m}\\alpha_{i}k(x_{i},\\bar{x})$, $\\boldsymbol{\\alpha}_{i}$ 是膨胀系数。 目标函数(5)可以重写为公式(6)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n         \\underset{\\boldsymbol{\\alpha}}{\\arg \\max}\\ \\ U(\\boldsymbol{\\alpha})=\\boldsymbol{\\alpha}^{T} K\\left(D^{\\prime}-W^{\\prime}\\right) K \\boldsymbol{\\alpha} \\\\\n         \\text{s.t. }\\boldsymbol{\\alpha}^{T} K(D-W) K \\boldsymbol{\\alpha}=1,\n    \\end{gathered}\n\\end{equation}\\tag{6}</script><p>其中 $K$ 是一个核矩阵，$K_{i,j}=k(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots, \\alpha_{n}]^{T}$ 由膨胀系数组成。 $D$ ($D_{ii}=\\sum_{j}W_{ij}$) 是一个对角矩阵，其条目是 $W$ 的列（或行，因为 $W$ 是对称的）和。</p>\n<h1 id=\"拓展LPP和NPE\"><a href=\"#拓展LPP和NPE\" class=\"headerlink\" title=\"拓展LPP和NPE\"></a>拓展LPP和NPE</h1><p>我们探讨了 LPP 是否可以扩展到2D和核函数方法。 此外，NPE 是对 Laplace Beltrami 算子的特征函数的另一种线性逼近。 因此，我们探索如何扩展 NPE，就像 LDE 对 LPP 所做的那样。</p>\n<h2 id=\"2DLPP\"><a href=\"#2DLPP\" class=\"headerlink\" title=\"2DLPP\"></a>2DLPP</h2><p>LPP 的目标函数是最小化重建误差，见公式(7)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}X)L(\\boldsymbol{a}^{T}X)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}X)D(\\boldsymbol{a}^{T}X)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X.\n    \\end{gathered}\n\\end{equation}\\tag{7}</script><p>根据公式(5)，我们可以把LPP的目标函数公式(7)变成公式(8)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{L,R}\\ \\ \\sum_{i,j}\\|L^{T}A_{i}R-L^{T}A_{j}R\\|^{2}W_{ij} \\\\\n        \\text{ s.t. } (L^{T}A_{i}R)D(L^{T}A_{i}R)^{T}=1.\n    \\end{gathered}\n\\end{equation}\\tag{8}</script><h2 id=\"Kernel-LPP\"><a href=\"#Kernel-LPP\" class=\"headerlink\" title=\"Kernel LPP\"></a>Kernel LPP</h2><p>假设$\\mathcal{F}$中的点积可以通过核函数$k(x_{1},x_{2})=\\Phi(x_{1})^{T}\\Phi(x_{ 2})$。 与公式(6)中的假设，我们可以重写 LPP 的目标函数公式(7)为公式(9)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{Y^{T}}\\sum_{i,j}(y_{i}-y_{j})^{2}W_{ij}=2(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T} \\\\\n        \\text{ s.t. }(\\boldsymbol{a}^{T}K)L(\\boldsymbol{a}^{T}K)^{T}=1,\\ \\boldsymbol{y}^{T}=\\boldsymbol{a}^{T}X,\n    \\end{gathered}\n\\end{equation}\\tag{9}</script><p>其中 $K$ 是一个核矩阵，$K_{ij}=\\Phi(x_{i},x_{j})$, 并且 $\\boldsymbol{\\alpha}=[\\alpha_{1},\\cdots,\\ alpha_{n}]$ 由膨胀系数组成。</p>\n<h2 id=\"拓展NPE\"><a href=\"#拓展NPE\" class=\"headerlink\" title=\"拓展NPE\"></a>拓展NPE</h2><p>LPP 线性逼近 Laplace Beltrami 算子 $\\mathcal{L}$ 的特征函数，而 NPE 中的矩阵 $M$ 提供了 $\\mathcal{L}^{2}$ 的离散逼近。 NPE 的目标函数是最小化重构误差，见公式(10)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{aligned}\n        \\arg \\min_{W} E(W) &= \\sum_{i}\\|x_{i}-\\sum_{j}W_{ij}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) &= \\sum_{i}\\|y_{i}-\\sum_{j}W_{ij}y_{ij}\\|^2 \\\\\n        &=\\boldsymbol{y}^{T}M\\boldsymbol{y}=\\boldsymbol{a}^{T}XMX^{T}\\boldsymbol{a}\n    \\end{aligned}\n\\end{equation}\\tag{10}</script><script type=\"math/tex; mode=display\">\n\\text{ s.t. }  \\sum_{j}W_{ij}=1,\\ \\boldsymbol{a}^{T}XX^{T}\\boldsymbol{a}=1,\\ \\boldsymbol{y}=\\boldsymbol{a}^{T}X,</script><p>其中 $I=diag(1,\\cdots,1)$。 此外，我们探讨了 LDE 对 LPP 的作用并扩展了 NPE。 $\\mathcal{R}^{n}$中的数据点$\\{x_{1}\\}_{i=1}^{m}$可以改写为数据矩阵$X=[x_{1}， \\cdots,x_{m}]\\in\\mathcal{R}^{n\\times m}$. 然后，我们通过以下步骤扩展 NPE。</p>\n<ul>\n<li><p>构建邻域图：对于无向图 $G$ 和 $G^{\\prime}$，考虑同一类的每一对点 $x_{i}$ 和 $x_{j}$ ($y_{i}=y_{j}$ ) 和不同的类 ($y_{i}\\neq y_{j}$)，如果 $x_{j}$ 是$x_{i}$的$k$个最近邻居之一，那就在$x_{i}$和$x_{j}$之间加一条边。</p>\n</li>\n<li><p>计算权重矩阵：对 $G$ 的矩阵 $W$ 加权</p>\n<script type=\"math/tex; mode=display\">\n     w_{ij}=e^{\\frac{-\\|x_{i}-x_{j}\\|^{2}}{t}}。</script><p>默认情况下，如果 $x_{i}$ 和 $x_{j}$ 没有连接，则 $w_{ij}=0$。 很明显，如此定义的 $W$ 是一个 $m \\times m$，稀疏对称矩阵。</p>\n</li>\n<li><p>找到对应于 $l$ 最大特征值的广义特征向量 $v_{1}, v_{2},\\cdots, v_{l}$，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n        XM^{\\prime}X^{T}v=\\lambda XMX^{T}v,\n\\end{equation}</script><p>其中 $M=(I-W)^{T}(I-W)$ 和 $M^{\\prime}=(I-W^{\\prime})^{T}(I-W^{\\prime})$ 是对称矩阵。 $x_{i}$ 的嵌入由 $z_{i}=V^{T}x_{i}$ 完成，其中 $V=[v_{1},\\cdots,v_{l}]$。</p>\n</li>\n</ul>\n<p>更进一步，上面的特征分解问题旨在保持相同标签的相邻点靠近，同时防止其他类的点进入邻域。 此外，NPE的目标函数可以变为公式(11)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\arg \\min_{W} E(W^{\\prime}) = \\sum_{i,j}\\|x_{i}-W_{ij}^{\\prime}x_{ij}\\|^2 \\\\\n        \\arg \\min_{Y} \\Phi(Y) = \\sum_{i,j}\\|V^{T}x_{i}-W_{ij}^{\\prime}V^{T}x_{ij}\\|^2 \\\\\n        \\text{s.t. }\\sum_{i,j}\\|V^{T}x_{i}-W_{ij}V^{T}x_{ij}\\|^2=1.\n    \\end{gathered}\n\\end{equation}</script><h1 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h1><p>这里主要讨论一下LDE与之前的算法的区别：</p>\n<p>Eigenface 旨在通过将数据在最大方差的方向投影来保持全局欧几里得结构，而 NPE 和 LPP 旨在通过最小化重构误差来保持局部流形结构。 此外，Eigenface、LPP 和 NPE 是无监督方法。 然而，Fisherface 和 LDE 是有监督的方法。 Fisherface 旨在通过最小化类内距离和类间距离之间的比率来寻找最有效的辨别方向。 此外，LDE 受到 Fisherface 的启发，并在 LPP 的基础上进行了改进。 因此，LDE 旨在通过最小化邻域中类内距离和类间距离之间的比率来保持内在的邻域关系。</p>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>主要是本节相关算法的代码，这里只贴LDE有关的，因为太多了。至于拓展LPP和NPE的，我之后应该会上传到github上：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy</span><br><span class=\"line\"><span class=\"keyword\">from</span> SubspaceLearning.Kernel <span class=\"keyword\">import</span> kernel</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造最经典的权重矩阵</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">construct_graph</span>(<span class=\"params\">data, label, k, t</span>):</span></span><br><span class=\"line\">    clusters = np.unique(label)</span><br><span class=\"line\">    class_i = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        class_i.append(label[:] == i)</span><br><span class=\"line\">    class_i = np.asarray(class_i)</span><br><span class=\"line\">    n = data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    W_full = np.zeros((n, n))</span><br><span class=\"line\">    SW = np.zeros((n, n))</span><br><span class=\"line\">    SB = np.zeros((n, n))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(i, n):</span><br><span class=\"line\">            dist = np.linalg.norm(data[i] - data[j])</span><br><span class=\"line\">            W_full[i][j] = math.exp(-(dist ** <span class=\"number\">2</span> / (t)))</span><br><span class=\"line\">            W_full[j][i] = W_full[i][j]</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"comment\"># G within</span></span><br><span class=\"line\">        cl = label[i]</span><br><span class=\"line\">        sl = class_i[cl][:]  <span class=\"comment\"># same label :true or false</span></span><br><span class=\"line\">        slindex = np.array(np.where(sl == <span class=\"literal\">True</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># within</span></span><br><span class=\"line\">        nslindex = np.array(np.where(sl == <span class=\"literal\">False</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># between class</span></span><br><span class=\"line\">        W_sl = W_full[i][sl]</span><br><span class=\"line\">        W_nsl = W_full[i][~sl]</span><br><span class=\"line\">        index = np.argsort(W_sl)[<span class=\"number\">1</span>:k + <span class=\"number\">1</span>]</span><br><span class=\"line\">        nindex = np.argsort(W_nsl)[<span class=\"number\">0</span>:k]</span><br><span class=\"line\">        SW[i][slindex[index]] = W_full[i][slindex[index]]</span><br><span class=\"line\">        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> SW, SB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构造01的权重矩阵</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">construct_graph_01</span>(<span class=\"params\">data, label, k</span>):</span></span><br><span class=\"line\">    clusters = np.unique(label)</span><br><span class=\"line\">    class_i = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> clusters:</span><br><span class=\"line\">        class_i.append(label[:] == i)</span><br><span class=\"line\">    class_i = np.asarray(class_i)</span><br><span class=\"line\">    n = data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    W_full = np.ones((n, n))</span><br><span class=\"line\">    SW = np.zeros((n, n))</span><br><span class=\"line\">    SB = np.zeros((n, n))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"comment\"># G within</span></span><br><span class=\"line\">        cl = label[i]</span><br><span class=\"line\">        sl = class_i[cl][:]  <span class=\"comment\"># same label :true or false</span></span><br><span class=\"line\">        slindex = np.array(np.where(sl == <span class=\"literal\">True</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># within</span></span><br><span class=\"line\">        nslindex = np.array(np.where(sl == <span class=\"literal\">False</span>))[<span class=\"number\">0</span>, :]  <span class=\"comment\"># between class</span></span><br><span class=\"line\">        W_sl = W_full[i][sl]</span><br><span class=\"line\">        W_nsl = W_full[i][~sl]</span><br><span class=\"line\">        index = np.argsort(W_sl)[<span class=\"number\">1</span>:k + <span class=\"number\">1</span>]</span><br><span class=\"line\">        nindex = np.argsort(W_nsl)[<span class=\"number\">0</span>:k]</span><br><span class=\"line\">        SW[i][slindex[index]] = W_full[i][slindex[index]]</span><br><span class=\"line\">        SB[i][nslindex[nindex]] = W_full[i][nslindex[nindex]]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> SW, SB</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#计算拉普拉斯矩阵</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Lap</span>(<span class=\"params\">W</span>):</span></span><br><span class=\"line\">    D = np.diag(np.<span class=\"built_in\">sum</span>(W, axis=<span class=\"number\">0</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> D - W</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">LDE</span>(<span class=\"params\">data, train_data, train_label, component, k, t</span>):</span></span><br><span class=\"line\">    SW, SB = construct_graph(train_data, train_label, k, t)</span><br><span class=\"line\">    SW = np.array((SW, SW.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LW = Lap(SW)</span><br><span class=\"line\">    SB = np.array((SB, SB.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LB = Lap(SB)</span><br><span class=\"line\">    X = train_data.T</span><br><span class=\"line\">    XLWXT = X.dot(LW).dot(X.T)</span><br><span class=\"line\">    XLBXT = X.dot(LB).dot(X.T)</span><br><span class=\"line\">    XLWXT = XLWXT + np.exp(-<span class=\"number\">5</span>) * np.eye(XLWXT.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.inv(XLWXT).dot(XLBXT)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)</span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[:(-component - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    data_ndim = np.dot(data, w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_ndim</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ddLDE</span>(<span class=\"params\">data, train_data, train_label, component1, component2, k, t</span>):</span></span><br><span class=\"line\">    n = train_data.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    n1 = n2 = <span class=\"built_in\">int</span>(math.sqrt(train_data.shape[<span class=\"number\">1</span>]))</span><br><span class=\"line\">    L = np.ones((n1, component1))</span><br><span class=\"line\">    R = np.ones((n2, component2))</span><br><span class=\"line\">    SW, SB = construct_graph(train_data, train_label, k, t)</span><br><span class=\"line\">    <span class=\"comment\"># solve for R</span></span><br><span class=\"line\">    Rleft = np.zeros((n2, n2))</span><br><span class=\"line\">    Rright = np.zeros((n2, n2))</span><br><span class=\"line\">    Lleft = np.zeros((n2, n2))</span><br><span class=\"line\">    Lright = np.zeros((n2, n2))</span><br><span class=\"line\">    A = np.zeros((n, n, n1, n2))</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">            A[i][j] = (train_data[i] - train_data[j]).reshape(n1, n2)</span><br><span class=\"line\">    <span class=\"comment\"># offset=10</span></span><br><span class=\"line\">    <span class=\"comment\"># while offset&gt;0.1:</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> z <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">2</span>):</span><br><span class=\"line\">        last_R = R.copy()</span><br><span class=\"line\">        last_L = L.copy()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">                ATLLTA = ((A[i][j]).T) @ (L) @ (L.T) @ (A[i][j])</span><br><span class=\"line\">                Rleft += SB[i][j] * (ATLLTA)</span><br><span class=\"line\">                Rright += SW[i][j] * (ATLLTA)</span><br><span class=\"line\">        eigVals, eigVects = scipy.linalg.eig(Rleft, Rright)</span><br><span class=\"line\">        eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">        eigValInd = eigValInd[:(-component2 - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">        R = eigVects[:, eigValInd]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">                ATRRTA = (A[i][j]) @ (R) @ (R.T) @ (A[i][j].T)</span><br><span class=\"line\">                Lleft += SB[i][j] * (ATRRTA)</span><br><span class=\"line\">                Lright += SW[i][j] * (ATRRTA)</span><br><span class=\"line\">        eigVals, eigVects = scipy.linalg.eig(Lleft, Lright)</span><br><span class=\"line\">        eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">        eigValInd = eigValInd[:(-component1 - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">        L = eigVects[:, eigValInd]</span><br><span class=\"line\">        offset = np.linalg.norm(np.squeeze(<span class=\"built_in\">abs</span>(last_R) - <span class=\"built_in\">abs</span>(R))) + np.linalg.norm(np.squeeze(np.<span class=\"built_in\">abs</span>(last_L) - <span class=\"built_in\">abs</span>(L)))</span><br><span class=\"line\">        <span class=\"comment\"># print(offset)</span></span><br><span class=\"line\">    B = L.T @ data.reshape(-<span class=\"number\">1</span>, n1, n2) @ R</span><br><span class=\"line\">    <span class=\"keyword\">return</span> B.reshape(data.shape[<span class=\"number\">0</span>], -<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">KernelLDE</span>(<span class=\"params\">data, train_data, train_label, ker, component, k,t</span>):</span></span><br><span class=\"line\">    SW, SB = construct_graph_01(train_data, train_label, k)</span><br><span class=\"line\">    SW = np.array((SW, SW.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LW = Lap(SW)</span><br><span class=\"line\">    SB = np.array((SB, SB.T)).<span class=\"built_in\">max</span>(axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    LB = Lap(SB)</span><br><span class=\"line\">    K = kernel(ker)(train_data, train_data,t)</span><br><span class=\"line\">    KLWKT = K.T.dot(LW).dot(K)</span><br><span class=\"line\">    KLBKT = K.T.dot(LB).dot(K)</span><br><span class=\"line\">    KLWKT = KLWKT + np.exp(-<span class=\"number\">5</span>) * np.eye(KLWKT.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = scipy.linalg.inv(KLWKT).dot(KLBKT)</span><br><span class=\"line\">    eigVals, eigVects = np.linalg.eigh(T)</span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[:(-component - <span class=\"number\">1</span>):-<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    data_ndim = (kernel(ker)(data, train_data,t)) @ w</span><br><span class=\"line\">    <span class=\"keyword\">return</span> data_ndim</span><br></pre></td></tr></table></figure>\n<p>然后Kernel LDE可以有如下的：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">kernel</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, ker</span>):</span></span><br><span class=\"line\">        self.ker = ker</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 线性核函数</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">linear</span>(<span class=\"params\">self, x1, x2</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x1 @ x2.T</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 多项式核</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">poly</span>(<span class=\"params\">self, x1, x2</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> (x1 @ x2.T) ** <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 高斯核</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">RBF</span>(<span class=\"params\">self, x1, x2, t</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> math.exp(-(np.linalg.norm(x1 - x2)) / (t))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ori</span>(<span class=\"params\">self, x1, x2</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> x1</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__call__</span>(<span class=\"params\">self, *args, **kwargs</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;linear&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.linear(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;poly&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.poly(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;RBF&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.RBF(*args, **kwargs)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.ker == <span class=\"string\">&#x27;&#x27;</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.ori(*args, **kwargs)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，主要是使用的数据集还是ORL人脸数据集，它由总共 400 张人脸图像组成，总共 40 人（每人 10 个样本）。</p>\n<p>使用九种方法用于对ORL进行降维。 降维后，我们对特征进行KNN（$k=3$）来计算分类精度。 LPP（LPP、2DLPP 和 Kernel LPP）和 LDE（LDE、2DLDE、Kernel LDE）的用户指定参数是分量 $d$、邻居 $k$ 和参数 $t$。</p>\n<p>更进一步，我们讨论了降维后维度对准确性的影响，参见图1：</p>\n<p><img src=\"/2022/01/16/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(6)-LDE/com.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 九种算法在ORL数据集上的实验结果。</center>\n此外，我们将讨论当 $Component$ 为 $20$ 时参数邻居 $k$ 和 参数 $t$ 的影响。 我们可视化这两个参数对准确性的影响，参见图2。\n<img src=\"/2022/01/16/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(6)-LDE/parameter.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 参数变化对LDE和LPP算法的影响。</center>\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>当然实验结果不太对劲，估计还是参数有问题或者写丑了？由于那个年代的代码基本都是matlab的，我这里复现都是使用Python，有些优化应该不太到位，也没有去参考源码。</p>\n"},{"title":"子空间学习(7)-Spectral Clustering and Normalized Cuts","catalog":true,"date":"2022-01-17T04:24:17.000Z","subtitle":"Subspace Learning-Spectral Clustering and Normalized Cuts","top":14,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Normalized Cuts and Image Segmentation（2000 TPAMI）**和**On Spectral clustering analysis and an algorithm（2001 NIPS）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述N-cut和谱聚类。\n\n# 摘要：\n\n信息处理中的许多问题都涉及使用从数据派生的矩阵的特征向量进行某种形式的聚类点。 其中，N-cut和谱聚类在归一化切割准则的框架内。 N-cut 将聚类问题视为图划分问题，并提出了一种新颖的全局标准，即归一化割，用于对图进行分割。 归一化切割标准测量不同组之间的总差异以及组内的总相似度。 此外，谱聚类通过使用矩阵扰动理论中的工具将 K-means 与 N-cut 相结合，并在许多具有挑战性的聚类问题上取得了良好的实验结果。 在本报告中，我们尝试以数学方式解释 N-cut 和谱聚类的主要思想。 此外，还包括对 DUT-OMRON 数据集的实验，以探索 N-cut 和光谱聚类的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# 前景知识\n\n## 聚类\n\n聚类是将总体或数据点 $X=[x_{1},x_{2},\\cdots,x_{n}]$ 分成若干组 $U=\\{U_{1},...,U_{k}\\}$ ，使得同一组中的数据点更相似，而不同组之间的数据点不那么相似。 简而言之，目的是分离具有相似特征的组并将它们分配到集群中，请参见以下表示：\n$$\n{\\forall} x_{ji}\\in U_{j},\\ x_{ji_{1}}\\ and\\ x_{ji_{2}}\\ are\\ more\\ similar.\n$$\n\n## K-means\n\nK-means 聚类是一种矢量量化方法，旨在将 $n$ 个观测值划分为 $k$ 个聚类，其中每个观测值都属于具有最近聚类中心的聚类。 K-means 聚类旨在将 n 个观测值划分为 $k (\\leq n)$ 个集合 $S = \\{S_{1},S_{2},\\cdots,S_{k}\\}$ ，目标使最小化簇内平方和，即：\n$$\n\\begin{equation}\n    \\underset{S}{\\arg \\min}\\sum^{k}_{i=1}\\sum_{x\\in S_{i}}\\|x-\\mu_{i}\\|^{2}=\\underset{S}{\\arg \\min}\\sum_{i=1}^{k}|S_{i}|VarS_{i},\n\\end{equation}\n$$\n其中 $\\mu_{i}$ 是 $S_{i}$ 中点的平均值。\n\n## 割\n\n一个图 $G=(V,E)$ 可以被分割成两个不相交的集合（A 和 B），$A \\cup B = V$, $A \\cap B = \\emptyset$，主要通过简单地删除连接这两个集合的边部分。这两个部分之间的不同程度可以计算为已删除边缘的总权重。 在图论语言中，它被称为割：\n$$\n\\begin{equation}\n    cut(A,B)=\\sum_{u\\in A,v\\in B}w(u,v).\n\\end{equation}\n$$\n\n## 割与聚类\n\n聚类的直觉是根据它们的相似性将不同组中的点分开。 对于以相似度图的形式给出的数据，这个问题可以重述如下：我们希望找到一个图的分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此之间是不相似的） ，并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。\n\n# Normalized Cuts\n\n图的最优二分法是最小化割值（Min-cut）的二分法，这种划分的数量是指数级的。 此外，Min-cut 在划分小点集时具有不自然的偏差。\n\n为了避免这两个限制，提出了归一化切割（N-cut）作为两组之间分离的度量。 N-cut 不是查看连接两个分区的总边权重的值，而是将切割成本计算为图中所有节点的总边连接的一部分，见公式(1)：\n$$\n\\begin{equation}\n    Ncut(A,B)=\\frac{cut(A,B)}{assoc(A,V)}+\\frac{cut(A,B)}{assoc(B,V)},\n\\end{equation}\\tag{1}\n$$\n其中 $assoc(A,V)=\\sum_{u\\in A,t\\in V}w(u,t)$ 是从 A 中的节点到图中所有节点的总连接，$assoc(B,V )$ 的定义类似。\n\n## 目标函数\n\nN-cut 问题的目标函数是最小化归一化割，见公式(2)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{\\textbf{y}}{\\arg \\min}\\frac{\\textbf{y}^{T}(D-W)\\textbf{y}}{\\textbf{y}^{T}D\\textbf{y}}\\\\\n    \\text{s.t. }\\textbf{y}^{T}D\\textbf{1}=0.\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n我们通过求解广义特征值系统最小化目标函数公式(2)，\n$$\n\\begin{equation}\n    (D-W)\\textbf{y}=\\lambda D\\textbf{y}.\n\\end{equation}\\tag{3}\n$$\n此外，上述公式(2)和公式(3)可以归一化，公式(2)可以被重写为公式(4)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{z}{\\arg \\min}\\frac{z^{T}D^{-\\frac{1}{2}(D-W)D^{-\\frac{1}{2}}}z}{z^{T}z}\\\\\n    \\text{s.t. }z^{T}z_{0}=0,\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $z=D^{\\frac{1}{2}}\\textbf{y}$。 $z_{0}=D^{\\frac{1}{2}}\\textbf{1}$ 是公式(5)的特征向量，这个特征向量的特征值为 0，即公式(5)的最小特征向量。 此外，$D^{-\\frac{1}{2}}(DW)D^{-\\frac{1}{2}}$ 是对称正半定的，因为 $DW$，也称为拉普拉斯矩阵，是已知的，为半正定。 因此，我们可以通过求解广义特征值分解来最小化目标函数公式(4)，\n$$\n\\begin{equation}\n    D^{-\\frac{1}{2}}(D-W)D^{-\\frac{1}{2}}z=\\lambda z.\n\\end{equation}\\tag{5}\n$$\n需要额外注意的是我们最后使用的是第二小特征值对应的特征向量来对图进行分割，因为公式(5)中第二小的特征向量 $\\textbf{y}$ 仅逼近最优归一化割解，它恰好最小化了以下问题：\n$$\n\\inf _{y^{T} \\mathbf{D} 1=0} \\frac{\\sum_{i} \\sum_{j}(y(i)-y(j))^{2} w_{ij} }{\\sum_{i} y(i)^{2} \\mathbf{d}(i)}\n$$\n其中 $d(i)=D(i,i)$。 粗略地说，这迫使指示向量 $\\textbf{y}$ 对紧密耦合的节点 $i$ 和 $j$采用相似的值。\n\n## 时间复杂度\n\n为所有特征向量求解一个标准特征值问题需要整个算法的主要计算量。 它需要 $0(n^{3})$ 操作，其中 $n$ 是图中的节点数。 但是，$n$ 是图像中的像素数，因此复杂度 $0(n^{3})$ 是不切实际的。 因此，N-cut 通过称为 Lanczos 方法的特征求解器提高了计算效率，其中它的运行时间为 $O(mn)+O(mM(n))$，其中 $m$ 是所需的最大矩阵向量计算次数，$M(n)$ 是 $Ax$ 的矩阵向量计算的成本，其中 $A=D^{-\\frac{1}{2}}(DW)D^{-\\frac{ 1}{2}}$。 由于$W$ 是稀疏的，$A$ 和矩阵向量也是稀疏的计算量只是 $O(n)$。\n\n一行 $A$ 与向量 $x$ 的内积的成本是 $O(n)$。 将所有内容放在一起，每个矩阵向量计算都需要 $O(n)$ 次操作，且常数因子很小。\n\n## 缺点\n\n当数据不够统一且存在异常值时，N-cut 无法切出图中孤立节点的小集合。\n\n# 谱聚类\n\n## 谱聚类的不同理解\n\n谱是指数据的相似度矩阵的特征值进行降维。在数学中，矩阵的谱是其特征值的集合。更一般地，如果 $T:V\\rightarrow v$ 是任何有限维向量空间上的线性算子，则它的谱是标量 $\\lambda$ 的集合，使得 $T-\\lambda I$ 不可逆。\n\n在降维的观点上，谱聚类技术利用数据相似矩阵的谱（特征值）进行降维，然后再进行较少维度的聚类。\n\n在图分割的观点上，我们希望找到图的一个分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此不同）并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。\n\n在随机游走的观点上，谱聚类可以解释为试图找到图的一个分区，使得随机游走在同一个集群中停留很长时间，并且很少在集群之间跳跃。\n\n## 算法流程\n\n$X={x_{1},\\cdots,x_{n}}$ 在 $\\mathcal{R}^{l}$ 中，我们想要聚类成 $k$ 个子集。 谱聚类的算法步骤为算法1。\n\n<img src=\"子空间学习(7)-Spectral Clustering and Normalized Cuts\\algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 谱聚类算法流程。</center>\n\n### 不同的构造图的方式\n\nA Tutorial on Spectral Clustering（2007）总结了三种图：\n\n- $\\epsilon-neighborhood$ 图：所有成对距离小于 $\\epsilon$ 的点都已连接。 $\\epsilon-neighborhood$ 图被视为未加权图。\n- $k$-最近邻图：顶点$v_{i}$和顶点$v_{j}$是连接的$v_{j}$在$v_{i}$的$k$个最近邻居中 . 然而，这个定义导致了有向图，因为邻域关系不是对称的。\n- 全连接图：所有点都简单地相互连接，具有正相似性，我们通过 $s_{ij}=s(x_{i},x_{j})$ 对所有边进行加权。\n\n### 不同的图拉普拉斯构造\n\nA Tutorial on Spectral Clustering（2007）总结了三种图拉普拉斯：\n\n- 非归一化图拉普拉斯矩阵定义为：\n  $$\n  L=D-W\n  $$\n\n- 有两个矩阵在文献中被称为归一化图拉普拉斯算子。 我们用 $L_{sym}$ 表示第一个矩阵，因为它是一个对称矩阵，第二个用 $L_{rw}$ 表示，因为它与随机游走密切相关。 两个矩阵彼此密切相关，定义为：\n  $$\n       L_{sym}:=D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}=ID^{-\\frac{1}{2}}WD^{- \\frac{1}{2}}\n  $$\n  $$\n  L_{rw}:=D^{-1}L=I-D^{-1}W.\n  $$\n\n# 实验结果\n\n主要是本节相关算法的代码，贴一下NC的（采用稀疏矩阵计算，会快一点），SC的sklearn有库，然后由于可以自定义相似矩阵$W$也挺方便的：\n\n```python\nimport numpy as np\nimport math\nfrom scipy.sparse import csr_matrix\nimport scipy.sparse as sparse\n\ndef sparse_max(A, B):\n    Ag = (A > B).astype(int)\n    return Ag.multiply(A - B) + B\n\ndef construct_graph(img, radius, t1, t2):\n    n = img.shape[0] * img.shape[1]\n    W = np.zeros((n, n))\n    data = []\n    row = []\n    col = []\n    for i in range(img.shape[0]):\n        for j in range(img.shape[1]):\n            ori = i * img.shape[0] + j\n            for x in range(i - radius, i + radius + 1):\n                for y in range(j - radius, j + radius + 1):\n                    if x < 0 or x >= img.shape[0] or y < 0 or y >= img.shape[1] or (x == i and y == j):\n                        continue\n                    else:\n                        # if math.fabs(np.sum(np.abs(img[i][j]-img[x][y])))>0.15:\n                        #     continue\n                        value = math.exp(-((x - i) ** 2 + (y - j) ** 2) / t1) * math.exp(\n                            -(np.linalg.norm(img[i][j] - img[x][y]) ** 2) / t2)\n                        data.append(value)\n                        row.append(ori)\n                        col.append(x * img.shape[0] + y)\n    return csr_matrix((data, (row, col)), shape=(n, n))\n\ndef NC(img, neighboor, t1, t2):\n    W = construct_graph(img, neighboor, t1, t2)\n    W = sparse_max(W, W.T)\n    D = sparse.diags(np.asarray(W.sum(axis=0)).reshape(1, -1), [0])\n    L = D - W\n    D_1 = sparse.diags(1 / np.sqrt(np.asarray(W.sum(axis=0))).reshape(1, -1), [0])\n    T = D_1.dot(L).dot(D_1)\n    eigVals, eigVects = sparse.linalg.eigsh(T, k=2, which='SA')\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[1]\n    w = eigVects[:, eigValInd]\n    w = D_1.dot(w)\n    w = np.asarray(w)\n    return w.real\n```\n\nsklearn调用SC的库：\n\n```python\nfrom sklearn.cluster import SpectralClustering\n\ndef SC(img,cluster):\n    clustering=SpectralClustering(n_clusters=cluster)\n    return clustering.fit_predict(img)\n```\n\n展示一些实验结果，主要是使用的数据集是DUT-OMRON数据集，它由5168张自然图像组成。结果是NC的二分类结果和SC的四分类结果，用于图像分割。\n<img src=\"子空间学习(7)-Spectral Clustering and Normalized Cuts\\NC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. N-cut实现二分类图像分割。</center>\n<img src=\"子空间学习(7)-Spectral Clustering and Normalized Cuts\\SC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. SC实现四分类分割。</center>\n\n\n# 总结\n\n效果还不错，实现应该比较到位。\n\n\n\n ","source":"_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts.md","raw":"---\ntitle: 子空间学习(7)-Spectral Clustering and Normalized Cuts\ncatalog: true\ndate: 2022-01-17 12:24:17\nsubtitle: Subspace Learning-Spectral Clustering and Normalized Cuts\ntop: 14\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Normalized Cuts and Image Segmentation（2000 TPAMI）**和**On Spectral clustering analysis and an algorithm（2001 NIPS）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述N-cut和谱聚类。\n\n# 摘要：\n\n信息处理中的许多问题都涉及使用从数据派生的矩阵的特征向量进行某种形式的聚类点。 其中，N-cut和谱聚类在归一化切割准则的框架内。 N-cut 将聚类问题视为图划分问题，并提出了一种新颖的全局标准，即归一化割，用于对图进行分割。 归一化切割标准测量不同组之间的总差异以及组内的总相似度。 此外，谱聚类通过使用矩阵扰动理论中的工具将 K-means 与 N-cut 相结合，并在许多具有挑战性的聚类问题上取得了良好的实验结果。 在本报告中，我们尝试以数学方式解释 N-cut 和谱聚类的主要思想。 此外，还包括对 DUT-OMRON 数据集的实验，以探索 N-cut 和光谱聚类的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# 前景知识\n\n## 聚类\n\n聚类是将总体或数据点 $X=[x_{1},x_{2},\\cdots,x_{n}]$ 分成若干组 $U=\\{U_{1},...,U_{k}\\}$ ，使得同一组中的数据点更相似，而不同组之间的数据点不那么相似。 简而言之，目的是分离具有相似特征的组并将它们分配到集群中，请参见以下表示：\n$$\n{\\forall} x_{ji}\\in U_{j},\\ x_{ji_{1}}\\ and\\ x_{ji_{2}}\\ are\\ more\\ similar.\n$$\n\n## K-means\n\nK-means 聚类是一种矢量量化方法，旨在将 $n$ 个观测值划分为 $k$ 个聚类，其中每个观测值都属于具有最近聚类中心的聚类。 K-means 聚类旨在将 n 个观测值划分为 $k (\\leq n)$ 个集合 $S = \\{S_{1},S_{2},\\cdots,S_{k}\\}$ ，目标使最小化簇内平方和，即：\n$$\n\\begin{equation}\n    \\underset{S}{\\arg \\min}\\sum^{k}_{i=1}\\sum_{x\\in S_{i}}\\|x-\\mu_{i}\\|^{2}=\\underset{S}{\\arg \\min}\\sum_{i=1}^{k}|S_{i}|VarS_{i},\n\\end{equation}\n$$\n其中 $\\mu_{i}$ 是 $S_{i}$ 中点的平均值。\n\n## 割\n\n一个图 $G=(V,E)$ 可以被分割成两个不相交的集合（A 和 B），$A \\cup B = V$, $A \\cap B = \\emptyset$，主要通过简单地删除连接这两个集合的边部分。这两个部分之间的不同程度可以计算为已删除边缘的总权重。 在图论语言中，它被称为割：\n$$\n\\begin{equation}\n    cut(A,B)=\\sum_{u\\in A,v\\in B}w(u,v).\n\\end{equation}\n$$\n\n## 割与聚类\n\n聚类的直觉是根据它们的相似性将不同组中的点分开。 对于以相似度图的形式给出的数据，这个问题可以重述如下：我们希望找到一个图的分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此之间是不相似的） ，并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。\n\n# Normalized Cuts\n\n图的最优二分法是最小化割值（Min-cut）的二分法，这种划分的数量是指数级的。 此外，Min-cut 在划分小点集时具有不自然的偏差。\n\n为了避免这两个限制，提出了归一化切割（N-cut）作为两组之间分离的度量。 N-cut 不是查看连接两个分区的总边权重的值，而是将切割成本计算为图中所有节点的总边连接的一部分，见公式(1)：\n$$\n\\begin{equation}\n    Ncut(A,B)=\\frac{cut(A,B)}{assoc(A,V)}+\\frac{cut(A,B)}{assoc(B,V)},\n\\end{equation}\\tag{1}\n$$\n其中 $assoc(A,V)=\\sum_{u\\in A,t\\in V}w(u,t)$ 是从 A 中的节点到图中所有节点的总连接，$assoc(B,V )$ 的定义类似。\n\n## 目标函数\n\nN-cut 问题的目标函数是最小化归一化割，见公式(2)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{\\textbf{y}}{\\arg \\min}\\frac{\\textbf{y}^{T}(D-W)\\textbf{y}}{\\textbf{y}^{T}D\\textbf{y}}\\\\\n    \\text{s.t. }\\textbf{y}^{T}D\\textbf{1}=0.\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n我们通过求解广义特征值系统最小化目标函数公式(2)，\n$$\n\\begin{equation}\n    (D-W)\\textbf{y}=\\lambda D\\textbf{y}.\n\\end{equation}\\tag{3}\n$$\n此外，上述公式(2)和公式(3)可以归一化，公式(2)可以被重写为公式(4)，\n$$\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{z}{\\arg \\min}\\frac{z^{T}D^{-\\frac{1}{2}(D-W)D^{-\\frac{1}{2}}}z}{z^{T}z}\\\\\n    \\text{s.t. }z^{T}z_{0}=0,\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $z=D^{\\frac{1}{2}}\\textbf{y}$。 $z_{0}=D^{\\frac{1}{2}}\\textbf{1}$ 是公式(5)的特征向量，这个特征向量的特征值为 0，即公式(5)的最小特征向量。 此外，$D^{-\\frac{1}{2}}(DW)D^{-\\frac{1}{2}}$ 是对称正半定的，因为 $DW$，也称为拉普拉斯矩阵，是已知的，为半正定。 因此，我们可以通过求解广义特征值分解来最小化目标函数公式(4)，\n$$\n\\begin{equation}\n    D^{-\\frac{1}{2}}(D-W)D^{-\\frac{1}{2}}z=\\lambda z.\n\\end{equation}\\tag{5}\n$$\n需要额外注意的是我们最后使用的是第二小特征值对应的特征向量来对图进行分割，因为公式(5)中第二小的特征向量 $\\textbf{y}$ 仅逼近最优归一化割解，它恰好最小化了以下问题：\n$$\n\\inf _{y^{T} \\mathbf{D} 1=0} \\frac{\\sum_{i} \\sum_{j}(y(i)-y(j))^{2} w_{ij} }{\\sum_{i} y(i)^{2} \\mathbf{d}(i)}\n$$\n其中 $d(i)=D(i,i)$。 粗略地说，这迫使指示向量 $\\textbf{y}$ 对紧密耦合的节点 $i$ 和 $j$采用相似的值。\n\n## 时间复杂度\n\n为所有特征向量求解一个标准特征值问题需要整个算法的主要计算量。 它需要 $0(n^{3})$ 操作，其中 $n$ 是图中的节点数。 但是，$n$ 是图像中的像素数，因此复杂度 $0(n^{3})$ 是不切实际的。 因此，N-cut 通过称为 Lanczos 方法的特征求解器提高了计算效率，其中它的运行时间为 $O(mn)+O(mM(n))$，其中 $m$ 是所需的最大矩阵向量计算次数，$M(n)$ 是 $Ax$ 的矩阵向量计算的成本，其中 $A=D^{-\\frac{1}{2}}(DW)D^{-\\frac{ 1}{2}}$。 由于$W$ 是稀疏的，$A$ 和矩阵向量也是稀疏的计算量只是 $O(n)$。\n\n一行 $A$ 与向量 $x$ 的内积的成本是 $O(n)$。 将所有内容放在一起，每个矩阵向量计算都需要 $O(n)$ 次操作，且常数因子很小。\n\n## 缺点\n\n当数据不够统一且存在异常值时，N-cut 无法切出图中孤立节点的小集合。\n\n# 谱聚类\n\n## 谱聚类的不同理解\n\n谱是指数据的相似度矩阵的特征值进行降维。在数学中，矩阵的谱是其特征值的集合。更一般地，如果 $T:V\\rightarrow v$ 是任何有限维向量空间上的线性算子，则它的谱是标量 $\\lambda$ 的集合，使得 $T-\\lambda I$ 不可逆。\n\n在降维的观点上，谱聚类技术利用数据相似矩阵的谱（特征值）进行降维，然后再进行较少维度的聚类。\n\n在图分割的观点上，我们希望找到图的一个分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此不同）并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。\n\n在随机游走的观点上，谱聚类可以解释为试图找到图的一个分区，使得随机游走在同一个集群中停留很长时间，并且很少在集群之间跳跃。\n\n## 算法流程\n\n$X={x_{1},\\cdots,x_{n}}$ 在 $\\mathcal{R}^{l}$ 中，我们想要聚类成 $k$ 个子集。 谱聚类的算法步骤为算法1。\n\n<img src=\"子空间学习(7)-Spectral Clustering and Normalized Cuts\\algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 谱聚类算法流程。</center>\n\n### 不同的构造图的方式\n\nA Tutorial on Spectral Clustering（2007）总结了三种图：\n\n- $\\epsilon-neighborhood$ 图：所有成对距离小于 $\\epsilon$ 的点都已连接。 $\\epsilon-neighborhood$ 图被视为未加权图。\n- $k$-最近邻图：顶点$v_{i}$和顶点$v_{j}$是连接的$v_{j}$在$v_{i}$的$k$个最近邻居中 . 然而，这个定义导致了有向图，因为邻域关系不是对称的。\n- 全连接图：所有点都简单地相互连接，具有正相似性，我们通过 $s_{ij}=s(x_{i},x_{j})$ 对所有边进行加权。\n\n### 不同的图拉普拉斯构造\n\nA Tutorial on Spectral Clustering（2007）总结了三种图拉普拉斯：\n\n- 非归一化图拉普拉斯矩阵定义为：\n  $$\n  L=D-W\n  $$\n\n- 有两个矩阵在文献中被称为归一化图拉普拉斯算子。 我们用 $L_{sym}$ 表示第一个矩阵，因为它是一个对称矩阵，第二个用 $L_{rw}$ 表示，因为它与随机游走密切相关。 两个矩阵彼此密切相关，定义为：\n  $$\n       L_{sym}:=D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}=ID^{-\\frac{1}{2}}WD^{- \\frac{1}{2}}\n  $$\n  $$\n  L_{rw}:=D^{-1}L=I-D^{-1}W.\n  $$\n\n# 实验结果\n\n主要是本节相关算法的代码，贴一下NC的（采用稀疏矩阵计算，会快一点），SC的sklearn有库，然后由于可以自定义相似矩阵$W$也挺方便的：\n\n```python\nimport numpy as np\nimport math\nfrom scipy.sparse import csr_matrix\nimport scipy.sparse as sparse\n\ndef sparse_max(A, B):\n    Ag = (A > B).astype(int)\n    return Ag.multiply(A - B) + B\n\ndef construct_graph(img, radius, t1, t2):\n    n = img.shape[0] * img.shape[1]\n    W = np.zeros((n, n))\n    data = []\n    row = []\n    col = []\n    for i in range(img.shape[0]):\n        for j in range(img.shape[1]):\n            ori = i * img.shape[0] + j\n            for x in range(i - radius, i + radius + 1):\n                for y in range(j - radius, j + radius + 1):\n                    if x < 0 or x >= img.shape[0] or y < 0 or y >= img.shape[1] or (x == i and y == j):\n                        continue\n                    else:\n                        # if math.fabs(np.sum(np.abs(img[i][j]-img[x][y])))>0.15:\n                        #     continue\n                        value = math.exp(-((x - i) ** 2 + (y - j) ** 2) / t1) * math.exp(\n                            -(np.linalg.norm(img[i][j] - img[x][y]) ** 2) / t2)\n                        data.append(value)\n                        row.append(ori)\n                        col.append(x * img.shape[0] + y)\n    return csr_matrix((data, (row, col)), shape=(n, n))\n\ndef NC(img, neighboor, t1, t2):\n    W = construct_graph(img, neighboor, t1, t2)\n    W = sparse_max(W, W.T)\n    D = sparse.diags(np.asarray(W.sum(axis=0)).reshape(1, -1), [0])\n    L = D - W\n    D_1 = sparse.diags(1 / np.sqrt(np.asarray(W.sum(axis=0))).reshape(1, -1), [0])\n    T = D_1.dot(L).dot(D_1)\n    eigVals, eigVects = sparse.linalg.eigsh(T, k=2, which='SA')\n    eigValInd = np.argsort(eigVals)\n    eigValInd = eigValInd[1]\n    w = eigVects[:, eigValInd]\n    w = D_1.dot(w)\n    w = np.asarray(w)\n    return w.real\n```\n\nsklearn调用SC的库：\n\n```python\nfrom sklearn.cluster import SpectralClustering\n\ndef SC(img,cluster):\n    clustering=SpectralClustering(n_clusters=cluster)\n    return clustering.fit_predict(img)\n```\n\n展示一些实验结果，主要是使用的数据集是DUT-OMRON数据集，它由5168张自然图像组成。结果是NC的二分类结果和SC的四分类结果，用于图像分割。\n<img src=\"子空间学习(7)-Spectral Clustering and Normalized Cuts\\NC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. N-cut实现二分类图像分割。</center>\n<img src=\"子空间学习(7)-Spectral Clustering and Normalized Cuts\\SC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. SC实现四分类分割。</center>\n\n\n# 总结\n\n效果还不错，实现应该比较到位。\n\n\n\n ","slug":"子空间学习(7)-Spectral Clustering and Normalized Cuts","published":1,"updated":"2022-01-13T12:56:14.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxxn002k3oue5hxe3s4b","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Normalized Cuts and Image Segmentation（2000 TPAMI）</strong>和<strong>On Spectral clustering analysis and an algorithm（2001 NIPS）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述N-cut和谱聚类。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>信息处理中的许多问题都涉及使用从数据派生的矩阵的特征向量进行某种形式的聚类点。 其中，N-cut和谱聚类在归一化切割准则的框架内。 N-cut 将聚类问题视为图划分问题，并提出了一种新颖的全局标准，即归一化割，用于对图进行分割。 归一化切割标准测量不同组之间的总差异以及组内的总相似度。 此外，谱聚类通过使用矩阵扰动理论中的工具将 K-means 与 N-cut 相结合，并在许多具有挑战性的聚类问题上取得了良好的实验结果。 在本报告中，我们尝试以数学方式解释 N-cut 和谱聚类的主要思想。 此外，还包括对 DUT-OMRON 数据集的实验，以探索 N-cut 和光谱聚类的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"前景知识\"><a href=\"#前景知识\" class=\"headerlink\" title=\"前景知识\"></a>前景知识</h1><h2 id=\"聚类\"><a href=\"#聚类\" class=\"headerlink\" title=\"聚类\"></a>聚类</h2><p>聚类是将总体或数据点 $X=[x_{1},x_{2},\\cdots,x_{n}]$ 分成若干组 $U=\\{U_{1},…,U_{k}\\}$ ，使得同一组中的数据点更相似，而不同组之间的数据点不那么相似。 简而言之，目的是分离具有相似特征的组并将它们分配到集群中，请参见以下表示：</p>\n<script type=\"math/tex; mode=display\">\n{\\forall} x_{ji}\\in U_{j},\\ x_{ji_{1}}\\ and\\ x_{ji_{2}}\\ are\\ more\\ similar.</script><h2 id=\"K-means\"><a href=\"#K-means\" class=\"headerlink\" title=\"K-means\"></a>K-means</h2><p>K-means 聚类是一种矢量量化方法，旨在将 $n$ 个观测值划分为 $k$ 个聚类，其中每个观测值都属于具有最近聚类中心的聚类。 K-means 聚类旨在将 n 个观测值划分为 $k (\\leq n)$ 个集合 $S = \\{S_{1},S_{2},\\cdots,S_{k}\\}$ ，目标使最小化簇内平方和，即：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{S}{\\arg \\min}\\sum^{k}_{i=1}\\sum_{x\\in S_{i}}\\|x-\\mu_{i}\\|^{2}=\\underset{S}{\\arg \\min}\\sum_{i=1}^{k}|S_{i}|VarS_{i},\n\\end{equation}</script><p>其中 $\\mu_{i}$ 是 $S_{i}$ 中点的平均值。</p>\n<h2 id=\"割\"><a href=\"#割\" class=\"headerlink\" title=\"割\"></a>割</h2><p>一个图 $G=(V,E)$ 可以被分割成两个不相交的集合（A 和 B），$A \\cup B = V$, $A \\cap B = \\emptyset$，主要通过简单地删除连接这两个集合的边部分。这两个部分之间的不同程度可以计算为已删除边缘的总权重。 在图论语言中，它被称为割：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    cut(A,B)=\\sum_{u\\in A,v\\in B}w(u,v).\n\\end{equation}</script><h2 id=\"割与聚类\"><a href=\"#割与聚类\" class=\"headerlink\" title=\"割与聚类\"></a>割与聚类</h2><p>聚类的直觉是根据它们的相似性将不同组中的点分开。 对于以相似度图的形式给出的数据，这个问题可以重述如下：我们希望找到一个图的分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此之间是不相似的） ，并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。</p>\n<h1 id=\"Normalized-Cuts\"><a href=\"#Normalized-Cuts\" class=\"headerlink\" title=\"Normalized Cuts\"></a>Normalized Cuts</h1><p>图的最优二分法是最小化割值（Min-cut）的二分法，这种划分的数量是指数级的。 此外，Min-cut 在划分小点集时具有不自然的偏差。</p>\n<p>为了避免这两个限制，提出了归一化切割（N-cut）作为两组之间分离的度量。 N-cut 不是查看连接两个分区的总边权重的值，而是将切割成本计算为图中所有节点的总边连接的一部分，见公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    Ncut(A,B)=\\frac{cut(A,B)}{assoc(A,V)}+\\frac{cut(A,B)}{assoc(B,V)},\n\\end{equation}\\tag{1}</script><p>其中 $assoc(A,V)=\\sum_{u\\in A,t\\in V}w(u,t)$ 是从 A 中的节点到图中所有节点的总连接，$assoc(B,V )$ 的定义类似。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>N-cut 问题的目标函数是最小化归一化割，见公式(2)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{\\textbf{y}}{\\arg \\min}\\frac{\\textbf{y}^{T}(D-W)\\textbf{y}}{\\textbf{y}^{T}D\\textbf{y}}\\\\\n    \\text{s.t. }\\textbf{y}^{T}D\\textbf{1}=0.\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>我们通过求解广义特征值系统最小化目标函数公式(2)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    (D-W)\\textbf{y}=\\lambda D\\textbf{y}.\n\\end{equation}\\tag{3}</script><p>此外，上述公式(2)和公式(3)可以归一化，公式(2)可以被重写为公式(4)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{z}{\\arg \\min}\\frac{z^{T}D^{-\\frac{1}{2}(D-W)D^{-\\frac{1}{2}}}z}{z^{T}z}\\\\\n    \\text{s.t. }z^{T}z_{0}=0,\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $z=D^{\\frac{1}{2}}\\textbf{y}$。 $z_{0}=D^{\\frac{1}{2}}\\textbf{1}$ 是公式(5)的特征向量，这个特征向量的特征值为 0，即公式(5)的最小特征向量。 此外，$D^{-\\frac{1}{2}}(DW)D^{-\\frac{1}{2}}$ 是对称正半定的，因为 $DW$，也称为拉普拉斯矩阵，是已知的，为半正定。 因此，我们可以通过求解广义特征值分解来最小化目标函数公式(4)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    D^{-\\frac{1}{2}}(D-W)D^{-\\frac{1}{2}}z=\\lambda z.\n\\end{equation}\\tag{5}</script><p>需要额外注意的是我们最后使用的是第二小特征值对应的特征向量来对图进行分割，因为公式(5)中第二小的特征向量 $\\textbf{y}$ 仅逼近最优归一化割解，它恰好最小化了以下问题：</p>\n<script type=\"math/tex; mode=display\">\n\\inf _{y^{T} \\mathbf{D} 1=0} \\frac{\\sum_{i} \\sum_{j}(y(i)-y(j))^{2} w_{ij} }{\\sum_{i} y(i)^{2} \\mathbf{d}(i)}</script><p>其中 $d(i)=D(i,i)$。 粗略地说，这迫使指示向量 $\\textbf{y}$ 对紧密耦合的节点 $i$ 和 $j$采用相似的值。</p>\n<h2 id=\"时间复杂度\"><a href=\"#时间复杂度\" class=\"headerlink\" title=\"时间复杂度\"></a>时间复杂度</h2><p>为所有特征向量求解一个标准特征值问题需要整个算法的主要计算量。 它需要 $0(n^{3})$ 操作，其中 $n$ 是图中的节点数。 但是，$n$ 是图像中的像素数，因此复杂度 $0(n^{3})$ 是不切实际的。 因此，N-cut 通过称为 Lanczos 方法的特征求解器提高了计算效率，其中它的运行时间为 $O(mn)+O(mM(n))$，其中 $m$ 是所需的最大矩阵向量计算次数，$M(n)$ 是 $Ax$ 的矩阵向量计算的成本，其中 $A=D^{-\\frac{1}{2}}(DW)D^{-\\frac{ 1}{2}}$。 由于$W$ 是稀疏的，$A$ 和矩阵向量也是稀疏的计算量只是 $O(n)$。</p>\n<p>一行 $A$ 与向量 $x$ 的内积的成本是 $O(n)$。 将所有内容放在一起，每个矩阵向量计算都需要 $O(n)$ 次操作，且常数因子很小。</p>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>当数据不够统一且存在异常值时，N-cut 无法切出图中孤立节点的小集合。</p>\n<h1 id=\"谱聚类\"><a href=\"#谱聚类\" class=\"headerlink\" title=\"谱聚类\"></a>谱聚类</h1><h2 id=\"谱聚类的不同理解\"><a href=\"#谱聚类的不同理解\" class=\"headerlink\" title=\"谱聚类的不同理解\"></a>谱聚类的不同理解</h2><p>谱是指数据的相似度矩阵的特征值进行降维。在数学中，矩阵的谱是其特征值的集合。更一般地，如果 $T:V\\rightarrow v$ 是任何有限维向量空间上的线性算子，则它的谱是标量 $\\lambda$ 的集合，使得 $T-\\lambda I$ 不可逆。</p>\n<p>在降维的观点上，谱聚类技术利用数据相似矩阵的谱（特征值）进行降维，然后再进行较少维度的聚类。</p>\n<p>在图分割的观点上，我们希望找到图的一个分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此不同）并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。</p>\n<p>在随机游走的观点上，谱聚类可以解释为试图找到图的一个分区，使得随机游走在同一个集群中停留很长时间，并且很少在集群之间跳跃。</p>\n<h2 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h2><p>$X={x_{1},\\cdots,x_{n}}$ 在 $\\mathcal{R}^{l}$ 中，我们想要聚类成 $k$ 个子集。 谱聚类的算法步骤为算法1。</p>\n<p><img src=\"/2022/01/17/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(7)-Spectral%20Clustering%20and%20Normalized%20Cuts/algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 谱聚类算法流程。</center>\n\n<h3 id=\"不同的构造图的方式\"><a href=\"#不同的构造图的方式\" class=\"headerlink\" title=\"不同的构造图的方式\"></a>不同的构造图的方式</h3><p>A Tutorial on Spectral Clustering（2007）总结了三种图：</p>\n<ul>\n<li>$\\epsilon-neighborhood$ 图：所有成对距离小于 $\\epsilon$ 的点都已连接。 $\\epsilon-neighborhood$ 图被视为未加权图。</li>\n<li>$k$-最近邻图：顶点$v_{i}$和顶点$v_{j}$是连接的$v_{j}$在$v_{i}$的$k$个最近邻居中 . 然而，这个定义导致了有向图，因为邻域关系不是对称的。</li>\n<li>全连接图：所有点都简单地相互连接，具有正相似性，我们通过 $s_{ij}=s(x_{i},x_{j})$ 对所有边进行加权。</li>\n</ul>\n<h3 id=\"不同的图拉普拉斯构造\"><a href=\"#不同的图拉普拉斯构造\" class=\"headerlink\" title=\"不同的图拉普拉斯构造\"></a>不同的图拉普拉斯构造</h3><p>A Tutorial on Spectral Clustering（2007）总结了三种图拉普拉斯：</p>\n<ul>\n<li><p>非归一化图拉普拉斯矩阵定义为：</p>\n<script type=\"math/tex; mode=display\">\nL=D-W</script></li>\n<li><p>有两个矩阵在文献中被称为归一化图拉普拉斯算子。 我们用 $L_{sym}$ 表示第一个矩阵，因为它是一个对称矩阵，第二个用 $L_{rw}$ 表示，因为它与随机游走密切相关。 两个矩阵彼此密切相关，定义为：</p>\n<script type=\"math/tex; mode=display\">\n     L_{sym}:=D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}=ID^{-\\frac{1}{2}}WD^{- \\frac{1}{2}}</script><script type=\"math/tex; mode=display\">\nL_{rw}:=D^{-1}L=I-D^{-1}W.</script></li>\n</ul>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>主要是本节相关算法的代码，贴一下NC的（采用稀疏矩阵计算，会快一点），SC的sklearn有库，然后由于可以自定义相似矩阵$W$也挺方便的：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.sparse <span class=\"keyword\">import</span> csr_matrix</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy.sparse <span class=\"keyword\">as</span> sparse</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sparse_max</span>(<span class=\"params\">A, B</span>):</span></span><br><span class=\"line\">    Ag = (A &gt; B).astype(<span class=\"built_in\">int</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Ag.multiply(A - B) + B</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">construct_graph</span>(<span class=\"params\">img, radius, t1, t2</span>):</span></span><br><span class=\"line\">    n = img.shape[<span class=\"number\">0</span>] * img.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    W = np.zeros((n, n))</span><br><span class=\"line\">    data = []</span><br><span class=\"line\">    row = []</span><br><span class=\"line\">    col = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(img.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(img.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">            ori = i * img.shape[<span class=\"number\">0</span>] + j</span><br><span class=\"line\">            <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(i - radius, i + radius + <span class=\"number\">1</span>):</span><br><span class=\"line\">                <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(j - radius, j + radius + <span class=\"number\">1</span>):</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> x &lt; <span class=\"number\">0</span> <span class=\"keyword\">or</span> x &gt;= img.shape[<span class=\"number\">0</span>] <span class=\"keyword\">or</span> y &lt; <span class=\"number\">0</span> <span class=\"keyword\">or</span> y &gt;= img.shape[<span class=\"number\">1</span>] <span class=\"keyword\">or</span> (x == i <span class=\"keyword\">and</span> y == j):</span><br><span class=\"line\">                        <span class=\"keyword\">continue</span></span><br><span class=\"line\">                    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                        <span class=\"comment\"># if math.fabs(np.sum(np.abs(img[i][j]-img[x][y])))&gt;0.15:</span></span><br><span class=\"line\">                        <span class=\"comment\">#     continue</span></span><br><span class=\"line\">                        value = math.exp(-((x - i) ** <span class=\"number\">2</span> + (y - j) ** <span class=\"number\">2</span>) / t1) * math.exp(</span><br><span class=\"line\">                            -(np.linalg.norm(img[i][j] - img[x][y]) ** <span class=\"number\">2</span>) / t2)</span><br><span class=\"line\">                        data.append(value)</span><br><span class=\"line\">                        row.append(ori)</span><br><span class=\"line\">                        col.append(x * img.shape[<span class=\"number\">0</span>] + y)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> csr_matrix((data, (row, col)), shape=(n, n))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">NC</span>(<span class=\"params\">img, neighboor, t1, t2</span>):</span></span><br><span class=\"line\">    W = construct_graph(img, neighboor, t1, t2)</span><br><span class=\"line\">    W = sparse_max(W, W.T)</span><br><span class=\"line\">    D = sparse.diags(np.asarray(W.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>)).reshape(<span class=\"number\">1</span>, -<span class=\"number\">1</span>), [<span class=\"number\">0</span>])</span><br><span class=\"line\">    L = D - W</span><br><span class=\"line\">    D_1 = sparse.diags(<span class=\"number\">1</span> / np.sqrt(np.asarray(W.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>))).reshape(<span class=\"number\">1</span>, -<span class=\"number\">1</span>), [<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = D_1.dot(L).dot(D_1)</span><br><span class=\"line\">    eigVals, eigVects = sparse.linalg.eigsh(T, k=<span class=\"number\">2</span>, which=<span class=\"string\">&#x27;SA&#x27;</span>)</span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    w = D_1.dot(w)</span><br><span class=\"line\">    w = np.asarray(w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> w.real</span><br></pre></td></tr></table></figure>\n<p>sklearn调用SC的库：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> SpectralClustering</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">SC</span>(<span class=\"params\">img,cluster</span>):</span></span><br><span class=\"line\">    clustering=SpectralClustering(n_clusters=cluster)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> clustering.fit_predict(img)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，主要是使用的数据集是DUT-OMRON数据集，它由5168张自然图像组成。结果是NC的二分类结果和SC的四分类结果，用于图像分割。<br><img src=\"/2022/01/17/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(7)-Spectral%20Clustering%20and%20Normalized%20Cuts/NC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. N-cut实现二分类图像分割。</center>\n<img src=\"/2022/01/17/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(7)-Spectral%20Clustering%20and%20Normalized%20Cuts/SC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. SC实现四分类分割。</center>\n\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>效果还不错，实现应该比较到位。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Normalized Cuts and Image Segmentation（2000 TPAMI）</strong>和<strong>On Spectral clustering analysis and an algorithm（2001 NIPS）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述N-cut和谱聚类。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>信息处理中的许多问题都涉及使用从数据派生的矩阵的特征向量进行某种形式的聚类点。 其中，N-cut和谱聚类在归一化切割准则的框架内。 N-cut 将聚类问题视为图划分问题，并提出了一种新颖的全局标准，即归一化割，用于对图进行分割。 归一化切割标准测量不同组之间的总差异以及组内的总相似度。 此外，谱聚类通过使用矩阵扰动理论中的工具将 K-means 与 N-cut 相结合，并在许多具有挑战性的聚类问题上取得了良好的实验结果。 在本报告中，我们尝试以数学方式解释 N-cut 和谱聚类的主要思想。 此外，还包括对 DUT-OMRON 数据集的实验，以探索 N-cut 和光谱聚类的有效性。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"前景知识\"><a href=\"#前景知识\" class=\"headerlink\" title=\"前景知识\"></a>前景知识</h1><h2 id=\"聚类\"><a href=\"#聚类\" class=\"headerlink\" title=\"聚类\"></a>聚类</h2><p>聚类是将总体或数据点 $X=[x_{1},x_{2},\\cdots,x_{n}]$ 分成若干组 $U=\\{U_{1},…,U_{k}\\}$ ，使得同一组中的数据点更相似，而不同组之间的数据点不那么相似。 简而言之，目的是分离具有相似特征的组并将它们分配到集群中，请参见以下表示：</p>\n<script type=\"math/tex; mode=display\">\n{\\forall} x_{ji}\\in U_{j},\\ x_{ji_{1}}\\ and\\ x_{ji_{2}}\\ are\\ more\\ similar.</script><h2 id=\"K-means\"><a href=\"#K-means\" class=\"headerlink\" title=\"K-means\"></a>K-means</h2><p>K-means 聚类是一种矢量量化方法，旨在将 $n$ 个观测值划分为 $k$ 个聚类，其中每个观测值都属于具有最近聚类中心的聚类。 K-means 聚类旨在将 n 个观测值划分为 $k (\\leq n)$ 个集合 $S = \\{S_{1},S_{2},\\cdots,S_{k}\\}$ ，目标使最小化簇内平方和，即：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{S}{\\arg \\min}\\sum^{k}_{i=1}\\sum_{x\\in S_{i}}\\|x-\\mu_{i}\\|^{2}=\\underset{S}{\\arg \\min}\\sum_{i=1}^{k}|S_{i}|VarS_{i},\n\\end{equation}</script><p>其中 $\\mu_{i}$ 是 $S_{i}$ 中点的平均值。</p>\n<h2 id=\"割\"><a href=\"#割\" class=\"headerlink\" title=\"割\"></a>割</h2><p>一个图 $G=(V,E)$ 可以被分割成两个不相交的集合（A 和 B），$A \\cup B = V$, $A \\cap B = \\emptyset$，主要通过简单地删除连接这两个集合的边部分。这两个部分之间的不同程度可以计算为已删除边缘的总权重。 在图论语言中，它被称为割：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    cut(A,B)=\\sum_{u\\in A,v\\in B}w(u,v).\n\\end{equation}</script><h2 id=\"割与聚类\"><a href=\"#割与聚类\" class=\"headerlink\" title=\"割与聚类\"></a>割与聚类</h2><p>聚类的直觉是根据它们的相似性将不同组中的点分开。 对于以相似度图的形式给出的数据，这个问题可以重述如下：我们希望找到一个图的分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此之间是不相似的） ，并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。</p>\n<h1 id=\"Normalized-Cuts\"><a href=\"#Normalized-Cuts\" class=\"headerlink\" title=\"Normalized Cuts\"></a>Normalized Cuts</h1><p>图的最优二分法是最小化割值（Min-cut）的二分法，这种划分的数量是指数级的。 此外，Min-cut 在划分小点集时具有不自然的偏差。</p>\n<p>为了避免这两个限制，提出了归一化切割（N-cut）作为两组之间分离的度量。 N-cut 不是查看连接两个分区的总边权重的值，而是将切割成本计算为图中所有节点的总边连接的一部分，见公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    Ncut(A,B)=\\frac{cut(A,B)}{assoc(A,V)}+\\frac{cut(A,B)}{assoc(B,V)},\n\\end{equation}\\tag{1}</script><p>其中 $assoc(A,V)=\\sum_{u\\in A,t\\in V}w(u,t)$ 是从 A 中的节点到图中所有节点的总连接，$assoc(B,V )$ 的定义类似。</p>\n<h2 id=\"目标函数\"><a href=\"#目标函数\" class=\"headerlink\" title=\"目标函数\"></a>目标函数</h2><p>N-cut 问题的目标函数是最小化归一化割，见公式(2)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{\\textbf{y}}{\\arg \\min}\\frac{\\textbf{y}^{T}(D-W)\\textbf{y}}{\\textbf{y}^{T}D\\textbf{y}}\\\\\n    \\text{s.t. }\\textbf{y}^{T}D\\textbf{1}=0.\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>我们通过求解广义特征值系统最小化目标函数公式(2)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    (D-W)\\textbf{y}=\\lambda D\\textbf{y}.\n\\end{equation}\\tag{3}</script><p>此外，上述公式(2)和公式(3)可以归一化，公式(2)可以被重写为公式(4)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n    \\underset{z}{\\arg \\min}\\frac{z^{T}D^{-\\frac{1}{2}(D-W)D^{-\\frac{1}{2}}}z}{z^{T}z}\\\\\n    \\text{s.t. }z^{T}z_{0}=0,\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $z=D^{\\frac{1}{2}}\\textbf{y}$。 $z_{0}=D^{\\frac{1}{2}}\\textbf{1}$ 是公式(5)的特征向量，这个特征向量的特征值为 0，即公式(5)的最小特征向量。 此外，$D^{-\\frac{1}{2}}(DW)D^{-\\frac{1}{2}}$ 是对称正半定的，因为 $DW$，也称为拉普拉斯矩阵，是已知的，为半正定。 因此，我们可以通过求解广义特征值分解来最小化目标函数公式(4)，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    D^{-\\frac{1}{2}}(D-W)D^{-\\frac{1}{2}}z=\\lambda z.\n\\end{equation}\\tag{5}</script><p>需要额外注意的是我们最后使用的是第二小特征值对应的特征向量来对图进行分割，因为公式(5)中第二小的特征向量 $\\textbf{y}$ 仅逼近最优归一化割解，它恰好最小化了以下问题：</p>\n<script type=\"math/tex; mode=display\">\n\\inf _{y^{T} \\mathbf{D} 1=0} \\frac{\\sum_{i} \\sum_{j}(y(i)-y(j))^{2} w_{ij} }{\\sum_{i} y(i)^{2} \\mathbf{d}(i)}</script><p>其中 $d(i)=D(i,i)$。 粗略地说，这迫使指示向量 $\\textbf{y}$ 对紧密耦合的节点 $i$ 和 $j$采用相似的值。</p>\n<h2 id=\"时间复杂度\"><a href=\"#时间复杂度\" class=\"headerlink\" title=\"时间复杂度\"></a>时间复杂度</h2><p>为所有特征向量求解一个标准特征值问题需要整个算法的主要计算量。 它需要 $0(n^{3})$ 操作，其中 $n$ 是图中的节点数。 但是，$n$ 是图像中的像素数，因此复杂度 $0(n^{3})$ 是不切实际的。 因此，N-cut 通过称为 Lanczos 方法的特征求解器提高了计算效率，其中它的运行时间为 $O(mn)+O(mM(n))$，其中 $m$ 是所需的最大矩阵向量计算次数，$M(n)$ 是 $Ax$ 的矩阵向量计算的成本，其中 $A=D^{-\\frac{1}{2}}(DW)D^{-\\frac{ 1}{2}}$。 由于$W$ 是稀疏的，$A$ 和矩阵向量也是稀疏的计算量只是 $O(n)$。</p>\n<p>一行 $A$ 与向量 $x$ 的内积的成本是 $O(n)$。 将所有内容放在一起，每个矩阵向量计算都需要 $O(n)$ 次操作，且常数因子很小。</p>\n<h2 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h2><p>当数据不够统一且存在异常值时，N-cut 无法切出图中孤立节点的小集合。</p>\n<h1 id=\"谱聚类\"><a href=\"#谱聚类\" class=\"headerlink\" title=\"谱聚类\"></a>谱聚类</h1><h2 id=\"谱聚类的不同理解\"><a href=\"#谱聚类的不同理解\" class=\"headerlink\" title=\"谱聚类的不同理解\"></a>谱聚类的不同理解</h2><p>谱是指数据的相似度矩阵的特征值进行降维。在数学中，矩阵的谱是其特征值的集合。更一般地，如果 $T:V\\rightarrow v$ 是任何有限维向量空间上的线性算子，则它的谱是标量 $\\lambda$ 的集合，使得 $T-\\lambda I$ 不可逆。</p>\n<p>在降维的观点上，谱聚类技术利用数据相似矩阵的谱（特征值）进行降维，然后再进行较少维度的聚类。</p>\n<p>在图分割的观点上，我们希望找到图的一个分区，使得不同组之间的边具有非常低的权重（这意味着不同集群中的点彼此不同）并且组内的边具有较高的权重（这意味着同一簇内的点彼此相似）。</p>\n<p>在随机游走的观点上，谱聚类可以解释为试图找到图的一个分区，使得随机游走在同一个集群中停留很长时间，并且很少在集群之间跳跃。</p>\n<h2 id=\"算法流程\"><a href=\"#算法流程\" class=\"headerlink\" title=\"算法流程\"></a>算法流程</h2><p>$X={x_{1},\\cdots,x_{n}}$ 在 $\\mathcal{R}^{l}$ 中，我们想要聚类成 $k$ 个子集。 谱聚类的算法步骤为算法1。</p>\n<p><img src=\"/2022/01/17/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(7)-Spectral%20Clustering%20and%20Normalized%20Cuts/algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 谱聚类算法流程。</center>\n\n<h3 id=\"不同的构造图的方式\"><a href=\"#不同的构造图的方式\" class=\"headerlink\" title=\"不同的构造图的方式\"></a>不同的构造图的方式</h3><p>A Tutorial on Spectral Clustering（2007）总结了三种图：</p>\n<ul>\n<li>$\\epsilon-neighborhood$ 图：所有成对距离小于 $\\epsilon$ 的点都已连接。 $\\epsilon-neighborhood$ 图被视为未加权图。</li>\n<li>$k$-最近邻图：顶点$v_{i}$和顶点$v_{j}$是连接的$v_{j}$在$v_{i}$的$k$个最近邻居中 . 然而，这个定义导致了有向图，因为邻域关系不是对称的。</li>\n<li>全连接图：所有点都简单地相互连接，具有正相似性，我们通过 $s_{ij}=s(x_{i},x_{j})$ 对所有边进行加权。</li>\n</ul>\n<h3 id=\"不同的图拉普拉斯构造\"><a href=\"#不同的图拉普拉斯构造\" class=\"headerlink\" title=\"不同的图拉普拉斯构造\"></a>不同的图拉普拉斯构造</h3><p>A Tutorial on Spectral Clustering（2007）总结了三种图拉普拉斯：</p>\n<ul>\n<li><p>非归一化图拉普拉斯矩阵定义为：</p>\n<script type=\"math/tex; mode=display\">\nL=D-W</script></li>\n<li><p>有两个矩阵在文献中被称为归一化图拉普拉斯算子。 我们用 $L_{sym}$ 表示第一个矩阵，因为它是一个对称矩阵，第二个用 $L_{rw}$ 表示，因为它与随机游走密切相关。 两个矩阵彼此密切相关，定义为：</p>\n<script type=\"math/tex; mode=display\">\n     L_{sym}:=D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}=ID^{-\\frac{1}{2}}WD^{- \\frac{1}{2}}</script><script type=\"math/tex; mode=display\">\nL_{rw}:=D^{-1}L=I-D^{-1}W.</script></li>\n</ul>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>主要是本节相关算法的代码，贴一下NC的（采用稀疏矩阵计算，会快一点），SC的sklearn有库，然后由于可以自定义相似矩阵$W$也挺方便的：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.sparse <span class=\"keyword\">import</span> csr_matrix</span><br><span class=\"line\"><span class=\"keyword\">import</span> scipy.sparse <span class=\"keyword\">as</span> sparse</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sparse_max</span>(<span class=\"params\">A, B</span>):</span></span><br><span class=\"line\">    Ag = (A &gt; B).astype(<span class=\"built_in\">int</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> Ag.multiply(A - B) + B</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">construct_graph</span>(<span class=\"params\">img, radius, t1, t2</span>):</span></span><br><span class=\"line\">    n = img.shape[<span class=\"number\">0</span>] * img.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    W = np.zeros((n, n))</span><br><span class=\"line\">    data = []</span><br><span class=\"line\">    row = []</span><br><span class=\"line\">    col = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(img.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(img.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">            ori = i * img.shape[<span class=\"number\">0</span>] + j</span><br><span class=\"line\">            <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(i - radius, i + radius + <span class=\"number\">1</span>):</span><br><span class=\"line\">                <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(j - radius, j + radius + <span class=\"number\">1</span>):</span><br><span class=\"line\">                    <span class=\"keyword\">if</span> x &lt; <span class=\"number\">0</span> <span class=\"keyword\">or</span> x &gt;= img.shape[<span class=\"number\">0</span>] <span class=\"keyword\">or</span> y &lt; <span class=\"number\">0</span> <span class=\"keyword\">or</span> y &gt;= img.shape[<span class=\"number\">1</span>] <span class=\"keyword\">or</span> (x == i <span class=\"keyword\">and</span> y == j):</span><br><span class=\"line\">                        <span class=\"keyword\">continue</span></span><br><span class=\"line\">                    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">                        <span class=\"comment\"># if math.fabs(np.sum(np.abs(img[i][j]-img[x][y])))&gt;0.15:</span></span><br><span class=\"line\">                        <span class=\"comment\">#     continue</span></span><br><span class=\"line\">                        value = math.exp(-((x - i) ** <span class=\"number\">2</span> + (y - j) ** <span class=\"number\">2</span>) / t1) * math.exp(</span><br><span class=\"line\">                            -(np.linalg.norm(img[i][j] - img[x][y]) ** <span class=\"number\">2</span>) / t2)</span><br><span class=\"line\">                        data.append(value)</span><br><span class=\"line\">                        row.append(ori)</span><br><span class=\"line\">                        col.append(x * img.shape[<span class=\"number\">0</span>] + y)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> csr_matrix((data, (row, col)), shape=(n, n))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">NC</span>(<span class=\"params\">img, neighboor, t1, t2</span>):</span></span><br><span class=\"line\">    W = construct_graph(img, neighboor, t1, t2)</span><br><span class=\"line\">    W = sparse_max(W, W.T)</span><br><span class=\"line\">    D = sparse.diags(np.asarray(W.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>)).reshape(<span class=\"number\">1</span>, -<span class=\"number\">1</span>), [<span class=\"number\">0</span>])</span><br><span class=\"line\">    L = D - W</span><br><span class=\"line\">    D_1 = sparse.diags(<span class=\"number\">1</span> / np.sqrt(np.asarray(W.<span class=\"built_in\">sum</span>(axis=<span class=\"number\">0</span>))).reshape(<span class=\"number\">1</span>, -<span class=\"number\">1</span>), [<span class=\"number\">0</span>])</span><br><span class=\"line\">    T = D_1.dot(L).dot(D_1)</span><br><span class=\"line\">    eigVals, eigVects = sparse.linalg.eigsh(T, k=<span class=\"number\">2</span>, which=<span class=\"string\">&#x27;SA&#x27;</span>)</span><br><span class=\"line\">    eigValInd = np.argsort(eigVals)</span><br><span class=\"line\">    eigValInd = eigValInd[<span class=\"number\">1</span>]</span><br><span class=\"line\">    w = eigVects[:, eigValInd]</span><br><span class=\"line\">    w = D_1.dot(w)</span><br><span class=\"line\">    w = np.asarray(w)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> w.real</span><br></pre></td></tr></table></figure>\n<p>sklearn调用SC的库：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cluster <span class=\"keyword\">import</span> SpectralClustering</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">SC</span>(<span class=\"params\">img,cluster</span>):</span></span><br><span class=\"line\">    clustering=SpectralClustering(n_clusters=cluster)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> clustering.fit_predict(img)</span><br></pre></td></tr></table></figure>\n<p>展示一些实验结果，主要是使用的数据集是DUT-OMRON数据集，它由5168张自然图像组成。结果是NC的二分类结果和SC的四分类结果，用于图像分割。<br><img src=\"/2022/01/17/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(7)-Spectral%20Clustering%20and%20Normalized%20Cuts/NC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. N-cut实现二分类图像分割。</center>\n<img src=\"/2022/01/17/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(7)-Spectral%20Clustering%20and%20Normalized%20Cuts/SC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. SC实现四分类分割。</center>\n\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>效果还不错，实现应该比较到位。</p>\n"},{"title":"子空间学习(8)-Sparse Representation","catalog":true,"date":"2022-01-18T04:24:17.000Z","subtitle":"Subspace Learning-Sparse Representation","top":15,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Sparse Representation For Computer Vision and**\n> **Pattern Recognition（2010 PIEEE）**和**Dictionaries for Sparse Representation Modeling（2010 PIEEE）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Sparse Coding（稀疏编码）和Dictionary Learning（字典学习）。\n\n# 摘要：\n\n过去几十年在图像处理方面取得的大部分进展可归因于图像内容的稀疏和冗余表示建模以及这些模型的应用。 数据的稀疏和冗余表示建模假设能够将信号描述为来自预先指定的字典的几个原子的线性组合。 虽然字典学习采取了不同的路线，但将字典附加到它应该提供的一组示例上。 在本报告中，我们尝试探索稀疏编码和字典学习的主要思想，并讨论它们之间的区别。 此外，我们在图像去噪、图像去模糊和图像超分辨率等多个应用中重现了 K-SVD 的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# 字典学习\n\n字典学习是信号处理和机器学习的一个分支，旨在找到一个框架 $D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}] $（称为字典）。 在数学上，输入数据可以表示为：\n$$\nx=D\\alpha\n$$\n其中$\\alpha$ 是一个系数向量。 请注意，稀疏编码中的 $\\alpha$ 是稀疏的。\n\n# 稀疏编码\n\n稀疏编码是一种表示学习方法，旨在找到输入数据的稀疏表示 $X=[x_{1},\\cdots,x_{K}],x_{i}\\in \\mathcal{R}^{d }$ ，稀疏表示有很多元素，数据可以由元素本身的线性组合表示。 这些元素称为原子，它们组成一个字典$D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}]$。 在数学上，输入数据可以表示为：\n$$\nx=D\\alpha \\tag{1}\n$$\n其中$\\alpha$ 是稀疏系数向量。\n\n## $l_{0}$和$l_{1}$范数的稀疏编码\n\n基于 L0-norm 和 L1-norm 的目标函数是公式(2)和公式(3)：\n$$\n\\begin{equation}\n    (\\alpha_{0},e_{0})=\\arg \\min \\|\\alpha\\|_{0}+\\|e\\|_{0} \\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{2}\n$$\n其中 $\\mathcal{l}^{0}$ 范数 $\\|\\cdot\\|$ 计算向量中非零的数量。 而$\\alpha=[0,\\cdots,0,\\alpha_{i}^{T},0,\\cdots,0]^{T}\\in \\mathcal{R}^{N}$是一个系数向量，除了与第 i 个类相关的条目外，其条目均为零。\n$$\n\\begin{equation}\n    \\min \\|\\alpha\\|_{1}+\\|e\\|_{1}\\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{3}\n$$\n其中$\\|\\alpha\\|_{1}=\\sum_{i}|\\alpha_{i}|$。\n\n对于数据 $x$，我们可以将 $x$ 表示为字典 $D$ 中原子的线性组合，如 $x=D\\alpha$。 当解决像公式(1)这样的稀疏编码问题时，我们将得到向量 $\\alpha$ 的许多解。 当我们添加 L0-norm 和 L1-norm 时，$\\alpha$ 将成为一个稀疏向量。 因此，我们可以稀疏地表示数据 $x$。\n\n## 不同的稀疏编码的区别\n\nL0-norm 和 L1-norm 的主要区别在于目标函数的不同表示。 更具体地说，L0 范数计算一个向量的非零元素的总数（见公式(4)），而 L1 范数是空间中向量每个元素的大小之和，见公式(5)。\n$$\n\\begin{equation}\n    \\|e\\|_{0}=\\sum_{1}^{K}x_{i}^{0}.\n\\end{equation}\\tag{4}\n$$\n\n$$\n\\begin{equation}\n    \\|e\\|_{1}=\\sum_{1}^{K}x_{i}.\n\\end{equation}\\tag{5}\n$$\n\n# 应用\n\n论文中主要介绍了Image Reconstruction（图像重建），Image Deblurring（图像去噪，可能包含在前面的？），Superresolution（图像超分），Learning to Sense等。每种应用都有一些基本的目标函数和任务描述，这里我不多提了，可以更多地关注原文。\n\n# 实验结果\n\n为了更直观地理解稀疏编码和字典学习，K-SVD 被应用于以下应用：图像去噪、图像去模糊、图像修复和图像超分辨率。\n\n评价标准采用<u>Peak signal-to-noise ratio（PSNR）</u>，在数据集上进行实验后，我们可视化了 K-SVD 在图像去噪、图像去模糊、图像修复和图像超分辨率方面的性能。 其中，图像超分辨率是有监督训练的，图像去噪、图像去模糊和图像修复是无监督训练的。 进一步，结果如图1，图2。\n\n主要是本节相关算法的代码，贴一下KVD做图像去噪的，注意如果是彩色图，KSVD要在每个通道上都使用一次：\n\n```python\nimport numpy as np\nfrom sklearn import linear_model\n\ndef KSVD(Y, dict_size,\n         max_iter=20,\n         sparse_rate=0.1,\n         tolerance=1e-10):\n    assert (dict_size <= Y.shape[1])\n\n    def dict_update(y, d, x):\n        assert (d.shape[1] == x.shape[0])\n\n        for i in range(x.shape[0]):\n            index = np.where(np.abs(x[i, :]) > 1e-7)[0]\n\n            if len(index) == 0:\n                continue\n\n            d[:, i] = 0\n            r = (y - np.dot(d, x))[:, index]\n            u, s, v = np.linalg.svd(r, full_matrices=False)\n            d[:, i] = u[:, 0]\n            for j, k in enumerate(index):\n                x[i, k] = s[0] * v[0, j]\n        return d, x\n\n    # initialize dictionary\n    if dict_size > Y.shape[0]:\n        dic = Y[:, np.random.choice(Y.shape[1], dict_size, replace=False)]\n    else:\n        u, s, v = np.linalg.svd(Y)\n        dic = u[:, :dict_size]\n\n    print('dict shape:', dic.shape)\n\n    n_nonzero_coefs_each_code = int(sparse_rate * dict_size) if int(sparse_rate * dict_size) > 0 else 1\n    print(n_nonzero_coefs_each_code)\n    for i in range(max_iter):\n        x = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)\n        e = np.linalg.norm(Y - dic @ x)\n        if e < tolerance:\n            break\n        dict_update(Y, dic, x)\n\n    sparse_code = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)\n\n    return dic, sparse_code\n\n#读取自己的带噪声的图片\n    #imgR = img_with_noise[:,:,0]\n    #imgG = img_with_noise[:,:,1]\n    #imgB = img_with_noise[:,:,2]\n    #dictionaryR, sparsecodeR = KSVD(imgR,size,max_iter=200)\n    #dictionaryG, sparsecodeG = KSVD(imgG,size,max_iter=200)\n    #dictionaryB, sparsecodeB = KSVD(imgB,size,max_iter=200)\n    #img_reconstructedR=dictionaryR @ sparsecodeR\n    #img_reconstructedG=dictionaryG @ sparsecodeG\n    #img_reconstructedB=dictionaryB @ sparsecodeB\n    #img_reconstructed = np.stack((img_reconstructedR, img_reconstructedG, img_reconstructedB), axis=2)#去噪后的图片\n```\n\n由于KSVD的四个实验里的三个实验是无监督的，所以效果不太好，PSNR也只有个位数，目测KSVD应该用于有监督会比较好。\n<img src=\"子空间学习(8)-Sparse Representation\\Image_debluring.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. KSVD图像去模糊。</center>\n<img src=\"子空间学习(8)-Sparse Representation\\inpainting_yiding.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. KSVD图片重建。</center>\n\n\n# 总结\n\nKSVD采用有监督做应该会比较好，本次读的两篇论文偏综述，对算法实现细节的描述不多。\n\n\n\n ","source":"_posts/子空间学习(8)-Sparse Representation.md","raw":"---\ntitle: 子空间学习(8)-Sparse Representation\ncatalog: true\ndate: 2022-01-18 12:24:17\nsubtitle: Subspace Learning-Sparse Representation\ntop: 15\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Sparse Representation For Computer Vision and**\n> **Pattern Recognition（2010 PIEEE）**和**Dictionaries for Sparse Representation Modeling（2010 PIEEE）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Sparse Coding（稀疏编码）和Dictionary Learning（字典学习）。\n\n# 摘要：\n\n过去几十年在图像处理方面取得的大部分进展可归因于图像内容的稀疏和冗余表示建模以及这些模型的应用。 数据的稀疏和冗余表示建模假设能够将信号描述为来自预先指定的字典的几个原子的线性组合。 虽然字典学习采取了不同的路线，但将字典附加到它应该提供的一组示例上。 在本报告中，我们尝试探索稀疏编码和字典学习的主要思想，并讨论它们之间的区别。 此外，我们在图像去噪、图像去模糊和图像超分辨率等多个应用中重现了 K-SVD 的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# 字典学习\n\n字典学习是信号处理和机器学习的一个分支，旨在找到一个框架 $D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}] $（称为字典）。 在数学上，输入数据可以表示为：\n$$\nx=D\\alpha\n$$\n其中$\\alpha$ 是一个系数向量。 请注意，稀疏编码中的 $\\alpha$ 是稀疏的。\n\n# 稀疏编码\n\n稀疏编码是一种表示学习方法，旨在找到输入数据的稀疏表示 $X=[x_{1},\\cdots,x_{K}],x_{i}\\in \\mathcal{R}^{d }$ ，稀疏表示有很多元素，数据可以由元素本身的线性组合表示。 这些元素称为原子，它们组成一个字典$D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}]$。 在数学上，输入数据可以表示为：\n$$\nx=D\\alpha \\tag{1}\n$$\n其中$\\alpha$ 是稀疏系数向量。\n\n## $l_{0}$和$l_{1}$范数的稀疏编码\n\n基于 L0-norm 和 L1-norm 的目标函数是公式(2)和公式(3)：\n$$\n\\begin{equation}\n    (\\alpha_{0},e_{0})=\\arg \\min \\|\\alpha\\|_{0}+\\|e\\|_{0} \\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{2}\n$$\n其中 $\\mathcal{l}^{0}$ 范数 $\\|\\cdot\\|$ 计算向量中非零的数量。 而$\\alpha=[0,\\cdots,0,\\alpha_{i}^{T},0,\\cdots,0]^{T}\\in \\mathcal{R}^{N}$是一个系数向量，除了与第 i 个类相关的条目外，其条目均为零。\n$$\n\\begin{equation}\n    \\min \\|\\alpha\\|_{1}+\\|e\\|_{1}\\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{3}\n$$\n其中$\\|\\alpha\\|_{1}=\\sum_{i}|\\alpha_{i}|$。\n\n对于数据 $x$，我们可以将 $x$ 表示为字典 $D$ 中原子的线性组合，如 $x=D\\alpha$。 当解决像公式(1)这样的稀疏编码问题时，我们将得到向量 $\\alpha$ 的许多解。 当我们添加 L0-norm 和 L1-norm 时，$\\alpha$ 将成为一个稀疏向量。 因此，我们可以稀疏地表示数据 $x$。\n\n## 不同的稀疏编码的区别\n\nL0-norm 和 L1-norm 的主要区别在于目标函数的不同表示。 更具体地说，L0 范数计算一个向量的非零元素的总数（见公式(4)），而 L1 范数是空间中向量每个元素的大小之和，见公式(5)。\n$$\n\\begin{equation}\n    \\|e\\|_{0}=\\sum_{1}^{K}x_{i}^{0}.\n\\end{equation}\\tag{4}\n$$\n\n$$\n\\begin{equation}\n    \\|e\\|_{1}=\\sum_{1}^{K}x_{i}.\n\\end{equation}\\tag{5}\n$$\n\n# 应用\n\n论文中主要介绍了Image Reconstruction（图像重建），Image Deblurring（图像去噪，可能包含在前面的？），Superresolution（图像超分），Learning to Sense等。每种应用都有一些基本的目标函数和任务描述，这里我不多提了，可以更多地关注原文。\n\n# 实验结果\n\n为了更直观地理解稀疏编码和字典学习，K-SVD 被应用于以下应用：图像去噪、图像去模糊、图像修复和图像超分辨率。\n\n评价标准采用<u>Peak signal-to-noise ratio（PSNR）</u>，在数据集上进行实验后，我们可视化了 K-SVD 在图像去噪、图像去模糊、图像修复和图像超分辨率方面的性能。 其中，图像超分辨率是有监督训练的，图像去噪、图像去模糊和图像修复是无监督训练的。 进一步，结果如图1，图2。\n\n主要是本节相关算法的代码，贴一下KVD做图像去噪的，注意如果是彩色图，KSVD要在每个通道上都使用一次：\n\n```python\nimport numpy as np\nfrom sklearn import linear_model\n\ndef KSVD(Y, dict_size,\n         max_iter=20,\n         sparse_rate=0.1,\n         tolerance=1e-10):\n    assert (dict_size <= Y.shape[1])\n\n    def dict_update(y, d, x):\n        assert (d.shape[1] == x.shape[0])\n\n        for i in range(x.shape[0]):\n            index = np.where(np.abs(x[i, :]) > 1e-7)[0]\n\n            if len(index) == 0:\n                continue\n\n            d[:, i] = 0\n            r = (y - np.dot(d, x))[:, index]\n            u, s, v = np.linalg.svd(r, full_matrices=False)\n            d[:, i] = u[:, 0]\n            for j, k in enumerate(index):\n                x[i, k] = s[0] * v[0, j]\n        return d, x\n\n    # initialize dictionary\n    if dict_size > Y.shape[0]:\n        dic = Y[:, np.random.choice(Y.shape[1], dict_size, replace=False)]\n    else:\n        u, s, v = np.linalg.svd(Y)\n        dic = u[:, :dict_size]\n\n    print('dict shape:', dic.shape)\n\n    n_nonzero_coefs_each_code = int(sparse_rate * dict_size) if int(sparse_rate * dict_size) > 0 else 1\n    print(n_nonzero_coefs_each_code)\n    for i in range(max_iter):\n        x = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)\n        e = np.linalg.norm(Y - dic @ x)\n        if e < tolerance:\n            break\n        dict_update(Y, dic, x)\n\n    sparse_code = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)\n\n    return dic, sparse_code\n\n#读取自己的带噪声的图片\n    #imgR = img_with_noise[:,:,0]\n    #imgG = img_with_noise[:,:,1]\n    #imgB = img_with_noise[:,:,2]\n    #dictionaryR, sparsecodeR = KSVD(imgR,size,max_iter=200)\n    #dictionaryG, sparsecodeG = KSVD(imgG,size,max_iter=200)\n    #dictionaryB, sparsecodeB = KSVD(imgB,size,max_iter=200)\n    #img_reconstructedR=dictionaryR @ sparsecodeR\n    #img_reconstructedG=dictionaryG @ sparsecodeG\n    #img_reconstructedB=dictionaryB @ sparsecodeB\n    #img_reconstructed = np.stack((img_reconstructedR, img_reconstructedG, img_reconstructedB), axis=2)#去噪后的图片\n```\n\n由于KSVD的四个实验里的三个实验是无监督的，所以效果不太好，PSNR也只有个位数，目测KSVD应该用于有监督会比较好。\n<img src=\"子空间学习(8)-Sparse Representation\\Image_debluring.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. KSVD图像去模糊。</center>\n<img src=\"子空间学习(8)-Sparse Representation\\inpainting_yiding.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. KSVD图片重建。</center>\n\n\n# 总结\n\nKSVD采用有监督做应该会比较好，本次读的两篇论文偏综述，对算法实现细节的描述不多。\n\n\n\n ","slug":"子空间学习(8)-Sparse Representation","published":1,"updated":"2022-01-13T12:56:23.363Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxxo002l3oueaymc11he","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Sparse Representation For Computer Vision and</strong><br><strong>Pattern Recognition（2010 PIEEE）</strong>和<strong>Dictionaries for Sparse Representation Modeling（2010 PIEEE）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Sparse Coding（稀疏编码）和Dictionary Learning（字典学习）。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>过去几十年在图像处理方面取得的大部分进展可归因于图像内容的稀疏和冗余表示建模以及这些模型的应用。 数据的稀疏和冗余表示建模假设能够将信号描述为来自预先指定的字典的几个原子的线性组合。 虽然字典学习采取了不同的路线，但将字典附加到它应该提供的一组示例上。 在本报告中，我们尝试探索稀疏编码和字典学习的主要思想，并讨论它们之间的区别。 此外，我们在图像去噪、图像去模糊和图像超分辨率等多个应用中重现了 K-SVD 的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"字典学习\"><a href=\"#字典学习\" class=\"headerlink\" title=\"字典学习\"></a>字典学习</h1><p>字典学习是信号处理和机器学习的一个分支，旨在找到一个框架 $D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}] $（称为字典）。 在数学上，输入数据可以表示为：</p>\n<script type=\"math/tex; mode=display\">\nx=D\\alpha</script><p>其中$\\alpha$ 是一个系数向量。 请注意，稀疏编码中的 $\\alpha$ 是稀疏的。</p>\n<h1 id=\"稀疏编码\"><a href=\"#稀疏编码\" class=\"headerlink\" title=\"稀疏编码\"></a>稀疏编码</h1><p>稀疏编码是一种表示学习方法，旨在找到输入数据的稀疏表示 $X=[x_{1},\\cdots,x_{K}],x_{i}\\in \\mathcal{R}^{d }$ ，稀疏表示有很多元素，数据可以由元素本身的线性组合表示。 这些元素称为原子，它们组成一个字典$D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}]$。 在数学上，输入数据可以表示为：</p>\n<script type=\"math/tex; mode=display\">\nx=D\\alpha \\tag{1}</script><p>其中$\\alpha$ 是稀疏系数向量。</p>\n<h2 id=\"l-0-和-l-1-范数的稀疏编码\"><a href=\"#l-0-和-l-1-范数的稀疏编码\" class=\"headerlink\" title=\"$l_{0}$和$l_{1}$范数的稀疏编码\"></a>$l_{0}$和$l_{1}$范数的稀疏编码</h2><p>基于 L0-norm 和 L1-norm 的目标函数是公式(2)和公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    (\\alpha_{0},e_{0})=\\arg \\min \\|\\alpha\\|_{0}+\\|e\\|_{0} \\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{2}</script><p>其中 $\\mathcal{l}^{0}$ 范数 $|\\cdot|$ 计算向量中非零的数量。 而$\\alpha=[0,\\cdots,0,\\alpha_{i}^{T},0,\\cdots,0]^{T}\\in \\mathcal{R}^{N}$是一个系数向量，除了与第 i 个类相关的条目外，其条目均为零。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\min \\|\\alpha\\|_{1}+\\|e\\|_{1}\\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{3}</script><p>其中$|\\alpha|_{1}=\\sum_{i}|\\alpha_{i}|$。</p>\n<p>对于数据 $x$，我们可以将 $x$ 表示为字典 $D$ 中原子的线性组合，如 $x=D\\alpha$。 当解决像公式(1)这样的稀疏编码问题时，我们将得到向量 $\\alpha$ 的许多解。 当我们添加 L0-norm 和 L1-norm 时，$\\alpha$ 将成为一个稀疏向量。 因此，我们可以稀疏地表示数据 $x$。</p>\n<h2 id=\"不同的稀疏编码的区别\"><a href=\"#不同的稀疏编码的区别\" class=\"headerlink\" title=\"不同的稀疏编码的区别\"></a>不同的稀疏编码的区别</h2><p>L0-norm 和 L1-norm 的主要区别在于目标函数的不同表示。 更具体地说，L0 范数计算一个向量的非零元素的总数（见公式(4)），而 L1 范数是空间中向量每个元素的大小之和，见公式(5)。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\|e\\|_{0}=\\sum_{1}^{K}x_{i}^{0}.\n\\end{equation}\\tag{4}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\|e\\|_{1}=\\sum_{1}^{K}x_{i}.\n\\end{equation}\\tag{5}</script><h1 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h1><p>论文中主要介绍了Image Reconstruction（图像重建），Image Deblurring（图像去噪，可能包含在前面的？），Superresolution（图像超分），Learning to Sense等。每种应用都有一些基本的目标函数和任务描述，这里我不多提了，可以更多地关注原文。</p>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>为了更直观地理解稀疏编码和字典学习，K-SVD 被应用于以下应用：图像去噪、图像去模糊、图像修复和图像超分辨率。</p>\n<p>评价标准采用<u>Peak signal-to-noise ratio（PSNR）</u>，在数据集上进行实验后，我们可视化了 K-SVD 在图像去噪、图像去模糊、图像修复和图像超分辨率方面的性能。 其中，图像超分辨率是有监督训练的，图像去噪、图像去模糊和图像修复是无监督训练的。 进一步，结果如图1，图2。</p>\n<p>主要是本节相关算法的代码，贴一下KVD做图像去噪的，注意如果是彩色图，KSVD要在每个通道上都使用一次：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">KSVD</span>(<span class=\"params\">Y, dict_size,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">         max_iter=<span class=\"number\">20</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">         sparse_rate=<span class=\"number\">0.1</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">         tolerance=<span class=\"number\">1e-10</span></span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dict_size &lt;= Y.shape[<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">dict_update</span>(<span class=\"params\">y, d, x</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> (d.shape[<span class=\"number\">1</span>] == x.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(x.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            index = np.where(np.<span class=\"built_in\">abs</span>(x[i, :]) &gt; <span class=\"number\">1e-7</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(index) == <span class=\"number\">0</span>:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">            d[:, i] = <span class=\"number\">0</span></span><br><span class=\"line\">            r = (y - np.dot(d, x))[:, index]</span><br><span class=\"line\">            u, s, v = np.linalg.svd(r, full_matrices=<span class=\"literal\">False</span>)</span><br><span class=\"line\">            d[:, i] = u[:, <span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j, k <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(index):</span><br><span class=\"line\">                x[i, k] = s[<span class=\"number\">0</span>] * v[<span class=\"number\">0</span>, j]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> d, x</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># initialize dictionary</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> dict_size &gt; Y.shape[<span class=\"number\">0</span>]:</span><br><span class=\"line\">        dic = Y[:, np.random.choice(Y.shape[<span class=\"number\">1</span>], dict_size, replace=<span class=\"literal\">False</span>)]</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        u, s, v = np.linalg.svd(Y)</span><br><span class=\"line\">        dic = u[:, :dict_size]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;dict shape:&#x27;</span>, dic.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">    n_nonzero_coefs_each_code = <span class=\"built_in\">int</span>(sparse_rate * dict_size) <span class=\"keyword\">if</span> <span class=\"built_in\">int</span>(sparse_rate * dict_size) &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(n_nonzero_coefs_each_code)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(max_iter):</span><br><span class=\"line\">        x = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)</span><br><span class=\"line\">        e = np.linalg.norm(Y - dic @ x)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> e &lt; tolerance:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        dict_update(Y, dic, x)</span><br><span class=\"line\"></span><br><span class=\"line\">    sparse_code = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dic, sparse_code</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取自己的带噪声的图片</span></span><br><span class=\"line\">    <span class=\"comment\">#imgR = img_with_noise[:,:,0]</span></span><br><span class=\"line\">    <span class=\"comment\">#imgG = img_with_noise[:,:,1]</span></span><br><span class=\"line\">    <span class=\"comment\">#imgB = img_with_noise[:,:,2]</span></span><br><span class=\"line\">    <span class=\"comment\">#dictionaryR, sparsecodeR = KSVD(imgR,size,max_iter=200)</span></span><br><span class=\"line\">    <span class=\"comment\">#dictionaryG, sparsecodeG = KSVD(imgG,size,max_iter=200)</span></span><br><span class=\"line\">    <span class=\"comment\">#dictionaryB, sparsecodeB = KSVD(imgB,size,max_iter=200)</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructedR=dictionaryR @ sparsecodeR</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructedG=dictionaryG @ sparsecodeG</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructedB=dictionaryB @ sparsecodeB</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructed = np.stack((img_reconstructedR, img_reconstructedG, img_reconstructedB), axis=2)#去噪后的图片</span></span><br></pre></td></tr></table></figure>\n<p>由于KSVD的四个实验里的三个实验是无监督的，所以效果不太好，PSNR也只有个位数，目测KSVD应该用于有监督会比较好。<br><img src=\"/2022/01/18/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(8)-Sparse%20Representation/Image_debluring.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. KSVD图像去模糊。</center>\n<img src=\"/2022/01/18/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(8)-Sparse%20Representation/inpainting_yiding.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. KSVD图片重建。</center>\n\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>KSVD采用有监督做应该会比较好，本次读的两篇论文偏综述，对算法实现细节的描述不多。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Sparse Representation For Computer Vision and</strong><br><strong>Pattern Recognition（2010 PIEEE）</strong>和<strong>Dictionaries for Sparse Representation Modeling（2010 PIEEE）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述Sparse Coding（稀疏编码）和Dictionary Learning（字典学习）。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>过去几十年在图像处理方面取得的大部分进展可归因于图像内容的稀疏和冗余表示建模以及这些模型的应用。 数据的稀疏和冗余表示建模假设能够将信号描述为来自预先指定的字典的几个原子的线性组合。 虽然字典学习采取了不同的路线，但将字典附加到它应该提供的一组示例上。 在本报告中，我们尝试探索稀疏编码和字典学习的主要思想，并讨论它们之间的区别。 此外，我们在图像去噪、图像去模糊和图像超分辨率等多个应用中重现了 K-SVD 的性能。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"字典学习\"><a href=\"#字典学习\" class=\"headerlink\" title=\"字典学习\"></a>字典学习</h1><p>字典学习是信号处理和机器学习的一个分支，旨在找到一个框架 $D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}] $（称为字典）。 在数学上，输入数据可以表示为：</p>\n<script type=\"math/tex; mode=display\">\nx=D\\alpha</script><p>其中$\\alpha$ 是一个系数向量。 请注意，稀疏编码中的 $\\alpha$ 是稀疏的。</p>\n<h1 id=\"稀疏编码\"><a href=\"#稀疏编码\" class=\"headerlink\" title=\"稀疏编码\"></a>稀疏编码</h1><p>稀疏编码是一种表示学习方法，旨在找到输入数据的稀疏表示 $X=[x_{1},\\cdots,x_{K}],x_{i}\\in \\mathcal{R}^{d }$ ，稀疏表示有很多元素，数据可以由元素本身的线性组合表示。 这些元素称为原子，它们组成一个字典$D\\in \\mathcal{R}^{d\\times n}：D=[d_{1},\\cdots,d_{n}]$。 在数学上，输入数据可以表示为：</p>\n<script type=\"math/tex; mode=display\">\nx=D\\alpha \\tag{1}</script><p>其中$\\alpha$ 是稀疏系数向量。</p>\n<h2 id=\"l-0-和-l-1-范数的稀疏编码\"><a href=\"#l-0-和-l-1-范数的稀疏编码\" class=\"headerlink\" title=\"$l_{0}$和$l_{1}$范数的稀疏编码\"></a>$l_{0}$和$l_{1}$范数的稀疏编码</h2><p>基于 L0-norm 和 L1-norm 的目标函数是公式(2)和公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    (\\alpha_{0},e_{0})=\\arg \\min \\|\\alpha\\|_{0}+\\|e\\|_{0} \\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{2}</script><p>其中 $\\mathcal{l}^{0}$ 范数 $|\\cdot|$ 计算向量中非零的数量。 而$\\alpha=[0,\\cdots,0,\\alpha_{i}^{T},0,\\cdots,0]^{T}\\in \\mathcal{R}^{N}$是一个系数向量，除了与第 i 个类相关的条目外，其条目均为零。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\min \\|\\alpha\\|_{1}+\\|e\\|_{1}\\ \\ subj \\ \\ x=D\\alpha+e,\n\\end{equation}\\tag{3}</script><p>其中$|\\alpha|_{1}=\\sum_{i}|\\alpha_{i}|$。</p>\n<p>对于数据 $x$，我们可以将 $x$ 表示为字典 $D$ 中原子的线性组合，如 $x=D\\alpha$。 当解决像公式(1)这样的稀疏编码问题时，我们将得到向量 $\\alpha$ 的许多解。 当我们添加 L0-norm 和 L1-norm 时，$\\alpha$ 将成为一个稀疏向量。 因此，我们可以稀疏地表示数据 $x$。</p>\n<h2 id=\"不同的稀疏编码的区别\"><a href=\"#不同的稀疏编码的区别\" class=\"headerlink\" title=\"不同的稀疏编码的区别\"></a>不同的稀疏编码的区别</h2><p>L0-norm 和 L1-norm 的主要区别在于目标函数的不同表示。 更具体地说，L0 范数计算一个向量的非零元素的总数（见公式(4)），而 L1 范数是空间中向量每个元素的大小之和，见公式(5)。</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\|e\\|_{0}=\\sum_{1}^{K}x_{i}^{0}.\n\\end{equation}\\tag{4}</script><script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\|e\\|_{1}=\\sum_{1}^{K}x_{i}.\n\\end{equation}\\tag{5}</script><h1 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h1><p>论文中主要介绍了Image Reconstruction（图像重建），Image Deblurring（图像去噪，可能包含在前面的？），Superresolution（图像超分），Learning to Sense等。每种应用都有一些基本的目标函数和任务描述，这里我不多提了，可以更多地关注原文。</p>\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>为了更直观地理解稀疏编码和字典学习，K-SVD 被应用于以下应用：图像去噪、图像去模糊、图像修复和图像超分辨率。</p>\n<p>评价标准采用<u>Peak signal-to-noise ratio（PSNR）</u>，在数据集上进行实验后，我们可视化了 K-SVD 在图像去噪、图像去模糊、图像修复和图像超分辨率方面的性能。 其中，图像超分辨率是有监督训练的，图像去噪、图像去模糊和图像修复是无监督训练的。 进一步，结果如图1，图2。</p>\n<p>主要是本节相关算法的代码，贴一下KVD做图像去噪的，注意如果是彩色图，KSVD要在每个通道上都使用一次：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> linear_model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">KSVD</span>(<span class=\"params\">Y, dict_size,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">         max_iter=<span class=\"number\">20</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">         sparse_rate=<span class=\"number\">0.1</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">         tolerance=<span class=\"number\">1e-10</span></span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">assert</span> (dict_size &lt;= Y.shape[<span class=\"number\">1</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">dict_update</span>(<span class=\"params\">y, d, x</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> (d.shape[<span class=\"number\">1</span>] == x.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(x.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            index = np.where(np.<span class=\"built_in\">abs</span>(x[i, :]) &gt; <span class=\"number\">1e-7</span>)[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">            <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(index) == <span class=\"number\">0</span>:</span><br><span class=\"line\">                <span class=\"keyword\">continue</span></span><br><span class=\"line\"></span><br><span class=\"line\">            d[:, i] = <span class=\"number\">0</span></span><br><span class=\"line\">            r = (y - np.dot(d, x))[:, index]</span><br><span class=\"line\">            u, s, v = np.linalg.svd(r, full_matrices=<span class=\"literal\">False</span>)</span><br><span class=\"line\">            d[:, i] = u[:, <span class=\"number\">0</span>]</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j, k <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(index):</span><br><span class=\"line\">                x[i, k] = s[<span class=\"number\">0</span>] * v[<span class=\"number\">0</span>, j]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> d, x</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># initialize dictionary</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> dict_size &gt; Y.shape[<span class=\"number\">0</span>]:</span><br><span class=\"line\">        dic = Y[:, np.random.choice(Y.shape[<span class=\"number\">1</span>], dict_size, replace=<span class=\"literal\">False</span>)]</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        u, s, v = np.linalg.svd(Y)</span><br><span class=\"line\">        dic = u[:, :dict_size]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;dict shape:&#x27;</span>, dic.shape)</span><br><span class=\"line\"></span><br><span class=\"line\">    n_nonzero_coefs_each_code = <span class=\"built_in\">int</span>(sparse_rate * dict_size) <span class=\"keyword\">if</span> <span class=\"built_in\">int</span>(sparse_rate * dict_size) &gt; <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"built_in\">print</span>(n_nonzero_coefs_each_code)</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(max_iter):</span><br><span class=\"line\">        x = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)</span><br><span class=\"line\">        e = np.linalg.norm(Y - dic @ x)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> e &lt; tolerance:</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        dict_update(Y, dic, x)</span><br><span class=\"line\"></span><br><span class=\"line\">    sparse_code = linear_model.orthogonal_mp(dic, Y, n_nonzero_coefs=n_nonzero_coefs_each_code)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dic, sparse_code</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取自己的带噪声的图片</span></span><br><span class=\"line\">    <span class=\"comment\">#imgR = img_with_noise[:,:,0]</span></span><br><span class=\"line\">    <span class=\"comment\">#imgG = img_with_noise[:,:,1]</span></span><br><span class=\"line\">    <span class=\"comment\">#imgB = img_with_noise[:,:,2]</span></span><br><span class=\"line\">    <span class=\"comment\">#dictionaryR, sparsecodeR = KSVD(imgR,size,max_iter=200)</span></span><br><span class=\"line\">    <span class=\"comment\">#dictionaryG, sparsecodeG = KSVD(imgG,size,max_iter=200)</span></span><br><span class=\"line\">    <span class=\"comment\">#dictionaryB, sparsecodeB = KSVD(imgB,size,max_iter=200)</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructedR=dictionaryR @ sparsecodeR</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructedG=dictionaryG @ sparsecodeG</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructedB=dictionaryB @ sparsecodeB</span></span><br><span class=\"line\">    <span class=\"comment\">#img_reconstructed = np.stack((img_reconstructedR, img_reconstructedG, img_reconstructedB), axis=2)#去噪后的图片</span></span><br></pre></td></tr></table></figure>\n<p>由于KSVD的四个实验里的三个实验是无监督的，所以效果不太好，PSNR也只有个位数，目测KSVD应该用于有监督会比较好。<br><img src=\"/2022/01/18/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(8)-Sparse%20Representation/Image_debluring.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. KSVD图像去模糊。</center>\n<img src=\"/2022/01/18/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(8)-Sparse%20Representation/inpainting_yiding.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. KSVD图片重建。</center>\n\n\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>KSVD采用有监督做应该会比较好，本次读的两篇论文偏综述，对算法实现细节的描述不多。</p>\n"},{"title":"子空间学习(9)-On Regularization and the Prior","catalog":true,"date":"2022-01-19T04:24:17.000Z","subtitle":"Subspace Learning-On Regularization and the Prior","top":16,"header-img":"/img/header_img/lml_bg.jpg","mathjax":true,"_content":"\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Sparse Representation For Computer Vision and**\n> **Pattern Recognition（2009 CVPR）**，**Robust subspace segmentation by low rank represnetation（2010 ICML）**和**L2graph（2016 TCYB）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述正则化中的一些先验。\n\n# 摘要：\n\n子空间聚类是传统聚类的扩展，旨在在数据集中的不同子空间中找到聚类。 通常在高维数据中，许多维度是不相关的，并且可以掩盖噪声数据中的现有聚类。 特征选择通过分析整个数据集去除不相关和冗余的维度。 在介绍子空间聚类算法之前，我们先探讨 L1-norm、L2-norm 和核范数。 此外，本报告对子空间聚类算法进行了调查，例如稀疏子空间聚类 (SSC)、低秩表示 (LRR) 和 L2graph。 然后，我们使用经验可扩展性和准确性测试比较了子空间聚类的三种主要方法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# On Regularization and the Prior\n\n## 从概率的角度解释$l_{1}$和$l_{2}$范数\n\n这里主要推导线性回归的概率解释，然后给出$l_{1}$和$l_{2}$范数在线性回归上的概率解释，只给证明：\n\n我们推导出线性回归的概率解释。 有两个假设：$\\epsilon$ 的下划线概率分布是一个高斯分布，我们可以在 $\\theta$ 上指定一个先验分布 $p(\\theta)$。\n\n让我们进一步假设 $y$ 可以分解为两个项，\n$$\ny=\\theta^{T}x+\\epsilon\n$$\n其中$\\epsilon$ 是解释噪声或未建模因子的误差项。如果$\\epsilon$ 的先验概率分布是一个高斯分布，那么我们将有\n$$\np(\\varepsilon)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp (\\frac{-(\\varepsilon)^{2}}{2 \\sigma^{2}}）。\n$$\n\n为了计算 $\\theta$ 或 $\\hat{\\theta}$ 的估计，我们使用最大似然估计，\n$$\n\\hat{\\theta}_{M L}=\\arg \\max _{\\theta} L(\\theta),\n$$\n其中 $L(\\theta) \\equiv p(y \\mid x ; \\theta)$ 是似然函数。然后我们有，\n$$\np(y \\mid x ; \\theta)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y-\\theta^{T} x\\right )^{2}}{2 \\sigma^{2}}\\right),\n$$\n似然函数将是，\n$$\nL(\\theta) \\equiv p(y \\mid x ; \\theta)=\\Pi_{i=1}^{N} p(y^{(i)} \\mid x^{(i)} ; \\theta）\n$$\n$$\n=\\Pi_{i=i}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y^{(i)}-\\theta ^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right),\n$$\n和对数似然$\\ell(\\theta)$，\n$$\n\\ell(\\theta) \\equiv \\log L(\\theta)=N \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{\\sigma^{2}} \\ frac{1}{2} \\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2} 。\n$$\n\n此外，我们可以很容易地看到最大化 $\\ell(\\theta)$ 等价于最小化\n$$\nJ(\\theta)=\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}，\n$$\n这给了我们熟悉的最小二乘成本函数。\n综上所述，在对误差项$\\varepsilon$ 的概率假设下，我们发现使用最小二乘回归模型求$\\hat{\\varepsilon}$ 等价于求$\\varepsilon$ 的最大似然估计。\n\n### $l_{2}$范数在线性回归上的概率解释\n\n给定一个数据集 $S=\\left\\{\\left(x^{(i)}, y^{(i)}\\right)_{i=1}^{N}\\right\\}$，我们打算根据当前观察找到最可能的 $\\theta$，即\n$$\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} p(\\theta \\mid S),\n$$\n其中 $p(\\theta \\mid S)$ 是后验概率分布，这样的估计量 $\\hat{\\theta}_{M A P}$ 也称为 $\\theta$ 的 MAP（最大后验）估计量。\n通过应用贝叶斯定理，我们可以得到\n$$\np(\\theta \\mid S) \\propto p(S \\mid \\theta) p(\\theta),\n$$\n所以最大化 $p(\\theta \\mid S)$ 等价于最大化 $p(S \\mid \\theta) p(\\theta)$。因此，我们会有\n$$\n\\hat{\\theta}_{MAP}=\\arg \\max _{\\theta} \\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{(i) }, \\theta\\right) p(\\theta) 。\n$$\n\n数据是从线性回归模型中提取的，因此 $p(S \\mid \\theta)$ 等于 $\\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{ (i)}\\right)$。如果我们假设$p(\\theta)$的概率分布是一个多元高斯分布，即$p(\\theta) \\sim N\\left(0, \\mathbf{I} \\sigma^{2} / \\lambda \\right)$，我们将有\n$$\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} Q(\\theta)=\\arg \\max _{\\theta} q(\\theta),\n$$\n$$\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\sqrt{\\frac{\\ lambda}{2 \\pi}} \\frac{1}{\\sigma} \\exp \\left(-\\frac{\\lambda \\theta^{T} \\theta}{2 \\sigma^{2}}\\right) \\ \\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}\n$$\n\n最大化 $q(\\theta)$ 等效于最小化成本函数\n$$\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\theta^{T} \\theta 。\n$$\n\n因此，优化问题变为，\n$$\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\theta^{T} \\theta,\n$$\n其中最后一项 $\\lambda \\theta^{T} \\theta=\\lambda\\|\\theta\\|^{2}$ 正是 $l_{2}$ 范数正则化项。\n\n### $l_{1}$范数在线性回归上的概率解释\n\n我们直接从拉普拉斯分布的最大后验估计推导出来，\n$$\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\prod_{j=1} ^{d}\\frac{1}{2b}exp(-\\frac{|\\theta_{i}|}{b}) \\\\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}\n$$\n\n最大化 $q(\\theta)$ 等效于最小化成本函数\n$$\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\sum_{j=1}^{d}|\\theta_{i}|。\n$$\n\n因此，优化问题变为，\n$$\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\|\\theta\\|,\n$$\n其中最后一项 $\\lambda \\|\\theta\\|=\\lambda \\sum_{j=1}^{d}|\\theta_{i}|$ 正是 $l_{1}$ 范数正则化项。\n\n# Sparse Subspace Clustering\n\n## Subspace Clustering\n\n原数据可以由多个子空间中的数据点表示，给定子空间集 $S=[s_{1},\\cdots,s_{m}]$ 中的数据点 $X=[x_{1},\\cdots,x_{n}]$，任务就是在多个子空间中找到最合适的子空间以及对应的数据点来表示原数据，由此：求子空间的个数$m$，它们的维数$D=[d_{1},\\cdot,d_{m}]$，每个子空间的基，以及数据的聚类，见公式(1)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        F=[f_{1},\\cdots,f_{n}]\\\\\n        f_{i}: \\ X\\rightarrow s_{i} \\\\ \n        f_{i}(X) \\ \\in \\ \\mathcal{R}^{d_{i}\\times n}.\n    \\end{gathered}\n\\end{equation}\\tag{1}\n$$\n\n## SSC\n\n稀疏子空间聚类的动机是直接使用位于子空间联合上的向量的稀疏表示将数据聚类到单独的子空间中。SSC的目标函数是：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        min \\|s\\|_{p}\\\\\n        \\text{s.t. } \\textbf{y}=As,\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $\\|s\\|_{p}$ 是 $s$ 的不同范数。 考虑一个向量 $x\\in \\mathcal{R}^{D}$，它可以表示为 $D$ 个向量 。 如果$\\{\\phi_{i}\\in \\mathcal{R}^{D}\\}^{D}_{i=1}$我们形成基矩阵 $\\Phi= [\\phi_{1},\\phi_{2},···,\\phi_{D}]$，我们可以将 $\\textbf{x}$ 写为\n$$\n\\boldsymbol{x}=\\sum_{i=1}^{D} s_{i} \\boldsymbol{\\psi}_{i}=\\Psi \\boldsymbol{s}，\n$$\n其中 $\\textbf{s}= [s_{1},s_{2}, . . . , s_{D}]$。 我们对 $i\\in \\{1,2,\\cdots ,m\\}$。 因此，\n$$\n\\textbf{y}=[y_{1},y_{2},\\cdots,y_{m}]^{T}=\\Phi \\textbf{x}=\\Phi \\Psi \\textbf{s}=A\\textbf{s},\n$$\n其中 $\\Phi=[\\phi_{1},\\phi_{2},\\cdots,\\phi_{m}]^{T}\\in \\mathcal{R}^{m\\times D}$ 称为测量矩阵。此外，SSC 还考虑了从线性或仿射子空间集合中提取的数据点被噪声污染的情况，带噪声的 SSC 的目标函数为公式(3)：\n$$\n\\begin{equation}\n    \\underset{Z}{\\arg \\min}\\|\\textbf{y}-A\\textbf{s}\\|^{2}+\\lambda \\|s\\|_{p}.\n\\end{equation}\\tag{3}\n$$\n\n# Low Rank Representation\n\n考虑 $\\mathcal{R}^{D}$ 中的一组数据向量 $X= [x_{1}, x_{2},\\cdots, x_{n}]$（每列是一个样本），每个样本可以用Dictionary中基的线性组合来表示 $A= [\\alpha_{1}, \\alpha_{2},···, \\alpha_{m}]$: $X=AZ$ ，其中 $Z= [z_{1}, z_{2},\\cdots, z_{n}]$ 是系数矩阵，每个 $z_{i}$ 是 $x_{i}$ 的表示。\n\nLRR 的目标函数是公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\min_{Z}\\|Z\\|_{*}\\\\\n        \\text{s.t. }X=AZ,\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $\\|\\cdot\\|_{*}$ 表示矩阵的核范数，即矩阵的奇异值之和，用于约束矩阵的低秩。对于稀疏数据，矩阵是低秩的，包含大量冗余信息。此信息可用于恢复数据和提取特征。矩阵 $X$ 的核范数定义为：\n$$\n\\begin{equation}\n    \\|X\\|_{*}=\\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right).\n\\end{equation}\\tag{5}\n$$\n根据上式，可以得出核范数等价于矩阵的特征值之和。考虑 X $X=U \\Sigma V^{T}$ 的特征值分解，可以得出以下结论：\n$$\n\\begin{aligned}\n    \\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right) &=\\operatorname{tr}\\left(\\sqrt{\\left(U \\Sigma V^{T}\\right)^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{T} U^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{2} V^{T}}\\right)\\left(\\Sigma^{T}=\\Sigma\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V^{T} V \\Sigma^{2}}\\right) \\\\\n    &=\\operatorname{tr}(\\Sigma).\n    \\end{aligned}\n$$\n\n# L2graph\n\n这篇文章主要是在谱聚类的基础上，使用$l_{2}$范数的特征来构建稀疏的相似矩阵。\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. L2graph算法流程。</center>\n<img src=\"子空间学习(9)-On Regularization and the Prior\\equation.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 相关公式。</center>\n\n# 实验结果\n\n为了更直观地理解这三种算法，展示一些实验结果，在如下两种数据集上做聚类评估。\n\n- MNIST：前 2k 个训练图像和前 2k 个测试图像。\n- 耶鲁数据库（$64\\times 64$）：包含 15 个人的 165 张 GIF 格式灰度图像，每个对象有 11 张图像。\n\n在DUT-OMRON数据集上做分割和去噪实验。\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\Acc.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 聚类效果评估。</center>\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\SSC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. SSC图像分割（二分类）。</center>\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\L2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. L2graph图像分割（二分类）。</center>\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\LRR.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4. LRR图像重建和图像分割。</center>\n代码太多了，我传一下L2graph的Python版代码，SSC和LRR的后续看github放一下吧，这两种算法github也能查到。\n\n```python\nimport numpy as np\nfrom sklearn.preprocessing import normalize\n\ndef Normalization(train_data):\n    norm_data = normalize(train_data, norm='l2', axis=1)\n    return norm_data\n\ndef ClusteringL2Graph(dat, lamda=1e2):\n    pos = 0\n    dat = dat.T\n    tmp = dat.T @ dat\n    if lamda == 0:\n        Proj_M = np.linalg.pinv(tmp)\n    else:\n        Proj_M = tmp + lamda * np.eye(tmp.shape[0])\n        Proj_M = np.linalg.inv(Proj_M)\n    Q = Proj_M @ dat.T\n    coef = []\n    for ii in range(0, dat.shape[1]):\n        stdOrthbasis = np.zeros((dat.shape[1], 1))\n        stdOrthbasis[ii] = 1\n        tmp1 = stdOrthbasis.T @ Q @ dat[:, ii]\n        tmp2 = np.linalg.pinv(stdOrthbasis.T @ Proj_M @ stdOrthbasis).ravel()\n        ci = Proj_M @ ((dat.T @ dat[:, ii]).reshape(dat.shape[1], 1) - (tmp1[0] * tmp2[0]) * stdOrthbasis)\n        coef.append(ci.tolist())\n    coef = np.asarray(coef).reshape(dat.shape[1], dat.shape[1]).T\n\n    # l2-norm\n    coef = coef - np.eye(coef.shape[0]) * coef\n    coef = Normalization(coef)\n    C = np.abs(coef) + np.abs(coef)\n    return C\n#test\n#C = ClusteringL2Graph(data)\n#clustering_L2=SpectralClustering(n_clusters=cluster, affinity='precomputed')\n#pred_label_L2=clustering_L2.fit_predict(C)\n```\n\n\n\n# 总结\n\n算法效果符合预期，文本理解可能还是不太深刻。\n\n\n\n ","source":"_posts/子空间学习(9)-On Regularization and the Prior.md","raw":"---\ntitle: 子空间学习(9)-On Regularization and the Prior\ncatalog: true\ndate: 2022-01-19 12:24:17\nsubtitle: Subspace Learning-On Regularization and the Prior\ntop: 16\nheader-img: /img/header_img/lml_bg.jpg\nmathjax: true\ntags:\n- Python\ncategories:\n- 子空间学习\n---\n\n> 子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：**Sparse Representation For Computer Vision and**\n> **Pattern Recognition（2009 CVPR）**，**Robust subspace segmentation by low rank represnetation（2010 ICML）**和**L2graph（2016 TCYB）**。基于此进行概念的梳理和思考，尝试从数学的角度去阐述正则化中的一些先验。\n\n# 摘要：\n\n子空间聚类是传统聚类的扩展，旨在在数据集中的不同子空间中找到聚类。 通常在高维数据中，许多维度是不相关的，并且可以掩盖噪声数据中的现有聚类。 特征选择通过分析整个数据集去除不相关和冗余的维度。 在介绍子空间聚类算法之前，我们先探讨 L1-norm、L2-norm 和核范数。 此外，本报告对子空间聚类算法进行了调查，例如稀疏子空间聚类 (SSC)、低秩表示 (LRR) 和 L2graph。 然后，我们使用经验可扩展性和准确性测试比较了子空间聚类的三种主要方法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。\n\n# On Regularization and the Prior\n\n## 从概率的角度解释$l_{1}$和$l_{2}$范数\n\n这里主要推导线性回归的概率解释，然后给出$l_{1}$和$l_{2}$范数在线性回归上的概率解释，只给证明：\n\n我们推导出线性回归的概率解释。 有两个假设：$\\epsilon$ 的下划线概率分布是一个高斯分布，我们可以在 $\\theta$ 上指定一个先验分布 $p(\\theta)$。\n\n让我们进一步假设 $y$ 可以分解为两个项，\n$$\ny=\\theta^{T}x+\\epsilon\n$$\n其中$\\epsilon$ 是解释噪声或未建模因子的误差项。如果$\\epsilon$ 的先验概率分布是一个高斯分布，那么我们将有\n$$\np(\\varepsilon)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp (\\frac{-(\\varepsilon)^{2}}{2 \\sigma^{2}}）。\n$$\n\n为了计算 $\\theta$ 或 $\\hat{\\theta}$ 的估计，我们使用最大似然估计，\n$$\n\\hat{\\theta}_{M L}=\\arg \\max _{\\theta} L(\\theta),\n$$\n其中 $L(\\theta) \\equiv p(y \\mid x ; \\theta)$ 是似然函数。然后我们有，\n$$\np(y \\mid x ; \\theta)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y-\\theta^{T} x\\right )^{2}}{2 \\sigma^{2}}\\right),\n$$\n似然函数将是，\n$$\nL(\\theta) \\equiv p(y \\mid x ; \\theta)=\\Pi_{i=1}^{N} p(y^{(i)} \\mid x^{(i)} ; \\theta）\n$$\n$$\n=\\Pi_{i=i}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y^{(i)}-\\theta ^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right),\n$$\n和对数似然$\\ell(\\theta)$，\n$$\n\\ell(\\theta) \\equiv \\log L(\\theta)=N \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{\\sigma^{2}} \\ frac{1}{2} \\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2} 。\n$$\n\n此外，我们可以很容易地看到最大化 $\\ell(\\theta)$ 等价于最小化\n$$\nJ(\\theta)=\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}，\n$$\n这给了我们熟悉的最小二乘成本函数。\n综上所述，在对误差项$\\varepsilon$ 的概率假设下，我们发现使用最小二乘回归模型求$\\hat{\\varepsilon}$ 等价于求$\\varepsilon$ 的最大似然估计。\n\n### $l_{2}$范数在线性回归上的概率解释\n\n给定一个数据集 $S=\\left\\{\\left(x^{(i)}, y^{(i)}\\right)_{i=1}^{N}\\right\\}$，我们打算根据当前观察找到最可能的 $\\theta$，即\n$$\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} p(\\theta \\mid S),\n$$\n其中 $p(\\theta \\mid S)$ 是后验概率分布，这样的估计量 $\\hat{\\theta}_{M A P}$ 也称为 $\\theta$ 的 MAP（最大后验）估计量。\n通过应用贝叶斯定理，我们可以得到\n$$\np(\\theta \\mid S) \\propto p(S \\mid \\theta) p(\\theta),\n$$\n所以最大化 $p(\\theta \\mid S)$ 等价于最大化 $p(S \\mid \\theta) p(\\theta)$。因此，我们会有\n$$\n\\hat{\\theta}_{MAP}=\\arg \\max _{\\theta} \\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{(i) }, \\theta\\right) p(\\theta) 。\n$$\n\n数据是从线性回归模型中提取的，因此 $p(S \\mid \\theta)$ 等于 $\\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{ (i)}\\right)$。如果我们假设$p(\\theta)$的概率分布是一个多元高斯分布，即$p(\\theta) \\sim N\\left(0, \\mathbf{I} \\sigma^{2} / \\lambda \\right)$，我们将有\n$$\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} Q(\\theta)=\\arg \\max _{\\theta} q(\\theta),\n$$\n$$\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\sqrt{\\frac{\\ lambda}{2 \\pi}} \\frac{1}{\\sigma} \\exp \\left(-\\frac{\\lambda \\theta^{T} \\theta}{2 \\sigma^{2}}\\right) \\ \\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}\n$$\n\n最大化 $q(\\theta)$ 等效于最小化成本函数\n$$\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\theta^{T} \\theta 。\n$$\n\n因此，优化问题变为，\n$$\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\theta^{T} \\theta,\n$$\n其中最后一项 $\\lambda \\theta^{T} \\theta=\\lambda\\|\\theta\\|^{2}$ 正是 $l_{2}$ 范数正则化项。\n\n### $l_{1}$范数在线性回归上的概率解释\n\n我们直接从拉普拉斯分布的最大后验估计推导出来，\n$$\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\prod_{j=1} ^{d}\\frac{1}{2b}exp(-\\frac{|\\theta_{i}|}{b}) \\\\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}\n$$\n\n最大化 $q(\\theta)$ 等效于最小化成本函数\n$$\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\sum_{j=1}^{d}|\\theta_{i}|。\n$$\n\n因此，优化问题变为，\n$$\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\|\\theta\\|,\n$$\n其中最后一项 $\\lambda \\|\\theta\\|=\\lambda \\sum_{j=1}^{d}|\\theta_{i}|$ 正是 $l_{1}$ 范数正则化项。\n\n# Sparse Subspace Clustering\n\n## Subspace Clustering\n\n原数据可以由多个子空间中的数据点表示，给定子空间集 $S=[s_{1},\\cdots,s_{m}]$ 中的数据点 $X=[x_{1},\\cdots,x_{n}]$，任务就是在多个子空间中找到最合适的子空间以及对应的数据点来表示原数据，由此：求子空间的个数$m$，它们的维数$D=[d_{1},\\cdot,d_{m}]$，每个子空间的基，以及数据的聚类，见公式(1)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        F=[f_{1},\\cdots,f_{n}]\\\\\n        f_{i}: \\ X\\rightarrow s_{i} \\\\ \n        f_{i}(X) \\ \\in \\ \\mathcal{R}^{d_{i}\\times n}.\n    \\end{gathered}\n\\end{equation}\\tag{1}\n$$\n\n## SSC\n\n稀疏子空间聚类的动机是直接使用位于子空间联合上的向量的稀疏表示将数据聚类到单独的子空间中。SSC的目标函数是：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        min \\|s\\|_{p}\\\\\n        \\text{s.t. } \\textbf{y}=As,\n    \\end{gathered}\n\\end{equation}\\tag{2}\n$$\n其中 $\\|s\\|_{p}$ 是 $s$ 的不同范数。 考虑一个向量 $x\\in \\mathcal{R}^{D}$，它可以表示为 $D$ 个向量 。 如果$\\{\\phi_{i}\\in \\mathcal{R}^{D}\\}^{D}_{i=1}$我们形成基矩阵 $\\Phi= [\\phi_{1},\\phi_{2},···,\\phi_{D}]$，我们可以将 $\\textbf{x}$ 写为\n$$\n\\boldsymbol{x}=\\sum_{i=1}^{D} s_{i} \\boldsymbol{\\psi}_{i}=\\Psi \\boldsymbol{s}，\n$$\n其中 $\\textbf{s}= [s_{1},s_{2}, . . . , s_{D}]$。 我们对 $i\\in \\{1,2,\\cdots ,m\\}$。 因此，\n$$\n\\textbf{y}=[y_{1},y_{2},\\cdots,y_{m}]^{T}=\\Phi \\textbf{x}=\\Phi \\Psi \\textbf{s}=A\\textbf{s},\n$$\n其中 $\\Phi=[\\phi_{1},\\phi_{2},\\cdots,\\phi_{m}]^{T}\\in \\mathcal{R}^{m\\times D}$ 称为测量矩阵。此外，SSC 还考虑了从线性或仿射子空间集合中提取的数据点被噪声污染的情况，带噪声的 SSC 的目标函数为公式(3)：\n$$\n\\begin{equation}\n    \\underset{Z}{\\arg \\min}\\|\\textbf{y}-A\\textbf{s}\\|^{2}+\\lambda \\|s\\|_{p}.\n\\end{equation}\\tag{3}\n$$\n\n# Low Rank Representation\n\n考虑 $\\mathcal{R}^{D}$ 中的一组数据向量 $X= [x_{1}, x_{2},\\cdots, x_{n}]$（每列是一个样本），每个样本可以用Dictionary中基的线性组合来表示 $A= [\\alpha_{1}, \\alpha_{2},···, \\alpha_{m}]$: $X=AZ$ ，其中 $Z= [z_{1}, z_{2},\\cdots, z_{n}]$ 是系数矩阵，每个 $z_{i}$ 是 $x_{i}$ 的表示。\n\nLRR 的目标函数是公式(4)：\n$$\n\\begin{equation}\n    \\begin{gathered}\n        \\min_{Z}\\|Z\\|_{*}\\\\\n        \\text{s.t. }X=AZ,\n    \\end{gathered}\n\\end{equation}\\tag{4}\n$$\n其中 $\\|\\cdot\\|_{*}$ 表示矩阵的核范数，即矩阵的奇异值之和，用于约束矩阵的低秩。对于稀疏数据，矩阵是低秩的，包含大量冗余信息。此信息可用于恢复数据和提取特征。矩阵 $X$ 的核范数定义为：\n$$\n\\begin{equation}\n    \\|X\\|_{*}=\\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right).\n\\end{equation}\\tag{5}\n$$\n根据上式，可以得出核范数等价于矩阵的特征值之和。考虑 X $X=U \\Sigma V^{T}$ 的特征值分解，可以得出以下结论：\n$$\n\\begin{aligned}\n    \\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right) &=\\operatorname{tr}\\left(\\sqrt{\\left(U \\Sigma V^{T}\\right)^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{T} U^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{2} V^{T}}\\right)\\left(\\Sigma^{T}=\\Sigma\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V^{T} V \\Sigma^{2}}\\right) \\\\\n    &=\\operatorname{tr}(\\Sigma).\n    \\end{aligned}\n$$\n\n# L2graph\n\n这篇文章主要是在谱聚类的基础上，使用$l_{2}$范数的特征来构建稀疏的相似矩阵。\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. L2graph算法流程。</center>\n<img src=\"子空间学习(9)-On Regularization and the Prior\\equation.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 相关公式。</center>\n\n# 实验结果\n\n为了更直观地理解这三种算法，展示一些实验结果，在如下两种数据集上做聚类评估。\n\n- MNIST：前 2k 个训练图像和前 2k 个测试图像。\n- 耶鲁数据库（$64\\times 64$）：包含 15 个人的 165 张 GIF 格式灰度图像，每个对象有 11 张图像。\n\n在DUT-OMRON数据集上做分割和去噪实验。\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\Acc.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 聚类效果评估。</center>\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\SSC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. SSC图像分割（二分类）。</center>\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\L2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. L2graph图像分割（二分类）。</center>\n\n<img src=\"子空间学习(9)-On Regularization and the Prior\\LRR.png\" alt=\"LLE-Val\" style=\"zoom:90%;\" />\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图4. LRR图像重建和图像分割。</center>\n代码太多了，我传一下L2graph的Python版代码，SSC和LRR的后续看github放一下吧，这两种算法github也能查到。\n\n```python\nimport numpy as np\nfrom sklearn.preprocessing import normalize\n\ndef Normalization(train_data):\n    norm_data = normalize(train_data, norm='l2', axis=1)\n    return norm_data\n\ndef ClusteringL2Graph(dat, lamda=1e2):\n    pos = 0\n    dat = dat.T\n    tmp = dat.T @ dat\n    if lamda == 0:\n        Proj_M = np.linalg.pinv(tmp)\n    else:\n        Proj_M = tmp + lamda * np.eye(tmp.shape[0])\n        Proj_M = np.linalg.inv(Proj_M)\n    Q = Proj_M @ dat.T\n    coef = []\n    for ii in range(0, dat.shape[1]):\n        stdOrthbasis = np.zeros((dat.shape[1], 1))\n        stdOrthbasis[ii] = 1\n        tmp1 = stdOrthbasis.T @ Q @ dat[:, ii]\n        tmp2 = np.linalg.pinv(stdOrthbasis.T @ Proj_M @ stdOrthbasis).ravel()\n        ci = Proj_M @ ((dat.T @ dat[:, ii]).reshape(dat.shape[1], 1) - (tmp1[0] * tmp2[0]) * stdOrthbasis)\n        coef.append(ci.tolist())\n    coef = np.asarray(coef).reshape(dat.shape[1], dat.shape[1]).T\n\n    # l2-norm\n    coef = coef - np.eye(coef.shape[0]) * coef\n    coef = Normalization(coef)\n    C = np.abs(coef) + np.abs(coef)\n    return C\n#test\n#C = ClusteringL2Graph(data)\n#clustering_L2=SpectralClustering(n_clusters=cluster, affinity='precomputed')\n#pred_label_L2=clustering_L2.fit_predict(C)\n```\n\n\n\n# 总结\n\n算法效果符合预期，文本理解可能还是不太深刻。\n\n\n\n ","slug":"子空间学习(9)-On Regularization and the Prior","published":1,"updated":"2022-01-13T12:56:28.949Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckyechxxo002n3ouea9sw4a3q","content":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Sparse Representation For Computer Vision and</strong><br><strong>Pattern Recognition（2009 CVPR）</strong>，<strong>Robust subspace segmentation by low rank represnetation（2010 ICML）</strong>和<strong>L2graph（2016 TCYB）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述正则化中的一些先验。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>子空间聚类是传统聚类的扩展，旨在在数据集中的不同子空间中找到聚类。 通常在高维数据中，许多维度是不相关的，并且可以掩盖噪声数据中的现有聚类。 特征选择通过分析整个数据集去除不相关和冗余的维度。 在介绍子空间聚类算法之前，我们先探讨 L1-norm、L2-norm 和核范数。 此外，本报告对子空间聚类算法进行了调查，例如稀疏子空间聚类 (SSC)、低秩表示 (LRR) 和 L2graph。 然后，我们使用经验可扩展性和准确性测试比较了子空间聚类的三种主要方法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"On-Regularization-and-the-Prior\"><a href=\"#On-Regularization-and-the-Prior\" class=\"headerlink\" title=\"On Regularization and the Prior\"></a>On Regularization and the Prior</h1><h2 id=\"从概率的角度解释-l-1-和-l-2-范数\"><a href=\"#从概率的角度解释-l-1-和-l-2-范数\" class=\"headerlink\" title=\"从概率的角度解释$l_{1}$和$l_{2}$范数\"></a>从概率的角度解释$l_{1}$和$l_{2}$范数</h2><p>这里主要推导线性回归的概率解释，然后给出$l_{1}$和$l_{2}$范数在线性回归上的概率解释，只给证明：</p>\n<p>我们推导出线性回归的概率解释。 有两个假设：$\\epsilon$ 的下划线概率分布是一个高斯分布，我们可以在 $\\theta$ 上指定一个先验分布 $p(\\theta)$。</p>\n<p>让我们进一步假设 $y$ 可以分解为两个项，</p>\n<script type=\"math/tex; mode=display\">\ny=\\theta^{T}x+\\epsilon</script><p>其中$\\epsilon$ 是解释噪声或未建模因子的误差项。如果$\\epsilon$ 的先验概率分布是一个高斯分布，那么我们将有</p>\n<script type=\"math/tex; mode=display\">\np(\\varepsilon)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp (\\frac{-(\\varepsilon)^{2}}{2 \\sigma^{2}}）。</script><p>为了计算 $\\theta$ 或 $\\hat{\\theta}$ 的估计，我们使用最大似然估计，</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{M L}=\\arg \\max _{\\theta} L(\\theta),</script><p>其中 $L(\\theta) \\equiv p(y \\mid x ; \\theta)$ 是似然函数。然后我们有，</p>\n<script type=\"math/tex; mode=display\">\np(y \\mid x ; \\theta)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y-\\theta^{T} x\\right )^{2}}{2 \\sigma^{2}}\\right),</script><p>似然函数将是，</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta) \\equiv p(y \\mid x ; \\theta)=\\Pi_{i=1}^{N} p(y^{(i)} \\mid x^{(i)} ; \\theta）</script><script type=\"math/tex; mode=display\">\n=\\Pi_{i=i}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y^{(i)}-\\theta ^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right),</script><p>和对数似然$\\ell(\\theta)$，</p>\n<script type=\"math/tex; mode=display\">\n\\ell(\\theta) \\equiv \\log L(\\theta)=N \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{\\sigma^{2}} \\ frac{1}{2} \\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2} 。</script><p>此外，我们可以很容易地看到最大化 $\\ell(\\theta)$ 等价于最小化</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}，</script><p>这给了我们熟悉的最小二乘成本函数。<br>综上所述，在对误差项$\\varepsilon$ 的概率假设下，我们发现使用最小二乘回归模型求$\\hat{\\varepsilon}$ 等价于求$\\varepsilon$ 的最大似然估计。</p>\n<h3 id=\"l-2-范数在线性回归上的概率解释\"><a href=\"#l-2-范数在线性回归上的概率解释\" class=\"headerlink\" title=\"$l_{2}$范数在线性回归上的概率解释\"></a>$l_{2}$范数在线性回归上的概率解释</h3><p>给定一个数据集 $S=\\left\\{\\left(x^{(i)}, y^{(i)}\\right)_{i=1}^{N}\\right\\}$，我们打算根据当前观察找到最可能的 $\\theta$，即</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} p(\\theta \\mid S),</script><p>其中 $p(\\theta \\mid S)$ 是后验概率分布，这样的估计量 $\\hat{\\theta}_{M A P}$ 也称为 $\\theta$ 的 MAP（最大后验）估计量。<br>通过应用贝叶斯定理，我们可以得到</p>\n<script type=\"math/tex; mode=display\">\np(\\theta \\mid S) \\propto p(S \\mid \\theta) p(\\theta),</script><p>所以最大化 $p(\\theta \\mid S)$ 等价于最大化 $p(S \\mid \\theta) p(\\theta)$。因此，我们会有</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MAP}=\\arg \\max _{\\theta} \\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{(i) }, \\theta\\right) p(\\theta) 。</script><p>数据是从线性回归模型中提取的，因此 $p(S \\mid \\theta)$ 等于 $\\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{ (i)}\\right)$。如果我们假设$p(\\theta)$的概率分布是一个多元高斯分布，即$p(\\theta) \\sim N\\left(0, \\mathbf{I} \\sigma^{2} / \\lambda \\right)$，我们将有</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} Q(\\theta)=\\arg \\max _{\\theta} q(\\theta),</script><script type=\"math/tex; mode=display\">\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\sqrt{\\frac{\\ lambda}{2 \\pi}} \\frac{1}{\\sigma} \\exp \\left(-\\frac{\\lambda \\theta^{T} \\theta}{2 \\sigma^{2}}\\right) \\ \\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}</script><p>最大化 $q(\\theta)$ 等效于最小化成本函数</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\theta^{T} \\theta 。</script><p>因此，优化问题变为，</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\theta^{T} \\theta,</script><p>其中最后一项 $\\lambda \\theta^{T} \\theta=\\lambda|\\theta|^{2}$ 正是 $l_{2}$ 范数正则化项。</p>\n<h3 id=\"l-1-范数在线性回归上的概率解释\"><a href=\"#l-1-范数在线性回归上的概率解释\" class=\"headerlink\" title=\"$l_{1}$范数在线性回归上的概率解释\"></a>$l_{1}$范数在线性回归上的概率解释</h3><p>我们直接从拉普拉斯分布的最大后验估计推导出来，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\prod_{j=1} ^{d}\\frac{1}{2b}exp(-\\frac{|\\theta_{i}|}{b}) \\\\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}</script><p>最大化 $q(\\theta)$ 等效于最小化成本函数</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\sum_{j=1}^{d}|\\theta_{i}|。</script><p>因此，优化问题变为，</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\|\\theta\\|,</script><p>其中最后一项 $\\lambda |\\theta|=\\lambda \\sum_{j=1}^{d}|\\theta_{i}|$ 正是 $l_{1}$ 范数正则化项。</p>\n<h1 id=\"Sparse-Subspace-Clustering\"><a href=\"#Sparse-Subspace-Clustering\" class=\"headerlink\" title=\"Sparse Subspace Clustering\"></a>Sparse Subspace Clustering</h1><h2 id=\"Subspace-Clustering\"><a href=\"#Subspace-Clustering\" class=\"headerlink\" title=\"Subspace Clustering\"></a>Subspace Clustering</h2><p>原数据可以由多个子空间中的数据点表示，给定子空间集 $S=[s_{1},\\cdots,s_{m}]$ 中的数据点 $X=[x_{1},\\cdots,x_{n}]$，任务就是在多个子空间中找到最合适的子空间以及对应的数据点来表示原数据，由此：求子空间的个数$m$，它们的维数$D=[d_{1},\\cdot,d_{m}]$，每个子空间的基，以及数据的聚类，见公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        F=[f_{1},\\cdots,f_{n}]\\\\\n        f_{i}: \\ X\\rightarrow s_{i} \\\\ \n        f_{i}(X) \\ \\in \\ \\mathcal{R}^{d_{i}\\times n}.\n    \\end{gathered}\n\\end{equation}\\tag{1}</script><h2 id=\"SSC\"><a href=\"#SSC\" class=\"headerlink\" title=\"SSC\"></a>SSC</h2><p>稀疏子空间聚类的动机是直接使用位于子空间联合上的向量的稀疏表示将数据聚类到单独的子空间中。SSC的目标函数是：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        min \\|s\\|_{p}\\\\\n        \\text{s.t. } \\textbf{y}=As,\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $|s|_{p}$ 是 $s$ 的不同范数。 考虑一个向量 $x\\in \\mathcal{R}^{D}$，它可以表示为 $D$ 个向量 。 如果$\\{\\phi_{i}\\in \\mathcal{R}^{D}\\}^{D}_{i=1}$我们形成基矩阵 $\\Phi= [\\phi_{1},\\phi_{2},···,\\phi_{D}]$，我们可以将 $\\textbf{x}$ 写为</p>\n<script type=\"math/tex; mode=display\">\n\\boldsymbol{x}=\\sum_{i=1}^{D} s_{i} \\boldsymbol{\\psi}_{i}=\\Psi \\boldsymbol{s}，</script><p>其中 $\\textbf{s}= [s_{1},s_{2}, . . . , s_{D}]$。 我们对 $i\\in \\{1,2,\\cdots ,m\\}$。 因此，</p>\n<script type=\"math/tex; mode=display\">\n\\textbf{y}=[y_{1},y_{2},\\cdots,y_{m}]^{T}=\\Phi \\textbf{x}=\\Phi \\Psi \\textbf{s}=A\\textbf{s},</script><p>其中 $\\Phi=[\\phi_{1},\\phi_{2},\\cdots,\\phi_{m}]^{T}\\in \\mathcal{R}^{m\\times D}$ 称为测量矩阵。此外，SSC 还考虑了从线性或仿射子空间集合中提取的数据点被噪声污染的情况，带噪声的 SSC 的目标函数为公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{Z}{\\arg \\min}\\|\\textbf{y}-A\\textbf{s}\\|^{2}+\\lambda \\|s\\|_{p}.\n\\end{equation}\\tag{3}</script><h1 id=\"Low-Rank-Representation\"><a href=\"#Low-Rank-Representation\" class=\"headerlink\" title=\"Low Rank Representation\"></a>Low Rank Representation</h1><p>考虑 $\\mathcal{R}^{D}$ 中的一组数据向量 $X= [x_{1}, x_{2},\\cdots, x_{n}]$（每列是一个样本），每个样本可以用Dictionary中基的线性组合来表示 $A= [\\alpha_{1}, \\alpha_{2},···, \\alpha_{m}]$: $X=AZ$ ，其中 $Z= [z_{1}, z_{2},\\cdots, z_{n}]$ 是系数矩阵，每个 $z_{i}$ 是 $x_{i}$ 的表示。</p>\n<p>LRR 的目标函数是公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\min_{Z}\\|Z\\|_{*}\\\\\n        \\text{s.t. }X=AZ,\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $|\\cdot|_{*}$ 表示矩阵的核范数，即矩阵的奇异值之和，用于约束矩阵的低秩。对于稀疏数据，矩阵是低秩的，包含大量冗余信息。此信息可用于恢复数据和提取特征。矩阵 $X$ 的核范数定义为：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\|X\\|_{*}=\\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right).\n\\end{equation}\\tag{5}</script><p>根据上式，可以得出核范数等价于矩阵的特征值之和。考虑 X $X=U \\Sigma V^{T}$ 的特征值分解，可以得出以下结论：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n    \\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right) &=\\operatorname{tr}\\left(\\sqrt{\\left(U \\Sigma V^{T}\\right)^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{T} U^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{2} V^{T}}\\right)\\left(\\Sigma^{T}=\\Sigma\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V^{T} V \\Sigma^{2}}\\right) \\\\\n    &=\\operatorname{tr}(\\Sigma).\n    \\end{aligned}</script><h1 id=\"L2graph\"><a href=\"#L2graph\" class=\"headerlink\" title=\"L2graph\"></a>L2graph</h1><p>这篇文章主要是在谱聚类的基础上，使用$l_{2}$范数的特征来构建稀疏的相似矩阵。</p>\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. L2graph算法流程。</center>\n<img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/equation.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 相关公式。</center>\n\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>为了更直观地理解这三种算法，展示一些实验结果，在如下两种数据集上做聚类评估。</p>\n<ul>\n<li>MNIST：前 2k 个训练图像和前 2k 个测试图像。</li>\n<li>耶鲁数据库（$64\\times 64$）：包含 15 个人的 165 张 GIF 格式灰度图像，每个对象有 11 张图像。</li>\n</ul>\n<p>在DUT-OMRON数据集上做分割和去噪实验。</p>\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/Acc.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 聚类效果评估。</center>\n\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/SSC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. SSC图像分割（二分类）。</center>\n\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/L2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. L2graph图像分割（二分类）。</center>\n\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/LRR.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图4. LRR图像重建和图像分割。</center><br>代码太多了，我传一下L2graph的Python版代码，SSC和LRR的后续看github放一下吧，这两种算法github也能查到。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> normalize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Normalization</span>(<span class=\"params\">train_data</span>):</span></span><br><span class=\"line\">    norm_data = normalize(train_data, norm=<span class=\"string\">&#x27;l2&#x27;</span>, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> norm_data</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ClusteringL2Graph</span>(<span class=\"params\">dat, lamda=<span class=\"number\">1e2</span></span>):</span></span><br><span class=\"line\">    pos = <span class=\"number\">0</span></span><br><span class=\"line\">    dat = dat.T</span><br><span class=\"line\">    tmp = dat.T @ dat</span><br><span class=\"line\">    <span class=\"keyword\">if</span> lamda == <span class=\"number\">0</span>:</span><br><span class=\"line\">        Proj_M = np.linalg.pinv(tmp)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        Proj_M = tmp + lamda * np.eye(tmp.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">        Proj_M = np.linalg.inv(Proj_M)</span><br><span class=\"line\">    Q = Proj_M @ dat.T</span><br><span class=\"line\">    coef = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ii <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, dat.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        stdOrthbasis = np.zeros((dat.shape[<span class=\"number\">1</span>], <span class=\"number\">1</span>))</span><br><span class=\"line\">        stdOrthbasis[ii] = <span class=\"number\">1</span></span><br><span class=\"line\">        tmp1 = stdOrthbasis.T @ Q @ dat[:, ii]</span><br><span class=\"line\">        tmp2 = np.linalg.pinv(stdOrthbasis.T @ Proj_M @ stdOrthbasis).ravel()</span><br><span class=\"line\">        ci = Proj_M @ ((dat.T @ dat[:, ii]).reshape(dat.shape[<span class=\"number\">1</span>], <span class=\"number\">1</span>) - (tmp1[<span class=\"number\">0</span>] * tmp2[<span class=\"number\">0</span>]) * stdOrthbasis)</span><br><span class=\"line\">        coef.append(ci.tolist())</span><br><span class=\"line\">    coef = np.asarray(coef).reshape(dat.shape[<span class=\"number\">1</span>], dat.shape[<span class=\"number\">1</span>]).T</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># l2-norm</span></span><br><span class=\"line\">    coef = coef - np.eye(coef.shape[<span class=\"number\">0</span>]) * coef</span><br><span class=\"line\">    coef = Normalization(coef)</span><br><span class=\"line\">    C = np.<span class=\"built_in\">abs</span>(coef) + np.<span class=\"built_in\">abs</span>(coef)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C</span><br><span class=\"line\"><span class=\"comment\">#test</span></span><br><span class=\"line\"><span class=\"comment\">#C = ClusteringL2Graph(data)</span></span><br><span class=\"line\"><span class=\"comment\">#clustering_L2=SpectralClustering(n_clusters=cluster, affinity=&#x27;precomputed&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\">#pred_label_L2=clustering_L2.fit_predict(C)</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>算法效果符合预期，文本理解可能还是不太深刻。</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>子空间学习系列主要讨论从PCA发表开始到2010年中，子空间学习相关论文。本文立足于论文：<strong>Sparse Representation For Computer Vision and</strong><br><strong>Pattern Recognition（2009 CVPR）</strong>，<strong>Robust subspace segmentation by low rank represnetation（2010 ICML）</strong>和<strong>L2graph（2016 TCYB）</strong>。基于此进行概念的梳理和思考，尝试从数学的角度去阐述正则化中的一些先验。</p>\n</blockquote>\n<h1 id=\"摘要：\"><a href=\"#摘要：\" class=\"headerlink\" title=\"摘要：\"></a>摘要：</h1><p>子空间聚类是传统聚类的扩展，旨在在数据集中的不同子空间中找到聚类。 通常在高维数据中，许多维度是不相关的，并且可以掩盖噪声数据中的现有聚类。 特征选择通过分析整个数据集去除不相关和冗余的维度。 在介绍子空间聚类算法之前，我们先探讨 L1-norm、L2-norm 和核范数。 此外，本报告对子空间聚类算法进行了调查，例如稀疏子空间聚类 (SSC)、低秩表示 (LRR) 和 L2graph。 然后，我们使用经验可扩展性和准确性测试比较了子空间聚类的三种主要方法。本文的解释会比较简略只提重点部分。需要注意的是本文有下划线的部分是一些需要了解的基础概念，由于篇幅，我就不在后面解释，望读者自行查阅。</p>\n<h1 id=\"On-Regularization-and-the-Prior\"><a href=\"#On-Regularization-and-the-Prior\" class=\"headerlink\" title=\"On Regularization and the Prior\"></a>On Regularization and the Prior</h1><h2 id=\"从概率的角度解释-l-1-和-l-2-范数\"><a href=\"#从概率的角度解释-l-1-和-l-2-范数\" class=\"headerlink\" title=\"从概率的角度解释$l_{1}$和$l_{2}$范数\"></a>从概率的角度解释$l_{1}$和$l_{2}$范数</h2><p>这里主要推导线性回归的概率解释，然后给出$l_{1}$和$l_{2}$范数在线性回归上的概率解释，只给证明：</p>\n<p>我们推导出线性回归的概率解释。 有两个假设：$\\epsilon$ 的下划线概率分布是一个高斯分布，我们可以在 $\\theta$ 上指定一个先验分布 $p(\\theta)$。</p>\n<p>让我们进一步假设 $y$ 可以分解为两个项，</p>\n<script type=\"math/tex; mode=display\">\ny=\\theta^{T}x+\\epsilon</script><p>其中$\\epsilon$ 是解释噪声或未建模因子的误差项。如果$\\epsilon$ 的先验概率分布是一个高斯分布，那么我们将有</p>\n<script type=\"math/tex; mode=display\">\np(\\varepsilon)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp (\\frac{-(\\varepsilon)^{2}}{2 \\sigma^{2}}）。</script><p>为了计算 $\\theta$ 或 $\\hat{\\theta}$ 的估计，我们使用最大似然估计，</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{M L}=\\arg \\max _{\\theta} L(\\theta),</script><p>其中 $L(\\theta) \\equiv p(y \\mid x ; \\theta)$ 是似然函数。然后我们有，</p>\n<script type=\"math/tex; mode=display\">\np(y \\mid x ; \\theta)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y-\\theta^{T} x\\right )^{2}}{2 \\sigma^{2}}\\right),</script><p>似然函数将是，</p>\n<script type=\"math/tex; mode=display\">\nL(\\theta) \\equiv p(y \\mid x ; \\theta)=\\Pi_{i=1}^{N} p(y^{(i)} \\mid x^{(i)} ; \\theta）</script><script type=\"math/tex; mode=display\">\n=\\Pi_{i=i}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y^{(i)}-\\theta ^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right),</script><p>和对数似然$\\ell(\\theta)$，</p>\n<script type=\"math/tex; mode=display\">\n\\ell(\\theta) \\equiv \\log L(\\theta)=N \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma}-\\frac{1}{\\sigma^{2}} \\ frac{1}{2} \\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2} 。</script><p>此外，我们可以很容易地看到最大化 $\\ell(\\theta)$ 等价于最小化</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}，</script><p>这给了我们熟悉的最小二乘成本函数。<br>综上所述，在对误差项$\\varepsilon$ 的概率假设下，我们发现使用最小二乘回归模型求$\\hat{\\varepsilon}$ 等价于求$\\varepsilon$ 的最大似然估计。</p>\n<h3 id=\"l-2-范数在线性回归上的概率解释\"><a href=\"#l-2-范数在线性回归上的概率解释\" class=\"headerlink\" title=\"$l_{2}$范数在线性回归上的概率解释\"></a>$l_{2}$范数在线性回归上的概率解释</h3><p>给定一个数据集 $S=\\left\\{\\left(x^{(i)}, y^{(i)}\\right)_{i=1}^{N}\\right\\}$，我们打算根据当前观察找到最可能的 $\\theta$，即</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} p(\\theta \\mid S),</script><p>其中 $p(\\theta \\mid S)$ 是后验概率分布，这样的估计量 $\\hat{\\theta}_{M A P}$ 也称为 $\\theta$ 的 MAP（最大后验）估计量。<br>通过应用贝叶斯定理，我们可以得到</p>\n<script type=\"math/tex; mode=display\">\np(\\theta \\mid S) \\propto p(S \\mid \\theta) p(\\theta),</script><p>所以最大化 $p(\\theta \\mid S)$ 等价于最大化 $p(S \\mid \\theta) p(\\theta)$。因此，我们会有</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MAP}=\\arg \\max _{\\theta} \\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{(i) }, \\theta\\right) p(\\theta) 。</script><p>数据是从线性回归模型中提取的，因此 $p(S \\mid \\theta)$ 等于 $\\prod_{i=1}^{N} p\\left(y^{(i)} \\mid x^{ (i)}\\right)$。如果我们假设$p(\\theta)$的概率分布是一个多元高斯分布，即$p(\\theta) \\sim N\\left(0, \\mathbf{I} \\sigma^{2} / \\lambda \\right)$，我们将有</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MA P}=\\arg \\max _{\\theta} Q(\\theta)=\\arg \\max _{\\theta} q(\\theta),</script><script type=\"math/tex; mode=display\">\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\sqrt{\\frac{\\ lambda}{2 \\pi}} \\frac{1}{\\sigma} \\exp \\left(-\\frac{\\lambda \\theta^{T} \\theta}{2 \\sigma^{2}}\\right) \\ \\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}</script><p>最大化 $q(\\theta)$ 等效于最小化成本函数</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\theta^{T} \\theta 。</script><p>因此，优化问题变为，</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\theta^{T} \\theta,</script><p>其中最后一项 $\\lambda \\theta^{T} \\theta=\\lambda|\\theta|^{2}$ 正是 $l_{2}$ 范数正则化项。</p>\n<h3 id=\"l-1-范数在线性回归上的概率解释\"><a href=\"#l-1-范数在线性回归上的概率解释\" class=\"headerlink\" title=\"$l_{1}$范数在线性回归上的概率解释\"></a>$l_{1}$范数在线性回归上的概率解释</h3><p>我们直接从拉普拉斯分布的最大后验估计推导出来，</p>\n<script type=\"math/tex; mode=display\">\n\\begin{gathered}\nQ(\\theta) \\equiv\\left(\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left(\\frac{-\\left(y ^{(i)}-\\theta^{T} x^{(i)}\\right)^{2}}{2 \\sigma^{2}}\\right)\\right) \\prod_{j=1} ^{d}\\frac{1}{2b}exp(-\\frac{|\\theta_{i}|}{b}) \\\\\nq(\\theta)=\\log (Q(\\theta))。\n\\end{gathered}</script><p>最大化 $q(\\theta)$ 等效于最小化成本函数</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta) \\equiv\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T} x^{(i)}\\right)^{ 2}\\right]+\\lambda \\sum_{j=1}^{d}|\\theta_{i}|。</script><p>因此，优化问题变为，</p>\n<script type=\"math/tex; mode=display\">\n\\hat{\\theta}_{MAP}=\\arg \\min _{\\theta}\\left[\\sum_{i=1}^{N}\\left(y^{(i)}-\\theta^{T } x^{(i)}\\right)^{2}\\right]+\\lambda \\|\\theta\\|,</script><p>其中最后一项 $\\lambda |\\theta|=\\lambda \\sum_{j=1}^{d}|\\theta_{i}|$ 正是 $l_{1}$ 范数正则化项。</p>\n<h1 id=\"Sparse-Subspace-Clustering\"><a href=\"#Sparse-Subspace-Clustering\" class=\"headerlink\" title=\"Sparse Subspace Clustering\"></a>Sparse Subspace Clustering</h1><h2 id=\"Subspace-Clustering\"><a href=\"#Subspace-Clustering\" class=\"headerlink\" title=\"Subspace Clustering\"></a>Subspace Clustering</h2><p>原数据可以由多个子空间中的数据点表示，给定子空间集 $S=[s_{1},\\cdots,s_{m}]$ 中的数据点 $X=[x_{1},\\cdots,x_{n}]$，任务就是在多个子空间中找到最合适的子空间以及对应的数据点来表示原数据，由此：求子空间的个数$m$，它们的维数$D=[d_{1},\\cdot,d_{m}]$，每个子空间的基，以及数据的聚类，见公式(1)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        F=[f_{1},\\cdots,f_{n}]\\\\\n        f_{i}: \\ X\\rightarrow s_{i} \\\\ \n        f_{i}(X) \\ \\in \\ \\mathcal{R}^{d_{i}\\times n}.\n    \\end{gathered}\n\\end{equation}\\tag{1}</script><h2 id=\"SSC\"><a href=\"#SSC\" class=\"headerlink\" title=\"SSC\"></a>SSC</h2><p>稀疏子空间聚类的动机是直接使用位于子空间联合上的向量的稀疏表示将数据聚类到单独的子空间中。SSC的目标函数是：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        min \\|s\\|_{p}\\\\\n        \\text{s.t. } \\textbf{y}=As,\n    \\end{gathered}\n\\end{equation}\\tag{2}</script><p>其中 $|s|_{p}$ 是 $s$ 的不同范数。 考虑一个向量 $x\\in \\mathcal{R}^{D}$，它可以表示为 $D$ 个向量 。 如果$\\{\\phi_{i}\\in \\mathcal{R}^{D}\\}^{D}_{i=1}$我们形成基矩阵 $\\Phi= [\\phi_{1},\\phi_{2},···,\\phi_{D}]$，我们可以将 $\\textbf{x}$ 写为</p>\n<script type=\"math/tex; mode=display\">\n\\boldsymbol{x}=\\sum_{i=1}^{D} s_{i} \\boldsymbol{\\psi}_{i}=\\Psi \\boldsymbol{s}，</script><p>其中 $\\textbf{s}= [s_{1},s_{2}, . . . , s_{D}]$。 我们对 $i\\in \\{1,2,\\cdots ,m\\}$。 因此，</p>\n<script type=\"math/tex; mode=display\">\n\\textbf{y}=[y_{1},y_{2},\\cdots,y_{m}]^{T}=\\Phi \\textbf{x}=\\Phi \\Psi \\textbf{s}=A\\textbf{s},</script><p>其中 $\\Phi=[\\phi_{1},\\phi_{2},\\cdots,\\phi_{m}]^{T}\\in \\mathcal{R}^{m\\times D}$ 称为测量矩阵。此外，SSC 还考虑了从线性或仿射子空间集合中提取的数据点被噪声污染的情况，带噪声的 SSC 的目标函数为公式(3)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\underset{Z}{\\arg \\min}\\|\\textbf{y}-A\\textbf{s}\\|^{2}+\\lambda \\|s\\|_{p}.\n\\end{equation}\\tag{3}</script><h1 id=\"Low-Rank-Representation\"><a href=\"#Low-Rank-Representation\" class=\"headerlink\" title=\"Low Rank Representation\"></a>Low Rank Representation</h1><p>考虑 $\\mathcal{R}^{D}$ 中的一组数据向量 $X= [x_{1}, x_{2},\\cdots, x_{n}]$（每列是一个样本），每个样本可以用Dictionary中基的线性组合来表示 $A= [\\alpha_{1}, \\alpha_{2},···, \\alpha_{m}]$: $X=AZ$ ，其中 $Z= [z_{1}, z_{2},\\cdots, z_{n}]$ 是系数矩阵，每个 $z_{i}$ 是 $x_{i}$ 的表示。</p>\n<p>LRR 的目标函数是公式(4)：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\begin{gathered}\n        \\min_{Z}\\|Z\\|_{*}\\\\\n        \\text{s.t. }X=AZ,\n    \\end{gathered}\n\\end{equation}\\tag{4}</script><p>其中 $|\\cdot|_{*}$ 表示矩阵的核范数，即矩阵的奇异值之和，用于约束矩阵的低秩。对于稀疏数据，矩阵是低秩的，包含大量冗余信息。此信息可用于恢复数据和提取特征。矩阵 $X$ 的核范数定义为：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n    \\|X\\|_{*}=\\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right).\n\\end{equation}\\tag{5}</script><p>根据上式，可以得出核范数等价于矩阵的特征值之和。考虑 X $X=U \\Sigma V^{T}$ 的特征值分解，可以得出以下结论：</p>\n<script type=\"math/tex; mode=display\">\n\\begin{aligned}\n    \\operatorname{tr}\\left(\\sqrt{X^{T} X}\\right) &=\\operatorname{tr}\\left(\\sqrt{\\left(U \\Sigma V^{T}\\right)^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{T} U^{T} U \\Sigma V^{T}}\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V \\Sigma^{2} V^{T}}\\right)\\left(\\Sigma^{T}=\\Sigma\\right) \\\\\n    &=\\operatorname{tr}\\left(\\sqrt{V^{T} V \\Sigma^{2}}\\right) \\\\\n    &=\\operatorname{tr}(\\Sigma).\n    \\end{aligned}</script><h1 id=\"L2graph\"><a href=\"#L2graph\" class=\"headerlink\" title=\"L2graph\"></a>L2graph</h1><p>这篇文章主要是在谱聚类的基础上，使用$l_{2}$范数的特征来构建稀疏的相似矩阵。</p>\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/algorithm.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. L2graph算法流程。</center>\n<img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/equation.png\" alt=\"LLE-Val\" style=\"zoom:90%;\">\n\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. 相关公式。</center>\n\n<h1 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h1><p>为了更直观地理解这三种算法，展示一些实验结果，在如下两种数据集上做聚类评估。</p>\n<ul>\n<li>MNIST：前 2k 个训练图像和前 2k 个测试图像。</li>\n<li>耶鲁数据库（$64\\times 64$）：包含 15 个人的 165 张 GIF 格式灰度图像，每个对象有 11 张图像。</li>\n</ul>\n<p>在DUT-OMRON数据集上做分割和去噪实验。</p>\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/Acc.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图1. 聚类效果评估。</center>\n\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/SSC.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图2. SSC图像分割（二分类）。</center>\n\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/L2.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<center style=\"color:#C0C0C0;text-decoration:underline\">图3. L2graph图像分割（二分类）。</center>\n\n<p><img src=\"/2022/01/19/%E5%AD%90%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0(9)-On%20Regularization%20and%20the%20Prior/LRR.png\" alt=\"LLE-Val\" style=\"zoom:90%;\"></p>\n<p><center style=\"color:#C0C0C0;text-decoration:underline\">图4. LRR图像重建和图像分割。</center><br>代码太多了，我传一下L2graph的Python版代码，SSC和LRR的后续看github放一下吧，这两种算法github也能查到。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.preprocessing <span class=\"keyword\">import</span> normalize</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Normalization</span>(<span class=\"params\">train_data</span>):</span></span><br><span class=\"line\">    norm_data = normalize(train_data, norm=<span class=\"string\">&#x27;l2&#x27;</span>, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> norm_data</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">ClusteringL2Graph</span>(<span class=\"params\">dat, lamda=<span class=\"number\">1e2</span></span>):</span></span><br><span class=\"line\">    pos = <span class=\"number\">0</span></span><br><span class=\"line\">    dat = dat.T</span><br><span class=\"line\">    tmp = dat.T @ dat</span><br><span class=\"line\">    <span class=\"keyword\">if</span> lamda == <span class=\"number\">0</span>:</span><br><span class=\"line\">        Proj_M = np.linalg.pinv(tmp)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        Proj_M = tmp + lamda * np.eye(tmp.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">        Proj_M = np.linalg.inv(Proj_M)</span><br><span class=\"line\">    Q = Proj_M @ dat.T</span><br><span class=\"line\">    coef = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> ii <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, dat.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        stdOrthbasis = np.zeros((dat.shape[<span class=\"number\">1</span>], <span class=\"number\">1</span>))</span><br><span class=\"line\">        stdOrthbasis[ii] = <span class=\"number\">1</span></span><br><span class=\"line\">        tmp1 = stdOrthbasis.T @ Q @ dat[:, ii]</span><br><span class=\"line\">        tmp2 = np.linalg.pinv(stdOrthbasis.T @ Proj_M @ stdOrthbasis).ravel()</span><br><span class=\"line\">        ci = Proj_M @ ((dat.T @ dat[:, ii]).reshape(dat.shape[<span class=\"number\">1</span>], <span class=\"number\">1</span>) - (tmp1[<span class=\"number\">0</span>] * tmp2[<span class=\"number\">0</span>]) * stdOrthbasis)</span><br><span class=\"line\">        coef.append(ci.tolist())</span><br><span class=\"line\">    coef = np.asarray(coef).reshape(dat.shape[<span class=\"number\">1</span>], dat.shape[<span class=\"number\">1</span>]).T</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># l2-norm</span></span><br><span class=\"line\">    coef = coef - np.eye(coef.shape[<span class=\"number\">0</span>]) * coef</span><br><span class=\"line\">    coef = Normalization(coef)</span><br><span class=\"line\">    C = np.<span class=\"built_in\">abs</span>(coef) + np.<span class=\"built_in\">abs</span>(coef)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> C</span><br><span class=\"line\"><span class=\"comment\">#test</span></span><br><span class=\"line\"><span class=\"comment\">#C = ClusteringL2Graph(data)</span></span><br><span class=\"line\"><span class=\"comment\">#clustering_L2=SpectralClustering(n_clusters=cluster, affinity=&#x27;precomputed&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\">#pred_label_L2=clustering_L2.fit_predict(C)</span></span><br></pre></td></tr></table></figure>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>算法效果符合预期，文本理解可能还是不太深刻。</p>\n"}],"PostAsset":[{"_id":"source/_posts/2020全国大学生数学建模比赛B题/1.jpg","slug":"1.jpg","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/1.png","slug":"1.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/10.png","slug":"10.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/11.png","slug":"11.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/2.png","slug":"2.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/3.png","slug":"3.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/4.png","slug":"4.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/5.png","slug":"5.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/6.png","slug":"6.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/7.png","slug":"7.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/8.png","slug":"8.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020全国大学生数学建模比赛B题/9.png","slug":"9.png","post":"ckyechxwk00013oue4napg7a0","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/0.png","slug":"0.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/1.png","slug":"1.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/10.png","slug":"10.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/11.png","slug":"11.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/12.png","slug":"12.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/13.png","slug":"13.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/1314.png","slug":"1314.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/14.png","slug":"14.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/15.png","slug":"15.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/16.png","slug":"16.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/1617.png","slug":"1617.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/17.png","slug":"17.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/18.png","slug":"18.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/19.png","slug":"19.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/2.png","slug":"2.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/20.png","slug":"20.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/21.png","slug":"21.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/22.png","slug":"22.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/23.png","slug":"23.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/24.png","slug":"24.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/25.png","slug":"25.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/26.png","slug":"26.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/3.png","slug":"3.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/4.png","slug":"4.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/5.png","slug":"5.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/6.png","slug":"6.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/7.png","slug":"7.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/8.png","slug":"8.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/2020年数学建模美赛A题/9.png","slug":"9.png","post":"ckyechxws00073oue6l8l4mbz","modified":0,"renderable":0},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/dark.png","slug":"dark.png","post":"ckyechxwt00093oue2u0t5fqh","modified":0,"renderable":0},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/home_posts_tag-true.png","slug":"home_posts_tag-true.png","post":"ckyechxwt00093oue2u0t5fqh","modified":0,"renderable":0},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/light.png","slug":"light.png","post":"ckyechxwt00093oue2u0t5fqh","modified":0,"renderable":0},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/livemylife-desktop.png","slug":"livemylife-desktop.png","post":"ckyechxwt00093oue2u0t5fqh","modified":0,"renderable":0},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/top.png","slug":"top.png","post":"ckyechxwt00093oue2u0t5fqh","modified":0,"renderable":0},{"_id":"source/_posts/Hexo-Theme-LiveMyLife/wave.png","slug":"wave.png","post":"ckyechxwt00093oue2u0t5fqh","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/1.png","slug":"1.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/10.png","slug":"10.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/11.png","slug":"11.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/12.png","slug":"12.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/13.png","slug":"13.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/14.png","slug":"14.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/15.png","slug":"15.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/16.png","slug":"16.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/17.png","slug":"17.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/18.png","slug":"18.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/19.png","slug":"19.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/2.png","slug":"2.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/20.png","slug":"20.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/3.png","slug":"3.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/4.png","slug":"4.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/5.png","slug":"5.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/6.png","slug":"6.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/7.png","slug":"7.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/8.png","slug":"8.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/关于使用Vercel和hexo搭建个人主页/9.png","slug":"9.png","post":"ckyechxwu000b3oueducyg18e","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/1.png","slug":"1.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/10.png","slug":"10.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/11.png","slug":"11.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/12.png","slug":"12.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/2.png","slug":"2.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/3.png","slug":"3.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/4.png","slug":"4.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/5.png","slug":"5.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/51.png","slug":"51.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/6.png","slug":"6.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/7.png","slug":"7.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/8.png","slug":"8.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/基于Yolov4和Deepsort的智能交通场景应用/9.png","slug":"9.png","post":"ckyechxwv000e3oueey4m5olg","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(2)-LLE/k.png","slug":"k.png","post":"ckyechxww000f3oueeq6b4ehi","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(2)-LLE/LLE-Val.png","slug":"LLE-Val.png","post":"ckyechxww000f3oueeq6b4ehi","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/1.jpg","slug":"1.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/10.png","slug":"10.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/11.png","slug":"11.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/12.png","slug":"12.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/13.png","slug":"13.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/14.jpeg","slug":"14.jpeg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/15.jpg","slug":"15.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/16.jpg","slug":"16.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/17.jpg","slug":"17.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/18.jpg","slug":"18.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/19.jpg","slug":"19.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/2.png","slug":"2.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/20.jpg","slug":"20.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/21.jpg","slug":"21.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/24.jpg","slug":"24.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/25.jpg","slug":"25.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/26.jpg","slug":"26.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/27.jpg","slug":"27.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/28.jpg","slug":"28.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/29.jpg","slug":"29.jpg","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/3.png","slug":"3.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/4.png","slug":"4.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/5.png","slug":"5.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/6.png","slug":"6.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/7.png","slug":"7.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/8.png","slug":"8.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/基于改进Mobilenetv2的东北虎识别平台/9.png","slug":"9.png","post":"ckyechxwz000j3ouegyh635hz","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(1)-PCA/test_pca.png","slug":"test_pca.png","post":"ckyechxx1000k3oue9qpv8ycc","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(1)-PCA/train_pca.png","slug":"train_pca.png","post":"ckyechxx1000k3oue9qpv8ycc","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/com.png","slug":"com.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/isomap_swiss.png","slug":"isomap_swiss.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/le_swiss.png","slug":"le_swiss.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/lle_swiss.png","slug":"lle_swiss.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/mds_swiss.png","slug":"mds_swiss.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/parameter.png","slug":"parameter.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/pca_swiss.png","slug":"pca_swiss.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(3)-LE/swiss.png","slug":"swiss.png","post":"ckyechxx3000p3ouefgph2ojt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(10)-t-SNE/MNIST.png","slug":"MNIST.png","post":"ckyechxx2000o3oue4g8c2ic1","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(10)-t-SNE/MNIST2.png","slug":"MNIST2.png","post":"ckyechxx2000o3oue4g8c2ic1","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/acc.png","slug":"acc.png","post":"ckyechxx5000u3oue4oqogxnt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/com.png","slug":"com.png","post":"ckyechxx5000u3oue4oqogxnt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/eig.png","slug":"eig.png","post":"ckyechxx5000u3oue4oqogxnt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/face.png","slug":"face.png","post":"ckyechxx5000u3oue4oqogxnt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(4)-LPP&NPE/parameter.png","slug":"parameter.png","post":"ckyechxx5000u3oue4oqogxnt","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(5)-GE/com.png","slug":"com.png","post":"ckyechxx6000w3oue4jfqhf3z","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(6)-LDE/com.png","slug":"com.png","post":"ckyechxx600103ouegpyz9e9p","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(6)-LDE/parameter.png","slug":"parameter.png","post":"ckyechxx600103ouegpyz9e9p","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts/algorithm.png","slug":"algorithm.png","post":"ckyechxxn002k3oue5hxe3s4b","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts/NC.png","slug":"NC.png","post":"ckyechxxn002k3oue5hxe3s4b","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(7)-Spectral Clustering and Normalized Cuts/SC.png","slug":"SC.png","post":"ckyechxxn002k3oue5hxe3s4b","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(8)-Sparse Representation/Image_debluring.png","slug":"Image_debluring.png","post":"ckyechxxo002l3oueaymc11he","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(8)-Sparse Representation/inpainting_yiding.png","slug":"inpainting_yiding.png","post":"ckyechxxo002l3oueaymc11he","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/Acc.png","slug":"Acc.png","post":"ckyechxxo002n3ouea9sw4a3q","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/algorithm.png","slug":"algorithm.png","post":"ckyechxxo002n3ouea9sw4a3q","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/equation.png","slug":"equation.png","post":"ckyechxxo002n3ouea9sw4a3q","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/L2.png","slug":"L2.png","post":"ckyechxxo002n3ouea9sw4a3q","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/LRR.png","slug":"LRR.png","post":"ckyechxxo002n3ouea9sw4a3q","modified":0,"renderable":0},{"_id":"source/_posts/子空间学习(9)-On Regularization and the Prior/SSC.png","slug":"SSC.png","post":"ckyechxxo002n3ouea9sw4a3q","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ckyechxwk00013oue4napg7a0","category_id":"ckyechxwp00043ouegyd1br3x","_id":"ckyechxwx000g3ouebf8cgyut"},{"post_id":"ckyechxwn00033oue85nqa4v5","category_id":"ckyechxwv000c3oue39spbh4i","_id":"ckyechxx2000m3oue80w40tcn"},{"post_id":"ckyechxws00073oue6l8l4mbz","category_id":"ckyechxwp00043ouegyd1br3x","_id":"ckyechxx4000q3ouecx07hjpu"},{"post_id":"ckyechxwt00093oue2u0t5fqh","category_id":"ckyechxx2000l3oue561qaq9t","_id":"ckyechxx6000x3oueg2rzb67a"},{"post_id":"ckyechxwu000b3oueducyg18e","category_id":"ckyechxx4000r3ouedvhi734q","_id":"ckyechxx800153oue7n3lg9xv"},{"post_id":"ckyechxwv000e3oueey4m5olg","category_id":"ckyechxx4000r3ouedvhi734q","_id":"ckyechxx800193oue7zv13kja"},{"post_id":"ckyechxww000f3oueeq6b4ehi","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxx9001e3oue10g1cffb"},{"post_id":"ckyechxwz000j3ouegyh635hz","category_id":"ckyechxx8001a3ouecwa16mdp","_id":"ckyechxxa001k3oueauazb42r"},{"post_id":"ckyechxx1000k3oue9qpv8ycc","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxa001o3oue3cuf28zh"},{"post_id":"ckyechxx2000o3oue4g8c2ic1","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxd001t3oued07jeiuj"},{"post_id":"ckyechxx3000p3ouefgph2ojt","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxe001x3oueepvn1wp4"},{"post_id":"ckyechxx5000u3oue4oqogxnt","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxg00213oue62uv0zbr"},{"post_id":"ckyechxx6000w3oue4jfqhf3z","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxg00233ouegcdphbtq"},{"post_id":"ckyechxx600103ouegpyz9e9p","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxh00253oue2rap3fdg"},{"post_id":"ckyechxxn002k3oue5hxe3s4b","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxp002p3ouea99abbp6"},{"post_id":"ckyechxxo002l3oueaymc11he","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxp002r3oueegd89txa"},{"post_id":"ckyechxxo002n3ouea9sw4a3q","category_id":"ckyechxx800143oue0cbybkdc","_id":"ckyechxxp002s3oue96tbd0r5"}],"PostTag":[{"post_id":"ckyechxx2000o3oue4g8c2ic1","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxx4000s3oue0nwrh9jk"},{"post_id":"ckyechxwk00013oue4napg7a0","tag_id":"ckyechxwq00053oue3datbw6u","_id":"ckyechxx5000v3oue0fe6gl8b"},{"post_id":"ckyechxwk00013oue4napg7a0","tag_id":"ckyechxwv000d3oue1yxd07m2","_id":"ckyechxx6000y3ouect5w4dma"},{"post_id":"ckyechxwk00013oue4napg7a0","tag_id":"ckyechxwx000i3oueayzv9izw","_id":"ckyechxx700123oue7xuj1hcz"},{"post_id":"ckyechxwk00013oue4napg7a0","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxx700133oue020z1gla"},{"post_id":"ckyechxx3000p3ouefgph2ojt","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxx800173ouefi3m5w3r"},{"post_id":"ckyechxx5000u3oue4oqogxnt","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxx800183oue12zq1s94"},{"post_id":"ckyechxx6000w3oue4jfqhf3z","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxx9001c3oued4xoe6m5"},{"post_id":"ckyechxx600103ouegpyz9e9p","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxx9001d3ouef1zh0xl9"},{"post_id":"ckyechxwn00033oue85nqa4v5","tag_id":"ckyechxx4000t3oue9v2hfqrn","_id":"ckyechxx9001h3oue9314fp04"},{"post_id":"ckyechxwn00033oue85nqa4v5","tag_id":"ckyechxx700113oueglfnfe2e","_id":"ckyechxxa001i3oue599d8ujc"},{"post_id":"ckyechxws00073oue6l8l4mbz","tag_id":"ckyechxwv000d3oue1yxd07m2","_id":"ckyechxxa001m3oue5gce6a02"},{"post_id":"ckyechxws00073oue6l8l4mbz","tag_id":"ckyechxx8001b3oue57jg022p","_id":"ckyechxxa001p3oue6wom5w8w"},{"post_id":"ckyechxws00073oue6l8l4mbz","tag_id":"ckyechxwx000i3oueayzv9izw","_id":"ckyechxxd001r3oueemqva8lg"},{"post_id":"ckyechxwt00093oue2u0t5fqh","tag_id":"ckyechxxa001l3ouegzbpf09s","_id":"ckyechxxe001v3ouehulh06kt"},{"post_id":"ckyechxwt00093oue2u0t5fqh","tag_id":"ckyechxxb001q3ouebg1t6xgv","_id":"ckyechxxf001y3oue50d09vwa"},{"post_id":"ckyechxwu000b3oueducyg18e","tag_id":"ckyechxxd001u3oueag3dfi62","_id":"ckyechxxh00263oue1ur7fs0f"},{"post_id":"ckyechxwu000b3oueducyg18e","tag_id":"ckyechxxf001z3ouefr4vhxvu","_id":"ckyechxxh00273oueh62lbnco"},{"post_id":"ckyechxwu000b3oueducyg18e","tag_id":"ckyechxxa001l3ouegzbpf09s","_id":"ckyechxxh00293oueg2sq4iwv"},{"post_id":"ckyechxwv000e3oueey4m5olg","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxxh002b3ouefil4e0af"},{"post_id":"ckyechxwv000e3oueey4m5olg","tag_id":"ckyechxxh00283oue4nvs3hwc","_id":"ckyechxxi002c3oue1fdefwf4"},{"post_id":"ckyechxww000f3oueeq6b4ehi","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxxi002e3ouefmyw5yso"},{"post_id":"ckyechxwz000j3ouegyh635hz","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxxi002h3ouehdig604n"},{"post_id":"ckyechxwz000j3ouegyh635hz","tag_id":"ckyechxxi002f3oue6kwf47p8","_id":"ckyechxxi002i3oue4uwi91a4"},{"post_id":"ckyechxx1000k3oue9qpv8ycc","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxxi002j3oue3xv4fqpr"},{"post_id":"ckyechxxn002k3oue5hxe3s4b","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxxo002m3oue5ovob0cc"},{"post_id":"ckyechxxo002l3oueaymc11he","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxxp002o3oue7lkwbg54"},{"post_id":"ckyechxxo002n3ouea9sw4a3q","tag_id":"ckyechxx2000n3oue5zxohr45","_id":"ckyechxxp002q3oue8jrj4i7i"}],"Tag":[{"name":"C++","_id":"ckyechxwq00053oue3datbw6u"},{"name":"Matlab","_id":"ckyechxwv000d3oue1yxd07m2"},{"name":"Latex","_id":"ckyechxwx000i3oueayzv9izw"},{"name":"Python","_id":"ckyechxx2000n3oue5zxohr45"},{"name":"Premiere Pro CC","_id":"ckyechxx4000t3oue9v2hfqrn"},{"name":"Osmo Mobile3","_id":"ckyechxx700113oueglfnfe2e"},{"name":"Google earth","_id":"ckyechxx8001b3oue57jg022p"},{"name":"Hexo","_id":"ckyechxxa001l3ouegzbpf09s"},{"name":"Hexo-Theme-LiveMyLife","_id":"ckyechxxb001q3ouebg1t6xgv"},{"name":"Javascript","_id":"ckyechxxd001u3oueag3dfi62"},{"name":"Vercel","_id":"ckyechxxf001z3ouefr4vhxvu"},{"name":"Pyqt5","_id":"ckyechxxh00283oue4nvs3hwc"},{"name":"Django","_id":"ckyechxxi002f3oue6kwf47p8"}]}}